name,contributor_type,technical_evidence,text_and_data_mining,authorship_and_ownership_of_works_generated_by_ai,infringement_and_liability_regarding_ai,comments_and_suggestions
Bita Amani,Academic,"In addition to various areas of research and development in the creation of diverse and robust AI industries providing a variety of tools and applications, AI systems are used in education, legal practice, automated decision making and adjudication, in legal advocacy, including in facilitating research, generating legal memoranda, and in creating and/or preparing new content and documents for filing with various courts across Canada.Such use has led to cautionary tales (e.g. Mata v. Avianca, Inc., United States District Court Southern District of New York, 2023) in the absence of necessary due diligence by counsel as officers of the Court in cases where the GenAI has “hallucinated” content, including in fabricating case law citations referenced in documents for submission and filing with a court. As tools improve in accuracy, trustworthiness, and efficacy, that the public in general, and specific users in particular, will make use of technical advancements is both desirable and to be expected where the AI tool is reliable and fit for its stated purpose. GenAI may be used for other forms of content creation (e.g to recreate scenes in litigation), to pattern recognition, and more mundane applications editorial functions.That artificial intelligence would be put to a range of such uses has been recognized increasingly by courts with a growing number of practice directives (e.g. Supreme Court of Yukon, Provincial Court of Nova Scotia, and the Federal Court of Canada (FCC)). In December 2023, the Federal Court of Canada issued its Notice to the Parties and Profession, The Use of Artificial Intelligence in Court Proceedings (https://www.fct-cf.gc.ca/Content/assets/pdf/base/2023-12-20-notice-use-of-ai-in-court-proceedings.pdf), expressing the expectation by the FCC to be informed by the parties “if they have used artificial intelligence to create or generate new content in preparing a document filed with the Court. If any such content has been included in a document submitted to the Court by or on behalf of a party or a third-party participant (“intervener”), the first paragraph of the text in that document must disclose that AI has been used to create or generate that content.” Further, a Declaration for AI generated content by parties, counsel, and intervenors is required by the Court as per the Notice. The Court recognizes the challenges and opportunities, noting that “AI may offer substantial benefits in the preparation of documents” while also noting that there remain, however, “obligations to maintain the integrity of judicial proceedings, safeguard public confidence in the judicial system, and uphold the rule of law.”Use of GenAI has the potential to provide greater access to justice for self-represented parties. Still, so as not to be overly inclusive in its scope of application, the Notice only applies to content generated by AI and not e.g. “AI that only follows pre-set instructions, including programs such as system automation, voice recognition, or document editing.” Effectively, this is a disclosure requirement that differentiates GenAI from the productive creative and expressive contribution of a human (and indeed adopts a human in the loop principle to ensure accuracy and trustworthiness in the use of AI documents submitted to the Court). The Court while providing practice guidance also in effect recognizes the vital and growing importance of GenAI tools in the legal system and by different users. In this context, important distinction should be made as between predictive AI (used e.g. in sentencing, and predicting risk and recidivism see e.g. Bita Amani, ""AI and Equality by Design"" https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3734665) and generative AI, with attention for their respective potential risks for perpetuating biased and discriminatory harms based on training data and its limitations.","The IP Scholars Submission (2021) set out full expectation and recommendation regarding the importance of a TDM exception in Canada that is worth repeating for emphasis and adopting through incorporation by reference. Use of copyrighted works for their informational content for analytical purposes is critical in preserving and advancing the public interest. TDM- as argued- is used on existing data sets to find patterns and such patterns are of important significance, particularly in relation to public goods such as public health, in which the public has a critically vital public interest. Such use of copyrighted works are, as was set out in the IP Scholars 2021 submission non-expressive and non-consumptive copies (at p 8), is in any case consistent with the principle of de minimis non curat lex (as an insubstantial and immaterial use of a work in vast collection of works), and should not constitute prima facie infringement under the law. Moreover, any prima facie infringement would not amount to culpable infringement as it should be captured by fair dealing under the Copyright Act, as a user right, for the purposes of research and private study. This interpretation is consistent with law and policy objectives of the Act as both a balanced approach that preserves the public interest (as per the Supreme Court of Canada in Theberge (para 30)), coheres with the broad and inclusive treatment given by the Supreme Court to research, and is likely to be “fair” under the related 6-fact CCH analysis. For greater certainty, as recommended in the IP Scholars 2021 submission, the legislation should be amended to make the fair dealing exception open-ended by adding the words “such as” prior to the list of enumerated purposes (so that the list is illustrative rather than exhaustive) and TDM should be formally recognized as an allowable purpose under the fair dealing by adding it or “informational analysis” to the illustrative list of allowable purposes. The current submission here repeats the more comprehensive submission made in 2021 to this end.","Adopting the position of IP Scholars submission (2021), the law should continue to limit recognition of authorship to human authors.",N/A,N/A
Sofian Audry,Academic,"Je peux parler à l'échelle de ma propre recherche au sein de mon institution universitaire d'attache. Dans le cadre de mes recherches, nous n'utilisons pas de contenu protégé par les droits d'auteur pour l'entraînement de nos systèmes. Nous récoltons généralement des données brutes issues de différents types de senseurs pour des applications artistiques en temps réel. Ces données sont conservées sur des serveurs protégés et sont anonymes.","Un principe général devrait s'appliquer pour les FTD d'une certaine envergure à visée commerciale afin que les créateurs de contenu soient protégés, tout en permettant la FTD avec moins de régulation pour la recherche, la création artistique, l'open source et les petites entreprises.",,,"J'aimerais mettre en garde le gouvernement contre une idée que j'ai entendue trop souvent, comme quoi on devrait réguler les artistes qui utilisent les IA génératives. Les artistes sont déjà les principales victimes des IA génératives développées par les grandes entreprises en technologie (on assiste en ce moment au plus grand vol de propriété intellectuelle de tous les temps) mais il ne faut pas blâmer les artistes qui utilisent les IA génératives à des fins de création, lesquels poussent le medium si loin qu'ils arrivent à créer des oeuvres originales, un peu comme on l'a vu dans le passé dans le monde de la musique avec l'utilisation du ""sampling"" (échantillonage). Il faut réguler les grandes entreprises qui profitent d'un monopole sur les données afin d'extraire du pouvoir et de la richesse au détriment des créateurs, tout en permettant aux créateurs de faire leur travail, ce qui inclut l'utilisation de ces outils."
Joel Blit,Academic,N/A,N/A,N/A,N/A,"It is clear that in the age of AI we will have to rethink copyrights. The stakes are too high to leave courts to interpret questions around AI and copyright based on existing laws without more clear directives from policymakers. The question, then, is how (if at all) copyrights should be modified for the age of AI.As a Professor, I come at these questions from the point of view of what is best for society as a whole (and not what is best for one group or another). My expertise is in innovation policy, artificial intelligence, and intellectual property. I have advised policymakers at all levels on these topics.My personal view is that copyrights need to be weakened for the age of AI and this for four main reasons:1. Rewards should be commensurate with investments2. Maintaining freedom to create will get harder3. A strong copyrights regime could make AI developments grind to a halt4. Technological neutrality in building on previous ideasIn the interest of time I will only briefly explain each of these. I would be happy to discuss these in more detail.1. Rewards should be commensurate with investmentsPatents and copyrights are temporary exclusive rights that reward inventors/creators for investing their time and money. However, society would be best off if the invention/content were made public from the beginning. The temporary nature of intellectual property rights is therefore a bargain between offering creators enough incentive to create and allowing society to benefit from the creations. This can be summarized as the utilitarian approach to intellectual property rights, and it is the approach that underlies most Western patent regimes.With AI, creating works will get much easier. Pictures, music, videos, or text can all be created in seconds, though typically the creator will work with GenAI interactively to create the content. Effectively, GenAI is a powerful tool that increases the efficiency with which creators can create content. Given that creators now need to spend much less time/money to create their content, a smaller reward (shorter or narrower copyrights) still provides sufficient incentive for the creator to create the content and society as a whole benefits from increased access to the content.2. Maintaining Freedom to Create will get HarderCreators have always stood on the shoulders of giants. Their creations are not made in a void but rather tend to be a recombination of previously existing content. The ideas expressed by writers are synthesized from ideas expressed by others, songs are influenced by previous music, etc. In a world of GenAI, where the creation of content is almost free, there is a real risk that the creative space will be colonized to such an extent that future creators will find it hard to create content that is distinct enough from everything that has come before so as not to infringe on the copyrights.This is probably best seen in the context of music. Recently, there have been a number of lawsuits claiming that a new song infringed on previous music because a certain element of the song was similar. If that is the bar (any similar element) and using GenAI millions of songs are created, it will be almost impossible for future artists to create music without infringing. If we interpret copyrights strongly it is just a matter of time before a music ""patent troll"" uses genAI to colonize the music space and sues future artists.Part of the solution is to ensure that content created by genAI is not copyrightable. But what if genAI created most of the song but a creator changed the beat? It will be very hard to draw the line between genAI created and human created. Like any other tool, people will use genAI to create things and it will be a joint effort. So we must ensure that content create by genAI is not copyrightable. But we must also ensure that copyrights only protect the exact song and do not cover any song that has an element that sounds similar. In other words, copyrights should be seen narrowly (they apply to that specific work, not to similar works).3. A strong copyrights regime could make AI developments grind to a haltCanada is lagging in innovation, productivity, and economic growth. Fortunately, AI presents an opportunity for our country to change the trajectory. But for that, we need to foster AI.Strong copyrights present a risk AI. The latest LLMs like GPT4 were trained on a significant fraction of all of the quality data available on the Internet. Without access to this data, they simply would not work. If the courts rule that the use of Internet data for training these models infringes on copyright the development of these models will grind to a halt (or will go underground, particularly in countries like China). Even if OpenAI wanted to pay for access to training data, there is no practical way that it could do so since ownership of the data is so diffuse. How do you negotiate with hundreds of thousands of individuals? How do you know what is and what is not copyright protected?4. Technological neutrality in building on previous ideasPeople have always been allowed to read essays and books, and recombine all of the ideas into their own book. Similarly, music artists have been allowed to listen to all the songs they want and recombine all of the musical elements into a new song. This is not dissimilar to what genAI does: it ingests lots of content and synthesizes new content.This begs the question of why people should be allowed to do it but not machines. In my view, all should be allowed to build on previous content to create new content as long as it is not an identical copy of previous content.Three main actionable recommendations come out of the previous discussion:1. Content created by, or ""mostly"" created by, machines should not be copyrightable2. In the age of AI, copyrights should be interpreted narrowly. They only cover the work that was created. Similar works should not be deemed to be infringing.3. The training of AI models on existing content should not be subject to copyright as long as the AI produces new content in the end.My apologies in advance for submitting such a brief and less than polished set of responses. I would be happy discuss any of these further. Please feel free to contact me."
Alissa Centivany and Kailin Rourke,Academic,"A NOTE ON TECHNICAL EVIDENCEAs the authors are independent experts and do not represent any organization, we are unable or ill-suited to provide responses to many of the technical questions posed. As is so often the case with LLMs and related “big data” systems, the ways these systems are deployed lacks transparency, are difficult to trace, and are not subject to reasonable notice and disclosure policies, and thus we can only assume that the data we generate through our work as a professor and student is being collected and used to train large language models. For example, Western University faculty and staff are provided with Microsoft Office (Microsoft 365) and Microsoft has major investments in OpenAI. We therefore speculate, without hard evidence (as evidence is obfuscated and withheld as a matter of course) that our data is being used without our specific knowledge or consent. In addition, some members of our community choose to use LLMs in the course of their work, either to produce or assist in the production of works or as a site of critical inquiry and research. In terms of the mitigation of risks, it is proceeding in an ad hoc, haphazard fashion. Individual instructors might set course-level policies regarding the use of generative AI, faculties might have their own policies, the University currently has no overarching policy that applies specifically to generative AI, but other policies likely provide some governance oversight, i.e. policies on academic integrity.","Clarity around copyright and TDM in Canada is critical. The following brief discussion aims to highlight what I believe to be the most salient factors to be considered in terms of proceeding with clarifying regulation.First, it is necessary to be careful and deliberate in terms of how we understand TDM. TDM cannot be clumped into a single monolithic category because, in practice, it actually consists of a number of distinct activities (and often distinct actors) that bear differently on any given copyright analysis. For example, the activity of “compiling a data set” may raise copyright concerns if code is written to scrape and copy protectible works and store the works in a database. Here, the creation and application of the scraping tool(s), the selling of the tool(s) to others, the scraping and copying of protected works, and the storage of those works in a database could all, separately and distinctly, create exposure to liability for copyright infringement. If a user subsequently queries the dataset to pull out key words or phrases, this might raise copyright-relevant concerns depending on various factors such as how much of the original texts are reproduced and for what purpose. Therefore, TDM should be understood as consisting of a series of distinct activities that may raise distinct copyright implications and we would all benefit from greater clarity about “which activities” are protected or exempted.Second, TDM not only consists of distinct copyright-relevant activities but often also involves distinct actors that may play a role in one part of the TDM “chain” but not other parts. To illustrate, an actor might create an application that scrapes and compiles data, or create an LLM that “trains” on that data, or create a user interface that enables third-parties to query the dataset, but the actor may not utilize or analyze the scraped data to produce new works or insights from it. Under existing law, it is TDM is often accomplished through collaboration or cooperation between distinct actors that might play different roles and, under existing copyright law, each of these actors’ exposure to liability for their part may be different (and unclear). We lack clear rules under existing law on how privity functions with regard to exemptions, rights, and defenses that typically favor end-users/creators of secondary works (e.g. fair dealing) might apply to intermediaries along the TDM chain. Thus, in clarifying the copyright implications of TDM, it is essential that Canada addresses questions of privity (whether intermediary actors that facilitate but do not directly engage in socially productive activities just discussed enjoy the exemptions, rights, and defenses users/creators might under the Act) and contributory or vicarious liability. It is my position that the socially productive use principle should govern how privity and vicarious liability might apply in the TDM context. In the case of emerging LLMs, I would argue that the nexus between creators/owners of the scraped datasets and query tools, i.e. ChatGPT, and users that might generate secondary works is too tenuous and ethically fraught to support claims of privity vis-à-vis fair dealing.Other jurisdictions have created TDM regulations on the basis of activity-type. For example, Japan permits TMD for data analysis, the UK and France allow it for non-commercial research, the EU permits it for scientific research by research orgs, and Singapore for computational data analysis. In the United States, its Copyright Act does not yet include specific TDM provisions, but case law seems to suggest that courts will consider whether or not a use is a “transformative” fair use. In terms of the aggregation of protected works into large datasets, U.S. case law arising from the mass digitization project undertaken by Google and various libraries is likely to provide the most relevant recent analog. In those cases, Google partnered with libraries to digitize their collections including, at least in the case of the University of Michigan library, millions of in-copyright works. The Authors’ Guild sued for infringement. The Second Circuit Court of Appeals held that digitizing print materials to facilitate search and discovery, and to support the provision of services for vision-impaired patrons, constituted non-infringing transformative uses. The actual mining activities (now made possible through HathiTrust’s research division for its (primarily academic members)) were not litigated and thus we do not know for certain how that Court would have ruled had TDM been at issue. While the copyright implications of TDM are still an open question under U.S. law, good arguments can be made that query’s made to HathiTrust’s corpus would also be exempt as a class of “non-consumptive and non-expressive uses”; users query the database to generate responses that they then interpret to form new insights and transformative secondary works under the supervision of HathiTrust research staff.The nature of TDM using HathiTrust is distinguishable from generative AI models in a number of key ways. First, the HathiTrust database was generated from lawfully obtained copies (the library’s print corpus) whereas we have no evidence that generative AI systems are comprised of lawfully obtained copies. Second, while TDM was not litigated in the HathiTrust case, the Second Circuit found that mass copying for purposes of facilitating search and discovery was a transformative fair use and this aligns with the kind of TDM activities HathiTrust supports. By contrast, generative AI systems produce outputs that are both consumptive (meant to be consumed or read just as the primary source was) and expressive. Third, HathiTrust is an organization that consists primarily of libraries and thus its mission, values, and culture are strongly aligned with research, education, and serving the public interest. Unlike libraries, which enjoy a special status in society that is also reflected in the Copyright Act, the firms creating generative AI systems are largely technology companies that are private, profit-driven entities whose interests and motives are quite different from libraries.Canada should clarify the copyright implications of TDM along the lines of what other jurisdictions have done, protecting TDM of protected works for “socially productive” purposes. Socially productive uses would include research, education, criticism, parody, non-consumptive and/or non-expressive uses, and uses that result in secondary works that serve a new and different function or purpose from the original one and are not a substitute for the original. [See Centivany, “Understanding Organizational Responses to Innovative Deviance: A Case Study of HathiTrust”, (2016) dissertation available in UMich Deepblue; Centivany, “Innovative Deviance: A Theoretical Framework Emerging at the Intersection of Copyright Law and Technological Change”, in Proceedings of the iConference (2015); Centivany “Contributory Transformative Use” (2017) manuscript on file with author.]Canada has an interest in supporting innovation and competition and greater clarity about both the activities and actors would promote those interests. However, it is also critical to note that the purpose of copyright law is not to support innovation (at least not in the dominant understand of innovation) or competition. Rather the aim of copyright law in Canada is to promote the creation and sharing of cultural works for the benefit of all and ensure that adequate incentives exist to foster creativity. It is doubtful that the outputs of generative AI systems satisfy the goals of the Act. Returning to the overarching purpose of the Act is always critical, but it is especially important when emerging technologies create policy vacuums, disequilibria, and instability. We should also be clear that not all innovation is socially productive. To the extent that generative AI is used to disintermediate workers in the cultural industries or intellectual sectors while monetizing data sets comprised entirely of unlawfully obtained works to facilitate the production of simulated creative outputs, it is not clear that this promotes the interests of the Copyright Act. Socially productive use, even where it might appear to transgress existing (and perhaps outdated) legal doctrine, can be a way for the Act to grow and adapt in light of emerging technologies while remaining faithful to the underlying purposes of the Act.","Most, if not all, jurisdictions condition authorship on “human-ness”. Under Canadian law, works require an author’s “skill and judgment” (meaning the use of one’s “knowledge, developed aptitude or practiced ability in producing the work” and one’s “capacity for discernment or ability to form an opinion or evaluating by comparing different possible options in producing the work”) and an exercise of “intellectual effort” in the “expression of ideas” (CCH). The government should clarify through an amendment to the Act that an “author” must be human.Questions might be raised as to whether the author of the LLM could be an author of the outputs produced through its use. The nexus between the author of the program or code, and the outputs of the AI, are too tenuous to justify copyright protection by proxy. The programmer does not met the just-stated requirements of authorship under the Act.Thus, the salient question here is whether or to what extent a generative AI-assisted human can obtain copyright protection for the AI outputs. This is a complex question that, in reality, should probably involve a case-by-case analysis akin to fair use or fair dealing inquiries. However, given that a primary object of the Act is to incentivize authors to create it is worth asking whether the limited monopoly afforded by copyright is the incentivizing factors for AI-assisted works, or rather whether the ease of use and inexpensiveness of generative AI is incentive enough. My position would be that copyright-related incentives are not necessary for AI-generated works and therefore they should not acquire protection. AI-assisted works would likely benefit from a fair dealing or fair use-like analysis, but these are costly and inefficient. Conclusions regarding authorship and ownership of AI-generated works should be guided by the overarching purpose of the Act. On balance, the outcome most consistent with the purpose of the Act and existing precedent is that works resulting from generative AI, absent sufficient human authorship, would enter the public domain.","Infringement and liability can arise in a few different ways regarding AI. First, it can result from scraping, copying, and other acts related to the creation of the dataset upon which the LLM or generative AI will train or operate. This issue was addressed in the previous discussion of TDM. Second, infringement can result from the outputs generated by the AI because, for example, they constitute unauthorized derivative works or are substantially similar to existing protected works. Third, if it is determined that the outputs of generative AI models may acquire copyright protection, should these works be treated the same as human-generated works for purposes of liability and infringement. As discussed in the previous section, consistent with other jurisdictions, copyright does not subsist in AI-generated works. For AI-assisted works, the question is more complex, but I conclude that, given the overarching purposes of the Act, the ease and efficiency of production using AI tools likely obviates the need for copyright-based incentives.With regard to whether AI outputs may constitute infringement works, either because they are unauthorized derivatives or because (using language from U.S. caselaw) they are substantially similar to protected works, the simple answer is “Yes”. Outputs generated by AI systems can infringe. Under fair dealing, research, private study, education, parody or satire, criticism or review, and news reporting may be exempt from liability for infringement if the factors articulated in the CCH test are also satisfied: the purpose, character, and amount of the dealing, alternatives to the dealing, nature of the work, and effect of the dealing on the work. (CCH v. LSUC (2004).The infringement analysis of AI-generated works would mirror the analysis had generative AI not been involved aside from the questions of contributory liability raised earlier in the TDM section. In other words, would the creator of the AI be contributorily liable for infringing outputs resulting from the queries of users? This is an open question, and we would look to other examples and case law to analogize and distinguish. For example, in the famous U.S. case Sony v. Universal, the court found the maker of the Betamax (a VCR-like device used for recording or “time-shifting” broadcast television shows) not liable because the device was capable of “substantial non-infringing uses”. The government should provide additional guidance on the extent to which the makers of generative AI systems can avail themselves of protection-through-privity or may be subject to vicarious liability.","This submission was prepared by Dr. Alissa Centivany, Assistant Professor at the Faculty of Information and Media Studies at the University of Western Ontario, and Ms. Kailin Rourke, student in the Master of Library and Information Science program at Western University. These comments reflect the views of the authors not Western University.As a general matter, we note that emerging technologies always pose challenges for existing legal regimes. From the printing press, to the player piano, to the VCR, to Napster, to ChatGPT, controversies are a normal, perhaps unavoidable, part of sociotechnical change. Technological change tends to be relatively fast-paced, forward-looking, and innovation-focused, while legal institutions and rules tend to change slowly, employing logics that are retrospective, bound to precedent, and (at least partially) concerned with preserving the legitimacy of the status quo. Presently, Generative AI systems are raising important, often complex questions regarding the nature of research and innovation, creativity and collaboration, expression and transformation, reliability and trust, and whether and how institutions critical to democracy such as the press, public education, elections, and parliament itself might be impacted or undermined. In light of the specific questions and interests outlined in ISED’s public consultation, the survey responses offered focus narrowly on the copyright implications of Generative AI systems which include concerns regarding authorship, ownership, infringement, attribution, consent, and fair dealing/use."
Carys Craig,Academic,"It is important to note that, in cataloguing the wide range of uses being made of AI systems in different fields, a distinction should be drawn between text and data mining (or what the INDU Copyright Act Review report called “informational analysis”) and generative AI. The public discourse is currently largely concerned with real and perceived risks presented by generative AI as a source of potential outputs that may compete with human-authored works, while the significant promises that may flow from informational analysis conducted through text and data mining seem to have been somewhat forgotten in the fray. By launching a second consultation focused on generative AI, there is a risk that the kind of text and data mining (TDM) that featured prominently in the previous consultation—and which motivated the INDU Committee to recommend the enactment of a copyright exception to expressly permit informational analysis—has been submerged by a wave of concerns (and something of a moral panic) about generative AI. In reviewing submissions in response to this question, then, the government should take clear note of the distinction between TDM (as a technologically facilitated process with a wide range of uses and applications) and generative AI (as a particular kind of machine-learning AI tool typically defined by the nature of its outputs). In addition to the training requirements and potential uses of generative AI, then, the vital role that TDM and informational analysis can play in research and the advancement of knowledge should remain at the forefront of any copyright policy response to AI. (See Sean M. Fiil-Flynn et al, “Legal reform to enhance global text and data mining research: Outdated copyright laws around the world hinder research”, 378(6623) SCIENCE 951-53 (2 December 2022). Whether in educational environments like the university or in the professional practice of law, it must be expected that people – students, educators, researchers, administrators, clerks, lawyers, judges, etc. – will use generative AI systems to assist them. As a technological tool, generative AI may be used in ways that enhance productivity, improve efficiency, elevate performance, equalize capacities, and advance inclusivity. It may also be used in ways that are unprofessional, unethical, antisocial, exclusionary, or that exacerbate inequalities.In legal research, for example, systems such as the Lexum AI tool on Canlii can be used to generate helpful summaries of cases and legislation in a manner that may improve understanding and ultimately advance access to justice. Chat-GPT may be used to efficiently generate, e.g., technical or formulaic legal writing, or even first drafts of documents or papers that will help stimulate ideas or assist with organizing information. Of course, Generative AI may also be misused as an ostensible research tool to produce, e.g., plausible sounding but “hallucinated” cases and citations that will mislead or misinform, or to generate important legal documents and decisions with insufficient (human) consideration, oversight, or developed expertise. It may be used without appropriate acknowledgement to produce outputs that effectively substitute for, e.g., scholarly writings or student assignments, in a manner that violates the letter or spirit of professional ethics and academic honesty.Generative AI is, after all, a general-purpose technology with potential uses in multiple spheres of activity. The value, appropriateness, and desirability of such uses will depend on the specific context, purpose, and effect. In law and socio-legal studies, AI systems may also be used to conduct important computational research and informational analysis. Osgoode Hall Law School’s Professor Sean Rehaag, for example, uses GPT-3 to extract data from online Federal Court dockets, enabling the identification of patterns in outcomes in thousands of cases. As Professor Rehaag writes, this project demonstrates “how machine learning can be used to pursue empirical legal research projects that would have been cost-prohibitive or technically challenging only a few years ago – and shows how technology…can…be used to scrutinize legal decision-making…” (See Sean Rehaag, “Luck of the Draw III: Using AI to Examine Decision-Making in Federal Court Stays of Removal (January 11, 2023). Refugee Law Lab Working Paper (11 January 2023), Osgoode Legal Studies Research Paper No. 4322881, https://ssrn.com/abstract=4322881.More broadly, as explained in the IP Scholars Submission (2021), the growing importance of TDM as a research method cannot be overstated. This is true across the full range of scholarly disciplines, as well as in journalism, education, civil society, and a wide range of commercial research. Unfortunately, copyright law may already be acting as a barrier to some such initiatives, having a chilling effect on research, journalism, and civil society projects.In legal education, legal practice, and academia – and, indeed, any field of activity — different AI use-cases present substantially different benefits and harms, many of which remain either anecdotal or speculative. It is therefore a mistake to generalize about AI uses or to extrapolate broad conclusions about the appropriate trajectory of AI technologies from particular use cases. The public interest in facilitating informational analysis in health research, for example (whether commercial or non-commercial) is very different from the public interest in facilitating the AI generation of graphic art. What we can do with these technologies now may be very different from what they enable us to do even a few years into the future. It would be premature and a mistake to anoint copyright law (which is concerned with encouraging the creation and dissemination of works of the arts and intellect (Théberge v Galerie d’Art du Petit Champlain Inc, 2002 SCC 34 (SCC)) with a central regulatory role in attempting to balance the harms and benefits of generative AI, specifically, or artificial intelligence technologies more broadly.","Given the vast volume of inputs required as training data for machine learning, copyright restrictions on the use of protected works place an enormous burden on AI research and development. There is currently a lack of clarity about the lawfulness of TDM projects in Canada. This uncertainty extends to core activities at each stage, from the compilation of large data sets to the technological processes involved in informational analysis and the training of AI models, as well as to any subsequent sharing or storage of data sets or models for, e.g., testing, replication, or transparency purposes. At any stage, the creation of digital reproductions of copyright protected works could present the risk of liability—and that risk could significantly chill AI research, development, and deployment. Unfortunately, this risk looms large in Canada even although digital copies used for training purposes will typically never reach a public audience. As explained in the IP Scholar's submission (2021), such “non-expressive” uses do not implicate the legitimate interests of copyright holders. Assembling datasets of digital copies is only the necessary first stage in the process of informational analysis whereby data is extracted from the works and tokenized, allowing models to be trained to identify and replicate patterns, frequencies, correlations, and structures. This is what enables generative AI to predict and output text, for example, that sounds plausible and appropriate. In this training process, the expressive work of authorship within a dataset is translated into statistics–the meaning is turned into math. The copyrightable work itself is typically not retained, while the kind of information extracted from the work is beyond the scope of copyright (which does not protect information, data, knowledge, ideas, styles, or commonplace elements). The digital copies assembled in training datasets are made for technical, incidental, and non-public purposes. Nonetheless, the copyright liability risk remains under letter of the current law and jurisprudence. The chilling effect of this uncertainty may be compounded by Canada’s statutory damages provisions since potential liability, calculated on a per copy basis, could be staggering.The IP Scholars’ Submission (2021) also explained why TDM would normally constitute fair dealing. Fair dealing in Canada is a user right, which “must not be interpreted restrictively.” (CCH [48]) Given the “large and liberal” interpretation to be accorded to fair dealing purposes, most TDM is likely to qualify as research or private study, meeting the first step in the fair dealing analysis (SOCAN v Bell [2012] SCC 36 [15]-[30]) Many uses made for machine-learning purposes are also likely to be “fair” under the second step given the purpose, character, and effect of the dealing and the absence of realistic alternatives. A court would consider the training purpose of the use as well as the fact that the copy typically does not reach the public, constitutes only a minimal fraction of a massive data set, and so does not compromise the core economic or moral interests of the copyright owner nor substitute for the work of the author in the market. It would likely also recognize that obtaining permission for the millions of works typically contained in a dataset would be an impossibility such that there is no realistic alternative to the use (Alberta v Access, 2012 SCC 37, [31]-[32]). Restricting training data only to non-copyright protected materials would produce inferior and incomplete data sets, reducing the capabilities of the AI and its fitness for purpose. In most projects, the use of copyright protected materials is reasonably necessary to achieve the ultimate purpose (CCH, [57]) of the AI researcher/developer. Even if it were somehow possible for an AI developer to license for the vast quantity of materials required for training purposes, this would not be relevant to finding fair dealing (CCH, [70]). If the vast majority of TDM activities is likely lawful under Canada’s existing copyright law, there is a concerning bent in the questions posed in the questionnaire regarding licensing. The questions seem to assume that securing licenses to conduct TDM activities in Canada is either necessary or appropriate. If TDM is non-infringing, licenses are unnecessary. As the Supreme Court explained, “[i]f a copyright owner were allowed to license people to use its work and then point to a person’s decision not to obtain a licence as proof that his or her dealings were not fair, this would extend the scope of the owner’s monopoly over the use of his or her work” (CCH, [70]). Redundant licensing arrangements produce unnecessary transaction costs, obstacles, and exclusions (especially for smaller, less well-resourced players) while also producing windfall gains and costly rent-seeking behaviour amongst rightsholders and their representatives. They should be avoided and certainly not encouraged as part of a policy response. Clarity in the law may be an important goal but it is not everything. Any legislative amendment that clearly subjects AI researchers/developers to onerous rights’ clearance requirements, owner opt-ins or opt-outs, or rightsholder remuneration obligations will chill AI research and development in Canada. As noted in the IP Scholars’ 2021 submission, clear copyright obstacles to TDM would also negatively affect competition in the AI industry, incentivize secrecy, and disincentivize transparency, sharing, and testing. It could also reduce the quality of AI models and their outputs, obstructing the use of comprehensive, inclusive, high-quality datasets, thereby encouraging reliance on limited, incomplete, and exclusionary or biased data sets, with detrimental results.Rather, the Act should be amended to clarify that informational analysis or TDM does not infringe copyright. This could be by means of a new exception, an addition to the incidental inclusion or temporary reproduction for technological processes provisions (ss.30.70, 30.71), and/or as an addition to the enumerated purposes in the fair dealing provisions (s. 29 or a new s. 29.3). Opening fair dealing by adding the words “such as” would allow dealings for non-enumerated purposes to qualify, accommodating most TDM activities while avoiding the risks of technology-specific legislative amendments.Drawing distinctions between commercial and non-commercial uses and/or users is unnecessary and will create obstacles to TDM and new grounds for confusion about scope and meaning. Requiring lawful access as a condition is unnecessary and redundant (if the copy or the manner in which it was accessed was unlawful, liability would already attach to the infringing actor). Such a restriction on the availability of the exception could create new grounds for uncertainty (defining lawful access; determining which jurisdiction's law applies; assessing the scope and applicability of express and implied contract terms, the relevance of TPM circumvention, the degree of knowledge required by the use, whether lawful access must be to lawful sources, etc.) (See e.g. Thomas Margoni, “Saving Research: Lawful Access to Unlawful Sources”, Kluwer Blog, 22 Dec 2023) Under the current copyright and anti-circumvention law, a lawful access requirement could effectively foreclose the availability and effectiveness of a TDM exception.If general transparency or disclosure obligations are to be imposed on AI developers (and there may be good reasons for doing so), these should not be tied specifically to “copyright-protected content”. Any requirement to record and disclose every copyright work used in training (bearing in mind that this includes not only traditional works of authorship but any and all original texts, images, photographs, videos, transcripts, etc. scaped from the web and compiled in a vast data set of billions of items) as well as, presumably, its author, owner, current copyright status, etc. would be incredibly (indeed impossibly) onerous, impracticable, and ultimately unfeasible.The questionnaire asks what level of remuneration would be appropriate for the use of a given work in TDM activities; but this seems to assume that there is a right to remuneration. There is not. Nor is any right implicated for which compensation can be demanded. Moreover, in the context of vast data compilations, it makes little sense to ascribe (more than nominal) value to any particular work. And given that works are used only as sources of data, the value gained from their inclusion has no measurable relation to their market value as works of authorship. Frankly, it will be impossible under current technologies to calibrate (micro-)payments made under collective licensing arrangements to actual usage of individual authors’ works. Attempting to identify an appropriate level of remuneration for individual rightsholders is therefore a misguided exercise. A redistributive levy scheme or tax could, of course, be imposed upon providers of generative AI systems and used to finance social and cultural funds (See Martin Senftleben, Generative AI and Author Remuneration, 54 54(1) IIC 1535 (2023))), but this is a very different—and much more compelling—proposition than purporting to appropriately remunerate individual rightsholders for the use of individual works in massive AI training datasets. As for preferred approaches, I would point to Japan’s new exception (Article 30(4)) permitting non-expressive uses, as well as to Israel (Opinion on Uses of Copyrighted Materials for Machine Learning (Dec. 2022)). I would also encourage consideration of the US response to this issue. While the scope of fair use for TDM is currently before the US courts, there are strong arguments and precedent to support the conclusion that non-expressive copies made for TDM purposes are lawful in the US (See eg Matthew Sag, “Copyright Safety for Generative AI” 61 Houston L Rev 305 (2023).","As explained at length in the IP Scholars’ submission (2021), the basic copyright rules regarding the ownership and authorship of AI generated works are currently clear. AI generated works are not copyrightable works of original expression and so they belong in the public domain. In the absence of a human author who exercises more than trivial or mechanical skill and judgment in the expression of an original work, there is no existing basis on which to claim copyright.This conclusion is consistent with the Canadian legislation and jurisprudence on authorship, copyright ownership, and originality. Under the Act, all copyrightable works require a human author. This is clearly implied or assumed in sections 5 (conditions for subsistence); sections 6 and 9 (copyright term), sections 13 (ownership), section 14 (moral rights), etc. Unlike in the US work-for-hire doctrine, there is no circumstance in Canada in which authorship of a work is deemed to belong to someone or something other than a human author who is the de facto source of the original expression. Unlike in, e.g., the UK, there is no specific deeming provision regarding authorship of computer-generated work. In the absence of such a provision, most jurisdictions agree that the defining threshold of ""originality"" precludes an AI from being an original author—AI-generated works without a human author therefore do not attract copyright protection.Such a conclusion is also consistent with the purpose of copyright law (to maintain a balance between the encouragement and dissemination of works of the arts and intellect and a just reward for creators (CCH)) and the principle of technological neutrality (which works to maintain that balance as technology evolves (ESA v SOCAN, 2022 SCC 30). Protecting AI-generated works by deeming authorship as a legal fiction would undermine rather than advance the objectives of copyright law. There are many arguments to support this assertion, including the following (for brevity): the AI does not need incentives to create works; the creation of the AI code is already incentivized by the copyright that attaches to it as a literary work; no author is denied their just reward when AI works are refused protection; there is no apparent risk of underproduction of AI-generated works that would necessitate or justify extending copyright to ensure their protection/incentivization; and if copyright offers economic rewards to set off the “costs of expression” (Landes & Posner’s ‘Economic Analysis of Copyright Act (1989)), these costs are significantly reduced in the case of AI generated works, such that the need for an economic return is significantly lessened. Perhaps the most important reason, however, is the potential consequence of allowing copyright to attach to AI generated works. This would create a cultural environment in which vast volumes of privately owned AI works would quickly become an obstacle to human authorship and a liability risk for creators and users alike, particularly when the owners of such vast collections can also employ algorithms to identify any work bearing a ""substantial similarity"" to any AI-generated work. Such an incentive—and disincentive—structure would surely fly in the face of copyright’s public and cultural policy objectives. Copyright law should focus on encouraging the expressive act of (human) authorship and not on rewarding the automated generation of outputs. I have made more expansive arguments elsewhere. See, e,g, “The AI-Copyright Challenge: Tech-Neutrality, Authorship, and the Public Interest” in Ryan Abbott (ed), Research Handbook on AI & IP (2022); “AI and Copyright” in Martin-Bariteau & Scassa (eds), Artificial Intelligence and the Law in Canada (2021); “The Death of the AI Author” with Ian Kerr, 52(1) Ottawa L Rev 33-86 (2021).The IP Scholars (2021) agreed that AI generated works do not meet the requirements of copyright in Canada. It was also suggested, however, that amendments to the Copyright Act could further clarify and confirm this conclusion. Specifically, we recommended confirming in section 2 of the Act, that “author” means a human being/natural person and adding to section 5 a clear statement that “copyright shall not subsist in a work created without a human author.” These recommendations remain sound, and recent developments in generative AI technologies have only underscored their importance.While it is simple to assert that copyrightable works require a human author, there remains the complicated question of how much human participation in the creation of a work is necessary in order for that person to be an author. More specifically, at what point, if any, might the user of a generative AI tool have done what is required of them to be regarded in law as an author of the output (or at least of any original expression contained in the output)?Recent decisions of the US Copyright Office have suggested that works created with the assistance of generative AI may be registrable, but that copyright would protect only the original creative expression of the human author contained within the registered work. In the examination of “Zarya of the Dawn”, the Office approved protection for the text and arrangement of images but denied protection for individual images created using Midjourney (notwithstanding arguments on behalf of the applicant Kashtanova that it had taken multiple rounds of careful prompt composition “to get closer and closer to what they wanted to express"") (Registration # VAu001480196 2023) The Office found that there was too much “distance” between the Kashtanova’s inputs and the AI outputs, pointing to a lack of predictability and control. Subsequently, the Copyright Office confirmed (88 FR 16190) that works that contain AI generated material may be registrable if the applicant claims only the human-authored content in the work (for example, the original selection and arrangement of elements in a compilation work) and excludes any more than de minimis content that was AI generated. The work “Théâtre D’opéra Spatial” has since been refused registration for containing a more than a de minimis amount of AI-generated content that the applicant was unwilling to disclaim (Copyright Review Board Sept. 5, 2023).These examples present challenging questions for copyright law. It is important to resist an elevated vision of romantic authorship that imagines the creative process to be wholly independent and originary, and that therefore discounts the kind of iterative, selective process that might gradually shape and define a work with enough specificity to capture the author’s intended expression, even if relying on assistive technologies. There are often intervening actors and technologies involved in creative processes that limit predictability or control. (See Dan Burk, “Thirty-Six Views of Copyright Authorship by Jackson Pollick 58 Houston L Rev 263 (2020)). Photographers may not predict or control how light will be captured in a photograph, or indeed what transpires in front of the camera. Choreographers give detailed instructions to dancers but may lack direct control over the dance as performed and recorded (fixed). These photographers and choreographers are nevertheless considered authors of the resulting work. The difference, however, is that the original expressive elements in the works remain attributable to them, while the ostensibly expressive elements of an AI generated output may not be attributable (i.e. do no originate with) the AI user. The creation of prompts may amount to literary expression, but prompts may also be merely technical or functional instructions, unprotected due to the idea/expression or merger doctrine. The AI user’s inputs may also be considered merely mechanical or trivial (and therefore unoriginal (CCH)). Even tweaks made directly to outputs may be merely editorial and so unoriginal or de minimus.Ultimately, however, it is conceivable that, in certain cases, an AI user could demonstrate sufficient skill and judgment in the expression of a specific work created using AI as an assistive technology to claim copyright in that work. Their copyright would, however, protect only those elements that constitute their original expression. Elements attributable to the machine would be beyond the scope of their right and free for others to use. In the case of compilation works, it may be simple to separate the author’s original selection and arrangement (copyrightable) from AI-generated components (uncopyrightable). In cases where authored and generated elements merge, this will be more challenging. While it may require careful dissection of works to identify protected elements in particular cases, this is nothing new. Indeed, this is how copyright always works (see Cinar (SCC)).These issues simply require the application of existing doctrine to new contexts and should therefore be left for the courts to work through. While registration is less central to Canada’s copyright system, CIPO would be well advised to follow the approach taken by the US Copyright Office. CIPO’s apparent acceptance of AI as a designated author for copyright registration purposes is contrary to the Copyright Act. The registration of Suryast (No. 1188619) names an AI App as co-author. If an AI cannot be an author, it cannot be a co-author. Nor can it have the kind of collaborative intent required for joint authorship, nor the capacity to consent to uses of the co-authored work. That copyright term is measured from the death of the last surviving author (s 9) is reason enough to reject the idea of AI-human joint authorship.While recognizing the evolving conceptual, practical, evidentiary and doctrinal challenges presented by generative AI, it should be clear that the proposed approach here remains as stated above and in the IP Scholars 2021 submissions: AI itself cannot be an author; and works without human authors are not protected by copyright.","Qu.: Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright?I have suggested in previous responses that the activity or process of training an AI on copyright protected inputs typically does not and should not infringe copyright in those works. When considering copyright infringement by generative AI, the focus should not be on the inputs but rather on the outputs of the AI. After all, it in only in respect of the outputs that it might be argued that the generative AI is in some sense competing with human authors and artists — this is where the effect on the market for traditional human-authored works may be felt. The important question for copyright law is whether the AI outputs constitute substantial reproductions of any particular copyright protected works upon which the AI model was trained.AI-generated outputs implicate the copyright in pre-existing works when the outputs are substantially similar to specific copyrighted works that were present in the training data. The test is whether the ordinary reasonable observer would regard a given output as substantially similar to the copyrightable elements of a given input. The copyright doctrine of independent creation means that a work produced independently, without copying, will not infringe copyright in a pre-existing work even if it is identical. Where a substantial similarity between an AI output and a protected work is simply a matter of coincidence (i.e. the work—or a derivative thereof—was not in the training data) the similarity is no basis for liability. However, if an AI is trained on a dataset that includes a particular protected work and subsequently produces a substantially similar output, then it is hard to chalk the similarity up to coincidence: there is access to the protected work and so the necessary causal connection. Is the protected input the causa sine qua non of the output, but for which the particular output would not have been made? (See Gondos v. Hardy et al.; (1982), 38 O.R. (2d) 555 at para. 32 (Ont. H.C.J.)). The inscrutability of the algorithm’s operation may make it impossible to say. One could argue that, by virtue of the automated generative system, all of its outputs are effectively independently created. Alternatively, some may argue, the AI’s outputs are effectively derived from its inputs, and the combination of access plus substantial similarity is sufficient to establish prima facie infringement.The point is that questions of access, causality, and substantiality similarity are always essential to the determination of infringement liability in copyright law. In my view, there is nothing about this infringement inquiry in the context of generative AI that makes it fundamentally different or even more difficult. Indeed, it may be easier to establish on what sources an AI has been trained than it is to know what works may have found their way into an author’s subconscious mind (Gondos).It is important to stress that, in the absence of a “substantial similarity” between an output and an input in the training dataset, the outputs cannot be regarded as infringing reproductions of preexisting works. As Pamela Samuelson explains, “While it is true that outputs are, in some sense, ‘based upon’ the works on which foundation models were trained, this has never sufficed to support derivative work [infringement] claims; there must be substantial similarity in expressions to infringe that right.” (Samuelson, Fair Use Defenses, supra note 84, Part III-A-2)If an output does not substantially reproduce the protected expression of an input, qualitatively or quantitatively, it cannot be an infringing reproduction. If it does, however, then it may be found to infringe drawing simply upon established law and precedent. Problems of proof always abound in this area of law, but they are no more pronounced (and indeed may even be more readily be answered) in the case of generative AI than in other more traditional creative contexts.Qu.: Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Who is responsible for an AI's infringing output? Copyright infringement is a matter of strict liability and does not require knowledge; but it does require causation and, in line with common law principle of tortious liability, some degree of responsibility for, or control over, the unlawful act (CBS Songs Ltd. v. Amstrad Consumer Electronics plc., 2 All E.R. 484). In the US jurisprudence, this has been articulated as a requirement of some “element of volition” with respect to the infringing conduct. (Mala Chatterjee & Jeanne C. Fromer, “Minds, Machines, and the Law: The Case of Volition in Copyright Law” (2019) 119:7 Colum. L. Rev. 1887) A volitional act requirement coheres with the intuition that individuals should be held responsible only for that which was under their control. In the case of AI outputs, the allocation of liability should depend on who, if anyone, has the necessary degree of control over the production of an infringing copy. In some cases, this may be the AI programmer (who could have programmed the AI to discard outputs that are substantially similar to individual inputs); in others, it may be the AI user whose prompts and selections produced the infringing output. In some cases, there may be joint liability while, in others, it may be that no person had responsibility or control over the infringing act. Even if individuals are not responsible for doing the infringing act, it could be argued that they “authorize” it (s. 27(1)) where they “sanction, approve or countenance” the infringing act (CCH). Importantly, however, “a person does not authorize infringement by authorizing the mere use of equipment.” Moreover, “[c]ourts should presume that a person who authorizes an activity does so only so far as it is in accordance with the law.” (CCH, par 38) Given the unpredictable nature of an infringing output by the AI system, the programmer or deployer of an AI tool cannot be taken to have authorized the infringement merely by virtue of having provided the technological means by which an infringing reproduction was made. However, if they could have employed, e.g., technological means to prevent the production of outputs that are substantially similar to inputs in the training data, it may be possible to find sufficient control to ground authorization liability in certain instances.Arguably, the user of an AI system could be said to have authorized the making of infringing copies where their prompts demonstrate a sufficient degree of control over the AI’s outputs (regardless of their knowledge of the particular inputs on which the AI was trained). One might query whether authorizing a machine is the same as authorizing a person to infringe, but section 3 does not require the relevant infringing acts to be carried out by a person. It could be argued, however, that the user of generative AI is entitled to presume that the AI will not produce infringing content that is substantially similar to any particular work on which it was trained, at least in the absence of control over its generative processes. In the absence of a human actor with de facto control over the machine’s outputs, there may be questions about whether and where liability could attach. In such a case, can the AI itself be said to infringe? The Copyright Act states that “it is an infringement of copyright for any person to do…anything that…only the owner of the copyright has the right to do.” (s. 27(1)) It would seem that, under the current law, the AI itself cannot be an infringer. Applying a principal-agent analysis, however, the machine’s act qua “agent” could potentially produce liability for whichever party notionally fits the role of “principal”—most likely the person that creates or deploys the AI. Notably, the legal questions about infringement liability are not specific to copyright law. These questions remain to be worked out in every area from criminal to contract to negligence and tort. The matter may appear more academic than practical, as there is little economic reason to have liability attach at the moment that an output is generated and visible on the individual AI user’s computer screen. Economic concerns are more likely presented when such copies begin to circulate, undermining the market for the original. The exploitation of infringing copies produces its own form of secondary liability that could readily extend to those seeking to exploit infringing AI outputs. It can be secondary infringement for a person to sell, rent, or distribute copies of works and other subject matter where the person knows or should have known that the copies infringe copyright (s. 27(2)). This could capture the sale or distribution of both infringing copies within a training dataset, for example (if these are not protected by fair dealing) and, potentially, infringing copies produced by a generative AI. Strictly speaking, however, the latter will be “infringing copies” only if an autonomous AI is deemed capable of infringing copyright in the first place. Secondary infringement requires that, for liability to attach, a person knows or should have known that the copy “infringes copyright or would infringe copyright if it had been made in Canada by the person who made it.” Once solution here may be to amend s. 27(2) to include dealing with “a machine-generated copy that would infringe copyright if it had been made in Canada by an unauthorized person.” As suggested above, the kinds of questions about legal liability and responsibility presented by AI generated works are not unique to copyright law, however, and remain to be worked out across the board. By and large, existing copyright doctrine is well equipped to address and work through these questions as they arise.","The joint submission of the fourteen Canadian IP Scholars submitted in the previous Consultation on a Modern Copyright Framework for Artificial Intelligence and cited in the current Consultation Paper addressed many of the issues raised in this Questionnaire. Its authors, all experts in Copyright Law and disinterested commentators on the copyright issues presented by AI, were already familiar with the technological affordances of generative AI at the time of that prior consultation. While it is certainly true that the rapid proliferation and growing ubiquity of tools like Chat-GPT and Midjourney, for example, have brought greater public attention to the arrival of generative AI, developments between the prior consultation and this one should not displace the positions previously articulated in that joint submission. I would urge that this earlier collaborative submission, representing the combined expertise of many of Canada’s leading copyright scholars, should continue to inform policymakers deliberating more specifically on generative AI and copyright at this time.I would also like to express my concern about the way in which this second consultation paper and questionnaire have shifted baseline expectations and principles. The proliferation of generative AI tools has certainly raised awareness about the technology and its affordances. It has also brought out numerous self-interested actors and market incumbents who see the opportunity to reap windfalls from the arrival of AI through the vehicle of copyright law and its expansion. I would urge the government to carefully evaluate the claims, demands, and assumptions of lobbyists, industry actors, collective management organizations and their representatives whose efforts to cash in on or reap financial gain from TDM and generative AI are perfectly understandable but ought not to guide or dictate Canadian copyright policymaking. Copyright law serves a public interest in encouraging creativity and fostering a vibrant public domain — if reforms are to be made to the law in response to technological developments, this should be in an effort to ensure that copyright law continues to serve the public interest, maintaining an appropriate balance between incentives and access, and between the rights of owners and users as technology evolves. (See Craig, “The AI-Copyright Challenge: Tech-Neutrality, Authorship, and the Public Interest” in Ryan Abbott (ed), Research Handbook on Artificial Intelligence and Intellectual Property (2022)). While public consultation is commendable, voices representing the public interest may be few and far between, and risk being drowned out by more vociferous stakeholders and their economic interests. As such, I note with concern the way in which the consultation paper explains the two main objectives in the balance when considering possible copyright policy options: 1) To support innovation and investment in AI and other digital and emerging technologies in all sectors in Canada; 2) To support Canada's creative industries and preserve the incentive to create and invest provided by the rights set out in the Canadian Copyright Act (the Act), including to be adequately remunerated for the use of their works or other copyright subject matter. First, it is worth noting that, under the Act, rightholders have only limited exclusive rights to control reproduction, publication and performance of their works, subject to users’ rights and consistent with the public interest (York University v Access Copyright 2021 SCC 32 [91]-[94]). They do not have a per se right to “adequate remuneration” for ""use"" of their works. There is no such general guarantee within the Copyright Act. More importantly, the rights and interests in the balance, as stated, include only industries’ interests in incentives to innovate, create and invest, and rightsholders rights to adequate remuneration. Nowhere in this so-called “balance” is any mention made of the public side of the balance – where is the public’s interest in the dissemination of works, for example, or users’ rights to use works for research or private study, education, downstream creativity, etc.? In other words, the consultation paper’s articulation of the objectives to be balanced in no way reflects the copyright balance as repeatedly articulated by Canada’s Supreme Court, and nor does it fairly represent the interests of users and the public that are surely at stake.Novel as it may be, it should be acknowledged that generative AI is raising age-old questions about the socio-economic structures of cultural production, creative activity, and the public interest. Policy makers are now being called upon to protect creators from the extractive, exploitative, and even existential threat posed by generative AI. In the haste to act, however, there is a risk of running into what I think of as a ""copyright trap”: the mistake of assuming that strengthening and expanding copyright law is the best tool to support creators and cultural production (when in fact it may do more harm than good). One way into the copyright trap is to assume that everything that has value must be privately owned. This leads to the assumption that AI outputs should be protected by copyright, but also that anyone who reaps value from a work without permission has taken something to which they have no right. In fact, many valuable things belong in the public domain and many productive uses are free. The mere fact that AI developers and users gain some value from training AI on pre-existing works, for example, need not render that activity unlawful free-riding; copyright owners are not thereby being denied the original value or enjoyment of their work to which they were otherwise entitled.Another route into the copyright trap is assuming that copying is inherently wrong such that every unauthorized copy must be unlawful. The reality is that copyright’s focus on copies and copying is an ill fit for the digital age where copying is easy and virtually costless, and almost every consumptive activity in relation to a work involves at least background digital copying. The policy focus should shift away from the mere technicality of making copies to the dynamics of creation and distribution in the modern cultural marketplace. In the context of AI and TDM, a misplaced fixation on copying directs our attention to digital copies in training data sets that are never enjoyed or consumed by public audiences or recipients. Such copies are immaterial and their existence as “copies” ought not to be what shapes and confines the future development of artificial intelligence. Finally, we risk running headlong into the copyright trap when we assume that the allocation of private copyright control holds the answer to creators’ economic struggles, empowering authors and artists to secure fair returns and future livelihoods. The trope of the starving artist has been dusted off and leveraged by market incumbents with the arrival of each new paradigm-shifting technology since the printing press. Sadly the reality is that copyright ill-serves the artists and creators that it purports to save. The intermediaries demanding their fair treatment are often the ones taking ownership of copyright from creators and extracting the bulk of royalty payments before passing along any remaining benefits. In the fast-moving debate over generative AI, the same dynamics are already apparent. It will be important for the government to assess the benefits that will actually flow to authors for any, e.g., collective licensing model or opt-in/out structure that it may consider putting in place. It seems highly unlikely that, given the vast numbers of works involved in ultimately producing AI outputs with relatively little economic value, a pro-rata micro-share of license fees could possibly make a significant difference in the economic lives of artists and authors.There are many good reasons to be concerned about the rise of generative AI and the threats that it presents to human creatives, consumers, and the public domain. There are also good reasons to be wary of allowing copyright law to shape the future development of AI technologies. If we want to encourage the development of ethical and responsible AI, we ought to ask what kind of material and training data should be available to AI developers to help to advance that goal. Care should then be taken not to erect copyright barriers that could compound the risks of bias in AI and produce a lack of competition in the AI industry.Writing about copyright and the Internet in her book ‘Digital Copyright’, Jessica Litman wrote about “The Art of Making Copyright Laws”. She observed that “the threat and promise of the Internet has induced those of us who are copyright lawyers to an act of breathtaking hubris. We define a set of rules that we say ought to be the basic copyright rules of the road, and then we construe those rules to govern every single way that information coded in electrons can move from one computer to another” p30.As we contemplate the threat and promise of generative AI, I would caution Canada’s lawmakers away from similar copyright overreaching – copyright law is neither apposite nor equipped to govern the way that generative AI is developed, trained, deployed, or enjoyed. Insisting that it should do so, and imagining that it is up to the task, could do far more harm than good. As stated in the IP Scholars’ 2021 submission, ""copyright law should not create barriers to entry in the development and advancement of new innovations.” Whether it is restrictions to training or onerous permissions, payment or record-keeping requirements, such copyright barriers would impede AI-related research and development, effectively determining who can engage in it, and negatively impacting the quality and functionality of AI models that are poised to become a pervasive part of our professional, social, and cultural lives."
Michael Geist,Academic,N/A,"The inclusion of an explicit exception for text and data mining (sometimes referred to as informational analysis) within the Copyright Act’s fair dealing provisions is long overdue. The adoption of a specific text and data mining exception is consistent with the 2019 Copyright Act review, which extensively examined the issue and recommended:The evidence persuaded the Committee that facilitating the informational analysis of lawfully acquired copyrighted content could help Canada’s promising future in artificial intelligence become reality. The Committee therefore recommends:Recommendation 23That the Government of Canada introduce legislation to amend the Copyright Act to facilitate the use of a work or other subject-matter for the purpose of informational analysis.The federal government has invested millions to support research and commercialization of AI in the hopes of making it a world leader. However, the current state of Canadian copyright law undermines this investment by inhibiting innovation through the creation of legal uncertainty and high barriers faced by the very groups the investment aimed to attract.AI research works by making machines smart. Whether this is focused on automated translation, big data analytics, or new search capabilities, it is dependent on data being fed into the system. Machines learn by scanning, reading, listening, or viewing human created works. The better the inputs, the better the outputs and the more inputs there are, the likelihood that results are biased or inaccurate decreases.Canadian copyright law inhibits this because restrictive rules limit the data sets that can be used for machine learning purposes, resulting in fewer pictures to scan, videos to watch, or text to analyze. Without a clear rule to permit machine learning, the Canadian legal framework trails behind other countries that have reduced risks associated with using data sets in AI activities in a manner that fairly treats both innovators and creators. Under the Canadian system, researchers either must risk copyright infringement by using protected works to make their machines smarter (which has a chilling effect on innovation), or severely limit the data sets used, thereby producing less “smart” machines than would be possible under a more open copyright regime. This raises concerns of bias and discrimination.Within the current framework, the fair dealing rules provide some protections and allow for some use of copyrighted work by AI companies without permission. Canadian courts have ruled that it is a right that should be interpreted in a broad and liberal manner and there are several purposes that would permit some text and data mining activities – notably exceptions for research, education, and private study.The corporations and high-profile talent attracted by the investment in the Canadian AI system have been calling for such an exception for many years. In 2018, various technology groups noted that the current uncertainties in the Copyright Act limit the ability for Canadian companies to “access a basic necessary resource to train their algorithms”.  Indeed, as of the time of this writing, of the 121 companies on the Government of Canada’s approved AI vendor list, 87 are Canadian, with almost all other vendors coming from competing nations with TDM exemptions.  Canada is one of the top countries in the world for AI research talent, with rates of growth currently exceeding that of the United States, the UK, Germany, France, and Italy.  Unfortunately, we lag behind in AI commercialization.  A clearly articulated copyright framework that allows TDM for commercial use is an important step toward changing that tide.Internationally, other countries have addressed this issue through text and data mining exceptions. In the above-mentioned discussion, Microsoft noted that there was a broad acceptance of text and data mining exceptions around the world and that Canada is posed to fall behind and be at a global disadvantage without one. They also noted that, unsurprisingly, the countries that have/are considering these exceptions are at the forefront of research involving data analytics and artificial intelligence.Countries such as the United States and Israel have elected to open up their fair use provision to exempt text and data mining activities, with Israel’s Attorney General issuing guidance to inform the exception.   Others have created specific exceptions. Examples of such exceptions can be found in Japan, the European Union, the United Kingdom, and Singapore.The EU enacted a mandatory exception for text and data mining for the purposes of scientific research but has permitted rightsholders to “contract out”.  The U.K.’s exception allows copies of works to be made without permission of the copyright owner for the purposes of automated analytical techniques to analyze text and data for patterns, trends, and other information. The law does not allow contracts to restrict data mining activities, but the exception is limited to non-commercial research. The approach adopted by Singapore specifically exempts text and data mining in their Copyright Act by exempting copies of works wherein the “copy is made for the purpose of computational data analysis; or preparing the work or recording for computational data analysis.”In order to not fall behind internationally and position ourselves as a world-leader, Canada needs to adopt a broad exception for text and data mining. Ultimately, machine learning does not harm the primary purposes of the original work – the goal is not to republish or compete with copyrighted materials, but to ensure that researchers and AI companies can mine the text and data for informational analysis purposes – thus including commercial uses in the exception will not harm rights holders and will facilitate Canadian innovation.Recognizing that there are concerns about the scope of a text and data mining exception, the government should consider including transparency requirements alongside the exception. There is a need for all stakeholders – copyright owners, users, and the broader Canadian public – to have easy access to disclosures about what content has been used in training AI systems. A mandatory transparency requirement would be akin to the attribution requirements in some fair dealing exceptions. By providing attribution in the form of transparent disclosures, the text and data mining exception would enable machine learning while also providing necessary safeguards for creators to better monitor and respond to the permitted use of their works within this exception.",There is no significant uncertainty at the moment and no need for legislative reform.,"Inclusion of Copyright Materials in LLMsThe inclusion of copyright materials in LLMs has emerged as a major source of concern for some rights holders, who argue that their rights are being infringed upon by virtue of the inclusion of their works without permission. I believe it is premature to introduce legislative reforms on the use of copyright works within LLMs. Indeed, notwithstanding the calls for immediate legislative reform, I believe that there are better approaches that balance the copyright concerns with the policy goals of developing beneficial generative AI systems that may support a wide range of activities including education, health care, and commerce. As the UK Minister for AI and intellectual property recently noted, there is no rush to regulate the AI field.First, there are a myriad of cases currently before the courts worldwide. These cases are likely to provide a first analysis of many of the copyright-related concerns with the inclusion of copyright materials within LLMs. For example, in Andersen v Stability AI Ltd, there are four different claims.  They are infringement of copyright, the removal of copyright management information under the DMCA, publicity claims where the defendant’s knowingly used the plaintiff’s names in their products (by allowing a user to request art in their specific style) and style by allowing a request in their artistic identities, unfair competition claims under the Lanham Act for the use of their art for commercial gain without permission or proper attribution. In Authors Guild v OpenAI Inc, the claims focus on the use of published works to train LLMs.  This is done by reproducing the works and that this act is central to the quality of the OpenAI product.There are many other cases that will canvass these claims. Generative AI companies will likely point to uses that do not infringe copyright, the inclusion of materials not subject to copyright protection, and the temporary nature of the reproductions, largely for statistical and analytical purposes. The AI companies typically do not reproduce actual full text of the underlying materials found in the LLMs.Given the legal uncertainties, it would be premature to intervene with legislative reform at this time. Rather, the government should maintain a watching brief on the litigation to see how these cases unfold and whether reforms may be required. Intervention with legislative reform runs the risk of altering or undermining both creator and user rights as the technology continues to evolve, market-based solutions emerge, and courts address the application of LLMs to current copyright laws. Rather than leaping into reforms that may have negative effects and entrench the power of a handful of AI and tech companies, it is preferable to better understand how the law has been applied to LLMs and generative AI tools and then identify potential gaps or reform solutions.Second, while allowing the litigation process to unfold, the government could encourage several private sector developments to the benefit of all stakeholders. These include greater transparency of which materials included within LLMs, akin to an attribution requirement for some fair dealing purposes. It could also include work toward an AI version of the robot.txt standard for data scraping. While the robot.txt standard has worked well for decades within the context of Internet search, there are other considerations in generative AI. Unlike search, generative AI tools may not direct the end user to the original source material, suggesting the mutual benefit in search may not be replicated in AI. As the legal process unfolds, a new standard specific to generative AI and LLMs is needed to allow rights holders to opt out of the inclusion of their works within LLMs.Third, the government moved quickly last year to develop Generative AI guidelines that address issues related to transparency, security, and fair practices. While there were some concerns expressed with how the guidelines were drafted, they provide a useful starting point for governing activities in the sector. Since the guidelines are only effective if implemented, the government should actively ensure that they are respected by AI companies and work to identify whether further provisions or amendments are needed.Outputs of Generative AI SystemsSimilar to the analysis on the inputs into generative AI systems, the outputs are also the subject of litigation. While there are some cases involving questions regarding the copyrightability of machine-generated works,  the more notable issue at the moment is whether works created by a generative AI system may infringe copyright if they appear to replicate an original work that may have been included within an LLM.However, notwithstanding some fears expressed in the media, replication is likely rare given the vast amounts of training data that are used to train an AI system.  For example, a study on GitHub’s Copilot found that reproduction of code took place only 0.1% of times.  A study on replication in the LAION Aesthetics dataset, which includes 12 million images, found that 1.88% of random outputs had a high similarity score with the training material, which was considered a high incidence rate among current studies.  The study noted that the reason for the high similarity results, was due to the prevalence of popular images in the dataset.  The study also used a small sample set, which only included 0.6% of LAION’s training data. In sum, it is fair to say that there is a small degree of memorization, which can lead to replication, of certain popular sources across AI models, but current studies reveal that the rate is quite low. The process of training an AI necessarily involves breaking large quantities of data apart, clustering, putting things that are similar together and then passing them through a noise filter.  At the end of this process, there is little left of the original work in the AI model, with some exceptions. The technological realities of generative AI suggest that infringing outputs is likely very rare. The government should not intervene with legislative reform to address what may be a non-issue. Rather, it should await the outcomes of litigation that may examine these issues in greater detail. Intervening at this premature stage, could harm creator rights, the development of AI technologies, and Canada’s competitiveness in a rapidly growing sector.","I am a law professor at the University of Ottawa where I hold the Canada Research Chair in Internet and E-commerce Law and serve as a member of the Centre for Law, Technology and Society. I focus on the intersection between law and technology with an emphasis on digital policies. I have edited multiple texts on Canadian copyright law and appeared many times before House of Commons committees on copyright law and policy. I submit these comments in a personal capacity representing only my own views.The consultation raises several questions related to generative AI and copyright. I have focused on three in this submission:(1) Should Canada proceed with a text and data mining exception as recommended in the 2019 Copyright Act review?(2) Should Canada introduce legislative reforms to address the use of copyright works in large language models (LLMs) that are central to the development of generative AI technologies?(3) Should Canada introduce legislative reforms to address copyright-related questions arising from the outputs of generative AI systems?My submission argues as follows:1. Introducing a text and data mining exception into Canadian copyright law is long overdue and should proceed as a copyright reform priority. Similar provisions are widely used in other jurisdictions. Proceeding with the exception would ensure that Canada implements a copyright framework for AI that encourages innovation and investment while also providing appropriate protections for creators.2. It is premature to introduce legislative reforms on the use of copyright works within LLMs. While there are both technical and copyright related issues related to LLMs, the copyright issue is currently before courts around the world in multiple cases that raise questions related to inclusion of copyrighted works within LLMs, whether such use constitutes infringement, and the potential application of limitations and exceptions. Given that these issues should become clearer as those cases progress, the government should maintain a watching brief to determine how the cases before the courts develop, whether market-based licensing alternatives emerge, and how the technology adjusts to reflect copyright-related concerns.3. It is similarly premature to introduce legislative reforms to address the outputs of generative AI systems. While many have expressed concerns about the occasional similarities between generative AI outputs and copyrighted works that may have been included within LLMs, a deeper dive into the technology suggests that infringement is very rare. The courts will again be called upon to examine these claims and the government should await those outcomes before proceeding with any potential legislative reforms.I also note that the next statutorily mandated Copyright Act review is due. Before proceeding with any reforms, it would be useful to conduct an assessment of the implementation of the recommendations from the last review conducted by the Standing Committee on Industry, Science and Technology and scope out a future review to update on outstanding issues and address emerging ones such as generative AI."
Daniel Gervais,Academic,N/A,"As I see it, Canadian policy should ideally aim to achieve three objectives.First, it should ensure the proper development of the AI industry in Canada. Second, it should ensure that Canadian “content” is properly reflected in AI training datasets for Large Language Models (LLMs), especially those used by Canadians. Third, it should ensure that Canadian creators are fairly compensated for the use of their copyright works, whether in Canada or elsewhere. These objectives are not presented in any kind of hierarchical order.To begin with what I consider low-hanging fruit, a transparency obligation concerning the data used to train AI models would allow Canadians and the Government of Canada to know whether those objectives are being achieved. The recently adopted EU AI Act may provide a useful precedent in that regard.Many LLMs are trained on available online material, sometimes any material that the AI system can locate. The status of online material is often misunderstood. A copyright work that is available online is not “copyright-free” unless it is licensed under those terms, or in the public domain. Some amateur content uploaded to various platforms and services is licensed under broad Terms of Service that allow reuse for several purposes, but those T&Cs must be considered case by case. Some of those T&Cs may allow reproduction for training. As most of the material was presumably made available before the  emergence of LLMs, the idea that it is all subject to an implied license for LLM training strikes me as at least anachronistic.Beyond publicly available material, there are troubling reports like this one (https://aicopyright.substack.com/p/the-books-used-to-train-llms) of datasets of books available electronically that were never authorized by rightsholders and where the “this was freely available” argument fails--independently of its legal value. Having said that, however, in my view the need for a new exception for TDM has not been demonstrated.First, bargaining around the issue may require knowing a better understanding of where fair dealing ends, a determination not yet done by courts.Second, even if and when a specific exception was added to the Act, Canadian courts may fall back on fair dealing, as happened in educational photocopying cases despite the existence of a specific exception.Third, an exception allowing any and all use of copyright material for AI training purposes would fail to achieve the third objective identified  above--and also the second objective unless it was accompanied by a transparency obligation that cannot be circumvented by relying instead on fair dealing. Moreover, a new exception is a policy risk in that it is almost certain to produce unintended effects. A *limitation* on rights (instead of a full exception) is appropriate, but its objective and scope should both be well delineated. Given the large number of small, medium, and large companies operating now or likely to do so in the future in the AI/TDM space and the even larger number of potentially affected copyright and related rights holders, individual transactions between rightsholders and user will not suffice. Transaction costs would be insurmountable. This supports the case for a limitation. The limitation that users require would limit their liability and allow them to proceed without having to ask permission.Naturally, users--even those with multibillion-dollar budgets--also want it all for free, but that would fail to achieve the third objective. The limitation should achieve all three objectives and include fair compensation for creators.In thinking about the contours of a such a limitation, four points should be made.First, as I have explained in several publications (e.g., Collective Management of Copyright and RelatedRights, 3rd edn, chapter 1), if a collective licensing system is in place, then functionally rightsholders do not (and probably cannot) say no despite the existence of an exclusive right. Why would they? Hence, this is the functional (though not the legal) equivalent of a compulsory license. Put differently, if a collective management approach is in place, licenses with worldwide effect could be made available, rendering a new exception or limitation unnecessary. The license could not only compensate creators, it could also set parameters for fair reporting of material used, thereby ensuring transparency.Second, a statutory limitation could be appropriate, with or without voluntary collective licenses. Canada could innovate by recognizing a right for creators to be compensated for the use of protected material for text and data mining, as Canada did in 1985 with private copying. The argument that the distribution of remuneration of that nature to creators is a ""black box"" can be easily refuted. I can provide additional information in that respect if that would be useful.Third, any limitation must factor in Canada's international obligations under the Berne Convention, theWCT, the WPPT, and the TRIPS Agreement, including the three-step test. I won’t elaborate on this here but could do so separately. I have also published extensively on this topic.Fourth and finally, the deeper question concerning a possible limitation is the nature of the right that would form the basis for a right to remuneration--whether as a voluntary license and/or a statutory limitation of creators' rights. There is little doubt that the training of LLMs often requires the making of a local copy of the training material. This is prima facie infringement in the jurisdiction where it is taking place, subject to applicable exceptions and limitations. This is a potential area for a licensing solution, even--I might say especially when--parties disagree about the exact scope of existing exceptions, as this would avoid years of uncertainty and litigation costs.It must be underscored that, though LLMs prima facie infringe when they ingest copyright material, subject to fair dealing, even if this matter is resolved in a way that ensures proper payment for creators, the ""ingestion"" process is unlikely to function as a source of ongoing remuneration. Large AI models will likely ingest any given element once or very few times. Larger models may then be made available to other AI companies as an ""infrastructural layer"". As there is only one human timeline, once most or all copyright material (roughly literary and artistic works from the past century) has been ingested, it will be difficult to justify ongoing royalties sufficient to allow creators to continue to do what they do. A separate area for potential licenses is the creation of outputs based on training data that is protected by copyright, a matter to which I return in my answers to the following questions.A last point is that the copying of material for the training of LLMs either omits or deletes copyright management information. This would seem to constitute a second, separate source of liability. It could also be managed, however, under the terms of a license that would contain proper parameters for the lawful use of protected material.","I do not believe there is much real uncertainty about most of the issues identified in the questionnaire.First, it is beyond cavil that historically copyright (droit d'auteur) has always depended on originality generated by (and only by) humans. Second, although what LLMs produce looks like literary and artistic works, the human creative process is completely different from the process used by LLMs to produce their outputs. Third--and here I want to take a very broad view before returning to the copyright-specific questions because I consider this background essential to debate the issue--recognizing machines as authors would greatly accelerate the replacement of human journalists, writers, songwriters, and artists, causing potentially irreversible damage to human progress. As we assess the impact of LLMs on human evolution and the evolution of ideas, we should at the very least not push the LLM gas pedal to the floor because there might be a cliff ahead. This is not the same issue as cases of genuine human-machine collaboration, a matter to which I return below.To be clear, this is not opposition to AI or LLM technology in any way. There are areas in which this technology will produce almost entirely beneficial results for humans, such as medical research--for example, its ability to identify new molecules and predict their efficacy, or to correlate certain genetic or other biomarkers and specific diseases (though I suspect the same predictive capabilities of the technology will be used by insurance companies to deny coverage to many Canadians without legislative interventions).For purposes of this response, however, it is important to note that the easiest task for LLMs is to mimic certain outputs of the human creative process. This does have some benefits in the short term, such as allowing people to improve a draft text they've written. However, as research in neuroscience and psychology has shown, once a cognitive task has been delegated to a machine, humans quickly lose the ability to perform it well. For example, people who learned to drive before the omnipresence of GPS can probably still do so in areas they knew before they started relying on a GPS, but depend on a GPS for most other trips.Professional creators of many forms of literary and artistic works, from journalists to songwriters to filmmakers to visual artists, learn by watching and getting feedback from more experienced creators.Accelerating the replacement of those humans by removing their ability to earn a decent living because machines can mimic the format of their creative endeavors cheaper and faster is fraught with potentially catastrophic risks. Imagine a world where all or almost all music is machine-produced or a world in which Canadians get all their news from machines, not other humans (journalists).As I wrote in an Essay published a few years ago:""If machines can produce […] literary and artistic works cheaper and faster than human creators, it a highly likely that industry will favor them over their human counterparts. In the copyright sphere, delegating to machines the task of helping us understand and interpret our world has profound consequences. It is through this interpretation that humans can become true agents in the world and ultimately change it. Delegating this very task to machines is thus pregnant with implications for the future for it changes its arc. It will not be complete obliteration of course. There will always be humans who write, pick up a paintbrush, or try to make a movie or sculpture, but if most of what we are given to read, watch or listen to comes from machines, much will be lost. If copyright protection is granted on outputs without a human cause, and assuming that the cost of machine productions will be lower (and machines will not ask for ongoing royalty payments or have reversion rights) then market forces will inescapably push for a replacement of human authors whenever it is commercially feasible."" D. Gervais,The Human Cause, in Research Handbook on Intellectual Property and Artificial Intelligence (R. Abbott, ed), (Edward Edgar, 2022) pp 21-38.I stand by that statement.I would add that copyright is an incentive, and I am not aware of convincing data to show a major crisis of underinvestment in Generative AI.In crafting the best policy, therefore, I urge the government to resist the commonly held view that any and all disruption caused by AI companies is per se positive and must be allowed by law, and instead consider that a diminution of the percentage of works created by humans available in commerce, from journalism to essays to novels, is not necessarily a clear positive. At the very least, it should not be accelerated by providing copyright rights to autonomous machine outputs Arguments in opposition to the approach outlined above usually begin with the observation that it takes  a lot of time and money to train an AI system. Fair enough. Yet, it also took time and money to produce  thousands of telephone books (getting the data from every subscriber, arranging it, and then printing  and distributing the books), but that was not a basis for copyright protection. Nor is Einstein's E=mc2  protected by copyright (or any form of IP for that matter). A related argument is that because some AI  outputs have commercial value, they should be protected. This is plainly wrong. Courts have long  recognized that ""what is worth copying is worth protecting"" is not a correct statement of the law. A third argument is that LLMs should be considered authors because they mimic human creativity by creating outputs that may look like they could have been produced by a human author, occasionally very well. I submit that mimicry is not a sound policy basis for a claim to a right. Then, if rights in machine outputs were recognized, who would be the rightsholder? The owner of the machine? The company that programmed the algorithm (and there could be many, such as the company  that created the model and the company that reused and adapted it), the company responsible for training, the person(s) who prompted the machine? Recognizing one over the other is difficult, but applying the notion of joint authorship in that context is doctrinally wrong (for these purported authors have not in fact collaborated).That being said, the authorship issue is a sliding scale in this context. A work can be produced by an author with the assistance of AI tools—as opposed to outputs produced autonomously by the machine what I call outputs without a (sufficient) human cause. If a work has sufficient human authorship, then the use of AI tools should not prevent the copyrightability of the work, though if the machine’s contribution is separable, then a question can be raised about the copyrightability of the machine-produced portions. I discuss this in more detail in The Human Cause chapter cited above.Finally, the question of the copyrightability of prompts is interesting. A detailed prompt (long enough and with sufficient originality) might be considered as text protected by copyright (literary work). The more interesting question is whether authoring (or “engineering”) a prompt means that the prompt “engineer” is the author of the resultant output. In almost every case, the answer should be negative.One can imagine situations, however, in which a series of consecutive detailed prompts could contain expressions of specific ideas that reflect human creative choices directly perceptible in the machine’s output, in which case the argument that the prompts’ originality may have “transferred” to the output could at least be made with some credibility. I see those situations as exceptional, however. But to avoid confusion, one must be very clear. Even if the prompt(s) contains detailed *ideas* that are reflected in the machine's output, ideas are not protected by copyright. Thus, one must look for expression in the prompt that transferred to the output, for example, an instruction to use some specific, original text.In summary, granting rights to machine productions would be a major doctrinal jump and a normative error. It would be the first type of second-degree intellectual property--exclusive rights not to something humans have made, but to what was made by what they have made. I see no reason to change copyright law so fundamentally without a very compelling reason, taking into account the major risks to human progress that any acceleration of the replacement of human authors is likely to cause.","LLMs necessarily produce outputs based on their training data. If that training data consists (entirely or even in part) of material protected by copyright or a related right, then that material is undeniably the basis for the output. That does not mean that machines infringe, however.The principal rights to discuss are the rights of reproduction, translation, and adaptation.The test for infringement of the right of reproduction is well known. The reproduction right is infringed only if a substantial part of a protected work is copied. This allows, for example, short quotes (at least of a larger work) to be taken without permission. Substantiality is related more to the quality rather than the quantity of what was taken. To determine whether someone has copied a work a three-part test is applied. The plaintiff must establish: first, that they created or otherwise own a copyright in a protected work; second, objective similarity between the plaintiff’s work and the defendant’s product (whether the defendant’s product is itself possibly a copyright work is immaterial); and third, that the defendant had access to the plaintiff’s work. The first question can be answered quickly and easily for most of the material protected by copyright used for LLM training purposes. Similarly, because there is at least some transparency (more would be far better) in terms of the material used, the third question can also be answered quickly and easily in the vast majority of cases. The key debate is, therefore, almost always about the second part of the test.The question is whether the output infringes the reproduction right in one or more identifiable pre-existing works. This test has been applied by Canadian courts for decades. The fact that a potentially infringing output was generated by a machine does not and should not change the applicable test.Although if an infringement does occur it would likely be in a work contained in the training dataset, it is certainly conceivable that an LLM could produce an output that copies a work not contained in its training dataset. The same three-part test should apply.Whether an output infringes the rights of adaptation or translation also requires identifying which preexisting work(s) was infringed. As the majority of the Supreme Court of Canada explained in Théberge:""[W]hile there is no explicit and independent concept of 'derivative work' in our Act, the words 'produce or reproduce the work ... in any material form whatever' in s. 3(1) confers on artists and authors the exclusive right to control the preparation of derivative works such as the union leaflet incorporating and multiplying the Michelin man in the Michelin case, supra. [...] In King Features Syndicate Inc. v. O .and M Kleemann Ltd., [1941] A.C. 417 (H.L.), under a provision in the English Act similar to s. 3(1) of our Act, the plaintiff's copyright in the cartoon character 'Popeye the Sailor' was held to be infringed by an unauthorized doll, i.e., the two dimensional character was reproduced without authorization in a new three-dimensional form.""Again, whether the output was produced autonomously by the machine, by a human, or by a machine-human ""collaborative"" effort, the infringement analysis remains essentially the same.I note that several major providers of AI services--specifically LLMs--have offered indemnifications to their users. Those indemnifications should be evaluated very cautiously. The legal text supporting the indemnifications for possibly infringing outputs often contains significant exclusions. For example, OpenAI’s Terms of Service (version dated November 6, 2023) exclude indemnifications for outputs which the “Customer or Customer’s End Users knew or should have known the Output was infringing or likely  to infringe, (ii) Customer or Customer’s End Users disabled, ignored, or did not use any relevant citation,  filtering or safety features or restrictions provided by OpenAI, (iii) Output was modified, transformed, or  used in combination with products or services not provided by or on behalf of OpenAI, (iv) Customer or  its End Users did not have the right to use the Input or fine-tuning files to generate the allegedly infringing Output, (v) the claim alleges violation of trademark or related rights based on Customer’s or its End Users’ use of Output in trade or commerce, and (vi) the allegedly infringing Output is from content from a Third Party Offering.” Whether the “should have known” clause imposes a duty on users to check whether a particular output may be infringing is unclear, but the standard is certainly open to various interpretations. Moreover, excluding any material that the user modified is noteworthy, as many users are likely to at least tweak the machine’s output. Would something like a format change be sufficient to exclude the application of the protection? Indemnifications offered by Google and Microsoft similarly contain important limitations, for good reasons. Google’s indemnity clause for example excludes customer uses “after receiving notice of an infringement claim.” There is ample support, therefore, for the claim in a recent Forbes article that “if you read the fine print, the protections offered are narrower than what’s suggested by the PR.” Brad Stone, ""AI Legal Protections May Not Save You from Getting Sued"", Forbes, 13 November 2023.I have also noted the promotion of automated filtering meant to prevent infringement. I am skeptical.Yet, humans often disagree and must rely on long litigation to decide whether a particular literary or artistic production infringes rights in one or more pre-existing works, often because of the fuzzy contours of fair dealing. How can this be automated with sufficiently high accuracy that a user could safely rely on it?In sum, although in common parlance LLM outputs are necessarily *based on* the material contained in their training dataset, it does not follow that every output will infringe a copyright or related right in that material. As explained above, rights in one or more identifiable works must be infringed. This means that fair remuneration for creators in terms of outputs is likely to be difficult to achieve, with the strongest basis at this juncture being the avoidance or resolution of litigation. As discussed in answers to previous questions, LLMs will infringe when they ingest copyright material, subject to fair dealing. Even if this matter is resolved in a way that ensures proper payment for creators, the ""ingestion"" process is unlikely to function as a source of ongoing remuneration. Larger LLMs will likely ingest a specific element only once or very few times.A potential solution to consider would be the creation of a right to remuneration based on the use of tokenized copyright works and objects of related rights in LLM datasets. I do not have the space here to elaborate more fully on this possibility, but I would be happy to do so separately in due time. Ideally, such an approach would reflect a multilateral consensus on the importance of human creators. A quick turnaround of the international community after a major technological breakthrough is far from unprecedented. In 1996, barely two years after such a major shock (the invention of the HTTP protocol and the ""World Wide Web""), two new treaties were adopted under the aegis of WIPO. The emergence of LLMs is at least as important a technological change, and arguably a far bigger one.",N/A
Faith O. Majekolagbe,Academic,N/A,"In addressing the seeming tensions between copyright and text and data mining (TDM) or copyright and artificial intelligence (AI), the Government of Canada should give careful consideration to the existing suite of exceptions and limitations in the Copyright Act, in particular the fair dealing exception. This is to avoid inadvertently shrinking the scope of user rights available to the public in Canada. I recommend examining the extent to which the fair dealing exception and other exceptions in the Copyright Act already permit certain TDM activities, including the use of copyrighted materials for AI training, bearing in mind that the Supreme Court of Canada in a plethora of cases has held that the exceptions must be given large and liberal interpretations (CCH v Upper Society of Upper Canada, 2004; Alberta (Education) v Access Copyright, 2012). For example, it is hard to see how the current fair dealing provision in section 29 of the Copyright Act cannot be relied on by researchers and institutions that support research (such as libraries, archives, museums, and educational institutions) to copy, extract, or otherwise use copyrighted works in any way for TDM activities for research purposes.What is needed in circumstances in which the current framework of copyright law in Canada can be rightly interpreted as exempting certain TDM activities from copyright control, is a clarification by the Government that these activities are indeed covered under the Copyright Act. This would provide certainty to the beneficiaries of the existing exceptions, including but not limited to researchers and institutions that support their research activities, and promote socially beneficial TDM activities that rely on existing copyrighted materials. In addition to a clarification note, it is important to prohibit the use of contractual and technological overrides that undermine existing copyright exceptions and serve as an obstacle to permissible TDM activities. Where libraries have obtained lawful access to copyrighted materials for research purposes, they should not have to negotiate new licences where the needed research purpose involves text and data mining.In circumstances where the current suite of exceptions cannot be interpreted as permitting a TDM activity, we should consider the nature of TDM activities and whether it is feasible to expect copyright clearances for the vast range of works involved; and whether data mining or the machine learning process that is integral to AI training is different in substance than other acts that we do in relation to copyrighted works outside the TDM or AI environment. Scholars have argued that mining or machine learning is not in essence different from the act of reading a copyrighted material (Flynn et al, 2020; Sag, 2019). Since the act of reading or learning from a copyrighted material does not require a licence, the argument that is that mining or machine learning which is akin to human reading or learning should not (Sag, 2019). This is especially so where the copyrighted materials have been lawfully accessed either through purchase, a use-licence, or outside paywalls on the internet. The mere fact that the works have to be reproduced and sometimes adapted into a machine-readable format should not in itself change the nature of the activity since TDM or machine learning as computational processes are impossible without technological reproduction.Furthermore, TDM and machine learning are arguably non-expressive uses of copyrighted materials since they often involve taking and using ideas, patterns, data, methods, etc, underlying the expressions in a work. These ideas, patterns, data, methods, etc, are unprotected and recyclable elements of copyrighted works (Majekolagbe, 2024). It has never been the case that copyright users who have lawfully access to copyrighted materials cannot use the ideas, patterns, and information in the materials to generate new ideas, information, and other outputs in so far as the resulting output is not a whole or substantial copy of the copyrighted works that was used in the research and creative process. At the heart of copyright law is the protection of the communication of an author's original expression to the public without the copyright owner's consent; copyright law does not seek to restrict the communication of the ideas, patterns or facts expressed in the work to the public (Sag, 2019). As such, acts like mining and machine learning, that do not communicate the author's original expressions to the public should not be regarded as infringing and clear exceptions to that effect should be contained in our copyright law. To regard these non-expressive acts as infringing is to undermine the longstanding idea-expression dichotomy in copyright law that has served to protect the private interests of rightsholders while also securing the interests of the public in using and enjoying copyrighted works. As Sag rightly notes, 'The idea-expression distinction is essential for any copyright system that aims to foster a vibrant and creative intellectual ecosystem.' (Sag, 2019) Permitting TDM and machine learning (non-expressive uses of copyrighted works) without the prior authorization of copyright owners is consistent with the core structure of copyright law in Canada and elsewhere.The approach to TDM and machine learning activities in Japanese copyright law could provide useful insights in the consideration of this issue in Canada. While Japan is known as the ""paradise for machine learning"" because of the liberal approach (which is consistent with the core structure of copyright law in Canada) it took to addressing the issue, the Singaporean approach to the issue is also worth considering. The European Union approach could also be considered, but bearing in mind the need to promote innovation and reduce obstacles to the development of AI technologies in Canada, especially socially beneficial technologies. To give more efficacy to any exceptions that we may develop in response to TDM and machine learning activities, we should prohibit the use of contractual and technological overrides that might undermine the exceptions.It should be pointed out that the UK approach to TDM is an example of what not to do in Canada because it limits the scope of permissible text and data mining activities to non-commercial research whereas, in Canada, our existing law permits fair dealing for both commercial and non-commercial research (Copyright Act, s. 29; SOCAN v Bell Canada, 2012; CCH v Upper Society of Upper Canada, 2004).Lastly, permitting the use of copyrighted works for TDM purposes and AI training should be addressed as a separate and distinct issue from the issue of the outputs of generative AI tools. Permitting AI developers or TDM users to use copyrighted works for TDM activities and AI training should not be interpreted as permitting them to produce or generate outputs that are similar or substantially similar to the works used for the TDM activities or AI training process. This difference should inform our approach to law and policy reform actions. There is no concern regarding the existing legal tests for demonstrating that an AI-generated work infringes copyright. There is no reason why the same legal tests for demonstrating that a produced work infringes copyright should not be applied in the context of AI-generated works. This should provide relief to copyright owners that their expressions remain protected under copyright law and that where AI-generated works that have been trained on their copyrighted works include complete reproductions or reproductions of a substantial part of their works, they have recourse under the existing legal framework for copyright protection in Canada. To strengthen the effectiveness of legal remedies, there is however a need to clarify where liability lies when AI-generated works infringe existing copyrighted works.On the whole, Canada's approach and response to the pressing issue of ""unauthorised"" use of copyrighted materials for TDM activities and as part of the machine learning process for the development of AI tools should be carefully considered in light of the need to balance the interests of copyright owners in obtaining a just reward for their labour and those of users in disseminating and using copyrighted works for socially beneficial purposes.","In responding to the issue of the authorship or ownership of AI-assisted and AI-generated works, the Government should be mindful of the fact that humans have used technologies to create works and other materials that have been the subject of copyright protection in Canada and elsewhere. While generative artificial intelligence tools are novel technologies, there are nonetheless tools that are used in creating works. For example, human beings use the technology of camera to capture images rather than paint on a canvas and create a sculpture and we grant copyright protection over those images in the same way we grant copyright over paintings and sculptures. There is therefore no reason why the current framework for the grant of copyright protection is not enough to determine when one gets copyright over an AI-assisted or AI-generated work especially given that these works are generated based on human prompts.There may however be policy reasons why these ""original"" works should be given a term of protection that is less than the life of the author plus 70 years, in which case, our copyright regime would need to be modified accordingly. For instance, some jurisdictions give a shorter term of copyright to photographs perhaps because of the huge role that technology plays in creating photographs and the consequent ease of creating photographs. This approach to photograph could be adopted for AI-assisted or AI-generated works given the huge role that the AI technology plays in creating the works and the consequent relative ease of creating those works.","There is no concern regarding the existing legal tests for demonstrating that an AI-generated work infringes copyright. There is no reason why the same legal tests for demonstrating that a produced work infringes copyright should not be applied in the context of AI-generated works. This should provide relief to copyright owners that their expressions remain protected under copyright law and that where AI-generated works that have been trained on their copyrighted works include complete reproductions or reproductions of a substantial part of their works, they have recourse under the existing legal framework for copyright protection in Canada. To strengthen the effectiveness of legal remedies, there is however a need to clarify where liability lies when AI-generated works infringe existing copyrighted works.",N/A
Fenwick McKelvey,Academic,"I am a professor at a non-profit public sector institution. Most recently, I have had to pay ProQuest for the right to data mine newspapers and other articles for not-for-profit research as many data brokers are focusing on commercial markets.","I am expressly concerned that commercial, for-profit research and training AI models will undermine my fair dealing rights and the public interest function of academic research. I am opposed to expanding fair dealing exemptions for training commercial, for-profit AI models usually by large corporate or start-ups. I see no need to modify our fair dealing exemptions and oppose broad exemptions as in Japan for TDM. The fair dealing exemptions focus on uses not technologies and should cover the appropriate exceptions for TDM. If anything better protection of fair dealing need to be developed to prevent situations such as: https://waxy.org/2022/09/ai-data-laundering-how-academic-and-nonprofit-researchers-shield-tech-companies-from-accountability/Copyright seems well suited already to deal with infringing uses if a user publishes infringing content from a system. My key concern is training data and its negative effects on publication and public data. Information commons, a concept I wish had been discussed further in the Discussion Paper, need to be protected from commercialisation least undermining public access to knowledge and the erosion of the public internet today.",Ownership of AI is a major issue especially in the classroom when its unclear who owns primarily AI-generated works. The lack of clear ownership raises issues about intellectual honesty.Any works generated through models trained off public data should be entered into the public domain without copyright protection.,N/A,"I would appreciate greater consideration of commons-based approaches to AI and machine learning, see: https://machineagencies.milieux.ca/ai-commons/"
Sarit K. Mizrahi,Academic,N/A,"Clarity surrounding the legitimacy of text and data mining under copyright is undoubtedly necessary to cement future growth in the AI arena.  The approach adopted, however, should avoid the kind of technology specific exceptions that have proven harmful to progress in the past.  Rather, it should take the form of a generalized exception that is capable of providing a legislative foundation for the development of AI as well as any future copy-based technologies.  And doing so requires legislative modifications capable of limiting copyright protection of uses on the basis of their purpose.Copyright essentially governs uses, full stop. It doesn’t take the pains to differentiate between uses that are communicative – and therefore compel authors’ speech, essentially inflicting the harm that the concept of infringement was designed to address – and uses that are not; uses that merely wield works’ material form for purposes that have little to do with their nature as instances of dialogue.  These are uses – or rather ‘nonuses,’ as law professor Abraham Drassinower dubs them – whose recognition under copyright quite simply overlooks “that it is not as a pattern of ink on a page, so to speak, but only as a communicative act that a work falls within the purview of copyright law” (Abraham Drassinower, What’s Wrong With Copying (Cambridge: Harvard University Press, 2015) at 13).Yet, even when copies are clearly not being used for communicative purposes, copyright law has found the need to position itself on such issues.  And it oftentimes does so by adopting technology specific exceptions that wind up generating future confusion over the permissibility of copying by other technologies that function somewhat differently.  Take, for instance, the temporary reproductions that facilitate our Internet browsing activities, the ‘copies’ that enable the technical process responsible for increased dissemination of and access to knowledge.  Involving “use of a work’s material form not as a work but as a tool, not communicatively but technically, […] it cannot be said to compel authors to speak” (Drassinower, ibid at 183).  It is, in other words, a paradigmatic instance of nonuse.  And yet copyright found it necessary to carve out an exception to permit this kind of ‘use’ leading to the impression that such nonuses might have otherwise qualified as infringement.  This provision – and the underlying notion upon which it’s based – have done little more than create ambiguity surrounding what, in fact, amounts to an actionable ‘use’ in the digital age.The same amendments that limited liability for making temporary digital copies, for instance, left Cloud Service Providers wondering whether the more permanent technical copies necessary to facilitate cloud-based storage might be held as infringing.  These are copies that are neither perceptible nor consumptive; they’re created strictly for the purposes of ensuring users’ access to data no differently than the temporary copies recognized as legitimate.  And yet providers and their users were faced with uncertainty, unsure of where they stood within copyright’s narrative; skeptical about the legal ramifications involved in the provision and use of these services. Rather than embracing new technologies that could enhance users’ liberty to generate cultural contributions, copyright often acts as a barrier that diminishes users’ freedom to engage in our creative landscape – all over mere technical ‘uses’ and imperceptible ‘copies.’  And the natural byproduct of this trend is what has inevitably led to the current debates surrounding the legitimacy of the copies upon which machine learning algorithms rely.  If mere technical, imperceptible, and non-consumptive copies find themselves within copyright’s ambit, surely there can be no question that artificial intelligence’s extraction of value from copyrighted content falls squarely within the sphere of ‘unauthorized use.’It's such that, by creating an exception for the paradigmatic instance of nonuse characterized by temporary reproductions for browsing, copyright placed in question the viability of future technologies that similarly rely on ‘the copy’ in a sense that’s less temporally limited but equally technical in nature.  And in so doing, copyright has pre-emptively delegitimized an entire novel creative sector; has reduced AI developers to mere infringers, rather than provided the necessary foundation to recognize them as equal and autonomous creators under the law.  Instead, developers find their creative choices dictated by the purviews of copyright; their autonomy to choose the quality data upon which they train their algorithms limited by the very nature of copyright itself (the human rights consequences of which have been extensively mapped by other academics within the context of the previous government consultation as well as elsewhere, so I will not repeat them here (see e.g. Amanda Levendowski, “How Copyright Law Can Fix Artificial Intelligence’s Implicit Bias Problem” (2018) 93 Wash L Rev 579). And when it comes to generative AI, developers’ use of subpar data – while perhaps less likely to produce significant copyright harms – instead results in tangible harms that are far more detrimental to a society seeking to promote a diverse and inclusive social dialogue.  It’s a trade-off that prioritizes the interests of rightsholders at the expense of our fundamental liberties; one that delegitimizes the creative practices of developers in ways that are already proving to inflict widespread societal damage (See e.g. Safiya Umoja Noble, Algorithms of Oppression: How Search Engines Reinforce Racism (New York: New York University Press, 2018); Cathy O’Neil, Weapons of Math Destruction:  How Big Data Increases Inequality and Threatens Democracy (New York: Crown, 2016); Ruha Benjamin, Race After Technology: Abolitionist Tools for the New Jim Code (Cambridge: Polity Press, 2019); Anupam Chander, “The Racist Algorithm?” (2017) 115 Mich L Rev 1023; Kate Crawford, Atlas of AI (New Haven: Yale University Press, 2021)).For these reasons, it is critical to avoid the kinds of pitfalls that previous technology-specific exceptions to copyright have produced lest they place in question the legitimacy of future copy-based technologies.  Rather than adopting a text-and-data-mining exception to enable AI development, it would be far more judicious to opt instead for replacing all existing technology-specific exceptions with a single broad and technologically neutral one that permits the use of copyright-protected content’s material form for technological developments, whatever they may be; that recognizes that ‘nonuses’ are not the kind of harm copyright should target.  It’s only in so doing that copyright will stop being an impediment to progress.","Although the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works does not appear to be impacting the development and use of generative AI, the law’s intervention is necessary to provide clarity about which uses of generative AI will be eligible to enjoy copyright protection. It’s crucial that whatever position is adopted differentiates between the uses of generative AI that advance copyright’s purpose of promoting progress and knowledge pursuit in order to ensure that it doesn’t induce unnecessary copyright expansion. To this end, it’s important to differentiate between fully machine-generated content and works that are AI-assisted.1. Fully Machine-Generated Content Should Enter the Public DomainExtending copyright to fully machine-generated content risks hindering knowledge pursuit and negating copyright’s fundamental goals. And it can do so in two ways. First, the speed with which generative AI can produce creative content – and in some cases, all possible combinations of content in a given field – would exponentially increase the number of works under copyright protection. Doing so would distance copyright from its central maxim, essentially making it the rule rather than the exception. And this approach would in turn limit the ways in which downstream creators could engage in their own pursuits by subjecting them to constraints over how they can draw on such content. Second, endowing fully machine-generated content with copyright protection is likely to disincentivize many from developing their own knowledge skills. The ease with which they could create and obtain copyright’s benefits using generative AI would likely lead them to rely more heavily on machines to create in their stead as they would be unable to justify the time and effort required to produce creative works themselves, ultimately reducing human participation in our creative culture and stalling the state of human knowledge.In light of the foregoing, there is little to support the copyright protection of fully machine-generated content. While it’s recognition under copyright would irrevocably alter the nature and substance of our social dialogue, negating the goals that copyright as a construct was designed to promote, it is unlikely that preventing generative AI’s outputs’ protection will thwart advances in this arena. There are already extensive uses for generative AI, even despite the uncertainty regarding their outputs’ copyright protection. They include generating simple newspaper articles, producing artistic works that can be sold for monetary gain, cybersecurity management, and human-machine collaborations – and these are but a few of the increasingly growing uses of generative AI.2. Considerations Regarding the Protection of AI-Assisted WorksThe risks presented by fully machine-generated content, however, are less likely to materialize in cases where generative AI is merely used to assist in the creation of a work. In order to promote the continued use and development of generative AI, and to shape its evolution in ways that are consistent with our cultural and dialogic values, copyright should endow AI-assisted works with protection as long as the human author’s contribution is sufficient and goes far beyond merely introducing prompts into the generative AI system. Whatever regime is devised for the protection of AI-assisted works must be capable of ensuring that the human author’s use of these kinds of systems remains in line with copyright’s values.First, it should ensure that authors of AI-assisted works do not use generative AI to replace the process of knowledge pursuit. Knowledge forms the building blocks of the kind of creativity that copyright seeks to promote. But how we pursue, create, and proliferate knowledge shifts with each advancement in information technology, forcing us to consider in greater depth whether or how each new development challenges our vision of the social dialogue’s foundation. Generative algorithms are no different. And we must ensure that the integration of algorithms into the creative process does not reduce the act of knowledge pursuit at its core to something more computational and less intellectually stimulating that fails to advance the cultural discourse in any meaningful way.Incorporating algorithms into the creative process shouldn’t be taken to imply that knowledge isn’t being pursued. If authors use algorithms merely to complement their role as human creator, they may just discover new ways of pursuing knowledge that spur novel forms of creativity. But if algorithms are used to assimilate knowledge in authors’ stead, as opposed to merely enhancing their creativity, it’s crucial to make more pointed inquiries. Chief amongst them being whether replacing the traditional building blocks of creativity with ones that are algorithmically generated negates the resulting work’s advancement of the social dialogue. It’s one thing for an author to turn to algorithms for inspiration after having acquired the knowledge necessary to offer ‘useful’ contributions to the existing creative landscape. It’s quite another when an author employs algorithms to avoid engaging directly with pre-existing culture at all.In effect, pursuing knowledge through the intermediation of an algorithm changes the building-blocks of knowledge that culminate in creativity, and in so doing, it fundamentally challenges our long-standing conceptions surrounding the ontology of authorship. Authors are traditionally considered as simultaneous consumers, remixers, and producers of works of authorship, works that are borne from social dialogue and that seek to further engage it. Creators who use algorithms to enhance their interaction with the works of their predecessors could still be categorized in this traditional fashion. But creators who use algorithms to assimilate knowledge in their stead – who bypass this important stage meant to develop their connection with pre-existing culture – become another sort of creator entirely: they become consumers and remixers of algorithmic output.But, as law professors Carys Craig and Ian Kerr profoundly observe, “human communication is the very point of authorship as a social practice” (Carys Craig & Ian Kerr, “The Death of the AI Author” (2021) 52:1 OLR 31 at 86). In other words, both the social dialogue and authorship as a construct rely on authors’ engagement with pre-existing authors. This position doesn’t imply that authors’ use of generative algorithms trained on the works of others necessarily precludes their creations from partaking in the social dialogue. Rather, it suggests that some knowledge of the works that make up these training datasets may be a necessary prerequisite to upholding our cultural discourse.Additionally, we must consider whether it’s at all desirable to allow our creations to be influenced by algorithmic perceptions of content whose origins we’re unaware of. The algorithm could very well be trained on the paintings of the greats, or the doodles of a 5-year-old, or even (as was discovered in the case of the datasets used to train Stable Diffusion’s algorithms, among others) child pornographic material. It seems contrary to progress to foster an environment in which authors adopt algorithmic contributions unquestioningly, allowing computer code to lead their creative works in distinct directions without reflecting on what exactly is motivating those outputs.Modern-day algorithms have already proven to strip us of “the human expectation of sovereignty over one’s own life and authorship of one’s own experience” (Shoshana Zuboff, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power (New York: Public Affairs, 2019) at 521). By mediating and reshaping both our perceptions and experiences, they play a significant role in ‘helping’ us formulate our thoughts and opinions, or even ‘assisting’ us in our decision-making processes. With algorithms’ widespread capacity to influence our actions and worldviews having long raised concerns surrounding their very palpable repercussions on our self-determination, copyright law’s recognition of AI-assisted must take steps to ensure that authors who collaborate with generative AI are provided with the tools necessary to preserve their authorial autonomy and prevent our social dialogue from being invisibly guided by these technologies.Considering society’s growing tendency to embrace algorithmic suggestions without thinking twice about them, it would be naïve to suggest that authors would be immune to the sort of reflexivity that tends to be fostered by algorithms whose training datasets are unavailable for scrutiny. Authors’ lack of awareness would serve to disempower them, to strip them of the information they need to immerse themselves in the sort of reflection that promotes creative autonomy and enables engagement in the kind of lofty pursuit that contributes to the social dialogue. And authors who aren’t empowered to reflect on the cultural discourse, neglect to exert the sort of independent thinking that pursues the kind of progress that copyright was designed to promote.In his thought-provoking discussion surrounding what separates us from machines, Rabbi Lord Jonathan Sacks observes that humans are defined by their unique capacity to “shape the world; to be active, not merely passive, in relation to the influences and circumstances that surround [them]” (Jonathan Sacks, <http://rabbisacks.org/three-stages-creation-bereishit-5779/>). If we are to maintain this characteristic that has proven so pivotal to our existence, the law must ensure that it’s recognition of AI-assisted works enhance the agonistic tendencies that inspire our capacity to think critically – and to shape the cultural and creative landscapes as a result – rather than permit them to be constrained by machines.","Greater clarity on where liability lies when AI-generated content infringes copyright protected works would certainly be welcome.  But so too would it be useful to obtain clarity on what kinds of generative AI outputs are, in fact, infringing. In essence, to avoid unduly hindering progress, it is crucial to carefully assess which harms to authors arising from generative AI’s outputs are, in fact, copyright harms before including them under the umbrella of infringement.Generative algorithms that are explicitly created to replicate the styles of certain authors have lately been a topic of great debate. While many such services could have significant uses other than to enable infringement (Copyright Act, s 27(2.4)(c)), several question whether these are enough to detract from their ability to so precisely replicate the styles of particular artists.  Are their non-infringing uses, in other words, more prominent than the potential harm suffered by these authors? If the only content used to train an algorithm is of a single artist it might be difficult to argue that any output is not, at least in some measure, an infringing reproduction.  But, where it learns to emulate style from a dataset of a particular artist, that it then amalgamates with the billions of other images upon which it was trained, it would be difficult to see any resulting output as a direct reproduction, let alone an infringing one.  Drawing on the mathematical representations of other images to produce a new image in the style of a pre-existing artist must, forcibly, be a new work (whether or not this new work ought to be eligible for copyright protection will depend on the extent of input from the human collaborator (see response to above question on generative AI and authorship)). Thus, even if developers of these kinds of AI models were aware that their service was being used in this fashion, and even if they specifically created their generative algorithms to emulate the styles of others, they should not be held liable for infringement.  Their goal was not to infringe copyright, but rather to emulate the style of pre-existing artists as so many have done before them. And despite some debate on the topic, it’s generally held that style is precluded from copyright protection (Jane C Ginsburg, “Exploiting the Artist’s Commercial Identity:  The Merchandizing of Art Images” (1995) 19 Colum-VLA JL & Arts 1 at 10). Its exclusion is necessary for achieving the very goal of copyright; for ensuring the promotion of progress.  Impressionism, cubism, modern art, and so on, are all styles that were used by numerous artists over the years, each in their own way.  If copyright were to encroach on style, the future of culture would hang in the balance.  That AI models can generate new images in a pre-existing style in a far more sophisticated fashion than any human should not militate in favour of including this element under copyright’s umbrella.But, while a claim of copyright infringement ought not to be available to authors whose works aren’t directly copied in the generative AI’s output, where the original author has a distinctive style that is of some renown then she might possess a valid claim in virtue of the tort of passing off if she can prove that she has incurred, or is likely to incur, damages.  The extension of the tort of passing off to the creative (as opposed to the trademark) context is, however, quite particular. Courts have generally been reluctant to recognize unfair competition arising from creative works that don’t involve any direct copying, as this would indirectly accomplish through a claim of passing off what copyright doesn’t allow directly, effectively extending a protection to style that might otherwise unreasonably limit the speech of others. The American case of Romm Art v Simcha International (786 F. Supp. 1126 (E.D.N.Y 1992) is quite illustrative of this tension.  Here, the plaintiff, who published posters of artist Tarkay, pursued the defendant in passing off for publishing posters by an artist named Patricia that imitated Tarkay’s visual style in the absence of direct copying.  The Court concluded that the likelihood of confusion existed because both posters conveyed “the same overall impression” (ibid at 1137) and appeared to exude Patricia’s publisher’s “intention of capitalizing on the plaintiff’s reputation and goodwill and any confusion between his and [plaintiff’s] product” (ibid 1139). Particular to this case was evidence that some galleries would frame the Patricia posters in a fashion that would conceal her name, which further militated in favour of the potential confusion. “As applied to the fine arts themselves,” notes law professor Jane Ginsburg, “the decision seems troublesome:  many artists styles owe a great deal to their predecessors.  The Tarkay ‘look’ itself strongly resembles a Matisse crossed with a Modigliani.  One would nonetheless be reluctant to suggest that either of these artists’ heirs should be able to enjoin the dissemination of Tarkay’s work, or that Tarkay should pay them royalties” (Ginsburg, supra at 16).  But, Ginsburg continues, “there may be a difference between emulation of another’s artistic style on the development of one’s own pictorial expression, and the commercial appropriation of an artist’s identity” (ibid, emphasis added).  In other words, it may be acceptable to draw inspiration from pre-existing artists, but it’s certainly not alright to imitate their style in a bid to pass off one’s work as that of another’s.What can be drawn from this line of reasoning within the context of stylistic imitations by generative AI?  Let’s take Canadian Sam Yang, for example, whose art has been used to train a generative algorithm to produce works in his style.  An artist of some renown, he sells his illustrations for educational and commercial purposes while also providing art instruction to nearly one million subscribers through his YouTube channel, Sam Does Arts.   Not only do each one of the images produced in his style by the generative algorithm look like they could very well have originated from him, but they each equally include the label SamDoesArts.  Although the burden of proving goodwill is quite significant, often requiring sufficient notoriety and distinctiveness of a ‘style’ such that it would automatically be associated with the artist’s work, Yang’s discrete following would likely militate in his favour.  Once established, this evidence would go a long way in proving that the AI-generated images in Yang’s style may have the potential to deceive those familiar with his work into believing that he was the source of their creation.The question is: who would ultimately be liable for passing off in the imitation of Yang’s style?  On the one hand, while the developer of the AI model in question may not itself be trading in imitations of Yang’s work, their mere provision of a service that could be used to train algorithms to generate stylistically similar works might lead potential purchasers of Yang’s artwork to quite simply use this technology to replicate his style.  But while the likelihood for damage to his goodwill exists, it’s not the AI model itself that creates the risk of confusion; anyone using it remains clear that the images generated didn’t originate from Yang himself.  From this perspective, then, it’s those who use these images in public-facing situations, where the potential for confusion as to the provenance of the artwork might occur, that would likely be liable under the tort of passing off.  Although this approach may not provide a remedy for those situations in which Yang might lose a sale where ordinary users generate images in his style for personal use rather than purchase one directly from him, it does at least tackle the unfair competition arising from the commercial use of images produced by this algorithm in his style.I am not, through this analysis, contradicting the uneasiness expressed by many authors and artists who feel as if their creative expressions are being misused by generative AI, nor am I claiming that these issues shouldn’t be tackled by the law.  What I am saying is quite simply that copyright isn’t the appropriate legislative vehicle to address all the harms suffered by pre-existing authors arising from the use of generative algorithms; that before jumping to the conclusion that copyright must tackle every single misuse of original works by AI, we must carefully consider whether the harm in question is, in fact, a copyright harm.  If it isn’t, we must resist the urge to inappropriately expand the scope of copyright, and quite simply rely on other legal avenues that are better suited to address the harms in question.  Doing otherwise risks producing unnecessary and avoidable harms that are far more threatening to our free and democratic society.",N/A
Stephen Spong,Academic,"The speed with which AI has evolved even in the past 12 months shows little sign of abating, even with legal challenges such as recently brought forward by the New York Times against OpenAI attempting to curb this growth. At the time of this writing (January 2024), being overly hasty in coming to conclusions about the current capacity for AI systems could lead to unintended consequences in terms of overly or insufficiently regulated areas. As per the Canadian Association of Research Libraries’ (CARL) submission, current best practices should be guided by the Innovation, Science, and Economic Development Canada’s Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems as well as frameworks established through legislation.While it is a delicate balance, at this point the restriction of AI should be limited as excessive restriction would likely have a deleterious effect on innovation. It is hoped that as the capacity and uses of AI are better understood, both governments and the courts would be able to further provide guidance through legislative and judicial means to ensure that growth is managed in a responsible manner.","The inclusion of a line of questioning around TDM is curious given the current lack of explicit language in the Copyright Act that permits such activities or provides guidelines for what is legally permissible and - in the case of the Canadian copyright framework - non-infringing. This lack of clarity has diverted researcher focus, time, and effort away from their research topics with an unnecessary infringement risk.It would be a welcome change to the Copyright Act to include language that provides clarity around TDM. The current framework (or lack thereof) impedes research by requiring a significant amount of copyright due diligence before meaningful work can be done with the raw data. A distinction should be made regarding commercial and non-commercial TDM activities, with the latter including research and educational uses that are non-compensable.Both the Canadian Association of Research Libraries (CARL) and Canadian Federation of Library Associations (CFLA) submissions include expanded rationales for expanding TDM provisions, highlighting that many key Canadian trading partners including the UK, EU, and Japan already have such provisions and that there has been a commensurate uptick in research activity and outputs. This submission supports that position.","Because AI-generated works do not involve a human exercise of skill and judgement, they do not merit copyright protection. This is a principle that is by now well-established in case law, starting with CCH Canadian Ltd. v. Law Society of Upper Canada, 2004 SCC 13, [2004] 1 SCR 339.However, in response to the Government’s question of “propos[ing] any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?” it would be worthwhile to amend the Copyright Act to further enshrine the principle of human involvement as a necessary element of authorship.","Liability and statutory damages for infringement are already set out in the Copyright Act, with limitations for educational institutions, libraries, archives, and museums.",N/A
Heather Morrison,Academic,"In libraries, machine learning AI in the form of recommender systems ranking results by relevance (like Netflix) is in widespread use. Generative AI is in earlier stages of exploration and/or implementation in libraries and information management as a means of further automating and enriching information resource description and classification. On the other hand, the tendency of popular AI tools such as ChatGPT to invent content is raising concerns about spread of mis- and disinformation, complicating the work of ensuring that the public has access to high quality, accurate information. In academia, AI is in early stages of use for the purposes of accelerating research. AI raises both interest and concern with respect to pedagogy. Noteworthy examples of emerging types of applications include language learning supports for students, brainstorming, and automated translation, noting that results to date are best considered as early drafts.","TDM for discovery purposes should be legal across all kinds of materials (e.g. to find songs, films, novels, and stories of interest, not for AGI training). To facilitate the advances AI is making possible in scientific and non-commercial research, TDM for training AGI should be legal for these purposes (follow UK / Switzerland example). One recommended change in copyright law to facilitate AI advances in Canada is to eliminate Section 41 Technological Protection Measures and Rights Management Information from the Copyright Act. This section prohibits circumvention even for purposes that are legal under the Act while it is unnecessary for purposes that are illegal under the Act. AI developers should be required to track and disclose materials used for training purposes. Legislation to this effect at this time would encourage development of efficient automated processes at an early stage in AI development.","Rapid growth of AI-generated content demonstrates that concerns about authorship and ownership are not a significant impediment. A Google search for ""Amazon ChatGPT self-publishing"" retrieves over 21 million results, with how-to books and publishing services at the top of the list. ChatGPT can produce a story ""in the style of"" a human author such as Margaret Atwood in seconds. This rapid growth raises two types of concerns 1) for human creators whose works and identity can easily be used with AI training to create new works to compete with the original creator and 2) for increasing production and distribution of mis/disinformation when a tool like ChatGPT (described by AI experts as having a tendency to ""hallucinate"") is used to create nonfiction works without the oversight of human experts.",N/A,"Achieving the potential benefits of AI requires TDM exemptions for scientific and non-commercial research following the UK / Switzerland example and elimination of Section 41 of the Copyright Act Technological Protection Measures and Rights Management Information. Most potential benefits of AI do not involve the use of others' copyrighted material – for example, companies and individuals using AI to automate or build on their own work. Encouraging AI users to make use of the copyrighted work of human creators raises two concerns, 1) the possibility of training AI using the work and identity of a human creator to capitalize on their identity and compete with them in the marketplace, and 2) the possibility of increasing creation of mis/dis-information in the case of non-fiction works. Concern about AI identity misuse is broader than traditional copyrighted works, for example use of images of individuals in pornographic works without their knowledge or consent."
Cohere Inc.,AI Firm,"(1) How does your organization access and collect copyright-protected content, and encode it in training datasets?The prevailing method followed by research organizations and companies to train AI models is to filter and encode data from a wide variety of sources, including publicly available, proprietary and synthetic data. In some cases, data that is subject to access controls may be used where access is permitted technologically or authorization has been obtained from the individual or entity who controls access to the data.The encoding process entails presenting information or other data as machine readable numerical tokens. These tokens are then computationally analyzed to train the model. During this training process, the model learns by identifying patterns occurring across a broad spectrum (represented by numerical tokens), and then compressing its learnings in the form of statistical correlations (e.g., model weights). Post-training, the model undergoes further retraining and safety and model evaluation processes to create a model that would be ready for operation. In addition, the models may be further fine-tuned with additional data, such as customer data or domain-specific proprietary data, in a process that tailors the model for more specific tasks or use-cases. Finally, once in operation, models are continuously monitored and evaluated to allow for the ongoing iteration and improvement of the models.As such, the inclusion of any individual datapoint in the training of the model (e.g., one individual piece of text) does not determine the model’s result. Rather, the model’s usefulness depends on the quantity and diversity of the data as a whole because AI models learn by synthesizing and aggregating diverse human knowledge that is presented during training and fine-tuning.Foundational large language models must be trained on large amounts of data (billions, if not trillions of data points), which, by necessity, requires accessing publicly available data online. Large amounts of data are required for a multitude of purposes, including to:- Develop, build and deploy models that are useful for learning and building on ideas and creating new knowledge and tools;- Ensure that the model learns statistical information representing all the complexities of semantic meaning and grammatical structure;- Evaluate and test models;- Identify and reduce the risk of bias and other potentially harmful outputs; and- Update and re-train models from time to time.Fulfilling each of these purposes is dependent on large, diverse data sets. The developer also needs large, diverse datasets so that the resulting model will understand different speech patterns, including everyday human speech, technical jargon, and literature. If the training data is limited—e.g., if it excludes entire categories of speech, or contains only a limited number of examples—the resulting model will not capture all of the nuances and statistical patterns that reflect the complexity of human language. That, in turn, will limit the function, usefulness, and flexibility of the resulting model.(2) How does your organization use training datasets to develop AI systems?See response to preceding question for a description of the prevailing method followed by research organizations and companies to train AI models.(3) In your area of knowledge or organization, what measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works?Among generative AI platforms, some of the available measures to mitigate the risk of AI-generated output infringing copyright include:- Testing, evaluating and fine-tuning models to reduce the likelihood of output replicating an existing work;- Deploying content filters and technical controls – e.g., software that evaluates generative output to identify and remove output that may replicate an existing work; and- Requiring users to comply with codes of conduct or usage guidelines which prohibit the use of AI systems for the purpose of generating infringing output.As AI-models and filters improve over time, the likelihood of AI-generated output infringing copyright (which is already low) will continue to fall.(4) In your area of knowledge or organization, what is the involvement of humans in the development of AI systems?Humans are involved at each stage of development and deployment of an AI system including:-Defining the objectives and operating parameters of the AI system;-Designing the model architecture and development the AI system in which such models are embedded within;-Collecting, selecting, preparing and encoding of data used to train and fine-tune models;-Collecting, selecting and encoding of post-training data used to enhance and fine-tune models, including related evaluation and experimentation;-Testing models to assess performance and the risk of biased or harmful output;-Fine-tuning models to enhance performance and safety, including to mitigate the risk of biased or harmful output; and-Deploying, operating and monitoring the performance of the AI systems and embedded models, including those that are put into production.(5) How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?Businesses and consumers use AI systems to, among other things:- Summarize and review large volumes of text to extract meaningful insights or information;- Generate text that is informed by the AI systems, such as generations for a certain audience;- Obtain information about publicly available or proprietary information (if fine-tuned on such) to inform decision making; and- Educate and improve access to disparate sources of publicly available information.","(1) What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?Clarity around copyright and TDM in Canada are prerequisites to the AI industry in Canada making the transition from a global leader in research and development to a viable market from which to scale up and operate successful companies.Harnessing the societal benefits of artificial intelligence through the development and commercialization of “safe, secure and trustworthy AI” – which is the underlying objective of the G7’s Hiroshima Process International Code of Conduct for Organizations – requires accessing publicly available data online.A lack of clarity around copyright and TDM will undermine Canada’s ambitions to be the home of world leading AI companies and ecosystems and risks entrenching global incumbents with access to vast amounts of information and compute, or entities with significant financial resources and ability to exclusively acquire such information to the exclusion of others, and withstand years of regulatory and legal uncertainty. AI companies and ecosystems will migrate to those jurisdictions with laws that either provide this clarity or are otherwise more favourable to AI development and commercialization – such as the United States, Japan and Singapore.Similarly, the lack of clarity related to TDM activities and copyright has undermined the building of AI infrastructure, specifically access to in Canada. The lack of access to large- scale, cost- effective AI compute has downstream effects, including limiting access to compute for researchers, civil society, and downstream deployers especially in sensitive sectors such as healthcare, finance, and public sectors, and AI sovereignty implications. Canada’s global ranking in AI is currently falling as other countries advance their own AI strategies, attract top AI talent, and invest in AI compute. A report from Tortoise Media found that Canada’s global AI ranking fell from fourth to fifth, and a significant drop in Canada’s global ranking was attributed to Canada’s lack of AI infrastructure.It is also reasonable to expect that uncertainty around copyright and TDM in Canada may undercut the distribution and deployment of AI systems in this country, further increasing the growing productivity gap between Canada and other leading economies, including the United States. The resulting uncertainty of a short-sighted approach may culminate in a Pyrrhic victory for copyright in Canada—with a potential opportunity to leverage Canada’s world-leading AI talent and resources squandered as the world adopts AI, the result being a tiny fraction of the economic value and wealth that should have been created. Such a loss may be incalculable and irrecoverable. (2) Are TDM activities being conducted in Canada? Why or why not?Only limited TDM activities (largely for non-commercial research) are being conducted in Canada. TDM for commercial purposes is mostly being conducted in the United States, Japan, Israel, South Korea, and other jurisdictions with laws that are more supportive of AI development and commercialization. Given that capital, AI infrastructure development and talent will gravitate to jurisdictions with favourable laws, this trend can be expected to continue as AI development grows.For TDM activities to become more prevalent in Canada, and for Canada’s capacity to enable the scaling-up of domestic AI-companies, it is critically important for Canada’s laws to provide certainty – either through favourable judicial decisions interpreting existing provisions in the Copyright Act or through the addition of a new exception to the Copyright Act specifying that TDM activities do not infringe copyright.(3) Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?TDM does not infringe copyright, making the licensing of works for TDM activities unnecessary for publicly available data. The process of training models involves learning concepts and facts from, and identifying patterns found in, data – similar to how an individual who reads a book gains knowledge. As these concepts, facts and patterns are not protected by copyright, copyright law should not be interpreted to prevent AI training.Furthermore, the computational analysis undertaken by an AI model during training does not involve the consumption of copyright protected data for their expressive content. Rather, such analysis involves mathematical calculations of probabilities, correlations, trends, and other patterns across the entire tokenized data set. Such analysis seeks to understand only the mathematical patterns (e.g., the relationships of specific tokens in relation to other tokens) distributed across the entire data set. These mathematical patterns are themselves not expressive content protected by copyright law.More broadly, the non-expressive encoding data does not have an impact on the market for an underlying work or related revenue models or the economic interests that copyright is intended to protect, as the rights holder continues to control access to the work. Restricting access to a work allows the rights holder to prevent the work from being used to train AI models. It also provides the rights holder with the option of making access to a work available for a fee. There exists today a multitude of business models and technological protection measures that can be – and are being – used by rights holders to control access to their copyright-protected works to generate revenue streams through voluntary licensing.(4) If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?Canada should adopt an express amendment to the Copyright Act to cover TDM activities. Such an express amendment should extend to:- Commercial and non-commercial uses;- All works and other subject matter; all copyright-relevant acts, including retention of data for purposes of verification and validation of results; and- The provision of AI services (i.e., permit service providers to perform AI activities on behalf of its end-users).An amendment to the Copyright Act to confirm that TDM activities do not infringe copyright should also make clear that TDM activities do not override access controls. The Copyright Act already includes provisions addressing technological protection measures, making the inclusion of new restrictions unnecessary. (5) Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?There has been significant discussion around compelling AI developers to disclose the datasets on which they have trained. We believe that would be a misguided policy decision for several reasons.First, such a requirement would be largely unworkable in practice:- LLMs are generally trained on a wide variety and innumerable quantities of publicly-available source material, such as web-crawled or scraped data, the very nature of which is disparate and ever-shifting. This stands in stark contrast to other technologies that rely on smaller datasets, which lend themselves to being provided or managed by a centralized provider. Correspondingly, because there is no central set of data vendors or a standardized approach to referring to individual copyrighted work, the copyright status of individual works contained in billions or trillions of datasets are effectively impossible to discern. Furthermore, there is significant variation in the nature and extent of metadata associated with each item of training data, and none that is specific to the copyrighted status of content that is publicly available.- LLMs are deployed internationally. Consequently, the burden of harmonizing copyright law for any given dataset across geographies prior to deployment would practically mean that no useful model would ever get off the ground.- Development of foundational models is an ongoing process that involves substantial amounts of work to filter and refine the training data used for each version of a model. Data used for one version of a model may not be used for a subsequent version and vice versa, multiplying the complexity of maintaining an up-to-date list of every copyrighted work that forms part of the training data for a specific version of a foundational model.- Every iteration of this technology may give rise to new considerations about data use and integration that are impossible to forecast, infinitely complicating the model training process. Consequently, prior to and at various stages during the model training of a new model iteration, the datasets themselves and aspects thereof need to be refined, structured, categorized or manipulated in a multitude of ways to address various factors from model efficacy to safety.Second, requiring developers to disclose the datasets used to train models would result in the disclosure of proprietary and commercially sensitive information.Third, and perhaps most important, compelling disclosure of training data for LLMs is at odds with existing copyright law principles given that TDM activities do not infringe copyright. To the extent that the Government of Canada still seeks to pursue any record-keeping or disclosure obligations, they should be aligned with globally recognized principles of responsible AI or corresponding current or emerging regulatory obligations and be limited to high-level disclosures (e.g., listing categories of data types used in training).(6) What level of remuneration would be appropriate for the use of a given work in TDM activities?Remuneration would not be appropriate given TDM does not infringe copyright. See our response above to Question 3.","(1) Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?Existing copyright principles can be applied to determine whether an AI-generated work or other subject matter is subject to copyright protection. The use of AI to create a new work entails an individual exercising their skill and judgment to prompt an AI-system or tool to generate a new work. An AI-generated work is often enhanced or modified, both with additional prompts and non-AI activities, to create a finished work. Whether the exercise of skill and judgment by an individual is sufficient to meet the test for originality and intellectual effort under Canadian copyright law can be assessed by the courts.(2) Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?Legislative amendments are not needed. As explained in our response to the preceding question, existing copyright principles can be applied to determine whether an AI-generated work or other subject matter is subject to copyright protection.","(1) Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?Existing copyright principles can be applied to determine whether an AI-generated work or other subject matter infringes copyright.(2) When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?Among generative AI platforms, some of the available measures to mitigate the risk of AI-generated output infringing copyright include:- Deploying content filters and technical controls – e.g., software that evaluates generative output to identify and remove output that may replicate an existing work; and- Requiring users to comply with contractual obligations, codes of conduct or usage guidelines which prohibit the use of AI systems for the purpose of generating infringing output.As AI-models and filters improve over time, the likelihood of AI-generated output infringing copyright (which is already low) will continue to fall.(3) Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Existing copyright principles can be applied to determine liability if an AI-generated work infringes an existing copyright-protected work.","(1) Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?Japan, Singapore, Israel, South Korea and the United States are jurisdictions that should be used to inform a Canadian consideration and approach to TDM. Japan and Singapore have amended their copyright laws to specify that TDM (or “computational data analysis”) is permitted for both commercial and non-commercial purposes, providing much-needed clarity for AI companies and ecosystems. While the United States does not have an express exception for TDM in its Copyright Act, it is a jurisdiction that is widely regarded as having laws more favourable to AI development and commercialization. Notably, the “fair use” exception in the US Copyright Act is more flexible than the “fair dealing” exception in Canada, since “fair use” is not restricted to a specific list of enumerated purposes that limit the scope of “fair dealing” in the Canadian Copyright Act and thus could hinder TDM activities in Canada for certain purposes. Israeli and South Korean copyright laws allow for fair use similar to the US’s fair use exception.Given the global and borderless nature of the development and deployment of generative AI, Cohere believes that it is vital for Canada to maintain interoperability with rules, regulations, and norms in other jurisdictions such as those listed above. To the extent that Canada was to distance itself by failing to adopt an express TDM amendment in copyright law, other jurisdictions would highlight this policy shift to become more attractive hubs of AI training and development. Furthermore, creating an outlier training regime in Canada would diminish access to diverse and differentiated AI models, leading to fewer available models in Canada, depriving Canadian businesses from access to state-of-the-art tools enjoyed by their foreign counterparts. Not only would the number of models be reduced, but the quality of those models would also suffer, as the ability to train on a diverse and global dataset, which is crucial to building AI systems that are safe, accurate, representative, and unbiased across many different regions and cultures, would likewise be significantly diminished.(2) Technical Measures and Outputs of AI SystemsWe are aware of some content creators’ concerns that the outputs of AI systems may be similar to the information on which the AI systems were trained. We view such outputs as a solvable technological challenge in AI systems, one which we are committed to mitigating through further development of AI systems and through the implementation of technical measures. We note, as have others, that such phenomena are difficult to reproduce and have been observed mostly through teams seeking to intentionally and actively force a model to generate those specific outputs. In other words, other than researchers testing the capabilities, weaknesses, and limitations of early LLMs, users have not reliably experienced reproductions of training data through typical usage. We believe that further testing, evaluation and fine-tuning of foundation models will result in a further reduction of the potential for this to occur. Models are trained to, and fundamentally their value is derived from, their ability to effectively and efficiently provide insights into, and unlock information about, an existing corpus of data, not reproduce it.(3) ConclusionCanada should adopt an express amendment to the Copyright Act to cover TDM activities. Such an express amendment should extend to:- Commercial and non-commercial uses;- All works and other subject matter; all copyright-relevant acts, including retention of data for purposes of verification and validation of results; and- The provision of AI services (i.e., permit service providers to perform AI activities on behalf of its end-users).Such an express amendment would:- Continue to maintain the balance between “promoting the public interest in the encouragement and dissemination of works of the arts and intellect and obtaining a just reward for the creator.”->This is because the training AI models do not displace the market for the underlying work. Based on how machine learning works and its purpose – to create new content – it is fair to conclude that the “information analysis” undertaken during model training is highly unlikely to harm the primary purpose of the original work. The objective is not to republish or compete with the work used for training purposes but rather to ensure that the text and data inputs can be used for analysis. It is for this reason that commercial use in a TDM exception will not negatively implicate rights holders’ copyright interest.->The “information analysis” is transformative and not replicative.- Be consistent with Canada’s international obligations. The TRIPs Agreement and Berne Convention require Member States to ensure that exceptions to copyright are confined to “certain special cases which do not conflict with the normal exploitation of the work and do not unreasonably prejudice the legitimate interests of the rights holder.”There is a lot at stake in the outcome of this consultation, particularly as it relates to TDM activities. If Canadian law prohibits TDM activities without a license or imposes a statutory remuneration regime, the ability of Canada to realize the many societal benefits of AI – including improved health care delivery, climate change measurement and reduction, enhanced productivity, and globally successful AI companies – will be compromised.Amending Canadian copyright law to provide rights holders with a new right to control TDM will not result in rights holders acquiring new revenue streams, as any meaningful TDM activities will be conducted outside Canada. Inadvertently, adding such a right will also undermine Canada’s emerging AI ecosystem and all but guarantee that development and commercialization of AI will happen largely elsewhere. More broadly, it also could result in AI systems, including systems that are critical to advancing health care, addressing the climate crisis and closing Canada’s productivity gap, not being made available for use in Canada.Thank you for the opportunity to submit our responses. We look forward to continuing to work with all stakeholders to clarify the best path forward for all."
Google,AI Firm,"Our Approach To Developing Artificial IntelligenceRecent years have seen huge breakthroughs in the use and application of artificial intelligence — and AI holds major promise for people around the world. It has the potential to unlock major benefits, from better understanding diseases to mitigating climate change and driving prosperity through greater economic opportunity.AI also already powers Google's core products, which help billions of people every day. Whether it's asking for movie times, finding the nearest doctor, or finding better routes home, our work in AI is centered on improving people's everyday experiences. Some of our most popular products at Google — like Lens and Translate — have at their core AI technologies like optical character recognition and machine learning. And countless other Google products now have AI built into them, making them more helpful to billions of people.Many of these improvements are possible thanks to Google Research's introduction of the Transformer model in 2017. The Transformer is considered the foundation of modern language models; on top of this architecture we are now able to build AI language models — like BERT, PaLM, MUM, LaMDA, and Gemini — that can do everything from solving complex math word problems to answering questions in new languages. They can even express their reasoning through chain-of-thought prompting.We believe our approach to AI must be both bold and responsible. To us that means developing AI in a way that maximizes the benefits to society while addressing the challenges. We were one of the first companies to publish a set of AI Principles, and we use an AI risk-assessment framework to identify and mitigate risks. Google DeepMind likewise adheres to our AI Principles and has a dedicated internal governance body — the Responsibility and Safety Council — tasked with upholding them. We also constantly learn from our research, our experiences, our users, and the wider community — and incorporate what we learn into our approach to developing and deploying AI.How AI Systems Work Artificial Intelligence and Machine LearningBefore discussing the process of machine learning, it is important to understand some basic terminology and types of AI systems. The term artificial intelligence describes a broad and diverse set of technologies. AI systems can be built in many ways. For instance, the computer opponent in a basic chess app might have some deterministic behaviours that are hard-coded by the developer in the form of if-then statements known as decision or production rules. The same is often true even of more advanced AI systems. The Deep Blue chess system that was the first computer to win a match against reigning world champion Gary Kasparov in 1997 was an expert system built using a large rule-set meant to imitate experts in a deterministic manner.Much of the recent progress we've seen in AI is based on machine learning (ML), a subfield of computer science where computers learn to recognize patterns from example data, rather than being programmed with specific rules. Because of the way they are built, ML models are able to complete tasks and solve problems that would have been impossible for expert systems. Deep learning is a specific ML technique based on neural networks. Neural networks use nodes or ""artificial neurons,"" inspired by models of brain neurons, as fundamental processing units which receive numeric inputs from, and pass outputs to, other neurons. Deep learning connects multiple layers of these artificial neurons. The interconnections between these neurons, also referred to as nodes, are numerical weights that essentially represent the importance of the contribution of that neuron to the final output. It is also relevant to note that there is no copy of the training data — whether text, images, or other formats — present in the model itself. Deep neural networks themselves determine the attributes of the data that they use to recognize patterns, as opposed to a human coder setting those attributes manually.For example, the AlphaGo model, developed by Google DeepMind, was the first computer program to defeat any professional human Go player and, soon after, the first to defeat a Go world champion. To accomplish that, AlphaGo had to employ an ML model. That is because Go is a profoundly complex game, one googol (10100) times more complex than chess. The power of the decision-making engine underlying Deep Blue would have been no match for a Go world champion.ML models have long been used for classification or prediction purposes, e.g., a system that can detect cats in photos or predict vehicular traffic patterns. However, recently, the ML models that have captured the most attention are generative AI models.Generative AIGenerative AI models can use what they have learned to create new content, such as text, images, music, and computer code. A ""large language model"" (LLM) is a generative AI model that finds patterns in human language, making it suitable for a range of writing tasks, including predicting the next words to complete a sentence or suggesting grammatical edits that preserve what you mean to say. During training, a model evaluates the proximity, order, frequency, and other attributes of portions of words, called tokens, in its training data. Tokens represent language data in its most disaggregated form. For example, the word ""indistinguishable"" is made up of three tokens: ""in"", ""distinguish"", and ""able"". The model itself selects which attributes of tokens to use. In this way, training is the discovery of probabilities of relationships between the tokens — ultimately not in any individual text, but in all of the text on which the model is trained. The trained model then comprises a large network of weights that represent these learned relationships. The model can then respond to a prompt and generate new text with a probability of addressing the prompt as determined by its training.Generative AI models are not databases or information retrieval systems. To be sure, when, for instance, an LLM is prompted for facts, it can generate articulate responses that may give the impression that it is retrieving information. But, fundamentally, the model is generating responses based on a statistical estimation of what a satisfactory response should look like. Put simply, it produces an average group of words, pixels, or sounds related to a prompt. Some have referred to this as, not an answer, but merely ""answer-shaped."" To understand how generative AI systems are built, it is easiest to take as an example the LLMs — like LaMDA, PaLM, and MusicLM — that underlie many of Google's latest AI advances.The technical process of ""learning"" for an LLM begins with training the model to identify relationships and patterns among words in a large dataset. Through this process, a generative AI model will adjust its parameters to reflect the mathematical relationships in the data. Once the model has adjusted its parameters to accurately reflect these relationships, it can then use them to generate new outputs based on those parameters. The number of parameters needed to capture the complexities and nuances of human language and facts about the world is vast.LLMs are developed in multiple stages, including pre-training and fine-tuning. Pre-training is a way of training an ML model on a wide variety of data. This gives the model a head start for when it is later trained on a smaller dataset of labeled data for a specific task. When an LLM is pre-trained, training material is analyzed to examine and extract statistical relationships among the individual tokens, words, and sentences, e.g., their frequency, importance, and semantic relationship to each other. The AI ""model"" is simply the encapsulation of those statistical facts in numbers. And given enough content — on the scale of hundreds of billions of tokens — the model may be able to embody the ways human language hangs together as a whole in the form of its parameters and nodes. Importantly, given the volume of tokens that models need to train on, any particular work standing alone is not essential or even necessary for that training. Instead, it is the total collection of works that is needed to train an AI model. Following pre-training, the model can be refined through a process called fine-tuning. Fine-tuning an LLM is the process of adapting a pre-trained LLM to improve its performance on a specific task. The model learns from additional example data to help hone its capabilities. For instance, one can fine-tune a general purpose LLM to teach it how to summarize technical reports in general by using a smaller set of examples of technical reports and accurate summaries.","Text and Data Mining ExceptionsInnovation in AI fundamentally depends on the ability of LLMs to learn in the computational sense from the widest possible variety of publicly available material. Fair use and text and data mining exceptions around the world support innovation by ensuring that developers are able to assemble the building blocks needed for the development of AI. These provisions further the purpose of copyright law by purposefully and carefully balancing protections for creators with the need for innovation and cumulative creativity.Canadian law already includes important exceptions and limitations to copyright that support the training of AI models. The fair dealing exception for research and private study is generally understood to include AI training, as ""many uses [of copyrighted works] made for machine-learning purposes are likely to be ""fair"" under the second step [of the fair dealing test], not least because such copies do not compromise the core interests of the copyright owner or substitute for the work of the author in the market."" Similarly, the exception for ""temporary reproductions for technological processes"" could also apply to the training of AI models in circumstances where the copyrighted works included in the training models were not retained beyond what was required for the training. However, to further encourage innovation, policymakers should consider creating even more certainty through the adoption of an express text and data mining exception for both research and commercial uses. Indeed, after conducting an extensive mandatory review of the Copyright Act, the Standing Committee on Industry, Science and Technology similarly concluded that ""facilitating the informational analysis of lawfully acquired copyrighted content could help Canada's promising future in artificial intelligence become reality"" and recommending ""that the Government of Canada introduce legislation to amend the Copyright Act to facilitate the use of a work or other subject-matter for the purpose of informational analysis"".It is not a coincidence that the leading innovative countries in the world have fair use or a specific text and data mining exception that includes commercial uses. And Canadian policymakers should consider a similar model to ensure that AI developers have the certainty necessary to invest in AI in Canada. For example, Japan's ""non-enjoyment"" statute recognizes that it must be permissible to use a work when the person's purpose is not to personally enjoy the work, but simply for use in data analysis. Singapore's Copyright Act similarly recognizes that copies made in the course of computational data analysis are permitted. Jurisdictions that recognize a flexible fair use exception, such as the United States, have held similar activities to be legal fair uses. And when the European Union's Copyright Directive (""EUCD"") adopted provisions on text and data mining (""TDM"") for both research and commercial uses, it did so with an understanding that these new technologies held enormous beneficial promise.These types of provisions are also in line with the Berne Three-Step Test. As explained in A Balanced Interpretation of the ""Three-Step Test"" in Copyright Law (""Munich Declaration""), the Three-Step Test's restriction of limitations and exceptions to exclusive rights to certain special cases do not prevent legislatures from introducing open-ended limitations and exceptions, so long as the scope of such limitations and exceptions is reasonably foreseeable. Additionally, limitations and exceptions do not conflict with a normal exploitation of protected subject matter, if they are based on important competing considerations. Finally, the Three-Step Test should be interpreted in a manner that respects legitimate public interests, notably in scientific progress and cultural, social, or economic development.Fair use provisions as well as narrower legislative exceptions that permit text and data mining for purposes of training machine learning models fit this description. Their scope is reasonably foreseeable and does not conflict with the normal exploitation of copyrighted works as copyright protection has always focused on protecting expression, not facts within or about that expression. And, as already described, the public interest in the scientific progress such uses make possible is entirely appropriate to consider when conducting a Three-Step analysis. Professor Martin Senftleben, who has written extensively about the three-step test, has even argued that TDM is not a traditional category of use that could be contemplated by existing international treaties – rather, it is 'an automated, analytical type of use that does not affect the expressive core of literary and artistic works', which therefore falls outside international copyright harmonization, and the three-step test, altogether.We understand that some have argued that AI developers should be required to license or get permission for training. However, such a requirement would be essentially impossible given the large amount of data needed to train AI models and the lack of comprehensive data about copyright ownership. As a result, it would effectively block the development and use of large language models and other types of cutting-edge AI. And if innovators are unable to leverage these building blocks needed for the development of AI, the many opportunities that come with this technology will be at risk. We will not be able to use AI to help unlock scientific discoveries and to tackle humanity's greatest challenges and opportunities – from improving cancer screening to developing solutions to tackle climate change. In addition, any limitation on the ability to train on publicly available material increases the risk that models will be trained on non-representative data — including potentially excluding marginalized or alternative voices from the training data. For example, restrictions or impediments to the training of models might lead some model developers to favor older data sets (such as out-of-copyright books from more than 100 years ago that are in the public domain) -- which could result in model outputs being skewed based on biased or inaccurate assumptions about, e.g., race, nationality, gender roles, and gender identity.Some have suggested a collective licensing structure as a potential solution to these challenges. However, there simply aren't any copyright collectives governing the wide array of copyrightable works that are currently being used (or could potentially be) in large data sets, or that fully cover the wide array of works within a class (e.g., non-Canadian works, etc). And in instances where there are collectives governing certain specific commercial uses of certain specific classes of works, a requirement to license a certain class would create an incentive to not develop AI models using those classes of works in favour of others which do not require a license (e.g., public domain, open source, non-copyrightable, etc). As a result, Canadian policymakers should reject proposals that would require licensing or permission to train AI models.There has also been significant discussion about compelling AI developers to disclose the datasets that they have trained on. Most LLMs are trained on a wide variety of publicly available online data, including web-crawled data, rather than on 'offline' datasets that are prospectively compiled and documented. Given that fact, a disclosure requirement would be unsound policy for several reasons. First, the source of much of the training, validation, testing, and input data is the massive volume of content available on the entire open World Wide Web — in contrast with models that use a limited number of well-defined, readily identifiable sources. Second, identifying the datasets used to train particular systems would expose competitively sensitive (and potentially trade-secret-protected) information. And third, AI developers do not have access to detailed or accurate information about copyright status, ownership, or licensing terms for the content available on the public web. In fact, there is no such source of truth anywhere in the world. Thus, complying with disclosure rules may simply prove impossible from the start. In addition, recently Google and other AI developers announced improved web publisher controls for training of generative AI models. These controls, and others like them soon to follow, make disclosure requirements unnecessary because they enable rightsholders to know and control ex ante whether their online content may be used for training of future models. Further, giving web publishers the ability to choose whether or not their content may be used for training may also facilitate new, market-based solutions.","Authorship and Ownership of Works Generated by AIScholars and policymakers alike have recognized that AI systems do not need an incentive to create, and so there is no sound public policy reason to extend copyright protection to AI-generated works. That said, the presence or absence of sufficient human intervention in the creative process is a nuance that will need to be addressed on a case-by-case basis. In particular, it is likely that most commercial uses of AI will entail at least some amount of human creativity. There may also be many cases where creators use these tools integratively as part of their creative process. In that circumstance, the final work product may well be protected by copyright. The question of what the scope of that copyright would be is a matter properly handled by the copyright offices and courts in the context of specific disputes.","Infringement and Liability regarding AIWe believe that existing copyright rules regarding infringement and liability, specifically those relating to platform safe-harbours, are sufficient to address the unique issues raised by AI technologies. The structure of the existing regime carefully balances the protections for rightsholders against the burdens on other stakeholders. It would be contrary to sound public policy to make any amendments to the Copyright Act that would unduly increase the obligations or risk for copyright infringement liability of internet intermediaries, including, but not limited to, amendments that could make intermediary stakeholders liable for replicating a style or method of creation and amendments that would exclude developers of generative AI systems from the safe harbour provisions at section 31.1 of the Copyright Act.In most jurisdictions, a work is not infringing unless its creator has improperly copied expressive content from a copyright-protected work — for example, under Canadian copyright law, a work must be produced or reproduced in ""substantial part"" for there to be infringement. Some have offered more novel infringement theories, challenging replication of an artist's style or arguing that all output of an AI system is an infringing work of the content the system was trained on. These theories are not founded in any cognizable copyright principles, and in fact run contrary to accepted copyright canons.Styles and creative methods are not copyrightable. In Cinar v. Robinson, The Supreme Court established that courts must adopt a qualitative and holistic approach to determining whether elements of a work are ""generic"" and therefore not copyrightable in the context of an infringement claim. The ""style"" of a work is arguably too generic to attract copyright protection according to this approach. Extending copyright protection to styles would impede the creation of wide swathes of original works and would run headlong into core concerns around freedom of expression. It would be similarly troubling to create a rule that regulates the method of drawing from or looking at other works during the creative process as it would treat every instance of mere inspiration as a basis for a claim of infringement. As was recognized long ago in the U.S. case Emerson v. Davies, every new work ""borrows and must necessarily borrow, and use much which was well known and used before.""Under the Copyright Act, safe harbour provisions shield intermediaries from obligations or liability in connection with alleged or proven copyright infringement where the intermediaries only provide the technical means by which others infringe. Canada's technologically neutral copyright laws have allowed stakeholders to constantly innovate without negatively impacting the creative and economic interests of rightsholders and users. The law has long been wary of permitting rightsholders to hold up technologies merely because they could potentially be used for infringing purposes. In Society of Composers, Authors and Music Publishers of Canada v. Canadian Assn. of Internet Providers, The Supreme Court of Canada held that Internet Service Providers do not authorize infringement by merely providing connectivity to their users—connectivity that the court emphasized was an important innovation for the dissemination of works. This holding mirrors a similar doctrine in U.S. copyright law which states that products or services that have substantial non-infringing uses do not invite copyright infringement. This rule exists to limit the copyright monopoly to its proper scope so that new technologies and the markets for them are allowed to develop. Generative AI is a technology engineered to create new works, not to copy or facilitate the copying of existing works. Excluding developers of generative AI systems from the Copyright Act's safe harbour provisions would put all innovation in the field of machine learning at risk.The possibility that a generative AI system can, through ""prompt engineering,"" be made to output content that is substantially similar to existing content does raise questions around the proper boundary between direct and secondary infringement. When an AI system is prompted by a user to produce an infringing output, any resulting liability should attach to the user as the party whose volitional conduct caused the infringement in the same way that the current Notice and Notice regime is designed to hold the internet subscribers committing infringing actions accountable for their behaviour rather than the internet service providers. The AI developer can be liable (or not) under doctrines of secondary copyright liability based on whether they had any actual knowledge that specific infringing material was being created using its system. A rule that would hold AI developers directly (and strictly) liable for any infringing outputs that users create would impose crushing liability on AI developers, even if they have undertaken reasonable measures to prevent infringing activity by users. Had that standard applied in the past, we would not have legal access to photocopiers, personal audio and video recording devices, or personal computers — all of which are capable of being used for infringement as well as for substantial beneficial purposes.We are aware of concerns that AI systems can output content that is substantially similar to individual pieces of content on which they were trained. According to the leading research paper in the field, this is an exceedingly rare occurrence, even under adversarial prompting. The possibility that AI models can occasionally, despite the best efforts of their developers, output content that replicates existing expression is a bug, not a feature, and developers are taking a range of measures to limit that occurrence even further, including deduplication of training data. This problem is well understood to be an open research challenge in the AI developer community and is, on that basis, a focus of significant attention that is expected to lead to effective interventions. It is a problem more effectively addressed technically, rather than legislatively.","How AI Will Unlock Scientific Discoveries, Help Organizations Tackle Societal Challenges, and Improve Our Everyday LivesAI's potential societal benefits to Canada and the world cannot be overstated. The technology's uses are extensive. From powering research that enables new scientific breakthroughs to product integrations designed to make everyday life easier, we're exploring responsible and innovative AI technologies that make a true difference for humanity. We are excited about the promise AI holds for solving some of the most persistent challenges facing our world.AI has the potential to significantly improve healthcare, including maternal care, cancer treatments, and tuberculosis screening. For example, understanding how a protein folds is important for medical research, but it is also time-intensive and painstaking. Google DeepMind's AlphaFold predicted 200 million protein structures that previously would have taken several years each to discover, effectively saving hundreds of millions of years of researchers' time. Structural biologists who use AlphaFold have seen their productivity grow 20% faster than those who do not. Google Research also recently announced a new LLM that could be a helpful tool for clinicians: Med-PaLM.AI can also help with mitigating and adapting to climate change: by tracking wildfire boundaries in real time; helping to reduce carbon emissions by decreasing stop-and-go traffic; and providing critical flood forecasts. Partnerships in the field of climate science will help organizations develop innovative solutions. For example, Google Research teamed up with American Airlines and Breakthrough Energy to bring together large amounts of data — like satellite imagery and weather and flight path data — to develop forecast maps to test if pilots can choose routes that avoid creating contrails (i.e., the thin, white lines sometimes seen behind airplanes that account for roughly 35% of aviation's global warming impact). This partnership showed that contrail avoidance has the potential to be a cost-effective, scalable solution to reduce the climate impact of flying.In addition, AI is powering progress in making the world's information accessible to people everywhere. Google's Data Commons project synthesizes publicly available data from government agencies and other authoritative sources into an open source, API-accessible knowledge graph available to everyone. It links references to unique entities (such as cities, counties, organizations, etc.) that exist across different datasets to nodes on the graph, such that users can access data about a particular entity aggregated from different sources without the significant data wrangling procedures required to clean or join records. Data Commons is also now using LLMs to create a natural language interface that allows users to ask questions, making it even more useful.And through our 1,000 Languages Initiative, we are working to build an AI model that will support the world's 1,000 most-spoken languages, bringing greater inclusion to billions of people in historically marginalized or underserved communities all around the world. While more than 7,000 languages are spoken globally, only a few are well represented online today. That means traditional approaches to training LLMs on text from the World Wide Web fail to capture the diversity of global communication. We've already made significant progress towards this goal with a Universal Speech Model trained on more than 400 languages. We also recently sponsored a competition that tasked researchers with developing AI models that could recognize American Sign Language Fingerspelling and translate it into text. Advances in this and similar areas can make the devices we all use more accessible.AI can also make a difference in our everyday lives. For example, AI is already powering many products that millions (and in some cases billions) of people use, such as Google Maps, Google Translate, Google Lens, and more. And now we are leveraging AI to help people ignite and assist their creativity with Bard, increase their productivity with Workspace tools, and revolutionize the way they access knowledge in Search. These types of tools have the potential to make everyday experiences easier, more productive, and more creative.How We Are Working With the Creative Community To Unlock New OpportunitiesWe also believe in AI's potential to amplify and augment human creativity, unlocking new opportunities for artists, creators, journalists, musicians, and consumers to engage creatively with new tools and expand the pie for everyone. In fact, we are already seeing creators exploring new areas, including the creation of new types of music, books, photography, and other art. We're excited about how AI can supercharge human creativity — not replacing it, but enhancing, enabling, and liberating it.With this in mind, we are committed to building tools that increase access to information and create new and expanded economic and creative opportunities for artists, small businesses, and creators of all kinds. To do this, we are working closely with the creative community to put these tools in the hands of creators and to tackle new challenges as they emerge.For example, we are working closely with our music partners to develop an AI framework to help us work toward our common goals. This includes YouTube's Music AI Incubator. The incubator will help inform YouTube's approach as we work with some of music's most innovative artists, songwriters, and producers in the industry, across a diverse range of culture, genres, and experience. We also announced a set of principles that will govern YouTube's work on AI.In addition, we announced Lab Sessions, a series of experimental collaborations with visionaries — from artists to academics, scientists to students, creators to entrepreneurs — to help them use AI to compose new music, support the creative writing process, better learn sign language, and more.Through the Google News Initiative, we are supporting training programs for journalists — so they can use AI in their work — and research into how AI can support the news ecosystem. In addition, we have built research tools like Pinpoint, which helps journalists and academics explore and analyze large collections of documents. Recently, a study by JournalismAI showed that almost three quarters (73%) of news organizations surveyed believe generative AI applications, such as Bard or ChatGPT, present new opportunities for journalism. Some respondents noted that AI can free up journalists' capacity for more creative work by taking on time-intensive tasks such as interview transcription and fact-checking.We are also prioritizing approaches that will allow us to send valuable traffic to web publishers, including news publishers. We've heard from web publishers that they want greater choice and control over how their content is used for emerging generative AI use cases. That is why we announced Google-Extended, a new control that web publishers can use to manage whether their sites help improve Bard and our Vertex AI generative APIs, including future generations of models that power those products. And it's why we're committed to engaging with the web and AI communities to explore additional machine-readable approaches to choice and control for web publishers.AI in CanadaGoogle's core platforms have long been powered by AI. Google was one of the first companies to use machine learning in our products and we became an ""AI first"" company in 2015. This technology offers radical potential for exponential growth, and Google is working to help Canada fully realize AI's economic potential.Google has been in Canada since 2001, with offices in Waterloo, Toronto, and Montreal, proudly supporting Canada's thriving tech sector and the Canadians who use our products everyday. Google has AI research labs in Toronto and Montreal.In Toronto, our mission is to drive innovation in neural network architectures and learning procedures in areas of strategic importance to Google. Beginning in 2016, the group's research spans a wide spectrum of basic questions in deep learning and diverse domains of application. This includes new architectures, new techniques for training neural networks, robust learning from small amounts of labeled data, and unsupervised learning. Current research is focused on four broad areas: neural network techniques, generative models, computer vision and graphics, and machine learning for systems and software.In November 2016, Google announced the launch of the Google Brain Team in Montreal, a deep learning and AI research group linked to Google headquarters in Mountain View. The following year, DeepMind Montreal was launched. Since then, the team has grown into a diverse group of research scientists and engineers and has made major contributions to DeepMind's mission and the scientific advancement of AI, contributing to over 45 scientific papers in leading machine learning conferences and peer reviewed journals. These include work in diverse topics such as: Infection detection, collaborative AI, ethical and social risks, and theorem proving.In 2023, Google Brain and Google DeepMind merged. Today, Google Research in Montreal performs both open-ended and applied research, in numerous areas including reinforcement learning, meta-learning, optimization, program synthesis, generative modeling, machine translation, and more. We also support the local academic community and have several academic collaborations, including with Mila – Quebec Artificial Intelligence Institute. In just five years, the local research teams in Montreal have helped boost the AI ecosystem in Canada, and the thriving research team is now helping reverse the ""academic brain drain""."
Microsoft Corp,AI Firm,"Access to data is critical for AI development. Recent groundbreaking advancements in AI require the ability to train AI models on vast amounts of training material. Large amounts of varied data is essential to allow AI models to perform accurately and without bias. For example, varied data sets enable diverse languages to be adopted and expressed in AI systems, allows varied cultural perspectives to be reflected, and enables AI to more broadly benefit everyone. Businesses, as well as open source AI projects, rely heavily on publicly accessible data to both develop and use AI.There is a shortfall in the data that companies and organizations have access to in order to benefit from the promise of AI. Despite having access to publicly available data, many organizations are still unable to access the data they need to be able to develop or benefit fully from AI. More open access to data is needed to help organizations of all types take advantage of AI. Open approaches which encourage data sharing can alleviate this problem. For example, governments are now taking steps to increase access to data: [https://eur-lex.europa.eu/eli/dir/2019/1024; https://ec.europa.eu/commission/presscorner/detail/en/ip_20_2102]Businesses are also recognizing that more should be done to enable greater access to data to drive societal and economic benefits: [https://www.industrydataforsociety.com/]Unless governments, businesses and civil society adopt an approach that is more focused on data sharing by default, only a limited number of organizations will have access to the data they need to be successful. Measures to prevent the use of publicly available data for AI training and analysis, for example through preventing TDM on publicly available data online, would greatly exacerbate this problem, and lead to only a handful of organizations who have the means to acquire data benefiting from AI.In general, training materials can be collected directly by AI developers from public sources, obtained from third parties who collect data and make it available for AI development, through direct agreements with data holders, or generated in house. For example, projects such as the Common Crawl and The Pile play an essential role in making data from publicly accessible sources available for training and using AI, particularly for smaller organizations and researchers that do not have the means to generate or collect massive and varied data themselves. AI developers may also negotiate data acquisition and sharing arrangements directly with data owners for access to proprietary or specialized data.There is no single approach to collecting and preparing data for training AI models. Different approaches will depend on the model, constraints of the development environment and the intended use of the model.  The need to preprocess and curate the data for training continues to change as approaches to technology develop.Methods for developing AI systems constantly evolve and change as technology develops, but in general, AI models learn by identifying patterns, correlations and concepts across the training data. This process enables new insights from patterns to be gleaned that could otherwise take a lifetime to uncover. A large language model is a highly complex algorithm with billions of parameters. Since AI models are algorithmic functions that read numbers, not text, words are transformed into “tokens” that are represented as numerical vectors. These vectors are generated to represent not just words but information about the semantic and contextual meaning of the words and their relationships to other words in the vocabulary. This enables the model to correlate relationships between words.During training, algorithms are trained so that they get better at performing a particular task. When training a large language model (LLM), training may involve improving the model’s ability to predict missing words from sentences it has never seen, based on concepts that it learns. The model stores what it has learned by updating the parameters of the function, referred to as “weights”. To do this, the tokenized training data is read by the model. In an example of self-supervised learning, the data will have some tokens masked, i.e., blanked out. This enables the model to predict the missing tokens, and then remove the mask to determine if it predicted the tokens correctly. At the start of the training process the weights may be set randomly and the initial predictions may work poorly. But the model weights will be updated depending on how accurately the model predicts the blanked-out tokens. As more tokens are seen by the model, the model will continue to learn by updating the weights reflecting patterns and trends which relate to underlying concepts in the training data. It is these patterns and trends that relate to concepts that are stored in the model, not the training data.Once the model has been trained using the data, the model does not use the original training materials or the tokenized training data to perform its tasks. Instead, the trained model can make predictions to guess outputs based on the patterns and concepts it has learned. When the trained model is used, it does not “copy” or “look up” data from a database. They are not recalling and outputting text from a webpage that was contained in the training materials.  Fundamentally, they are tools that analyze data to understand patterns so that they can guess outputs. At their core, AI models are extremely advanced and complex statistical models.To address the concerns of rightsholders, AI developers may take measures to mitigate the risk of AI tools being misused for copyright infringement. Microsoft incorporates measures and safeguards to mitigate potentially harmful uses across our AI tools. These measures include the use of meta-prompts and classifiers, which are controls that add additional instructions to a user prompt to limit harmful or infringing outputs. For example, Bing Chat will decline to provide song lyrics or provide extracts from books if requested.Microsoft continues to improve current mitigations and implement new ones in response to our learnings and encourages rightsholders to help us think through effective industry best practices. GitHub’s recently announced reference feature was developed with engagement and feedback from the developer community. The feature enables developers to choose whether to block code that matches code in public repositories or allow the code suggestions with information about the matching public code on GitHub, further placing developers in the driver’s seat when using these tools: [https://github.blog/2023-08-03-introducing-code-referencing-for-github-copilot/] In the rare case where a GitHub Copilot suggestion matches public code, developers can see a list of repositories where that code appears and their licenses, so that they can chose whether to use the code, and whether an attribution is needed.Microsoft has also committed to indemnify and defend customers of our commercial Copilot offerings if a third party sues them for using Microsoft’s commercial Copilot offerings or the output generated by these tools, provided that the customer has used the guardrails built into the products:[https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/]This Copilot Copyright Commitment reflects Microsoft’s commitment to building responsible, AI-powered products and tools that limit the risk of infringing outputs. It also provides a strong incentive for Microsoft customers to use the guardrails that Microsoft has included in its products to mitigate the risk of copyright infringement. This program helps Microsoft educate users on appropriate uses of AI technology and reinforce how users can respect intellectual property rights.Microsoft has also introduced new options for webmasters to control use of their web content in responses provided from Bing Chat. Using this feature, content owners can control the results that are identified in search by preventing their content  from being provided through the chat interface. This change came from collaboration with rightsholder communities. And Microsoft has offered the ability for living artists to request that their name not be used to generate prompts in Bing Image Creator.These steps are not required by copyright law, but Microsoft is committed to listening to the concerns of artists and creators and looking for ways to address potential concerns that arise from the use of generative AI.The degree of involvement of humans is significant in the overall development of AI systems but varies across each stage. In relation to the training of AI models and the handling of training data, recent advancements have shifted the degree of involvement, and the training process is expected to continue to evolve as research and the technology further develops. For example, until recently, for some machine learning methods, it has been necessary to curate and label specific types of data, making these methods labour and resource intensive. Self-supervised methods of machine learning, which may precede other methods like reinforcement learning from human feedback (RLHF), do not require a human to label the data; as a result, self-supervised methods have vastly increased the scale of data that machine learning methods are able to read, giving rise to the enhanced performance that we are seeing now. Developers of large-scale AI models developed with self-supervised training therefore optimize for the quantity of data – since the more data available to train a model, the better the performance of the model. Narrower data sets and human involvement enable RLHF, and humans are also involved in efforts to develop platform services and applications that leverage models and in the process of mapping, measuring, and managing risks with models and systems.","There is ongoing debate regarding how copyright can be used to prevent the development or use of AI systems, when the development or use involves the analysis of a work protected by copyright. This uncertainty discourages the development and use of AI in Canada, and creates uncertainty among rightsholders regarding how their works may be used, particularly with respect to the works they chose to make freely available online. More clarity could be created by issuing guidance explaining that TDM is not a copyright infringement, pointing to existing legislation that permits TDM such as the exceptions in the Copyright Act for fair dealing and temporary reproductions for technological processes. More information could be made available to rightsholders to explain ways in which rightsholders can control the use of their work, for example by technically restricting access to their works. Clarity would be best achieved through legislative changes to copyright law to introduce an explicit copyright exception for TDM such as that introduced in Japan and elsewhere.TDM activities, such as AI development and use, are more likely to take place in jurisdictions where there is legal clarity that such acts are permitted. Nevertheless, due to the broad nature of TDM to capture other types of data analysis beyond AI training, it is highly likely that TDM activities are taking place in Canada, particularly in relation to data analytics more generally and in relation to the use of AI to analyse large data sets.Performing TDM does not require a copyright license because performing TDM is not a copyright infringement. It is not a copyright infringement to analyse works and learn concepts and facts. Intermediate copies that may be created in the technical process in order for the machine to analyse the work would be permitted under existing exceptions in Canadian copyright law. Confusion over this point can create challenges for rightsholders when deciding how to build business models for works that they may want to monetize. While TDM is not a copyright infringement that requires licensing, there are other opportunities to build revenue models around data services. New markets and business models for data providers can flourish as a result of AI development, without the need to place prohibitions on permissionless uses, such as reading and training. For example, copyright owners can enable convenient methods of access that eliminate many of the hurdles and expenses associated with large scale crawling or mass digitization. Owners can include non-public metadata and other materials that make these works more useful than the same content crawled online. While licenses are not required to train AI, rightsholders may choose to provide licenses in relation to the output of a model to enable users to confidently use the rightsholders work in the outputs that would otherwise be a copyright infringement.If the Government were to amend the Copyright Act to further clarify that the scope of copyright protection does not prevent TDM, Canadian copyright legislation would benefit from a clear TDM exception for both commercial and non-commercial purposes, to address the potential lack of clarity mentioned previously. This will encourage AI development and use in Canada and create more investment in this sector.Microsoft is committed to transparency to ensure that AI systems are understandable and that their capabilities and intended uses are clear. However, there should not be a requirement for AI developers to keep records of, or disclose what copyright-protected content was used in the training of AI systems. Training large scale AI models, often referred to as foundation models, analyse vast volumes of data, often from publicly available sources. It would not be feasible to record such information and any such requirement would inhibit AI development.Microsoft is committed to an open dialogue with the creative and publishing industries to ensure that we support the ecosystem of content creators in a changing digital environment. The creator industry is, and will continue to be, at the heart of our culture, shaping our identity and values. This is why AI should remain human centric and is best used as a tool to support human creativity. AI will play an important role in creating value and providing benefit across all sectors and industries, including creator industries. AI will enable greater human expression and creativity, empowering even more people to create like never before. It is important to keep in mind that it is not a copyright infringement to learn from copyright-protected works, and the use of AI to read and learn should not require compensation. However, certain applications of AI may generate outputs that impact existing business models of artists, and we should be discussing how to support artists in those situations.","It is important that human authors be able to secure copyright protection in their works regardless of what types of tools they use in their creative process, whether more traditional tools such as cameras and filters, or more technically advanced tools such as computer aided design software or generative AI. Often, an author will use substantial creativity and exercise skill and judgment to instruct the AI tool to produce the desired result. For decades, authors have used both human and technical assistants to create their works, particularly for large works such as architectural designs or massive murals, but use of those assistants and tools have never blocked authors from obtaining copyright protection for their original works. The author still controls the creative process and decides on the finished creation.Consider, for example, software developers that are using generative AI to assist in the generation of code. GitHub Copilot is behind an increasing percentage of lines of code written by developers using the tool, 46% early this year, and predicted to increase to 80% in the coming years: [https://github.blog/2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities] However, the developer is in control of the entire development process: the structure of the program, how they prompt Copilot for suggestions, how they accept, iterate on, or edit suggestions. And in some ways, developers are in even more control of the work they are creating when using Copilot because they remain focused on the creative process rather than searching for documentation and examples. For this reason, the current guidance from the U.S. Copyright Office to set a threshold level of creativity, and only claim the human contributions, is not feasible to follow and should not be adopted in Canada.As a policy matter, disallowing copyright protection for works created with the assistance of AI tools risks chilling the adoption of this new technology. Individuals who use these tools as part of their creative process will need certainty that the works they generate will be eligible for copyright protection. Without such assurances, the commercial viability of the works made using AI tools is undermined, which will significantly impact the interests of creators who use these tools. The adoption of these tools will also be impacted, which in turn will discourage the development of these tools, which could ultimately negatively impact the competitive advantage of Canada in the AI space.No legislative changes are necessary regarding copyright ownership and authorship in light of AI assisted works. AI is a tool like any other tool that artists can use to help them create new and innovative works. Existing copyright law does not prevent a human artist from being an author of a copyright work when AI is used. The AI system should not be considered an artist or author and this is consistent with existing legislation.","Canadian copyright law provides rightsholders robust protection against the use of AI to create works that are a substantial taking of a copyrighted work without permission. The existing legal tests in Canada are sufficient.A rightsholder should not need to know if a work has been accessed by an AI model. This is particularly relevant as technology evolves to increase the effectiveness and efficiency of training. It is conceivable that data will not need to be stored in order to train. Data can already be streamed for training purposes, it is also more energy efficient for algorithms to be close to the data they are trained on. It is possible that algorithms could move across publicly available data in a similar way to how federated learning algorithms are dispersed. Keeping track of data that has ever been read by an algorithm, which may include real time sensor data and transient data sources etc., may add significant processing costs and energy consumption demands, and compromise possible advancements in this area.One reasonable line of inquiry for rightsholders would be in relation to the circumstances leading to an output of AI that infringes copyright, i.e., that it includes a substantial taking of a copyrighted work without permission. In this case, other factors will be more relevant than the existence of the work in the data that was used for training, such as the way in which the AI was used, including the construction of the prompt which may include the work of the copyright owner. Such an inquiry may include the analysis of confidential information belonging to the user of the AI and should be left to the courts to consider. AI developers may assist in determining whether AI outputs are similar to the original work of a rightsholder, rather than being commonly presented patterns in different sources, by using tools such as code referencing used in GitHub Copilot: [https://github.blog/2023-08-03-introducing-code-referencing-for-github-copilot/]To address the concerns of rightsholders, AI developers may take measures to mitigate the risk of AI tools being misused for copyright infringement. As previously stated, Microsoft incorporates many measures and safeguards to mitigate potentially harmful uses across our AI tools. These measures include metaprompts and classifiers, controls that add additional instructions to a user prompt to limit harmful or infringing outputs. For example, Bing Chat will decline to provide song lyrics or provide extracts from books that are available online.Microsoft has also introduced new options for webmasters to control use of their web content in responses provided from Bing Chat. Using this feature, results that are identified in search can be blocked from being provided through the chat interface. This change came from collaboration with rightsholder communities. And Microsoft has offered the ability for living artists to request that their name not be used to generate prompts: [https://www.bing.com/images/create/help?FORM=GENHLP] These steps are not required by copyright law, but Microsoft is committed to listening to the concerns of artists and creators and looking for ways to address potential concerns that arise from the use of generative AI.Microsoft continues to improve current mitigations and implement new ones in response to our learnings and encourages rightsholders to help us think through effective industry best practices.  GitHub’s recently announced reference feature was developed with engagement and feedback from the developer community. It lets developers choose whether to block code that matches code in public repositories or allow the code suggestions with information about the matching public code on GitHub, further placing developers in the driver’s seat when using these tools.Microsoft has also committed to indemnify and defend customers of our commercial Copilot offerings if a third party sues for using Microsoft’s commercial Copilot offerings or the output generated by these tools, provided that the customer has used the guardrails built into the products: [https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/] This Copilot Copyright Commitment reflects Microsoft’s commitment to building responsible, AI-powered products and tools that limit the risk of infringing outputs. It also provides a strong incentive for Microsoft customers to adopt responsible practices to mitigate these risks. This program helps Microsoft educate users on appropriate uses of AI technology and reinforce how users can respect intellectual property rights.Generative AI can be applied to many different scenarios, many of these scenarios have nothing to do with the interests of copyright owners such as drug discovery and material development. In some cases, however, where AI can be used by a user to create expressive works, AI could be used to create works that infringe copyright. The way in which the user uses the tool is important. Just like other general-purpose technologies, like the photocopier, computer, search engine, and camera, copyright law places responsibility on the user for infringing activity, and the user must act responsibly when using these tools.","Microsoft believes that AI has the potential to improve people’s lives in ever-expanding ways. The ability of AI to help advance human knowledge and understanding will lead to improvements in medicine, science, and industry. Organizations and individuals will use AI to innovate, create, obtain critical insights, and address significant societal challenges. AI will power tools that make everyone more productive at work, school, or home. Microsoft is confident in the promise of AI and its capacity to improve the human condition.Microsoft and its customers use AI systems across a wide range of sectors to solve real world problems by analyzing and understanding processes, methods, information, facts, and insights contained in documents, media, data, and articles (some of which include copyrighted works). This website documents examples of how companies of all sizes are using Microsoft AI in their businesses: [https://www.microsoft.com/en-us/ai/ai-customer-stories] Furthermore, many societal benefits are supported by AI, such as enabling resource management when supporting first aid responders in emergencies and identifying locations that are most vulnerable to climate change. Enabling rapid drug discovery, improving public services and enabling better access to education.We recognize, however, that some artists, writers, musicians and other creators have questions and concerns around the impact that AI, and especially large-scale “generative” AI, will have on their work and their economic opportunities. These fears echo concerns voiced with innovative technologies in the past: the printing press, the camera, the photocopier, the VCR, the internet. And while these concerns are understandable in a period of technological advancement, we have also heard from other professional artists that generative AI is empowering them to make art more accessible and allowing them to pioneer entirely new artistic mediums. We are committed to continue to listen to all stakeholders to strive to develop AI to serve society broadly."
Verto Health,AI Firm,"For training of datasets we use industry specific datasets available in the public domain, or internally produced synthetic data based on statistical reprfesentations of data attributes.Training data sets are used to train ML algorithms. We might also extract subsets of data to create test data sets that are used to validate the trained ML algorithms. The content of these extracts support the development of net new data that does not belong to a single entity; in many cases this training data can be randomly generated to approximate real-world data.To mitigate any liability risks related to infringement of data used for training or validation, we respect all licensing, use and access policies required by the owner/publisher of the training data sets. For example, we would complete registration and/or credentialing requirements for access and use of the data set. Data sets are used for training ML algorithms. Data is not embedded in our ML algorithms. Data may also be used to validate the trained algorithms. For internally generated synthetic data, we take precautions to ensure that the data in our algorithm (preventing leakage and potential for infringement of our data by others) nor do we publish our internally produced data sets.Further we require that humans be involved in all steps of the coding/creation, training and validation of ML algorithms. Humans must create the bulk of a work product (source code, ML algorithm, script etc.)Within our organization, we are using generative AI in limited ways to a) generate and/or optimize source code b) support general business productivity activities, such as generating base templates for agendas, synthesizing internally generated notes or documents to extract themes or actions, identify industry/common responsibilities for specific role descriptions or trivial activities such as suggesting ice breaker activities.With respect to the use of generative AI for source code, our use is restricted to a) generation of non-core source code and/or code that is easily replaced b) generation of small snippets of code only; i.e. the generated code cannot form a substantial part and/or the full body of the code c) forming the basis for a section of code. In all cases, humans must review and integrate generated code and must create the majority of the content and/or any content that is novel, core or unique.Within our industry domain (healthcare), AI is increasingly used to analyze, identify and/or predict patient and population care, outcomes or clinical recommendations. AI is also used to synthesize and/or codify demographic, clinical and other information. ML algorithms can be very specific to condition or clinical workflow. In our organization we are using AI to identify patient and population clinical pathways, to identify population cohorts and clusters and to identify and predict patients or populations deviating from pathways that are based on clinical concepts. To-date, the focused approach to these algorithms is a probabilistic one as opposed to generative. In the future, there may be an opportunity for generative tasks but that is not the case to-date.","Clarity around copyright and TDM would include a plain language explanation of the Act and implications for TDM with industry specific examples. Clarity would also include definitions of authorship, where and when use of generative AI in TDM constitutes infringement and clarity on liability and protection strategies.With respect to TDM activities, we are proceeding with caution. Internal guidance includes requesting citations and references with any query; separately validating any information returned; identifying and respecting any licensing, copyright or other ownership requirements. We are restricting use of ChatGPT to closed versions, available only to our organization and only for certain activities (described in prior section). We have an acceptable use policy which will undergo legal review to ensure we are considering and safeguarding infringement, liability and protections of any IP or Copyright (ours or others).With respect to keeping records of use, we require that generated AI be validated (references, citations, licenses) where possible and that the work be properly attributed. With respect to use of data sets, we require that our internal users abide by registration, certification and use policies for access and use of those data sets. As we move into using generative AI for generation of code snippets and/or optimization of code, we require that the sections of source code that were generated are tagged/identified within the source code.With respect to amendments to the Act to clarify the scope of permissible TDM activities, we do not have sufficient expertise to comment on how the Act should be amended (scope and safeguards) and/or the expected impact of such an exception on your industry and activities.At present we do not have expertise or sufficient experience to comment on renumeration or approaches from other jurisdictions that could inform policy for Canada.In areas where we lack expertise we are responding by limiting or restricting use, proceeding within known constraints and best practices and seeking legal counsel for clarification and guidance.","We are proceeding with caution on the use of AI and seeking legal guidance for appropriate use and to better understand terms and conditions for generative AI tools with respect to liability, infringement and protection.When using generative AI we have found that it is not always easy to identify attribution and/or ownership. Citations/references returned by generative AI do not always correlate to actual sources of information.","We do have concerns related to the potential for infringement of copyright. With respect to infringement of our copyrighted works by others we have varying degrees of protection including operational agreements (NDAs, employee agreements etc.), information classification and use and disclosure policies, and maintaining privacy and control over works such as source code. Regardless, as the use of generative AI evolves, it is unclear how publicly available information could be incorporated into works being authored outside of our organization and how we would be aware of such infringement and/or detect it.With respect to infringement on works authored by others, we have spoken to the fact that it is difficult to attribute works of content generated by AI. As such we are very careful about how we use AI to protect ourselves.With respect to commercialization of our AI applications, we mark our source code and other materials with Copyright, we have agreements in place (internal and external) and we also develop and seek patent protection for novel works.Similar to prior comments, plain language guidance that is industry specific would be helpful.We do not have sufficient expertise to comment on how approaches in other jurisdictions can inform a Canadian policy.","As a start up/scale up in digital health with a number of innovations in various states of patent protection. We engage legal council for activities related to information protection, liability, disclosure etc. These activities are expensive but are important to protect us. As we move into areas such as generative AI, we have found that we are required to engage legal for guidance and advice. These services are expensive for small, growing organizations to undertake but are vital to ensure that innovation, IP and copyright are able to be undertaken, advanced and that we remain productive through use of available resources. Support from government, in the form of information, guidance, considerations and/or funding would support emerging innovations and organizations to continue to be protected and that organizations can leverage these technologies to their advantage. The financial impacts of proceeding in alignment with legal and ethical concerns, while protecting our works is substantial.Another area of consideration is how other legislation and regulation impacts use of these technologies in our domain. Specifically for a healthcare organization, legislation such as PIPEDA and PHIPA (in Canada) may conflict with generative AI and/or potential that use of tools may lead to inadvertent leakage of information, inappropriate context for specific jurisdictions, trust in systems/algorithms by healthcare organizations if underlying technology is not clear in attribution and/or best practices followed etc. We think about these requirements, as well as ethical use of AI in healthcare guidelines, and the potential areas of impact when determining how and where we will use generative AI. In many areas we have proceeded with an abundance of caution which may impact our ability to innovate and/or  be productive."
SECUR3D,AI Firm,"How does your organization access and collect copyright-protected content, and encode it in training datasets?A: We currently only access and train off of datasets that are wholly owned or licensed, open-source, and/or rights free data. Our organization is focused on visual IP and copyright protection so we try to employ ethical standards when it comes to training data to avoid hypocritical criticisms.·         How does your organization use training datasets to develop AI systems?A: Our organization deploys both proprietary software and advanced AI systems to facilitate digital content analysis and protection to our customers. Currently we use ethically trained datasets to analyze and compare 2D textures of 3D models, identify brand infringement, and detect explicit content.Eventually we will be training new datasets to analyze and compare 3D meshes.·         In your area of knowledge or organization, what is the involvement of humans in the development of AI systems?A: Research and Development: Humans are integral to the conceptual and practical development of AI technologies. This includes conducting scientific research, formulating algorithms, designing machine learning models, and developing the underlying computational architecture.Data Preparation: One of the most significant contributions of humans in AI development is in the realm of data preparation. This involves collecting, cleaning, and organizing data, which AI systems use for learning. The quality and diversity of this data are critical for the effectiveness and impartiality of AI models.Training and Tuning: AI systems, especially those based on machine learning, require training. Humans are involved in this process by selecting appropriate training data, adjusting parameters (tuning), and refining algorithms based on the performance of the AI system during its training phase.Ethical and Legal Considerations: Humans are essential in addressing the ethical and legal aspects of AI. This includes ensuring that AI systems are developed and used in a manner that is ethical, respects privacy, avoids bias, and complies with legal standards and regulations.User Experience Design and Interface Development: The design of user interfaces and the overall user experience for AI systems are crafted by humans. This aspect ensures that AI systems are accessible, user-friendly, and effective in meeting the needs of the users.Testing and Quality Assurance: Human oversight is crucial in testing AI systems for errors, biases, and performance issues. Quality assurance processes often involve human evaluators who can identify and rectify issues that automated testing might miss.Integration and Application: Humans are involved in integrating AI systems into existing technological frameworks and in applying AI solutions to practical problems in various industries, such as healthcare, finance, transportation, and more.Ongoing Monitoring and Maintenance: After deployment, AI systems require continuous monitoring and maintenance. Humans are responsible for overseeing these systems, updating them as needed, and ensuring they continue to function effectively and safely.Policy Making and Governance: Policymakers and regulators, who are humans, are responsible for creating and enforcing policies and regulations that govern the development and application of AI technologies. This ensures that AI is used responsibly and beneficially in society.·         How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?A: Everyone is using AI in some form or another as a tool to expedite workflows and processes. From very basic rudimentary using ChatGPT for email responses, to using Midjourney to quickly concept out different visual styles and themes, to using Copilot to write and check engineering code. AI systems and tools are enhancing and fundamentally improving work and social lives, but the larger issue is these systems have and continually to be built unethically.","·         What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?A: Clarity would mean better ability for companies and individuals to understand where exactly the legal line(s) fall and hopefully operate more ethically than the current standard. Clearly defined and substantiated legal ground with equal outlines for repercussions would hopefully curtail bad actor behavior around copyright and TDM. As with any other policy or legislation, if clarity is absent, there is no way to determine what action falls within being lawful, and will skew behaviour as anything is permitted.·         Are TDM activities being conducted in Canada? Why or why not?A: TDM activities are certainly being conducted in Canada. While perhaps not as prevalent nor publicized as TDM practices being done by large US-based tech and AI firms, those ethical and unethical practices are definitely being done in Canada. The fact that the Canadian government is actively engaged in a consultation process to understand and address the implications of TDM activities within its copyright framework somewhat answers that question.·         Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?A: Without regulation around licensing work for AI/TDM purposes, there is no framework to do so, and content is being used without regard for licensing. There isn’t much regard for licensing given that the vast majority of data is readily available online and can be accessed to train AI models without repercussion. The current standard is fundamentally to take whatever you can get your hands on to train models, and face punishment after, if any. This needs to change. ·         What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?A: Non-Negotiated Licenses: These are commonly found in mass market products, such as software, and often take the form of click-wrap or browse-wrap licenses. In these cases, the user must expressly agree to the terms by clicking a button or checking a box. These licenses are typically non-negotiable and unilateral, meaning they are set by the licensor without room for modification by the user. It is important for users to review sections on ""Authorized Uses,"" ""Non-Permitted Uses,"" and ""Intellectual Property"" in these agreements, as they often contain clauses relevant to TDM activities​​.Open and Public Licenses: These are more general licenses under which copyright holders release their works for public use without requiring special permission. A well-known example of this type of license is the Creative Commons licenses, which allow content to be used under specified conditions, making them suitable for certain TDM activities​​.Legal Considerations and Fair Use: In some jurisdictions, like the United States, fair use provisions may apply to TDM activities, particularly for non-fully open access content where the user is not the copyright holder. However, contractual and licensing agreements can override standard copyright laws and may limit the use of content even in ways that might otherwise be considered fair use​​.Intellectual Property Laws: Different countries have various intellectual property laws that can affect the use of content for TDM. While some laws allow TDM without explicit permission from rights holders, others require explicit permission. In cases where legal exceptions allow for TDM, aspects of a license or contract may still limit how content can be used for TDM​​.·         Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?A: Yes, all records should be required to be maintained and to be made available upon challenge to the system’s integrity.·         Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue? A: Yes, a few examples below.European Union - General Data Protection Regulation (GDPR): The GDPR is one of the most influential data protection regulations globally. It emphasizes data privacy and gives individuals significant control over their personal data. Canada could look at how GDPR balances data utility and privacy.United States - Health Insurance Portability and Accountability Act (HIPAA): HIPAA sets the standard for protecting sensitive patient data in the U.S. While it's specific to healthcare, the principles of data protection and privacy can be informative for broader TDM strategies.Australia - Consumer Data Right (CDR): Australia's CDR provides consumers with greater control over their data. It mandates that businesses give consumers access to their personal data and the ability to authorize secure access to this data by third parties.Singapore - Personal Data Protection Act (PDPA): Singapore's PDPA governs the collection, use, and disclosure of personal data. It's an example of a framework that balances data protection with organizational needs and innovation.Japan - Act on the Protection of Personal Information (APPI): Japan's APPI is another robust personal data protection law. It is known for its unique approach to data management, emphasizing both the protection of personal information and the utilization of personal data.United Kingdom - Data Protection Act 2018: This act is the UK’s implementation of the GDPR. It contains provisions and exemptions tailored to domestic needs, which could be particularly instructive for a country like Canada, which has its own specific legal and cultural context.","·         Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?A: Yes, with no clarity many opt out of AI use, or use AI irresponsibly. Companies face backlash from creator communities when they are caught using AI, as it is viewed as a cheap and unethical replacement for commissioning original work. In terms of development, this is continuing, but it is done so without any ethical concern to ownership and attribution, meaning that models have already been trained on unauthorized data and will already have issues that only continue being further built upon.·         Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?A: Yes, through informed policy analysis and policy making, as well as through addressing creator concerns, and legal battles against AI use of copyrighted materials and intellectual property. The stance of the government should be to protect creators’ rights and ensure that their work cannot be infringed upon or used without authorization. A framework and set of standards for responsible AI use should be constructed and applied to models producing content.·         Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?A: Yes, current events show that across the world, governments are moving to learn more about responsible AI use, and implement better policy and means for regulations. MIT provides a good high-level overview of national movement toward AI policy across key players, and where this got throughout 2023 (https://www.technologyreview.com/2024/01/05/1086203/whats-next-ai-regulation-2024/). Similarly, examining the lawsuits currently in progress against generative AI models such as those created by OpenAI and Midjourney are great points of analysis when it comes to infringement that is being alleged against these companies.","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?A: Yes, they are lacking and need much better software and competencies behind them. All current systems created to demonstrate AI use are faulty and don’t accurately pick up on AI use; this is both in terms of text and visual content.·         What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output? A: Simply put, the biggest barrier is there is no technical way to identify whether an AI system accessed or copied copyright-protected content from a generated output. This issue is currently exacerbated in creative industries where more often than not AI is replicating exact style and tone from artists or writers based on unauthorized training of their data. A detailed public log from a company/ organization that has documented their training data would only be part of the puzzle in overcoming this larger barrier. ·         When commercializing AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?A: Little to no measures as none are currently explicitly required, though they should be.·         Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works? A: Yes, without this clarity it is nearly impossible to enforce copyright protection or to identify legal cause for copyright infringement. Creators and IP rights holders deserve to know that their work is protected and that they have the ability to challenge situations where their rights are not respected. ·         Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?|A: Yes, current events show that across the world, governments are moving to learn more about responsible AI use, and implement better policy and means for regulations. MIT provides a good high-level overview of national movement toward AI policy across key players, and where this got throughout 2023 (https://www.technologyreview.com/2024/01/05/1086203/whats-next-ai-regulation-2024/). Similarly, examining the lawsuits currently in progress against generative AI models such as those created by OpenAI and Midjourney are great points of analysis when it comes to infringement that is being alleged against these companies.","·         Are there any other considerations or elements you wish to share about copyright policy related to AI?A: Beyond creating a legal framework that will inform both companies and individuals operating within the AI space, or simply using AI, it’s more important than ever to stimulate support for companies focused on creating systems that can work in parallel to legislation, helping all rights holders and stakeholders of original works safe from IP and copyright theft/ infringement. All over Canada, teams like our own at Secur3D, are facing the problem of IP and copyright infringement head on, and working tirelessly to build complementary solutions. Our team, for example, is working on new software and tools which leverages AI to deliver digital content analysis, moderation, and authentication, at scale. These are capabilities intended to streamline the protection and authentication of 3D models across the digital landscape, eliminating IP and copyright infringement before it is able to occur.The reality is, current protection vehicles are antiquated and reactive, and certainly do not take into account the disruptive nature of AI innovation. Without new solutions being able to advance and gain traction, policy, alone, will struggle to meet the speed and volume at which content is being uploaded online. This would render even the best informed framework for IP and copyright protection fairly ill functioning. In the same way that the government has provided specialized support to various sectors when development was necessary, it would be extremely beneficial to approach copyright protection in the same way, and consider the businesses and individuals already working toward critical improvements in the space."
AI Impact Alliance,Alliance / Union / Guild,N/A,"Faute de place dans la section Commentaires, j'ajoute une mise en contexte ici.À l’ère de l’IA et peut-être tout surtout depuis les développements disruptifs en IA générative, la définition d’ «Art», et conséquemment de qui peut être reconnu comme artiste, est bousculé et, dans certains contextes, côtoie de plus en plus près celle de l’IA générative. Ceci a un impact sur l’éligibilité à se prévaloir de financement auprès des organismes artistiques et culturels, sur l’allocation de budgets (financement public) et de financement de projets (bourses, prêts, etc). L’allocation de fonds traditionnellement alloués à des artistes reconnus par des pairs via un processus géré par des organismes culturels indépendants du gouvernement (arm length arts organizations), pourrait se voir alloués à des technologues (programmeurs).  Ces fonds favorisent traditionnellement un retour sur investissement (ROI) public qui contribue de façon importante à l’économie canadienne, mais aussi à la fibre sociale (Social Return On Investment) essentielle pour contrer les effets de la crise de la mésinformation et la polarisation. Les politiques de financement culturelles adoptées par ses organismes visent à contribuer activement à la Réconciliation, une priorité exprimée par le Conseil consultatif sur l’IA du Canada lors de nos rencontres. Il est donc important lors de la rédaction du rapport final d’éviter de confondre « œuvre » et « résultante algorithmique », « programmeur » et « artiste ». La mutation de la définition de l’Art s’observe entre autres dans les conférences sur l’IA où les scientifiques en sciences informatiques (IA) se prononcent de plus en plus sur cette définition (NeurIPS, ACM, etc), et ce parfois en défense des artistes, mais sans en connaître les impacts sur les politiques culturelles et économiques plus globalement. (Ex : https://arxiv.org/abs/2306.04141) Ce soudain intérêt de ces conférences pour définir ce qu’est l’art n’est pas désintéressé et risque d’ouvrir une brèche à la formation de politiques culturelles légitimes et démocratiques.À Montréal en juin dernier, Deepmind (Google), un partenaire du Mila, m’a invité à me joindre à un projet financé par le Mila (fonds publics) en « art » génératif qui se concluait avec des recommandations en politiques publiques. J’ai refusé et lancé la pétition Art Impact AI qui a été signée par près de 2000 personnes demandant entre autres la fin de type de pratique de lobbying/capture réglementaire. https://www.change.org/ArtXAIConversationLa métamorphose de la définition d’art a aussi un impact sur le droit de se prévaloir l’exception pour usage « artistique » au sens de la loi sur la protection des renseignements personnels. Toute modification à loi sur le droit d’auteur devra être harmonisée avec le projet de loi C-27, si celui-ci est adopté. La partie 1 du PL C-27 (article 38) réitère une exception déjà existante dans LPRPDE stipulant qu’une “Organisation peut recueillir les renseignements personnels d’un individu, à son insu ou sans son consentement, lorsque la collecte est faite uniquement à des fins journalistiques, artistiques ou littéraires.”Il s’agit d’une exception jusqu’ici peu utilisée, mais, dans un contexte d’économie numérique et créative dont la croissance est notable, son utilisation dans le développement de systèmes d’IA nous met face à des questions importantes. En jurisprudence canadienne, l'exception pour “fins artistiques” est rarement portée à l’attention de la Cour,  mais lorsqu’elle l’a été, on retrouve une cause où Google argumente pour obtenir une exception pour fins journalistiques (refusé) et une où est accordée une architecture de données géologiques a été reconnue par la Cour comme un art. Ceci pourrait mener à des situations où des données personnelles sont colligées et monétisées sans le consentement d’une personne dans le but d’entraîner un système d’IA générative si celui-ci a des finalités artistiques, littéraires ou journalistiques. Combinée avec une modification à la loi qui facilite la FTD, cette mutation de la définition de l’art ouvre la porte à des utilisations malveillantes des données personnelles.NBP: Voir la décision portant sur l’Affaire intéressant un renvoi soumis au cours d’une enquête menée par le Commissaire à la protection de la vie privée du Canada sur une plainte entre le Commissaire et Google (LCC), Cour fédérale, Ottawa, 2021, et celle où la Cour reconnaît une base de données sismiques conçu par des géologues comme une création “artistique"".",,,"La prémisse de cette consultation est que « le droit d'auteur au Canada vise à favoriser un marché adapté aux besoins changeants des utilisateurs, tout en continuant d'offrir aux créateurs les droits dont ils ont besoin pour encourager l'investissement et la création d'emplois dans l'ensemble de l'économie ». Rappelons toutefois que le droit de la propriété intellectuelle, dont fait partie le droit d’auteur, comprend les moyens de protéger les expressions créatives de l'intellect qui ont une valeur commerciale et morale, et ce pour tous les secteurs de l’économie canadienne, y compris celui des arts et de la culture. Il vise à encourager le processus créatif et promouvoir l'investissement en garantissant aux investisseurs (publics ou privés), un retour sur investissement. Puisque toute innovation technologique de cette envergure devrait être accompagnée d’innovation sociale, un retour social sur investissement en IA est également à favoriser.Une entente commune sur ce que sont les objectifs stratégiques, et les objectifs prioritaires de la loi sur le droit d’auteur devrait être faite en collaboration avec le secteur des arts et de la culture et tenir compte des implications genrées et régionales de l’adoption de l’IA. De plus, l’étude des impacts d’une modification à la loi sur le droit d’auteur doit se faire à la lumière d’une stratégie d’égalité des genres en économie numérique. Le profil des travailleurs, des professionnels, des entrepreneurs et des investisseurs actifs au sein des industries créatives et numériques est différent de celui des artistes et professionnels des arts et de la culture. Ces derniers sont plus présents dans des regroupements et organismes culturels à but non lucratif ou à mission sociale. Cette distinction est importante, car les femmes et les personnes en région n’auront pas un accès égal ni équitable aux bénéfices de ces investissements.Les femmes représentent une petite minorité des programmeurs d'IA. Cette Disparité entre les genres dans le domaine de la formation en IA est un problème important, car elle limite la diversité et l'inclusivité au sein de l'industrie, conduisant potentiellement à des algorithmes d'IA biaisés et une sous-représentation des points de vue féminins. Ces biais peuvent conduire à des résultats discriminatoires dans les applications de l'IA, affectant divers aspects de la société, notamment l'emploi, les soins de santé, etc. Il cause également un accès inégal au potentiel économique que représente l’IA. En effet, les femmes constituent une petite minorité de propriétaires dans les entreprises de l’IA générative. Ce manque de représentation des femmes aux postes de propriété dans l'industrie de l'IA limite leur pouvoir de décision et influence sur l'orientation des technologies de l'IA. De plus, les emplois des femmes, et ceci est vrai également dans le secteur des arts et de la culture, comptent plus de tâches automatisables et donc sont plus à risque de perte de revenus, affaiblissant leur autonomie économique.Dans le document de consultation, l’ISDE écrit : « Les utilisateurs peuvent également utiliser la même application d'IA, fournir des données supplémentaires et utiliser l'application pour générer des œuvres. L'utilisateur peut demander à l'IA de générer plusieurs œuvres, puis organiser ces œuvres pour en choisir une en particulier qui répond à certaines normes artistiques. De plus, l'utilisateur peut modifier l'œuvre sélectionnée générée par l'IA, en ajoutant sa propre contribution artistique. Un utilisateur possédant des connaissances techniques plus poussées peut adapter l'application d'IA, soit directement, soit en fournissant une formation supplémentaire à l'IA, ce qui lui permet de générer des œuvres qui répondent à ses objectifs et à ses besoins particuliers. Ces possibilités, bien que simplifiées, illustrent la variété d'interventions humaines possibles dans les œuvres assistées par l'IA. »Je voudrais souligner que l’utilisateur, et surtout l’utilisateur expert qui est en mesure de modifier, mettre au point l’algorithme pour répondre à ses intentions artistiques  (en faisant par exemple une mise au point d’un système d’IA générative via les RAGs (Retrieval Augmented Generation) risque fort de ne pas être une femme. https://www2.deloitte.com/us/en/pages/consulting/articles/state-of-women-in-ai-today.html). Le Canada s’est engagé envers l’équité des genres en vertu de plusieurs politiques, notamment la Politique féministe du Canada, et le Programme mondial sur les femmes, la paix et la sécurité. Le FMI a également lancé sa stratégie d’égalité des genres en 2022, invitant les gouvernements à en faire la considération pour relancer une économie prospère et durable. Toute modification à la loi sur le droit d’auteur doit se faire en tenant compte de celle-ci et l’impact très différent de l’IA sur les femmes, les personnes en région et les communautés autochtones et des Premières Nations.Afin d’ «offrir aux créateurs les droits dont ils ont besoin pour encourager (…) la création d'emplois dans l'ensemble de l'économie », la mesure des impacts devrait être amorcée dès le départ (faire partie des consultations, collecte de données en amont pour bien évaluer l’impact, etc).https://www.ledevoir.com/politique/canada/786915/le-canada-ignore-les-progres-de-sa-politique-feministe-selon-la-vg."
Alliance des producteurs francophones du Canada (APFC),Alliance / Union / Guild,"L’Alliance des producteurs francophones du Canada (APFC) est membre de la Coalition pour la diversité des expressions culturelles (CDEC). Dans le cadre de la consultation sur le droit d’auteur à l’ère de l’intelligence artificielle générative, menée par le gouvernement du Canada, l’APFC a collaboré à l’élaboration du mémoire de la CDEC. Nous appuyons les observations de la Coalition et reprenons, dans ce formulaire, les réponses qui sont pertinentes pour les membres producteurs de l’APFC.Cette consultation est axée sur l’« IA générative », c'est-à-dire sur des systèmes utilisant des modèles d'apprentissage profond capables de générer des contenus créatifs de haute qualité en se basant sur les œuvres sur lesquelles ils ont été formés. En comparaison, l’« IA traditionnelle » désigne généralement des outils ou des systèmes qui exécutent des tâches spécifiques en se basant sur des règles prédéfinies et des entrées de données. Utiliser l'IA pour aider à rédiger une réponse à un courriel est nettement différent de l'utiliser pour produire une chanson, une illustration ou un poème. Lorsqu'il s'agit de déterminer si des modifications sont nécessaires dans la politique sur le droit d'auteur, il est important de faire une distinction entre les deux. Nous concentrons notre réponse sur cette prochaine génération d'IA.Nos membres reconnaissent le potentiel de l'IA et explorent les avantages de cette nouvelle technologie. L'IA, tout comme d'autres outils, peut être utilisée pour améliorer et soutenir la créativité humaine lorsqu'elle est utilisée de manière responsable et éthique. Dans les industries culturelles, l'IA est utilisée comme un outil qui soutient – sans remplacer – l'expression originale humaine des œuvres des créateurs. Certains créateurs utilisent l'IA comme un outil dans le cadre de leur processus créatif pour réduire certains aspects fastidieux et répétitifs de leur travail. Les producteurs l'utilisent pour aider à la mise en page, au style, aux effets visuels, à la correction des couleurs et à l'amélioration des détails, entre autres. Lorsqu'elle est utilisée de manière responsable, l'IA peut apporter une valeur considérable au processus créatif. Cependant, lorsqu'elle est utilisée de manière irresponsable, l'IA a le potentiel de sérieusement compromettre et endommager le secteur culturel au Canada et dans le monde entier.","En tant que principe général, les développements de l'IA peuvent et doivent coexister avec un système de droit d'auteur qui encourage les créateurs à créer et à diffuser leurs œuvres tout en protégeant les ayants droit. Cependant, les plateformes d'IA générative tirent d'importants bénéfices de l'utilisation non autorisée et de la reproduction d’œuvres provenant notamment des membres de l’APFC.La fouille de texte et de données (FTD) utilisée dans la formation des systèmes d'IA générative implique la reproduction de grandes quantités de données et d'œuvres protégées par le droit d'auteur. Ces inputs (entrées) dans la FTD sont souvent des œuvres protégées par le droit d'auteur, pour lesquelles aucune licence n'est demandée et aucune compensation n'est versée aux titulaires de droits.Les productions de l'IA générative posent également des questions fondamentales et existentielles pour le secteur culturel; elles violent souvent les droits d'auteur des créateurs en produisant et en partageant du contenu qui ressemble de près aux œuvres originales, communément appelées ""imitations"" visuelles et sonores. Cela se produit fréquemment en réponse à des requêtes d'utilisateurs recherchant une telle réplication.Aussi, les applications de l'IA, y compris la FTD, sont utilisées pour créer des médias synthétiques (deepfakes, hologrammes, répliques numériques, doublures, voix off, personnages virtuels et environnements). Si la production incorpore l'image ou la ressemblance de l'artiste-interprète, il s'agit d'une reproduction d'une partie substantielle de la prestation de cet artiste-interprète et d'une contrefaçon.Enfin, la production générée par l'IA peut également porter atteinte aux droits moraux des auteurs.  Par exemple, si une œuvre est commercialisée comme étant « dans le style » ou « dans le son » d'un auteur particulier, le résultat sera souvent une reproduction « bâtarde », une copie inférieure de l'œuvre de l'auteur. La production contrefaite peut également être utilisée dans des contextes inappropriés (ex. campagne politique). Ces deux exemples peuvent porter un réel préjudice à l'honneur et à la réputation de l'auteur.Ces types de productions sont en concurrence directe avec le marché des œuvres des créateurs et menacent les moyens d'existence des producteurs, artisans et artistes du Canada.Toutes ces utilisations, et les atteintes qui en découlent, doivent être prises en compte lors de l'examen des implications de l'IA générative sur la politique du droit d'auteur.La clarté absolue concernant le droit d'auteur et la FTD au Canada n'est pas nécessairement l'objectif de cette consultation, ni de la politique du droit d'auteur en général, d'autant plus que le marché se développe autour de ces nouvelles utilisations. Il y a de sérieux risques à supposer qu'une nouvelle forme de technologie nécessite automatiquement la création d'une nouvelle exception. Les approches réflexives ne peuvent pas tenir compte de la vitesse à laquelle la technologie de l'IA générative évolue et de l'impact qui en résulte sur les marchés concernés.En outre, l'introduction d'une nouvelle exception pour la FTD interférerait avec la capacité des utilisateurs et des titulaires de droits à fixer les limites de ce marché émergent. Il serait particulièrement disruptif de la part du gouvernement d'introduire une nouvelle exception pour la FTD alors que des modèles de licence pour l'utilisation d'œuvres, de performances et d'enregistrements sonores protégés par le droit d'auteur dans le cadre de l'IA générative sont en train de se développer et d'émerger. Compte tenu du marché naissant de l'octroi de licences pour les activités de gestion des droits FTD et des partenariats d'IA générative qui se développent entre les développeurs d'IA et les titulaires de droits, le gouvernement devrait laisser le marché élaborer des solutions de licence basées sur le marché pour les utilisations de la FTD dans l'IA générative.Ceux qui réclament des exceptions préfèrent faire pression sur les gouvernements du monde entier plutôt que de proposer des solutions fondées sur le marché. Après tout, les solutions basées sur le marché ont parfois un prix tandis que les exceptions sont généralement gratuites.Un système de retrait (opt-out) exigerait que tous les titulaires de droits d'auteur surveillent chaque plateforme d'IA générative disponible au Canada et envoient une sorte d'avis à chaque opérateur d'IA générative ou développeur d'application pour l'informer qu'il a choisi de « se retirer » de l'exception à des fins de gestion des droits de reproduction. Les titulaires de droits d'auteur devraient d'abord savoir que leurs œuvres, prestations ou enregistrements sonores sont utilisés par l'opérateur d'IA générative ou le développeur d'applications, ou envoyer un avis à chacun d'entre eux. Les titulaires de droits n'auraient pas non plus de recours en cas de copie effectuée avant qu'ils ne se retirent. Il s'agit là d'une charge énorme pour les titulaires de droits d'auteur, qui est tout à fait disproportionnée par rapport à ce problème supposé.Dans d'autres juridictions, il a été suggéré qu'un régime de licence obligatoire pourrait être approprié pour la FTD. Les licences obligatoires privent les créateurs et les titulaires de droits d'auteur de leurs droits exclusifs d'autoriser la reproduction de leurs œuvres, prestations ou enregistrements sonores en les obligeant à concéder des licences, ce qui les prive d'une compensation équitable pour ces utilisations. De même, il prive les titulaires de droits de la possibilité d'interdire l'utilisation de leur contenu par un service qui pourrait en fin de compte cannibaliser leur propre travail ou qui produit un contenu qui agit comme un substitut de leur travail original. La mise en œuvre d'un tel régime imposerait également aux titulaires de droits d'auteur une charge importante en termes de gestion et d'application. En outre, la mise en œuvre d'une licence obligatoire pour la FTD est une solution à la recherche d'un problème.Il n'y a aucune raison de conclure que la Loi actuelle est insuffisante pour faire face à toute utilisation qui pourrait survenir en ce qui concerne la formation de l'IA générative. La Loi sur le droit d'auteur est suffisamment neutre sur le plan technologique pour permettre le développement technologique et favoriser l'innovation en IA générative.Les développeurs et les plateformes d'IA en sont parfaitement conscients : entrer sur un marché implique d'assumer la responsabilité de l'impact de leur nouvelle technologie sur ce marché et les acteurs qui le composent. Les plateformes doivent respecter les droits d'auteur des créateurs et créatrices.Les nombreuses exceptions prévues par la législation canadienne sur le droit d'auteur ont déjà provoqué un déséquilibre structurel dans la Loi sur le droit d'auteur : un déséquilibre qui prive les titulaires de droits de leur « juste récompense » et qui peut décourager et dissuader les auteurs et les titulaires de droits d'auteur de créer et de diffuser leurs œuvres, leurs interprétations et leurs enregistrements sonores. L'introduction d'exceptions supplémentaires pour les besoins de la TDM ne fera qu'accentuer le déséquilibre recherché dans la Loi sur le droit d'auteur.Recommandation 1 : Que le gouvernement ne modifie pas les exceptions actuelles pour inclure la FTD ni ne mette en place de nouvelles exceptions pour la FTD.La compensation et la juste rémunération requises pour l'utilisation d'une œuvre donnée, d'un enregistrement sonore ou d'une performance seront, et devraient être, déterminées par le marché, la Commission du droit d'auteur ou les tribunaux et non par le gouvernement.Cette question doit faire l'objet de négociations entre les titulaires de droits et les plateformes d'IA générative, ce qui encouragerait une solution basée sur le marché pour la FTD.D’autre part, l'autorisation et la permission sont aussi importantes que la compensation, en particulier lorsque la production du système peut entrer en concurrence avec l'œuvre originale ou s'y substituer. Là encore, ce sont les négociations de marché et le marché des licences en développement qui devraient trancher ces questions, et non le gouvernement.De nombreuses plateformes comme Google et Microsoft semblent croire que la formation de leurs systèmes est déjà exemptée ou qu'elle ne nécessite pas d'autorisation, en vertu du droit d'auteur au Canada. Ces positions posent des défis aux titulaires de droits qui souhaitent accorder des licences pour leurs œuvres, leurs interprétations et leurs enregistrements sonores dans le cadre de la FTD.De plus, les ayants droit n'ont aucune visibilité sur le fait que leurs œuvres ou d'autres sujets ont été utilisés dans la formation de n'importe quelle plateforme d'IA générative. La FTD sur n'importe quelle plateforme est une boîte noire. Cette asymétrie de l'information, et le déséquilibre du pouvoir de négociation qui en résulte, rend la surveillance et les opportunités de licence qui en résultent incroyablement difficiles pour les ayants droit. Dans le meilleur des cas, les transactions de licence sont inefficaces : les titulaires de droits n'ont d'autre choix que de deviner si un système d'IA générative donné a utilisé leurs œuvres ou d'attendre que l'opérateur d'un système les contacte pour obtenir une licence. Dans le pire des cas, on assiste à une défaillance totale du marché, les opérateurs profitant du contenu des créateurs. Ce déséquilibre doit être corrigé.Recommandation 2 : Que les plateformes d'IA générative soient tenues de se conformer aux exigences de transparence, y compris, mais sans s'y limiter : (i) publier les enregistrements des œuvres, enregistrements sonores et performances protégés par le droit d’auteur qui ont été utilisés par les plateformes ; (ii) concevoir le modèle pour éviter qu'il ne génère des contenus illégaux ou contrefaits ; et (iii) divulguer que le contenu produit par l'IA.",,,"L’APFC appui les autres recommandations formulées par la CDCE pour améliorer la Loi sur le droit d'auteur. Nous nous joignons à la Coalition pour demander que la prochaine réforme du droit d'auteur inclue ces autres recommandations, même si elles ne sont pas soumises à la présente consultation.Les six recommandations urgentes des membres de la CDEC :1. Modifier les dispositions relatives à l'utilisation équitable dans le contexte de l'éducation afin qu'elles ne s'appliquent que lorsqu'une œuvre n'est pas disponible dans le commerce en vertu d'une licence accordée par le titulaire des droits ou une société de gestion collective.2. Intégrer le droit de suite dans la Loi sur le droit d'auteur.3. Abolir l'exemption de la redevance d'exécution publique pour les artistes-interprètes et les producteurs des stations de radio commerciales.4.  Modifier la définition de l'enregistrement sonore pour y inclure les enregistrements sonores qui accompagnent les œuvres audiovisuelles.5. Modifier la Loi pour confirmer le caractère obligatoire des tarifs approuvés par la Commission du droit d'auteur.6. Rétablir le régime de la copie privée dans le secteur de la musique.Les six recommandations à moyen-terme des membres de la CDEC:1. Ratifier le traité de Pékin et accorder des droits moraux et économiques aux artistes interprètes sur les supports audiovisuels dans la Loi.2. Relever les limites supérieures et inférieures des dommages-intérêts statutaires en cas de violation commise à des fins non commerciales et permettre l'établissement de dommages-intérêts supérieurs en cas d'utilisation systématique et massive.3. Veiller à ce que les ayants droits des divers secteurs disposent des mêmes outils en faisant en sorte que toutes les sociétés de gestion collective puissent réclamer des dommages statutaires de trois à dix fois supérieurs à la valeur du tarif qui n'a pas été payé.4. Bonifier le régime de la copie privée en autorisant le paiement de redevances pour les ayants droits des secteurs de l'audiovisuel, de la littérature et des arts visuels.5. Modifier l'exemption prévue à l'article 32.2, paragraphe 3, afin de limiter son application aux actes non motivés par l'appât du gain.6. Prendre en compte les besoins et les réalités des artistes, créateurs et organisations autochtones."
BSA | The Software Alliance,Alliance / Union / Guild,"OverviewFirst, as regards ISED’s questions about Text and Data Mining (Section 2.1), text and data mining, also referred to as computational analysis, typically involves turning data into tokens that are looking for statistical correlations with other tokenized data. Some of that data may be part of a copyrighted work, but the use normally has nothing to do with the expressive content of a work. A book may be used to learn language skills, which are then used for improved database management practices. In general, we believe that a reproduction of a lawfully accessed work for purposes of computational analysis should qualify as fair dealing under Canadian law. For greater certainty, we recommend that Canada adopt an express exception in the Canadian Copyright Act to cover copying of a lawfully accessed work for the purpose of “computational analysis.”Relatedly, we understand that there have been voluntary, industry conversations around automated tools to indicate that the rights-owner does not want a website used for training purposes, similar to the current “do not crawl” tools. We encourage further conversations to determine whether a consensus standard is possible.DiscussionIn Section 2.1, ISED asks about how data is used to train AI systems in the context of text and data mining – also known as computational analysis. As discussed in more detail below, there are different approaches to AI training, but this is the core of each: turning bits of data into tokens and finding statistical correlations from the tokens. The bits of data may be part of a licensed data set, they may be freely available online, or they may be part of a combination of different sets.Training data may or may not be part of a copyrighted work, since there are no formalities to copyright protection and all expressive works are protected. The training set, however, is used to enable studying of non-expressive data it contains. This enables the system to learn, for instance, how language functions or about spatial relationships. While this form of data analysis should qualify as fair dealing under Canadian law and/or should be accommodated in a statutory exemption, there may be situations in which the copyright owner or publisher wants to prevent the data use for training purposes. There are ongoing industry conversations about how to create metatags to create a signal on an otherwise freely available website, and we hope that the Government of Canada and ISED will encourage those conversations.A.           Artificial Intelligence in a Copyright ContextAI machine learning encompasses a vast array of technologies developed or deployed for use in a variety of different industries and applications. Machine learning depends upon computational analysis of training data to identify correlations, patterns, or other metadata in order to develop a model that can make predictions or recommendations based on future data inputs.  More recently, generative AI has emerged, allowing for the creation of new outputs in textual, visual, or aural formats.1. Applications of AIWe offer below a few (widely recognized) examples of insights, predictions, and other outputs derived from computational analysis in the machine learning context:While the use cases are diverse, the elements of training each are very similar and discussed below.2. The AI Development Life CycleThe AI development life cycle typically includes the following steps:","B.           The Use of Copyrighted Works to Train AI ModelsAs discussed above, computational analysis is typically applied to a large training data corpus that may comprise millions or billions of tokenized data elements. Depending on how the model is trained, data accessible over the Internet may be collected as part of the raw data set that is transformed into that corpus. This raw data may include copyrighted works because a substantial portion of the internet is potentially subject to copyright protection, but importantly, however, not all of the material online is subject to copyright, in part because copyright protection does not extend to facts, ideas, or mathematical concepts.Computational analysis may involve two sets of reproductions that potentially implicate the Canadian Copyright Act: (1) reproductions necessary to create a corpus of “training data,” and (2) temporary reproductions that are incidental to the computational process of training the AI model. In each case, the reproductions are “intermediate” in the sense that they are not visible or otherwise made available to the public. Instead, the reproductions are the necessary byproduct of a technical process that is aimed at identifying non-copyrightable information about the underlying corpus of works – i.e., the correlations and patterns that inform the creation of the AI model and enable it to make predictions based on future data inputs. Such intermediate, non-expressive reproductions do not compete with and have no impact on the economic interests that copyright is intended to protect.Furthermore, computational analysis does not involve the consumption of any copyrighted works for their expressive content. Rather, such analysis involves mathematical calculations of probabilities, correlations, trends, and other patterns across the entire tokenized data set. Such analysis seeks to understand only the mathematical patterns (e.g., the relationships of specific tokens in relation to other tokens) distributed across the entire data set. These mathematical patterns are themselves not expressive content protected by copyright law. 1. Reproduction of a Work for Purposes of AI Computational Analysis Should Qualify as Fair Dealing under the Copyright ActIt is impossible to draw a generalized conclusion that all applications of AI involving the reproduction of copyrighted works will qualify as fair dealing. Nevertheless, in most cases, it is appropriate to treat as fair dealing the creation and use of AI training databases for the purposes of analyzing a large collection of individual works to identify patterns, correlations, and other metadata to develop an AI model that makes predictions about future data inputs.Sections 29, 29.1 and 29.2 of the Copyright Act permits “fair dealing” as an exception to exclusive copyright. To qualify for this exception, the “dealing” in copyrighted content must be “fair” and for the purpose of research, private study, criticism, review, or news reporting. For the reasons stated below, the AI developer would ideally be able to rely on the fair dealing doctrine to construct an AI training database using materials to which he or she has lawful access. We offer an illustrative explanation of these points below. For example, an AI developer seeking to create a natural language processing model – such as an AI-driven predictive typing model – can rely on publicly available textual material (ranging from poetry or novels to anonymous website commentary) to create the training database. In such a scenario, the AI developer would not be reproducing this text for its expressive purpose. Rather, the reproductions would be made solely for the purpose of extracting unprotected information about the English or French language – i.e., the correlations, patterns, and relationships among the 26 letters of the alphabet and the millions of English and French language words, as they appear in thousands of stock phrases, figures of speech, similes, metaphors, grammar patterns, and common linguistic formulations and expressions. Neither these letters, words, and phrases, nor the mathematical patterns among them across thousands or millions of writings, are copyright protectable subject matter.Furthermore, the ultimate use of the computational analysis applied to the data set is often far removed from the intended use of the original content. Auto-complete functionality in predictive typing software comprises a new creation in the form of software code that is distinct both from the entire AI training corpus and from any single work within that corpus. Software code that can suggest the endings of commonly used phrases is many steps removed from any copyrighted works found in the underlying raw data. Finally, such functionality simply does not compete with any copyrighted works in any manner that copyright is intended to protect. 2. Canada Should Amend the Copyright Act to Adopt an Express Exception Covering Copying of a Lawfully Accessed Work for the Purpose of Computational AnalysisAs discussed above, reproduction of a lawfully accessed work for purposes of computational analysis should qualify as fair dealing under Canadian law.However, for greater certainty, BSA recommends that Canada adopt an express exception in the Canadian Copyright Act to cover copying of a lawfully accessed work for the purpose of “computational analysis.” Consistent with international best practice, ISED should ensure that any such exception is technologically neutral, sufficiently flexible so as to be future-proof, and agnostic as to purpose and user. With that in mind, the exception should extend to:Importantly, such an exception would be consistent with Canada’s international obligations. The TRIPs Agreement and Berne Convention require Member States to ensure that exceptions to copyright are confined to “certain special cases which do not conflict with the normal exploitation of the work and do not unreasonably prejudice the legitimate interests of the rights holder.”An exception to facilitate computational analysis of lawfully accessed works is consistent with each of these requirements. It would meet the “certain special cases” requirement insofar as it is clearly and narrowly tailored to advance a significant public interest in the development of AI. It will not conflict with the normal exploitation of copyrighted works because reproductions made during a computational analysis process are not visible to humans and cannot substitute for or displace markets for the original works.And, finally, a computational analysis exception will not prejudice the legitimate interests of a rights holder because the value derived from such processes is unrelated to the expressive content that copyright is intended to protect. Indeed, the very purpose of performing computational analysis is identify non-copyrightable information – such as the relationships and correlations between large corpuses of works – that can be used to train AI models. The value derived from such activity lies not in the factual information that is gleaned from any single source, but rather in the discovery of entirely new forms of knowledge that emerge from the identification of patterns and correlations that exist between large bodies of disparate sets of data.3. Any Other Reproductions Will Qualify as a Temporary Reproduction for a Technological Process under Section 30.71 of the Copyright ActIn addition to the reproductions that may be needed to create an AI training database, reproductions may also be made when the training data undergoes the computational analysis that occurs during the machine learning process. The Copyright Board of Canada interpreted this Section 30.71 as “intended to capture copies that happen automatically, or without the direct control of the user”, and that are automatically deleted once the technological process is completed.These fleeting reproductions are an inevitable byproduct of working with digital media, which must be loaded into the random access memory (RAM) of a computing device to be accessed, analyzed, manipulated or even deleted. In some circumstances, the creation of RAM copies may constitute a reproduction that is cognizable under the Canadian Copyright Act. However, the fleeting nature of the RAM copies involved in the machine learning process are unlikely to be considered “copies” that implicate the reproduction right.4. Voluntary Measures and Consensus SolutionsThere have been calls to create mechanisms that restrict access to works online for any purpose, including training an AI system. It should be remembered that automated “do not crawl” tools can prevent access to works online for any purpose, including training an AI system. We support further voluntary conversations between creators and AI developers and deployers to arrive at effective, consensus technical mechanisms.","C.           The Copyrightability of Material Generated by an AI SystemSection 2.2 asks about copyrightability. For both policy and legal reasons, copyright protection should be available for works generated by a human using AI. As long as sufficient human skill and judgment was involved in the creation of the work, the tool used in aiding the expression should not matter.Inquiries regarding copyrightability will turn on a close examination of the degree of human skill and judgment. Artificial intelligence is increasingly being used as a tool in all categories of creative works. A decision to limit copyrightability when AI is used would significantly chill adoption of AI solutions. In turn, this would limit creative expression and impact Canadian AI development.Works that emerge as outputs of AI systems and meet the human skill and judgment requirement should continue to be eligible for copyright protection. In most cases, AI systems will function as tools used by human authors to execute upon their creative vision. For instance, photographers will use AI-enabled tools to automate the tedious process of editing their images,  architects will use AI to augment their designs to enhance their energy efficiency,  and filmmakers will use AI to ensure that the movement of their animated characters appear more life-like.  In each of these cases, the creative contribution and exercise of skill and judgment by the human user makes it easy to conclude that the output would be copyrightable.The use of generative AI should not change the analysis. Certainly, there will be cases at either extreme, in which it is either clear that there was a lack of or trivial amount of human involvement or, on the other hand, generative AI was not part of the creative expression. We encourage ISED, in the first instance, to take a broad view of copyrightability. The Canadian Copyright Act provides courts with sufficient flexibility to closely examine these considerations when needed.","D.           Potential Liability for Infringing Works Generated Using AI SystemsSection 2.3 relates to potentially infringing works generated using AI systems.  BSA offers the following observations.1. Current Copyright Law Protects Copyright Holders from Infringement, Including in Cases Arising from AI Generated ContentCopyright holders should have full and effective remedies when their rights are infringed. This principle applies equally to outputs generated using AI systems and outputs generated in other ways. Whenever such infringement is found, it is critical to fully compensate artists and creators for any damages caused.In our view, existing copyright law should prove adequate to address questions of infringement. In most AI use cases, such as those described above, the output of an AI system will not implicate copyright at all. However, AI, like other technologies, could be used to create infringing material. Generally speaking, in those situations, infringement liability would be premised upon an assessment of the degree of similarity with the copyrighted work. Many users of generative AI will be small businesses experimenting with new tools, and enforcement decisions should take account of this. Liability would also arise in other appropriate cases, such as those involving derivative works.Plaintiffs may also seek to bring infringement actions against providers of AI-related services. Here too, existing copyright doctrines should prove adequate in evaluating and apportioning liability. If a plaintiff demonstrates that a direct infringement has occurred, courts will evaluate whether the service provider should be deemed contributorily and/or vicariously liable for its users’ conduct. In the context of contributory liability claims, the staple article of commerce doctrine will ensure that providers of AI services with substantial non-infringing uses are not liable for their users’ infringing activity unless there is evidence that the service was made available with the object of promoting its use to infringe copyright.2. AI Models Trained on Sufficiently Large Data Sets Are Less likely to Produce Infringing OutputsWhile it is important not to conflate training data with the output of an AI system, it is worth noting that the more data available for training, the less likely the system will produce a copy or derivative of an input (in the absence of a user’s intent to infringe). In any well-designed AI model trained on a sufficiently large data set, computational analysis should never (or only in the rarest of circumstances) produce outputs that are “substantially similar,” let alone “virtually identical,” to any specific copyrighted work.  As Professor Matthew Sag of Emory University has explained,At the moment, memorization [i.e., the accidental replication of a particular work from a training set] is an edge case. For the most part, the link between the training data and the output of generative AI is attenuated by a process of decomposition, abstraction, and remix. Generally, pseudo-expression generated by large language models does not infringe copyright because these models “learn” latent features and associations within the training data, they do not memorize snippets of original expression from individual works. Additionally, some AI developers and deployers are already taking steps to engage with artists and creators on how to support their work in a changing digital environment and taking steps to limit misuse of an AI system, such as limiting what prompts can be used.","BSA thanks the ISED for the opportunity to provide comments in response to the ISED’s consultation. As discussed above, the non-consumptive computational analysis of copyrightable content in AI training data sets should not be treated as an infringement of copyright under Canadian law. While we believe that the computational analysis of copyrightable content in AI training data sets is not a copyright infringement under Canadian law, to the extent that Canadian law is unsettled in this regard, we urge the development of a specific statutory exemption to the use of copyrighted material within AI training sets. At the same time, BSA also supports multi-stakeholder efforts relating to AI training processes as well as efforts to minimize the risk of infringement. And to the extent that infringement occurs, BSA strongly supports fully protecting content creators."
Coalition for the diversity of cultural expressions,Alliance / Union / Guild,"B. Fact Finding: Recent Applications of Generative Artificial Intelligence (AI) in the Cultural SectorThe CDCE has been examining the interaction between AI and culture for several years. [See for example, CDCE (2018), Ethical Principles for the Development of Artificial Intelligence Based on the Diversity of Cultural Expressions : https://cdec-cdce.org/wp-content/uploads/2018/11/EN-CDCE-AI.pdf.] Our members recognize AI’s potential and are exploring the benefits of this new technology. AI, like other tools, can be used to enhance and support human creativity when used responsibly and ethically. In the cultural industries, AI is used as a tool that supports – not replaces – the original human expression of creators’ works. Some creators are using AI as a tool as part of their creative process to reduce some of the time-intensive, rote aspects of their work. Publishers and producers are using it to assist with layout, style, visual effects, color-correction, and sharpening detail, among other things. When used responsibly, AI can provide tremendous value to the creative process. However, when used irresponsibly, AI has the potential to seriously undermine and damage the cultural sector and the diversity of cultural expressions in Canada, and around the world.This Consultation is focused on “Generative AI”, that is, systems that use deep-learning models that can generate high-quality creative content based on the works, performances, and sound recordings they have been built on. In comparison, “traditional AI”, generally refers to tools or systems that perform specific tasks based on predefined rules and inputs. Using AI to assist in crafting a response to an email is markedly different than using it to produce a song, an illustration, or a poem. When considering whether change is needed to copyright policy, there is a need for careful differentiation between the two. We are pleased that the Government has focused this Consultation on Generative AI and concentrate our response on that next generation of AI.As a general principle, AI developments can and should co-exist with a copyright system that incentivizes creators to create and disseminate their work and protects the rights of copyright owners. But Generative AI platforms are profiting significantly from the unauthorized uses and reproductions of the works, sound recordings and performances represented by CDCE members.As noted in the Consultation Paper, the text, and data mining (TDM) used for Generative AI systems involves the reproduction of large quantities of data and copyright-protected works, performances and sound recordings. These “inputs” in TDM are often copyright-protected works, or other subject matter, for which no licenses are sought, nor any compensation flowing to rightsholders.TDM also infringes authors’ moral rights. No attribution is given to the authors of the text, music, artwork, and other copyright-protected content that is ingested into Generative AI systems, either during the training of the system or during the use of the system. TDM also distorts works, including by cropping photographs, using lower resolutions, and disaggregating lyrics, text, or lines of music into segments and reassembling them into different sequences. These material alterations and mutilations offend the integrity of authors’ works to the prejudice of their honour and reputation.The outputs of Generative AI similarly pose fundamental and existential issues for the cultural sector. As examples, in the music sector, Jukebox, released by OpenAI in Beta form, can produce a “wide range of music and singing styles, and generalizes to lyrics co-written by a language model and an OpenAI researcher” precisely because it has ingested vast amounts of previously composed and recorded music. [See Jukebox (openai.com) : https://openai.com/research/jukebox] Similarly, MuseNet can generate up to “4-minute musical compositions and can combine styles from country to Mozart to the Beatles”. OpenAI states that MuseNet discovered patterns of harmony, rhythm, and style using the same technology as GPT-2, a large language model that ingested a dataset of 8 million webpages. [See: MuseNet (openai.com): https://openai.com/research/ musenet]. Books3, used to train Meta’s Generative AI, was based on a collection of more than 191,000 pirated books. [See: These 183,000 Books Are Fueling the Biggest Fight in Publishing and Tech – The Atlantic : https://www.theatlantic.com/technology/archive/2023/09/books3-database-generative-ai-training-copyright-infringement/675363/].Generative AI outputs also often infringe creators’ copyrights by reproducing and communicating to the public “lookalikes” and “soundalikes” of creators’ original expression, often in response to prompts of users seeking exactly that. In addition, various applications rely on AI, including TDM, to generate synthetic media, such as deepfakes, holograms, digital replicas, stand-ins, voiceovers, virtual characters, and environments. Applications can reproduce a person’s voice, image and/or likeness. Text-to-speech systems can reproduce a person’s voice, while other systems can rework the facial expressions of actors to assist with dubbing. If the output incorporates performer’s image or likeness, it is a reproduction of a substantial part of that performer’s performance and an infringement.Finally, AI-generated output can also infringe authors’ moral rights. As one example, if a work is marketed as “in the style of” or “in the sound of” a particular author, the use will often be a bastardization and inferior copy of the author’s work. Infringing output can also be used in inappropriate contexts, like in a political campaign with which the author does not agree. Both examples could cause real prejudice to the honour and reputation of the author.These types of outputs compete directly with the market for creators’ works, and threaten the livelihoods of Canada’s writers, authors, actors, publishers, musicians, songwriters, composers, visual artists, performers, directors, labels, music publishers, and producers.All these uses, and the consequent infringements, must be considered when examining the copyright policy implications of Generative AI.","C. Proposed New Exceptions are Unwarranted and UnnecessaryThe Consultation paper asks, “What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?” Absolute clarity around copyright and TDM in Canada need not be the goal of this Consultation, or of copyright policy more generally, especially as the market is developing around these new uses. Serious risks arise from assuming that a new form of technology automatically requires the creation of a new exception. Reflexive approaches do not, and cannot, consider the speed at which Generative AI technology is evolving and the resulting impact on affected markets.Moreover, introducing a new exception for TDM now would interfere with the ability of market participants, namely users and rightsholders, to set the boundaries of that emerging market. It would be particularly disruptive for the Government to introduce a new exception for TDM as licensing models are developing and emerging. Various licensing models for the use of copyright-protected works, performances and sound recordings in Generative AI already exist in the market, including:Given the nascent market for the licensing of TDM activity and Generative AI partnerships that are developing between AI developers and rightsholders, now is most certainly not the time for the Government to step in and introduce new exceptions. Instead, the Government should allow the market to work out market-based licensing solutions for TDM uses in Generative AI. According to the Consultation Paper, “Because of the large quantity of data often involved in training such models, in particular when sources from the Internet, obtaining any necessary authorization from rights holders to make reproductions of the works or other subject matter in the course of these activities could be a significant burden”. Given the above examples, this is most certainly not the case.Rather, it appears that those who are calling for exceptions prefer to lobby governments around the world as opposed to coming up with market-based solutions. After all, sometimes market-based solutions come with a price. Exceptions are usually free. The Consultation Paper raises the 2019 EU Directive that requires member states to provide two TDM exceptions: one for research and heritage institutions, and one for any other person and purposes, which rightsholders can “opt out” of. Any suggestion of an “opt-out” regime for TDM is both controversial and impractical. The introduction of an exception that gives rightsholders the ability to “opt-out” of such an exception turns copyright on its head. Copyright is an opt-in system: no formality is required for a work to attract copyright protection. Requiring a copyright owner to advise a platform that it objects to the use of its work in TDM for Generative AI is a formality that violates Canada’s obligations under the Berne Convention. There is no basis to throw out these fundamental principles of copyright law and Canada’s international treaty obligations.An opt-out system would require all copyright owners to monitor every Generative AI platform available in Canada and send some sort of notice to each Generative AI operator or application developer advising that it has chosen to “opt-out” of the exception for TDM purposes. As discussed below, copyright owners would first have to know that their works, performances, or sound recordings were being used by the Generative AI operator/application developer, or otherwise send a notice to all of them. Rightsholders would also have no remedy regarding any copying that took place before they opted-out. That is a massive burden to put on copyright owners and is wildly disproportionate to this supposed problem.There have been suggestions in other jurisdictions that a compulsory licensing regime may be appropriate for TDM. Compulsory licensing deprives creators and copyright owners of their exclusive rights to authorize the reproduction of their works, performances, or sound recordings by forcing them to license, deprive them of fair compensation for those uses. It similarly deprives rightsholders of the ability to prohibit the use of their content by a service that might ultimately be cannibalizing the need for their own labour or that produces content that acts as a substitute for their original work. The implementation of such a regime would also impose a significant burden on copyright owners to administer and enforce. Additionally, implementing compulsory licensing for TDM is a solution in search of a problem. Compulsory licensing might make sense in certain special cases when voluntary licensing is impossible, such as the use of copyright-protected works or other subject-matter by retransmitters contemplated under section 31 of the Copyright Act. But here, licensing is not impossible: there is a functioning and growing market for licensing for TDM uses.There is no reason to conclude that the current law is insufficient to address any uses that might arise with respect to the training of Generative AI. The Copyright Act is sufficiently technologically neutral to accommodate technological development and foster Generative AI innovation. As noted in the Consultation paper, there are existing exceptions in the Copyright Act that may assist users in appropriate cases. Until and unless a Canadian court or the Copyright Board exposes a real deficiency with respect to Generative AI that needs to be addressed, there is no valid policy reason to introduce any exception for TDM.As AI developers and platforms are keenly aware, entering any market involves assuming responsibility for the impact of their new technology on that market and the players within it. The platforms must be responsible for respecting the copyrights of creators.Numerous exceptions in Canada’s copyright laws have already caused a structural imbalance in the Copyright Act: an imbalance that is depriving rightsholders of their “just reward” and that may otherwise discourage and disincentivize copyright owners from creating and disseminating their works, performances, and sound recordings. The introduction of any additional exceptions for TDM purposes would only serve to further upend the balance sought in the Copyright Act. There is no need to introduce exceptions allowing further uses of rightsholders’ works, performances, or sound recordings in Generative AI systems.Recommendation 1. That the Government neither amend the current exceptions to include TDM, nor implement new exceptions for TDM.D. Questions of Fair Compensation Should Be Left for the Market to DetermineWith respect, when and how rightsholders should be compensated for the use of their works, performances, or sound recordings as inputs into Generative AI systems is not a question that should be answered by the Government. Nor should the Government interfere with the question about what level of remuneration is appropriate. The compensation and fair remuneration required for the use of a given work, sound recording, or performance will, and should, be set by the market or, if need be, the Copyright Board of Canada.This question is properly the subject of negotiations between rightsholders and Generative AI platforms. There may indeed be instances where rightsholders agree with a platform that compensation is not necessary. But the Government should not decide that question. Doing so would simply impede those negotiations and prevent a market-based solution for TDM.But additionally, it is not just compensation that should be the focus of the question. Among other things, the Copyright Act provides rightsholders with exclusive rights to reproduce their works, performances and sound recordings, or any substantial part thereof, and to authorize any such acts. These rights are engaged when copyright-protected works, performances and sound recordings are ingested into Generative AI systems. Authorization and permission are as important as compensation, particularly when the system output might compete with, or act as a substitute for, the original work. Again, market negotiations and the developing licensing market ought to decide these questions, not the Government.","THIS IS THE CONTINUATION OF THE PREVIOUS SECTION (TDM), DUE TO THE CHARACTER LIMIT.E. Challenges with Licensing, Monitoring and EnforcementThe Consultation Paper asks whether rightsholders are facing challenges in licensing their works or related rights for TDM activities. Many platforms appear to believe the ingestion of copyright-protected content in their systems is already exempted, or that it does not require authorization, under copyright law in Canada. Globally, Google is so confident that the inputs to some of its Generative AI platforms and the output generated by them are non-infringing that it is indemnifying its users from copyright infringement claims:“If you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved. To do this we will employ a two-pronged, industry-first approach designed to give you more peace of mind when using our generative AI products. The first prong relates to Google’s use of training data, while the second specifically covers generated output of foundation models. Taken together, these indemnities provide comprehensive coverage for our customers who may be justifiably concerned about the risks associated with this exciting new frontier of generative AI products.” [See: Google: https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification]Microsoft is similarly confident, offering to “defend its customers from intellectual property infringement claims arising from the customer’s use and distribution of the output of its Generative AI Copilot services”. [See: Microsoft: https://www.microsoft.com/en-us/licensing/news/microsoft-copilot-copyright-commitment].Notably, the former VP of audio at Stability AI (the maker of the popular image generator Stable Diffusion) announced that he recently resigned from his role at Stability AI because he did not agree with the company’s opinion that ingesting copyright-protected content into Generative AI models is fair use. [See Stability AI VP quits in 'fair use' copyright protest • The Register: https://www.theregister.com/2023/11/16/stability_ai_vp_quits/]These types of ingrained and bullish positions pose challenges for rightsholders in licensing their works, performances, and sound recordings for TDM.In addition, rightsholders have no insight into whether their works, performances or sound recordings have been ingested into any Generative AI platform. TDM on any platform is a black box. This information asymmetry, and resulting imbalance in negotiating power, makes monitoring and the resulting licensing opportunities incredibly difficult for rightsholders. At best, licensing transactions are inefficient: rightsholders are left with the choice of guessing whether a particular Generative AI system has used their works or waiting for the operator of a system to approach them for a licence. At worst, there is complete market failure where operators are free riding off the backs of creators’ content. This imbalance must be corrected. For all these reasons, we recommend the Government apply legally binding transparency obligations to Generative AI systems, like those that were recommended by the European Parliament and contained in the provisional agreement for foundation models [See: European Parliament : https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence and European Council: https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/]Recommendation 2. That Generative AI platforms be required to comply with transparency requirements, including, but not limited to: (i) publishing records of the copyright-protected works, sound recordings and performances that were ingested into the platform; (ii) designing the model to prevent it from generating illegal or infringing content; and (iii) disclosing that the output produced by the system was generated by AI.These obligations ought not be limited to “high-impact systems” as defined and contemplated in the Artificial Intelligence and Data Act (AIDA) proposed in Bill C-27 but must apply to all Generative AI large language models.The imposition of transparency requirements should not cause any real challenges for developers because they already document this data. As one example, the GPT-2AI model card published by Open AI in 2019 includes a list of the top one thousand domains present in their dataset, as well as their frequency. In this log, you will find illegal sites (Pirate Bay), pornography (YouPorn) and sites of rightsholders (Le Monde, CBC) [See https://github.com/openai/gpt-2/blob/master/model_card.md] By requiring transparency, not only will rightsholders have access to essential information for the management of their copyrights and related rights, but users of the systems will have critical information about the sources and biases that may be inherent in the system itself.While these proposed transparency requirements are not all copyright-specific, and may instead more properly be the subject of Bill C-27 or other legislation, increased transparency in the inputs into and use of Generative AI will help ensure the systems are responsible, lawful, safe, transparent, accountable, and non-discriminatory.THIS IS THE BEGINNING OF THE NEW SECTION ""AUTHORSHIP AND OWNERSHIP""F. Attribution/Ownership/AuthorshipThe questions asked in the Consultation regarding authorship and ownership of copyright in AI-generated content raise fundamental questions for the cultural sector. While the Copyright Act does not explicitly define the word “author”, Canadian case law has already reiterated that original works protected by copyright must be the product of an author’s exercise of skill and judgment, which “must not be so trivial that it could be characterized as a purely mechanical exercise”. [CCH v. The Law Society of Upper Canada, [2004] 1. S.C.R. at para. 25.]Debates on this issue are ongoing at WIPO and in many other jurisdictions, including the United States and the European Union. However, the international consensus is that human authorship is core to copyright and that content generated by AI without any human involvement is not, and should not be, protected by copyright. CDCE agrees with this consensus. The same principles apply to performer’s performances: only human performances are entitled to rights and protections under the Copyright Act.The purpose of copyright is, in part, to obtain a just reward for the creator (and prevent someone other than the creator from appropriating whatever benefits may be generated) and to incentivize further creation. At this point in time, there is no need to amend the Copyright Act to create new rights to incentivize the creation of AI-generated content.Granting copyright or related rights to Generative AI systems for autonomous or mechanical content, without original expression of an idea attributed to a human author or performer, would shift the copyright regime from a paradigm of protecting and promoting human creativity to the pursuit of innovation and revenues for companies of all kinds. This would have far-reaching consequences, the long-term impact of which is difficult to anticipate. Finally, there is something perverse and frankly, offensive about suggesting that there should be an exception to human authors’ and performers’ copyrights and related rights for the inputs into Generative AI systems, while also providing the same platforms with additional copyright protections for non-human generated outputs. Leaving aside the resulting job losses in the sector, this prospect of mass production of pseudo-cultural content entirely generated by Generative AI systems is a major social concern. “Creation” would be the result of companies seeking solely to make their products mass marketed and profitable, as opposed to having a multitude of diverse creators and artists expressing their own thoughts, views, opinions, commentary, and creativity.Products resulting from purely mechanical AI generation processes that lack original human expression are not “works” protected by copyright or any sort of neighbouring right and should not become so.Recommendation 3. That the Government not amend the Act to afford copyright protection to AI-generated content.In addition, it is important that performer’s performances continue to have rights and protections like those they current enjoy under the Copyright Act, whether or not the underlying content is generated by AI. Recommendation 4. That performers' performances remain fully protected under the Copyright Act, including when the content performed is AI-generated.","G. Infringement and Liability.To establish infringement, a rightsholder must prove that the defendant copied or made available all or a substantial part of a work, performance, or sound recording, that the defendant had access to the original work, performance or sound recording and that the original work, performance, or sound recording was the source of the copy. Independent creation is a complete defence to infringement.The biggest barrier to determining whether an AI system accessed or copied a specific copyright-protected work, sound recording, or performance is the lack of transparency described above. Without some knowledge of the copyright-protected content ingested into a Generative AI system, rightsholders can only suspect that their content has been used without authorization. In some cases, this will lead to undetected or unproveable large-scale infringements. It will also lead to a process where rightsholders are forced to sue Generative AI platforms they assume have infringed their copyrights in to (hopefully) obtain disclosure in discoveries, incurring significant time, resources, legal and expert fees, and expenses. At the end of that process, a rightsholder may find out the platform never had access to the copyright-protected content in the first place. This would result in a wildly inefficient system and cannot be the intent of the Government.Requiring Generative AI systems to publish records of the copyright-protected content that was ingested into the systems is necessary so that copyright owners can protect and monetize their intellectual property. With these transparency obligations in place, liability could potentially arise for primary, secondary, or authorizing infringement, enabling infringement, moral rights infringement, removal of digital rights management information, and circumvention of technological protection measures. From an infringement perspective, the current Copyright Act will be sufficient to address issues specific to Generative AI provided these record-keeping and disclosure obligations are in place.Perhaps more importantly, transparency requirements will also promote a functioning and more efficient licensing market where rightsholders and users can negotiate on a more level playing field by reducing the information asymmetry that is currently present in the market.Finally, the Government must consider the impact of Generative AI on authors’ and performers’ moral rights, including their rights to the integrity of their works and performances, as well as name and likeness rights and rights of personality and publicity. While not nearly a full answer to these issues, transparency obligations and disclosure requirements will at least signal that uses like deepfakes and voiceovers, are not sanctioned by the performers they are imitating.Ultimately, the aim of this Consultation on Generative AI should be to encourage responsible use of copyright protected works and a healthy, functioning licensing market for the use of copyright-protected works, sound recordings and performances in TDM. Transparency obligations that require Generative AI platforms to disclose records of the copyright-protected content that was ingested – as opposed to the creation of new exceptions – is the best way to ensure that Generative AI can continue to innovate alongside a copyright system that incentivizes creators to create and disseminate their work and that provides them with their just reward.","Here is a summary of the CDCE recommendations for this consultation :- Recommendation 1. That the Government neither amend the current exceptions to include TDM, nor implement new exceptions for TDM.- Recommendation 2. That Generative AI platforms be required to comply with transparency requirements, including, but not limited to: (i) publishing records of the copyright-protected works, sound recordings and performances that were ingested into the platform; (ii) designing the model to prevent it from generating illegal or infringing content; and (iii) disclosing that the output produced by the system was generated by AI.- Recommendation 3. That the Government not amend the Act to afford copyright protection to AI-generated content.- Recommendation 4. That performers' performances remain fully protected under the Copyright Act, including when the content performed is AI-generated.H. Other Copyright Act Amendments The CDCE has made other recommendations to improve the Copyright Act, which are reproduced here. We request that the next copyright reform include these other recommendations, even if they are not subject to the current consultation.We thank the Government for this opportunity to provide our comments on this important Consultation.The six urgent recommendations of CDCE members:1. Amend the fair dealing provisions in the context of education so that they only apply where a work is not commercially available under a license by the rightsholder or a collective society.2. Incorporate resale right into the Copyright Act.3. Abolish the public performance royalty exemption for performers and producers for commercial radio stations.4. Amend the definition of sound recording to include sound recordings that accompany audiovisual works.5. Amend the Act to confirm the binding nature of tariffs set by the Copyright Board.6. Restore the private copy regime in the music sector.The six mid-term recommendations of CDCE members:1. Ratify the Beijing Treaty and grants moral and economic rights to performing artists on audiovisual media in the Act.2. Raise the upper and lower limits of statutory damages for non-commercial violations and allow the establishment of higher damages in case of systematic and massive use.3. Ensure that right holders in the various sectors have the same tools by ensuring that all collecting societies can claim statutory damages of three to ten times the value of the tariff that has not been paid.4. Improve the private copying regime by allowing the payment of royalties for rights holders in the audiovisual, literary, and visual arts sectors.5. Amend the exemption in section 32.2(3) to limit its application to acts without motive of gain.6. Take into account the needs and realities of Indigenous artists, creators, and organizations.The CDCEThe Coalition for the Diversity of Cultural Expressions (CDCE) brings together the main English and French professional organizations in the cultural sector in Canada. It is composed of 54 organizations that collectively represent the interests of more than 360,000 professionals and 2,900 organizations and businesses in the book, film, television, new media, music, performing arts and visual arts sectors. The CDCE’s main objective is to ensure that cultural goods and services are excluded from trade negotiations and that the diversity of cultural expressions is present in the digital environment.The Coalition ensures that Canada retains the sovereign right to develop, implement and modify the policies, programs and measures required to ensure we have a robust supply of Canadian artistic expressions of all kinds, in every medium, and from all communities. CDCE also works to protect and promote our artists and cultural industries, and to ensure there is a rich diversity of cultural expressions in Canada and globally, including in the digital environment.The Copyright Act is one of the key tools available to the Canadian government to foster a viable, sustainable, and diverse cultural ecosystem. The rapid developments in generative artificial intelligence over the past year will undoubtedly impact the diversity of cultural expressions in Canada. It is timely to question the robustness of the Copyright Act in this context. The CDCE, however, wishes to emphasize from the outset that this is not the only legislative tool that can or should be mobilized to protect the diversity of cultural expressions in response to these developments. The cultural sector requests to be included in all Canadian reflections surrounding the governance of AI."
"The International Alliance of Theatrical Stage Employees (""IATSE"")",Alliance / Union / Guild,"The International Alliance of Theatrical Stage Employees (""IATSE"") is the largest trade union representing workers in Canada's entertainment industry. Founded in 1893 (1898 in Canada), IATSE  has over 170,000 members - 34,000 of whom are in Canada. Their membership is comprised of virtually all of the behind-the-scenes workers necessary to the functioning of the entertainment industry - across film & television, animation, live entertainment, conventions, and trade shows. IATSE represents a wide range of creators and highly skilled technicians, including cinematographers, SPFX artists, animators, costume designers, props masters, hair stylists, makeup artists, aerial riggers, scenic carpenters, and many more. On a film set, the majority of the people working will be IATSE members. In a word, they are the crew.IATSE does not collect copyright protected content, use AI-generated content or develop AI systems. However, IATSE members are directly impacted by the use of AI-assisted and AI-generated content in the entertainment industry. The use of AI systems in the entertainment industry affects both current and future work opportunities and the ability of human workers to protect their livelihoods.Absent legal safeguards to protect copyrighted works and intellectual property, AI can be used as a tool for sophisticated theft and unauthorized replication of creative works that IATSE members have brought to life. Without legal protections, there will be incentive to train AI technologies to consume creative works for profit to the detriment of workers.AI is already a tool in use in the entertainment industry which is grappling with its unchecked proliferation. Realistic replications have been made of creative works using AI including voices, faces, performances, and sounds. The rapid advances of this technology have led entertainment industry employers in the industry to consider how AI systems may create opportunities for profit. In both the Writers Guild of America (WGA) and the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA) labour disputes in 2023, the use of AI was a key issue.Without appropriate guard rails, the work of IATSE members can be used to train AI systems to create material without consent or contribution. It is an ongoing concern to IATSE that AI generated content may replace work historically performed by trained professionals including art directors, costume designers, audio visual technicians and others.The use of AI in the entertainment industry presents a great opportunity to complement existing roles through the availability of additional tools instead of a harmful weapon that will devalue creative work. The legal framework must protect the human efforts engaged in creative work.In light of its role in the industry, IATSE is well positioned to provide a worker's perspective concerning AI and its use in the entertainment industry.","TDM activities in the entertainment industry must be regulated. AI systems should not be used to consume copyrighted material to create works without permission from and compensation to copyright holders.TDM activities in the entertainment industry rely on the use of copyrighted works to operate. The TDM systems cannot operate without first consuming human created work such as writings, recordings, photographs or videos. For example, TDM activities can be used to consume entire works of art to create a product such as a screenplay. TDM has been used to create convincing replicas of works including scripts, audios and visuals.There must be basic floors and protections included in the legal framework for those who may be impacted by TDM activities. TDM activities must be transparent. Without this transparency, the rights holders and creative contributors will face practical impossibilities in understanding where works have been consumed. An opt out system should not be adopted as it would unduly place the onus on copyright holders to enforce their rights. An opt out system would create a windfall for technology companies to profit until each copyright holder asserts a right.Similar to privacy legislation in Canada, the legal framework should include a clear consent requirement. Express consent should be mandatory before copyrighted works are used to train AI systems and generate material. Records must be kept and disclosed in order to permit inspection or investigation of the content that was used in TDM activities. Without such a requirement, it would be practically impossible to investigate or challenge any TDM uses. Rights holders would lack the requisite knowledge to assert or enforce rights.Developers of AI systems that engage in TDM activities must be required to collect, retain and disclose records relating to the specific materials used to train their models. This material should be searchable in order to provide a practical mechanism by which individuals and trade unions can monitor and enforce rights. The enforcement tools must include ""teeth"" in order to be effective. The legal framework must include penalties, damages, and rights of action where it can be demonstrated that a work was used in TDM activities without a corresponding record. The legal framework must hold those who create TDM systems accountable for the consumption of data and creative material. The act of consuming the material itself must be fairly compensated as it is this material that is used in TDM activities to train the system. The legal framework must reinforce the bargaining power of labour unions such as IATSE in securing fair compensation for the use of material in TDM activities.Canada should not model legislation in the European Union, United Kingdom, Japan or other jurisdictions which have to some extent passed legislation permitting the consumption of copyrighted works without consent or compensation. For example, Japan allows for the consumption of copyrighted material for use in commercial works and does not require a party to first have legal access to those works. Any broad TDM exemptions or a failure to require consent and compensation will devalue labour and destroy any possibility of a basic floor of ethical rights and acceptable uses of this powerful technology.","The authorship of AI assisted works is a complex question which is not easily answered. For copyright to arise under the current jurisprudence, work must be produced by an author's skill and judgement. The use of AI as a tool at some point in the creation of a work should not in itself wholly disqualify a work from copyright protection.There are instances where this technology is already ethically in use as a tool by creatives in the process. Where creative professionals use their human labour to use AI as a tool to create work, there must be distinction in the law to recognize and protect that human effort. Copyright law must distinguish between creative works that are largely machine created and those that are a result of human effort, guidance and creative control. Where AI is used as a tool to create a work, while being guided and molded by a human, that human expression ought to receive legal protection.  Works that are predominantly AI generated lack a requisite human element and should not be recognized as eligible for copyright.","The legal framework must provide sufficient enforcement mechanisms in order to provide tools by which copyright holders can actually assert their rights. Assessing infringement of copyrighted works by AI systems creates certain difficulties in determining the identity of the creator of the infringing work. Greater clarity must be provided concerning where liability lies both in the circumstances of primary and secondary infringement. Liability must not only attach to those creating AI work that infringes copyright, but also where it is further distributed. Record keeping, stored data sets and transparency mechanisms are necessary to understand what work was used or reproduced in the creation of AI generated work. Ultimately, it is humans who must be responsible for the actions of the AI systems they create. Enforcement mechanisms will be meaningless if malicious actors can hide behind the activities of the technology they have enabled. IATSE welcomes clarity in ensuring liability rests with those who infringe copyright protected works.",N/A
"The Canadian Animation Guild, IATSE Local 938",Alliance / Union / Guild,"Measures to limit risk of producing copyright-infringing work are distinct to the different levels of authority and creative involvement that individuals have during a production. The workers are responsible for sourcing, producing and editing assets, art and writing. Leadership in studios will decide upon the methods, tools and programs that workers must employ on a project. CAG938 is able to provide perspective on what measures are taken by all of these roles to mitigate risks of copyright infringement.Workers are required to ensure that assets they produce for clients and studios are free of copyright infringing material. This responsibility is easy to meet when working with standard artist tools because the production of the work employs many conscious choices. An artist can decide to not reuse work they have created for a client in the past, and to not plagiarise work made by others. Any risk they are exposed to in the completion of their work is within their own control because they are exercising their judgement at each step of the process.If workers are required to use AI in the completion of their work it is no longer easy for an individual worker to ensure the output they produce is free of infringing material. Artists are not generally trained in the skills needed to examine the quantity of data needed to train a generative AI model and ensure that dataset is free of copyright-protected material. Additionally, no production schedule allows them the time to fully examine a dataset, should they in fact have the skills to do so. They would not be able to reasonably remove the ability of an AI model to produce infringing output, and would be far less able to recognize infringing works created by AI.Most animation studios in Canada are not developing their own datasets and models for generative AI in-house. Studios are licensing pre-existing datasets and models. Our AI in the Workplace report form hosted on the CAG938 website (CAG938.ca) has received reports indicating that studios that are using AI tools are employing Open AI, Midjourney, Chat GPT, Adobe Firefly and Dall-E in their explorations. Because the studios are relying solely on these outside tools, they are not taking a role in the curation of the datasets being used and rely on the developers of the tools to report accurately on the use of copyright-protected data.It is possible for a human artist to create work that is copyright-infringing without intending to, but it happens rarely and at a rate that is reasonable to correct, while work that is created through generative AI is much more prone to infringing on copyright. Creative products are made through the synthesis of human memory and expression and workers create based on what they have seen and felt. It is easy for a worker to know when they are intentionally plagiarising someone. Studio management can thus rely on the workers they employ to not produce infringing material. Generative AI uses no such self-awareness when working with the massive datasets it relies on. Also, it is drawing on a body of work many times larger than any one artist on a team could hold in mind. The massive datasets make it difficult to recognize infringing output made by the generative AI, because there is no guarantee that the workers on a production would be aware of all of the copyright-protected works in the dataset. Taken together, work created by generative AI is prone to “overfitting” and creating work that would violate copyright protections. The Institute of Electrical and Electronics Engineers (IEEE) recently reported on this issue and assembled a useful demonstration of how easy it is to prompt infringing material from generative AI. (https://spectrum.ieee.org/midjourney-copyright) If the team of artists and management both fail to recognize infringing output that a generative AI is likely to produce, it opens both of these groups up to risk.Largely, the ability to mitigate risk of generative AI producing infringing content is out scope for individuals making artistic and management choices in the Canadian animation industry. The individuals that do have access to the training data are the only ones that can prevent infringing output being produced by managing the data that is input into the model in the first place.The creative industries in Canada have been involved in the development of AI systems by no choice of our own. Our local’s members and their peers are being relied upon as producers of training data. This data can include the scraping of workers’ independently produced artworks as well as the work they make for hire in studios. It is a massive amount of labour and human experience. Generative AI would not have developed to the point that it has without our work fed into it.In very simple terms, the developers that gather the datasets upon which generative AI relies, produce them by using web crawlers, scrapers and data mining. They collect massive amounts of data from across the web and from archives, and sort it into usable sets of data using a system such as a Contrastive Language–Image Pre-training program (CLIP). The CLIP identifies what words describe what images, and from the parsing of those relationships it then predicts what it is being asked for when prompted to create something. This explanation is a simplification of how LAION curates their LAION-5B dataset, used by many developers including Stability AI, Midjourney, and Google, and how Open AI describes their own CLIP approach. Deeper intricacies in the process exist, but this is a solid summation of the processes.Even though the majority of creative workers in the Canadian entertainment industries are not writing code, we are involved in the creation of these systems as subjects of study. The generative AI’s outputs suffer when the input of training data is interrupted, either through cloaking artwork through the Glaze program (https://techcrunch.com/2023/03/17/glaze-generative-ai-art-style-mimicry-protection/) or actively attacking the images in the data source through data “poisoning” tools such as Nightshade (https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/). When we are removed from the generative AI process, it ceases to function. As essential players in the creation of this technology, we have a right to decide how it is used.Generative AI can show up in myriad ways across the Canadian Animation and Video game industries. Our Local has received reports of the use of AI in pre-visualization, design, writing, compositing and in at least one visual effects studio, all steps of the pipeline. Generative AI has been used to create short animations in their entirety for large clients such as Disney and Warner Music. It has also been introduced into production pipelines in large and small ways from assistive colouring, to automation of processes, writing of emails and sorting of job applications.Animation, Games and VFX studio management often hopes to use AI as a tool to cut costs by automating work. The 2023 Writers’ Guild of America and Screen Actors’ Guild strikes in the United States spotlighted the lengths to which the The Alliance of Motion Picture & Television Producers were willing to go to have free rein to automate the labour of their workers. The WGA struck for 148 days and SAG-AFTRA struck for 118 days before the final tentative agreements, that included protections against AI, were accepted. The AMPTP are large clients of the Canadian entertainment industries, so their interests are naturally replicated in the Canadian studios that service them. Unregulated AI usage could result in a marked shrinkage of the animation, video games and VFX industries and result in a large loss of jobs.Another harmful angle that arises from AI being used to cut costs on creative work is the loss of unique Canadian artistic expression in a broader media landscape. Canadians have a distinct and valuable perspective that is appreciated worldwide. Within our nation we also have incredible varieties of human experiences and subjectivities that create a rich culture. AI design asks it to generate output based on the patterns identified in the training data. Therefore, it tends to recreate any bias present in the training data reducing its output to an echoing of dominant attitudes in culture. Because AI is unable to observe and experience the world and develop a sapient subjectivity, it cannot innovate in art in the way Canadians always have. Many great Canadian artists in the animation industry developed their unique artistic voices with the same jobs that are at risk of automation. Canadian animation and its distinct history risk losing the next generation to the cost-cutting associated with generative AI automation.In the future, there may be room for AI to be used as assistive tools to help make the work of creatives more efficient without resulting in automation of their labour. Canadian software developers have created tools that have become standard across the international animation industry, such as the Toon Boom suite, the industry standard 3D software Maya and the robust VFX software Houdini. Canadian-developed assistive AI software, that could rise to the international standard level that other tools have achieved, risks being lost in the current climate around generative AI. Generative AI banks on false promises about what it can do, and sells itself as a replacement for skilled human labour. The natural distrust for technologies peddled in this way stymies the potential for adoption of actual useful AI tools that could elevate human performance. Copyright legislation that protects the labour of creatives will also create markets for AI ingenuity that can exist alongside creative workers.Across the board, technical evidence suggests that legislation is needed to make clear how generative AI should interact with copyright.","Clarity and regulation around copyright and TDM, applied appropriately, would help to boost both the AI and creative industries. The ability for copyright holders to opt out of TDM is essential to new legislation. Ideally, law would allow for all Canadians to enjoy security in the knowledge that by default their personal and copyright protected data may not be used for TDM. Regulations that protect the copyright of creatives and ensure that they are fairly compensated for the use of their works, or that allow them to opt out of the use of their works, will give artists the safety they need to be able to work alongside new technology.Current TDM law in Canada does not guarantee the right to opt out of data mining. This lack of control, combined with the fact that large quantities of data that is being mined was scraped from public internet pages leaves many Canadians feeling exposed and has broken their trust in public virtual spaces. The LAION-5b dataset was created through the TDM of the data collected by Common Crawl. Common Crawl is a project that employs web crawlers and data scraping to maintain what it describes as a copy of the internet. LAION-5b is used as a dataset for Stability AI, Midjourney, Google’s Imagen and more AI models. A developer can download an artist’s body of work, mine it for data, and then output work that either is directly infringing on that artist’s copyrights or so visually similar to that it would be mistaken for their output, without ever speaking to that artist. Where there is consent, there can be no trust in the technology.When an artist attempts to exercise their copyright and remove their work from TDM for AI, the lack of relevant copyright law can embolden the infringement. This backfiring was the experience of Sam Yang, a Toronto-based artist. (https://shorturl.at/bgsKW) Yang found himself unable to rely on existing copyright law, because it does not adequately define infringement when AI is involved.When copyright is respected, and the work that can be done in AI is limited to innovation within those parameters, that is when truly useful tools will be developed. Most AI tools on the market currently are polished randomization tools that use mass amounts of copyright-protected work in order to generate flashy output. While that output may look impressive, it betrays a lack of competency or insight. Under scrutiny, the errors that are made by AI are very basic and easily to spot. This casts doubt on the efficacy of the tools and undermines the credibility of the entire field. Smaller, properly licensed datasets will necessitate true innovation in AI.TDM is happening in Canada, and the copyright protected data of Canadians is being processed using TDM. We have observed the data of our industry peers being used, and the low barrier to conducting TDM makes it easy for anyone to engage in this practice. While it may be possible to list every individual running TDM applications within Canada, it is less useful than examining the evidence that TDM is impacting Canadian industry.Canadian artists’s data is being mined for training generative AI. Examining the Midjourney name list alone, which was entered into evidence in the Andersen v. Stability AI Ltd. lawsuit, makes it clear that developers relied heavily on the work of Canadian artists in order to train generative AI. (https://shorturl.at/pzGNZ) On this list of names, our union identified a number of our members as well as their clients. Canadian labour is present in the work captured from companies like Riot Games, and is likely captured in works attributed to animation professionals that work with Canadians such as Lauren Faust (My Little Pony) and Justin Roiland (Rick and Morty). Other notable Canadian artists that are on the Midjourney name list are: Danny Antonucci, Seb McKinnon, Joy Ang, Anastasia Ovchinnikova, Jason Rainville, Zara Alfonso, Janine Johnston, John Howe, Michael Walsh, Kate Beaton, Fiona Staples, Attila Adorjany, Bobby Chiu, Nina Matsumoto and more. Further, the presence of these names on the Midjourney list indicates that the program was trained to specifically mimic them. Works by many other artists yet to be identified have been mined to make up the rest of the training data to make broad descriptive categories.TDM is easily accessible for those with sufficient technical knowledge. A brief internet search quickly turns up the CLIP code that is used by many generative AI developers. (https://shorturl.at/IM258) There are also lists of open source LLMs available (https://shorturl.at/lrPX1) and proprietary options that can be licensed. Some research efforts, such as the BMO Lab for Creative Research, will publish details about their use of TDM (https://shorturl.at/ijFIS) while many for-profit ventures will not. With this ease of access, one can assert that where AI is being developed, TDM is happening. The government has a responsibility to regulate its use.Canada’s existing copyright law does not adequately require those conducting TDM to approach copyright holders for licensing to access their work. Because these developers need a massive quantity of data and are able to get it for free using datasets like LAION-5b, they have no incentive to ask permission or pay rights holders. Licensing modes for works at the scale needed can’t exist without both parties entering into good faith negotiations about employing them.Licensing for AI training is being explored most often by companies that sell stock photos, fonts, and creative assets. Their pricing structures reflect that existing industry. A client pays once for access to the assets, pays a higher fee for commercial use, and then pays additional fees to train AI. The right to negotiate costs for widespread or corporate usage of their assets is reserved in line with how they licence their other products. This is a useful framework to apply to licensing work for TDM as it allows for nuance based on usage.The question of remuneration is difficult to answer without precedent for what copyright the user of the generative AI will hold on the AI’s output. In keeping with current standards for licensing art assets, licensors should be able to determine the cost of the licence based on the demand and what income they stand to lose via automation and all relevant legal terms of service.Clarifying the scope of permissible TDM must require that TDM only be conducted on licensed data with rights holder’s consent. In line with existing policy, Canada is most lenient in when activities are conducted for research purposes. Canada’s own Panel on Research Ethics states that “An important mechanism for respecting participants' autonomy in research is the requirement to seek their free, informed, and ongoing consent. This requirement reflects the commitment that participation in research, including participation through the use of one's data or biological materials, should be a matter of choice and that, to be meaningful, the choice must be informed.” TDM and the industries, processes and models that rely on it should not be subject to any less strict regulations than researchers would.Regulating TDM in this way would serve to protect professionals across all sectors. Those who wish to be included in development of AI will be able to engage autonomously. Individuals that desire to opt out will be able to do so. This equitable relationship will allow both workers and technology to flourish.AI developers should be required to keep records of data used in the training of their models and be able to disclose records when asked. To enable record keeping, metadata should be retained when scraping images and/or conducting TDM. This will allow AI developers to accurately index, curate and credit their datasets. To enforce copyright, one must be able to know if protected work has been used, so records must be kept and reported.Disclosure of the use of copyright-protected works in an AI product to the public is essential. Especially in cases where generative AI produces output that could be mistaken for the work of an individual artist, it must be made clear that it was made by AI. This would prevent fraud and misrepresentation of an individual’s character. The disclosure must state that AI generated the work and explain how to request the details of the data from the developer.New legislation in the EU sets a strong example for how to handle AI makes it clear that TDM must respect the EU’s copyright law. It divorces copyright law from AI law in order to prevent AI technology from influencing copyright, or being an exception to the laws.""Any use of copyright protected content requires the authorization of the rightholder concerned unless relevant copyright exceptions apply”, and “where the rights to opt out has been expressly reserved in an appropriate manner, providers of general-purpose AI models need to obtain an authorisation from right holders if they want to carry out text and data mining over such works.”Additionally, they go further to state that any TDM activities or AI products or services that seek to do business in the EU must conform to their copyright and privacy standards.The EU will also require all general purpose AI developers to: “put in place a policy to respect Union copyright law in particular to identify and respect, including through state of the art technologies where applicable, the reservations of rights expressed pursuant to Article 4(3) of Directive (EU) 2019/790;” And “draw up and make publicly available a sufficiently detailed summary about the content used for training of the general-purpose AI model, according to a template provided by the AI Office;”Its also worthy of note that these obligations apply to general purpose AI developers, as mentioned above. The EU recognises that regulating AI outside of high-risk applications is necessary to the wellbeing of their member nations. Canada should adopt a similar stance.","Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?The uncertainty around the rights to ownership and authorship of works created with AI is absolutely a stumbling block in the development and adoption of AI tools. The myriad processes involved in the creation of generative AI outputs, coupled with the lack of regulation has left many individuals and businesses interested in the space to wait for precedent to be set before exploring their options. In creative industries, ownership of intellectual property (IP) is an essential element of conducting our business and compensating parties involved in projects. When the rights are unclear in these situations, all other processes that depend on the IP agreements get bottlenecked or threatened with liability. It is impossible for any widespread use of a new technology to be adopted in an entertainment industry when IP rights aren’t clearly delineated.Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?The government should propose clarification on copyright ownership for AI-assisted and AI-generated works, and it should do so in a way that is carefully informed by the nuances of different use cases and the impacts those uses have. Generally, our Local supports copyright legislation that grants authorship only to work created by humans. (ie, in the case of a storybook with AI illustrations and human-written text, the text would be subject to copyright and the illustrations would not.)Within that stance, we feel that there are some nuances that must inform copyright law for AI-generated works:-What were the terms of the licence on the training works that the AI-prompter used to generate their product? Works generated using source material from the public domain should not able to be copyrighted by a prompter, content that is generated using works made in “for hire” agreements that predate the application of generative AI should not be able to be copyrighted by the prompter, and works generated by infringing upon copyright or privacy should also not be able to be copyrighted by the prompter. However, in a case where both parties enter into an agreement where the individual from whom the training data is being sourced from is willing to grant copyright to the prompter, some allowances for copyright may be made.-What were the terms of the licence for the TDM and other AI software the prompter used to generate their product? It is unclear if the hand that an AI developer has in writing TDM parameters entitles them to any editorial authorship. There may be methods outside of the mainstream of generative AI where developers working with LLM could be exerting creative authorship through their curation processes when making more sophisticated generative AI models than Stability AI, Midjourney, Imagen, Dreamup and their competitors. Currently, these generative AI programs take a position of neutrality in the creative process, similar to how an art creation program such as Photoshop does, but there may be other developers in the field that merit a more nuanced position.-Did the prompter create all of the data/work that was used to train the model? Do they own the copyright to that data/work? If an artist is using AI assistance or generative AI that has been trained solely on their own creative output, that could be looked at as a nuance that allows for copyright to be applied to an AI product. Artists currently make assistive tools such as custom typefaces or art brushes to automate parts of their processes to increase their own productivity without a loss of copyright on the finished product. When made with entirely their own copyrighted material, it should fall within copyright protected works.-If a work is created with AI-assistance, to what extent was the labour completed by a human and to what extent was the work generated by AI? When authorship based on the above examples is unclear, decisions regarding copyright protection should heavily favour the amount of human labour that goes into producing the end result. This will help to retain value on the physical and creative work of humans, and the innovation and creativity that is intrinsic to that process.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?Both the United States and the EU have created precedent that human authorship is an essential element of making anything eligible for copyright protection. As mentioned above in our submission regarding TDM in the EU, our local feels that AI policy in the EU is a solid reference point for Canada. Seeing consensus for this position in our closest trading partner, the United States, reinforces our position that these are good examples to follow when crafting Canadian Legislation.","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?Existing legal tests for copyright infringement were written with human-scale infringement in mind, and legal frameworks that are reasonable for humans are not reasonable when evaluating machine processes. A new mode of evaluation must be created to specifically evaluate AI-generated material.Human-scale and generative AI-scale remix and sampling are very different, any output that is produced by these two modes is different as well, even if they appear similar on a surface level. The concepts of transformative works and fair-use function on the transformation created by the synthesis of a human’s intent and subjectivity creating new meaning from the copyright-protected works that are referenced. As of yet, generative AI models have not been proven to be capable of exercising judgement, expressing a subjective stance or demonstrating any awareness of what the output they are creating means in any human-equivalent way. In their paper, “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜” (https://dl.acm.org/doi/10.1145/3442188.3445922) authors and AI researchers Emily M. Bender, Timnit Gebru and Angelina McMillan-Major warn that generative AI is only capable of creating human-like expression, and that the meaning seen in generative AI is brought to it by the viewer as a result of a very human desire to ascribe meaning to recognizable patterns. What AI produces is stochastic, or random, sequences of forms or words that have a high probability of matching what a prompter has requested. Similar to how a parrot may be capable of saying the words “pretty” and “bird” but has no sapient knowledge of what either of those phrases signify.AI is factually incapable of the synthesis and meaningful expression that a human being is able to perform. With this essential distinction in mind, the best way to rule on infringement in cases of AI-generated content is to examine the training material for unlawfully-used copyrighted material. To ascribe any weight to the perceptual difference that is created through the generative AI production process as transformative work is to distract oneself from the material realities of the processes and their real-world implications. If an AI-generated work relies on copyright-infringing material to be generated, it is violating copyright.What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?Many developers of generative AI are secretive about their datasets and the parameters they apply when using TDM to build their generative AI models. Datasets like LAION-5b are massive and sample even more massive source material. LAION-5b is “5.85 billion pairs of image URLs and the corresponding data”, which is a 240 terabyte bundle of files, and it is based on Common Crawl’s repository of web data, which boasts a size of multiple petabytes of data. (One Petabyte is equal to 1000 terabytes.) While LAION-5b includes the metadata of their image-text pairs in their dataset, the preservation of this metadata is up to the next user of the dataset. If this metadata is destroyed, it becomes incredibly difficult to search a massive repository of data for infringing images.Additionally, copyright-protected materials can be “laundered” to dodge copyright protection and create the illusion of a generative AI system that is capable of creating works without infringing input. In her paper for the IEEE, ""AI Imagery and the Overton Window of Data Laundering” author Sarah K. Amer describes the data laundering process in text to image generators as follows:“STEP 1 Visual media (pictures, art, illustration, logos, etc.) is scraped from the internetSTEP 2 Scraped media is stored in a dataset or group of datasetsSTEP 3 Scraped media is used to train AI text-to-image models using GAN and Diffusion architectureSTEP 4 Training produces and stores latent images based off of the original mediaSTEP 5 New imagery is later generated from the stored latent image bases by an AI end user to sell”Amer goes on to describe that companies will gain access to copyright protected works as part of research projects under non-profit and academic entities. Once the data laundering is complete as part of the research stage, the companies will sell their laundered dataset and model and become for-profit organisations. (https://arxiv.org/pdf/2306.00080.pdf) This shell game obfuscates the path the data took to becoming training material for a generative AI model, and it is currently unclear what the legality of this pipeline is.Our Local, and the entertainment industry at large, feels that this laundering process is not substantially transformative of the copyright-protected source material in theory or in practice. We feel it is clear, for reasons we have stated above, that generative AI models are not capable of the meaningful synthesis that constitutes transformative works and that the products of these generative AI programs still appear to be copyright-infringing after this laundering process. Regulation must close this legal loophole that has been exploited to make it difficult to prove that generative AI is infringing copyright.When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?Use of AI applications in the creative sectors in Canada is largely conducted in an end-user capacity, and not in a developmental capacity. Many large studios are avoiding applications of AI at any large scale because they cannot exercise meaningful oversight of the data used to train AI tools, and their actual liability in the process is legally unclear. Studios insulate themselves from risk by relying on AI for steps of the creative process that are not broadcast or published in an obvious way. This can take the form of ideating works that will be redrawn by human artists, automating image editing, or other uses that create the appearance to the viewer that generative AI was not used.A small number of studios and individuals have sought out agreements with copyright holders that allow for licensing and consent around content use for training generative AI, and the more successful examples of this look like the copyright regulation suggestions we have made in this submission. Unfortunately these examples are the exception and not the rule.Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Yes, the Government should clarify liability in the case of AI-generated works infringing on copyright protected works. Liability for copyright infringement lies with any parties that were responsible for the assembly, curation and direction of the dataset. Whether those parties are the developers creating the generative AI tools, or the clients or users of those tools that freely chose to use those tools and publish the product of them. Developers should be responsible for providing accurate information to clients and users about the copyright status of the materials in their datasets, and should they misrepresent that information, the clients and users should be released from liability.Additionally, when it is unclear who amongst the developers of generative AI is ultimately liable for infringement caused by AI, claimants should be able to exercise multiple avenues in order to claim compensation. If no individual person can be clearly found to be at fault, strict liability claims should be open to claimants. And in cases where errors have led to the issue, claimants should be able to claim compensation as they would for a defective product.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?Again, it behoves the Canadian Government to look to the EU for examples on effective approaches for liability in copyright infringement. While the functionality of Canadian legislation will be different than a multi-state entity like the EU, we urge Canada to look to the ethos behind the EU’s Artificial Intelligence Liability Directive. This directive seeks to make it easier and simpler for the claimants who are harmed by AI to seek compensation for that harm, because it is easier for AI to harm those claimants. This would be an essential step in levelling the playing field between rights holders and any bad actors that are utilising AI to infringe on those rights. When it becomes easier to violate rights, it must also become easier to defend those rights.","I am submitting these responses on behalf of the Canadian Animation Guild, IATSE Local 938 (CAG938). We are a quickly growing union representing animation and video game workers in Canada. Currently we represent 420+ active union members and 600+ workers currently in the process of bargaining their first collective agreements. Additionally, IATSE organisers are collaborating with workers in animation, video games and visual effects (VFX) studios across the country who are seeking union representation. Our local's submissions on this topic are thereby representative of the sentiments of the members of our local as well as the concerns of the broader Canadian entertainment industries that are seeking representation with us or alongside us.As an international union, IATSE is a member of the Human Artistry Campaign (HAC). As such, our local submission is guided by the Core Principles for Artificial Intelligence Applications in Support of Human Creativity and Accomplishment defined by the HAC. Per the Core Principles for Applications of Artificial Intelligence and Machine Learning Technology published by IATSE on July 5th, 2023 we seek to:-Ensure entertainment workers are fairly compensated when their work is used to train, develop or generate new works by AI systems-Prioritise the people involved in the creative process and protect owners of intellectual property from theft-Improve transparency of the use of AI & machine learning systems-Prevent legal loopholes that can be exploited by individuals, companies, and organisations in the U.S., Canada, and otherwiseCAG938's members have a strong interest in what shape AI legislation in Canada will take, and we are grateful for the opportunity to make a submission on this topic. This submission will focus on our knowledge of and recommendations for the application of copyright law to generative AI in the industries that our work touches. Alongside these points, our Local would like to assert that it is in support of the Canadian Labour Congress's position that AI regulation is essential across all industries that are impacted by its adoption, not just the ones that have been designated as ""high-impact"" by the Canadian Government.Legislation should be approached from a point of view that places human rights, labour, societal impact, accountability and privacy at the forefront. It is only by ensuring that those priorities are met that Canada can safely rely on AI to improve the lives of its workers and grow its industries. Without those safeguards in place, Canada is at serious risk of enabling harm on a massive scale to the privacy, safety and livelihoods of its citizens. The Canadian government must not allow industry to circumvent the copyright protections that Canadians rely upon to protect both their labour and culture.In closing, our Local would like to emphasise how essential it is that copyright law is not considered in a vacuum when dealing with AI. Privacy law is an essential part of this discussion, and many aspects of the generative AI issue must be addressed through a lens of protecting the privacy of Canadians.Throughout this submission, our arguments have focused on the very real impacts of generative AI and copyright on the professional work and livelihoods of Canadian artists and entertainment workers. For workers in our industries there is not always a clear line between our personal and professional lives, especially when one attempts to draw it around things we have created. We work for studios, we work for ourselves, and we share art in public to build community. With the lack of privacy protections in Canada around TDM that don't guarantee individuals the right to opt-out of these processes, Canadian artists are at risk of losing the spaces they have relied upon in order to share skills, network and build a world-renowned industry. Privacy laws must account for all of these nuances in order to preserve the livelihood and wellbeing of Canadian creative workers.Privacy and copyright legislation must work together to protect Canada's vibrant creative industries. All regulations must put workers first, and not fail to support the preservation and elevation of Canadian innovation and creativity. Regulations must ensure that rights holders are able to exercise control and consent over how their work is used, that workers are fairly compensated for their labour, that the needs of people are prioritised over the development of technology, that practices around AI are transparent and that all loopholes that allow for the exploitation of workers and rights holders are closed.The members of CAG938 and the workers that make up Canada's world class entertainment industries will be watching the Canadian Government's decisions on this matter closely. We are hopeful for a bright future that values human expression, labour and fairness for all.Respectfully submitted on behalf of the Canadian Animation Guild, IATSE Local 938."
Directors Guild of Canada,Alliance / Union / Guild,"1. The Directors Guild of Canada (DGC) appreciates the opportunity to submit comments and recommendations as part of the public consultation on Copyright in the Age of Generative Artificial Intelligence, organized by the Department of Innovation, Science, and Economic Development (ISED). In 2023, Artificial Intelligence has become a focal point of interest for the DGC, as the audiovisual industry undergoes rapid disruption due to the widespread use of various forms of artificial intelligence, particularly Generative AI. This disruption is exemplified by the role played by AI in the recent dual strikes by the Writers Guild of America and SAG-AFTRA in Hollywood.2. The DGC is a national labour organization that represents key creative and logistical personnel in the film, television and digital media industries. It was created in 1962 as an association of Canada’s film and television directors. Today, it has over 7,000 members drawn from 47 different craft and occupational categories covering all areas of direction, production, editing and design of screen-based programming in Canada.3. In a recent survey of national DGC members, respondents described their relationship with AI tools and expressed concerns about the potential harms and risks of AI in relation to their jobs. More than 85% of members indicated that AI should be considered of high or extremely high importance in the list of DGC advocacy priorities.4. Seventy-two percent of DGC members are familiar with the concept of Generative AI and machine learning but very few admit to having partial or solid AI skills. Looking ahead one to five years, 56% of members are concerned about the possibility of their expertise and skills being replaced by AI.5. When it comes to the use of Generative AI, usage varies depending on the DGC Caucus and work category. Members already report a large positive impact of AI on their creative, logistical, and administrative work. It should be noted that Generative AI is generally used as a tool to augment productivity, and members see the value of enhanced tasks, whether they are creative (for instance the creation of a mood board or inspirational visuals for a director) or logistical (a text-to-text Generative AI used by an assistant director for example).6. For directors’ authorship rights specifically, the risks are multiple: widespread text and data mining, including to train and deploy AI models, have the potential of robbing their creative and economic rights, and the lack of clarity regarding the attribution of copyright when using a Generative AI tool also endangers their economic prospects.7. For the DGC membership and the screen industry at large, it is rather difficult to predict how AI systems might transform jobs and work routines or affect creative rights. Considering this, the DGC believes that the Government should exercise restraint before having a clear understanding on the impact of TDM on the existing rights and production ecosystem.8. The DGC considers the copyright-related questions of the Government consultation as being equally relevant to both business and cultural concerns. This is an opportunity to consider how the rules around AI can serve creators and the society in general. In DGC’s view, it is essential that future AI developments preserve and augment human creativity.","The creative industries need clarity around Copyright and Text and Data Mining to operate1. The present consultation on Copyright and Generative Artificial Intelligence is an opportunity for the Government to provide further clarifications and safeguards to prevent text and data mining (TDM) to further disrupt the existing copyright creative/production ecosystem. The screen production industry, in Canada as well as in other key jurisdictions, including the United States, operates on the clarity of copyright ownership and market-based licensing and remuneration mechanisms.2. We note the consultation asks “how and when rightsholders could or should be compensated for the use of copyright-protected content as inputs in the development of AI”. In our view this question omits the fundamental consideration as to whether copyright owners have the right to authorize the uses of their works for TDM purposes. This issue is not solely about remuneration; it is whether creators should be able to control whether their works are copied and used for TDM purposes in the first place. We believe they do and should have that right and this technologically neutral right needs to be preserved with reference to TDM activities.3. Common industry practice with regards to agreements and contracts has developed in such a way that the creator, producer, studio, broadcaster or distributor participate in a production with the assurance of having assigned or secured the rights necessary to exploit it. Licensing and the orderly exploitation of rights is at the centre of the film and television industry. These rights need to be preserved in order to generate revenues, ensure investments are recouped and profits are realized and to ensure continued employment by the creative sector in Canada. These rights also need to be protected, especially when it comes to TDM.4. Therefore, content creators and audiovisual authors need complete clarity around copyright and TDM. A modern copyright system should continue to protect creators, authors and copyright owners among new AI developments. As a first step, ensuring that AI developers provide more transparency around TDM in order to allow creators to provide consent and be rightfully compensated is one of the most urgent DGC priorities with respect to AI alongside authorship and ownership, which are both part of a general copyright policy centered around the creator.5. The TDM process used in the training of Generative AI systems involves the cloning of large swaths of copyrighted works. While Generative AI companies now are realizing that they need licenses to operate legally and are starting to negotiate licenses, in the absence of transparency and legal clarity, such licensing may be inhibited which will result in no compensation to rightsholders. Moreover, the relationship between AI companies, TDM activities and rightsholders is not clearly defined yet in Canada and many other similar sized jurisdictions.6. Both the Generative AI “inputs” and “outputs” also threaten human creation and creators’ livelihoods. When using copyrighted works without consent, Large Language Models (LLMs) risk devaluating human creation. TDM then represents a form of “copyright laundering”, as there is not a clear understanding of the processes at work with machine learning. The public and Government need to understand the different steps when datasets are being treated by LLMs. TDM seemingly converts stolen or copyrighted data so that it can be later sold or used by ostensibly legitimate Generative AI tools.7. The operators of LLMs claim that their models do not contain copies of works ingested for training purposes. However, that is not the case. Recent research confirms that LLMs are capable of generating outputs that are exact copies of the input data. As such, the contention that only “logical” or “semantic” information is extracted from ingested works simply cannot withstand scrutiny. The operators of AI tools also argue that their uses of works are “transformative”. But the reality is that Generative AI tools do not transform but instead exploit the entirety of the databases they mine.8. While DGC directors and other members are protected by collective agreements entered with producers, they have no such protection in the case of new players such as AI companies. These players are not bound to DGC contract provisions, and the TDM can potentially harm directors’ artistic expression and remuneration.9. The DGC believes that there is no compelling argument to create new exemptions for TDM and to do so would adversely affect the copyright balance that promotes innovation in our industry. The current Copyright Act is interpreted to be technology-neutral and is adaptable to technological developments. The balance in the Act both promotes innovation and enables rightsholders to license and exploit their works and be rewarded for their creative efforts. Recommendations:10. Should the Canadian government consider a TDM exception, it should include the criteria identified above and be narrowly crafted. The exception should only apply where the work is accessed lawfully by the beneficiary and, insofar as the rightsholders have not reserved in an appropriate manner the rights to make reproductions and extractions for text and data mining – including through agreements and licenses, machine readable means, or through the use of technical measures.11. The list of copyrighted content used to train AI tools should be made available to the rightsholders and users. Additionally, the content output produced by Generative AI tools should be identified and marked, such as with watermarks, to separate synthetic creations (in part or as a whole) from human ones. Rightsholders should also have the legal right to make demands of any AI company that offers services in Canada, for a list of works used to train the AI model, or at the very least, whether specific identified works owned or licensed by a rightsholder have been used to train the AI model. There should also be a right to require the AI entity to conduct and publish independent audits that include relevant information related to the works used to train the AI models and whether the works remain stored in the models (in any material form), and whether they are capable of generating outputs that reproduce all or any substantial parts of ingested works.12. The proposed amendments to Canada’s draft Artificial Intelligence Act (AIDA) include measures that must be taken before a general-purpose AI system can be made available or changed. The DGC recommends that, in addition to the requirements already included in the proposed amendments, that AIDA expressly include a requirement on persons who make available or manage a general-purpose system to:(a) Put in place and follow a policy to respect Canadian copyright law. This should apply to any TDM exception should one be enacted. These obligations should apply regardless of the jurisdiction in which the copyright-relevant acts underpinning the training of these systems take place. This is necessary to ensure a level playing field among providers of general-purpose AI systems where no provider should be able to gain a competitive advantage in the Canadian market by applying lower copyright standards than those provided in Canada. This is consistent with the draft EU Artificial Intelligence Act.(b) If the system generates digital output consisting of text, images or audio or video content, a detailed plain-language description has been prepared and published of the copyright works and other subject matter that have been used to train the system in accordance with the regulations.13. We note that Bill C-27, before Parliament, is intended to regulate certain high impact AI systems. The DGC submits that any AI system that is developed or deployed in Canada and that uses copyright works for its training data should be subject to regulation under AIDA. The definition of “harm” under AIDA should include any wide scale unauthorized use of works for training AI systems.","36. The Consultation questions regarding authorship and ownership of copyright in AI-generated works reflect the current ongoing debates taking place in many jurisdictions: can the copyright be attributed to AI-generated works? In the United States and in European jurisdictions, the global trend is to defend human authorship as a central principle over machines. The DGC is concerned that the lingering uncertainty surrounding authorship and AI might negatively affect creators using Generative AI tools and their likes.37. The DGC is supportive of a comprehensive copyright framework that continues to provide predictability and fair remuneration in the film and television industry for Canadian directors and creators – including the ability to negotiate for such rights on any future platform, including AI entities.38. The DGC has collective agreements already in place with producers’ associations that recognize directors’ rights. Under the Canadian Copyright Act and DGC’s collective agreement, DGC directors are entitled to authorial rights, including moral and economic rights. However, Canadian directors and writers have no recourse under their respective bargained collective agreements to protect credit on their work if an AI entity, which has no contractual relationship with the Guilds, scrape their work for text and data mining.Canadian authorship attribution parameters39. The Copyright Act attributes authorship to an individual human author and considers the originality of a work to be the determining parameter to award copyright. Consequently, the authorial rights should continue to be attributed to human directors, even when AI tools are being used, as long as there is sufficient original human involvement in the process of creation. This position has already been validated with the US Copyright Office ruling of May 2023 that only protects the product of human creativity.40. A main purpose of the Copyright Act is to reward the authors for their creative labours and to incentivise creation by providing them with exclusive rights. In its current state, the Act protects the creator’s status, including when AI is being used to assist in the creative process. This provides a sound framework for protection.41. DGC opposes giving protection for synthetic content produced solely using Generative AI tools. This would effectively permit individuals that use Generative AI tools to obtain copyrights derived from the creative labours of our members and this synthetic content would then be able to compete with the original content of our members. This is in line with a recent US court ruling that says that AI computer generated art cannot be protected by copyright.42. Earlier this year, the Directors Guild of America (DGA) negotiated unprecedented AI protections in their new collective agreement with the U.S. studios. These new protections require that the work and duties of directors must be done by a person, excluding recognizing Generative AI as a person in the contract. The DGA agreement also underlines the importance of director decision-making with regard to the use of Generative AI and other AI technologies in its work.43. In the face of the rapid development of AI technologies, and as exemplified by the recent strikes from U.S. unions and guilds, collective agreements today represent the most appropriate and quickest way to address questions related to authorship and protect human creativity. Canada’s Copyright Act is technology-agnostic and should be protecting authors and creators’ moral rights and all exclusive rights when being used by AI companies.44. Despite our view that copyright can only subsist in works if they are original and result from the exercise of skill and judgment of individuals, because of the importance of the issue, we recommend that the Government clarify that the originality required for copyright subsistence must be the skill and judgment of human beingsDGC RecommendationRecommendation 3: The DGC recommends that the Government make an amendment to the Copyright Act to confirm that the originality requirement in the Act is solely the skill and judgment of human beings.We also note that the Consultation Paper refers to the approaches in the U.K., Ireland and New Zealand, whereby “in the case of a literary, dramatic, musical or artistic work which is computer-generated, the author shall be taken to be the person by whom the arrangements necessary for the creation of the work are undertaken.”The DGC opposes any amendment that would deem authorship to “the person by whom the arrangements necessary for the creation of the work are undertaken.” As noted above, under the current law, directors are considered the author of film and television productions. Any such amendment risks introducing a major change in the law that could give producers copyright in film and television productions. Further, where the productions are based in part on the use of Generative AI, it risks giving producers at least some copyright interest in works that under the current law would vest all copyrights in the director.DGC RecommendationRecommendation 4: The DGC recommends that the Government not amend the law to deem authorship in a computer-generated work to be in the person by whom the arrangements necessary for the creation of the work are undertaken.","The DGC believes that the liability rules related to copyright infringement are well established. The DGC believes that existing laws related to direct infringement (including infringement by reproduction and authorization) and accessorial liability (including inducing, procuring and acting in concert), and defenses to infringement such as fair dealing are sufficient for the present time, subject to the following. There is currently uncertainty as whether outputs that are derived from copyright works but that do not reproduce all or a substantial part of a work are infringing. This is particularly problematic because many outputs of AI systems are generated based on the uses of many works. The outputs may be in the “style” of an author or otherwise appropriate small portions from many works. Thus, deployers AI systems may be able to evade copyright infringement in their outputs by denying that any particular output is a reproduction of any particular work. This situation could also risk negatively influencing a fair dealing analysis of whether training of AI systems using unlicensed content is infringing, as courts will likely focus on many factors including whether the outputs of Generative AI systems are infringing.Based on the foregoing, we urgently recommend that the Government study how to protect copyright owners against the generation of outputs that are based upon or derived from the uses of copyright content even though individual outputs may not be infringing. This should include consideration of the need to expand exclusive rights, ensure that a fair dealing analysis is not tainted by a gap in the law that does not recognize collective contributions of authors to the generation of computer outputs, and how to ensure that authors can obtain compensation for this derived synthetic content.We note that France’s National Assembly Bill aimed at regulating artificial intelligence by copyright would establish a mechanism to provide for compensation to authors for all computer-generated content whose origin cannot be determined.DGC RecommendationRecommendation 5: The DGC recommends that the Government study how to protect copyright owners against the generation of outputs that are based upon or derived from the uses of copyright content even though the individual outputs may not be infringing.",N/A
Guilde des musiciens et musiciennes du Québec (GMMQ),Alliance / Union / Guild,"Cette soumission constitue une position commune des associations et société suivantes :Artisti, une société de gestion collective canadienne représentant divers artistes-interprètes pour la gestion collective de leur droit à la rémunération équitable et leur droit à la rémunération découlant de la copie privée ainsi que tout ou partie de leurs droits exclusifs ;L'Union des artistes (UDA), un syndicat professionnel représentant les artistes de plusieurs disciplines œuvrant en français ou dans toute autre langue à l'exception de la production faite et exécutée en anglais;La Guilde des musiciens et musiciennes du Québec (GMMQ), une association d'artistes légalement reconnue au Québec pour représenter les musiciens professionnels, notamment lors de la négociation d'ententes collectives visant leurs conditions de travail et de rémunération.Celles-ci voient le potentiel de l'IA à titre d'outil de création : plusieurs de leurs membres s'en servent d'ailleurs comme d'instruments leur permettant de livrer une prestation. Il est néanmoins essentiel d'encadrer l'utilisation de la technologie, particulièrement dans le contexte de la fouille de textes et de données (« FTD »), puisque les prestations des artistes interprètes sont actuellement utilisées à cette fin à leur insu, sans rétribution.","Question 1: Une plus grande clarté et transparence permettraient de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les prestations d'artistes interprètes sont utilisées, ainsi que les rôles et responsabilités des différentes parties prenantes. Ceci permettrait également de déterminer : (i) dans quel(s) contexte(s) l'analyse informationnelle est autorisée, ou non, par le régime actuel de droit d'auteur canadien et ainsi, (ii) quelles licences et rétributions doivent être versées aux titulaires des prestations d'artistes interprètes.Question 2: Oui, des activités de FTD sont actuellement menées au Canada, afin d'entraîner des modèles algorithmiques. Les activités de développement et d'entraînement de systèmes d'IA peuvent impliquer la reproduction de contenus protégés par droit d'auteur dont des prestations d'artistes interprètes ou leur voix et leur image hors prestation, et ce, sans qu'ils y consentent ou reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d'y remédier. En outre, il est essentiel que l'autorisation (de type « opt-in » et non « opt-out ») des artistes interprètes soit obtenue préalablement à toute reproduction de leurs prestations, leur voix ou leur image, et qu'une rétribution juste et équitable leur soit versée en contrepartie de cette utilisation. L'obtention de ces consentements devra prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, un contentement distinct devra être obtenu auprès des artistes-interprètes si l'autorisation initialement consentie aux producteurs ne couvre pas la FTD, ce qui est le cas pour l'instant. À cet égard, il est également important de rappeler que les artistes interprètes qui ont consenti à ce que leurs prestations soient intégrées à une œuvre cinématographique ne peuvent présentement pas exercer leurs droits de l'article 15 (1) compte tenu de l'article 17(1) de la Loi sur le droit d'auteur et qu'ils ne peuvent pas non plus bénéficier de droits moraux à l'égard de ces prestations audiovisuelles. Afin de résoudre ces enjeux, le Canada devrait ratifier le Traité de Beijing, ce qui permettrait aux artistes-interprètes audiovisuels d'exercer un meilleur contrôle sur leurs prestations incorporées dans des œuvres cinématographiques.Question 3: Oui. En outre, il est difficile pour les artistes interprètes de déterminer quel contenu est utilisé dans le contexte de la FTD et quelle est l'ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d'imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d'IA.Question 4: Diverses licences sont disponibles pour les activités de FTD impliquant l'exercice d'un droit réservé aux titulaires de droit d'auteur, à savoir la reproduction. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d'auteurs incluant les artistes interprètes ou être obtenues par le biais d'une société de gestion collective. En effet, en ce qui a trait aux artistes interprètes, la possibilité de faire des reproductions de leurs prestations aux fins de la FTD n'est généralement pas incluse dans les autorisations qu'ils ont données aux producteurs d'enregistrements sonores ou d'œuvres cinématographiques, ces autorisations visant essentiellement l'exploitation commerciale des enregistrements sonores et des œuvres cinématographiques. Il faudrait donc que des autorisations aux fins de FTD soient obtenues auprès des artistes interprètes ou de leur société de gestion collective. Les artistes interprètes ou leur société de gestion collective seraient tout à fait à même de les émettre.Pour rappel : ces licences ne semblent présentement pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner notamment pour les artistes interprètes qui peinent à obtenir une juste compensation pour l'utilisation de leurs contenus. Comme les prestations reproduites aux fins de FTD sont des prestations fixées sur des enregistrements sonores ou audiovisuels et qu'il s'agit de prestations d'œuvres, plusieurs mécanismes peuvent être envisagés pour compenser les ayants droits visés pour cette utilisation qui est faite de leurs prestations : l'introduction d'un droit à une rémunération équitable pour la FTD ou un droit à rémunération via un mécanisme semblable à celui de la copie pour usage privé font partie de ces mécanismes.Question 5: La reproduction des prestations d'artistes interprète aux fins de la FTD ne pas couvertes par les dispositions contractuelles qui encadraient la fixation de ces prestations. C'est donc dire qu'aux fins de cette activité, l'autorisation de l'artiste interprète devrait donc systématiquement être obtenue. En effet, il ne faut pas oublier que la reproduction d'une prestation aux fins de la FTD impliquera souvent la reproduction de la voix et de l'image d'un artiste interprète (des données biométriques), qui sont des attributs de sa personnalité protégés par les droits de la personnalité, le droit à la vie privée et les législations en matière de protection de données personnelles.Compte tenu de ces différentes protections législatives, il semble donc impossible d'envisager une exception pour permettre l'utilisation de ces prestations impliquant la voix ou l'image d'un artiste aux fins de la FTD puisqu'un ensemble d'autres dispositions législatives contrecarraient et contrediraient l'introduction d'une telle exception.Nous ne sommes donc pas favorables à l'adoption d'une exception générale permettant la FTD, laquelle serait, par ailleurs, également contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l'ADPIC et l'ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d'auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l'exploitation normale de l'œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur.Ainsi, si jamais le gouvernement décidait d'adopter malgré tout une exception de FTD (ce que nous ne recommandons pas), il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l'exception soit : (i) limitée à des cas spécifiques (par exemple, à des fins de recherche) ; (ii) assujettie à des conditions d'application strictes (par exemple, l'accès à l'œuvre ou objet de droit d'auteur doit être licite) ; et (iii) assortie du versement d'une juste rétribution au bénéfice des titulaires de droits d'auteur, ainsi que d'un mécanisme de retrait (« opt-out ») pour les titulaires de droits d'auteur.Finalement, cette exception ne devrait pas s'appliquer aux droits moraux, mais uniquement aux droits dits « économiques ».Question 6 (tenue de registres): Oui, nous le recommandons : il s'agit d'une obligation essentielle qui devrait être intégrée dans la Loi sur le droit d'auteur. La transparence est l'un des principes fondamentaux qui devraient guider en tout temps les développeurs de systèmes d'IA.Question 7: Le niveau de rémunération doit être juste et équitable, basé sur les utilisations faites des contenus protégés. Dans tous les cas, la rémunération devrait être arrimée avec les autorisations obtenues et prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, une rémunération distincte devra être versée aux artistes-interprètes si l'autorisation initialement consentie aux producteurs des contenus reproduits ne couvrait pas la FTD.Question 8: Comme exposé plus tôt, il n'est pas recommandé d'introduire une exception de FTD au Canada. Au contraire, il est essentiel de veiller au respect de la Loi sur le droit d'auteur et des autres dispositions législatives trouvant présentement application (tels que les droits de la personnalité et ceux liés à la protection des renseignements personnels qui sont en jeux lors de la reproduction des prestations d'artistes interprètes à d'autres fins que celles initialement consenties ou la reproduction de leur voix et leur image hors-prestations) en s'assurant que l'autorisation des artistes interprètes soit obtenue et qu'une rémunération juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de FTD.Nous recommandons également qu'une obligation de transparence ou de tenue de registres soit imposée aux chercheurs et développeurs de systèmes d'IA générative, dans le contexte de la FTD. Si toutefois le Canada souhaitait, en dépit de nos recommandations et en contravention des droits de la personnalité, droit à la vie privée et droits liés à la protection des renseignements personnels qui protègent la voix et l'image des artistes interprètes, introduire une exception de FTD, il devra veiller à ce que cette exception respecte les balises internationales, soit d'application limitée et assortie d'un mécanisme de retrait (« opt-out ») pour les titulaires de droits d'auteur.À cette fin, le gouvernement canadien pourrait examiner la situation prévalant au sein de l'Union européenne, la Suisse et le Royaume-Uni.","Question 1: Oui. Cette incertitude a notamment des répercussions sur la rémunération des artistes tels que les musiciens, dont les contenus se retrouvent « dilués » sur des plateformes telles que Spotify. En effet, dans la mesure où des contenus « artificiels » envahissent les plateformes de diffusion, les vrais contenus seront noyés dans cette mer de contenus « artificiels » qui pourraient accaparer une proportion des redevances qui seraient autrement destinées aux véritables artistes interprètes.L'absence de protection des contenus « artificiels » a par ailleurs une incidence sur la protection des véritables prestations d'artistes-interprètes.En outre, il existe une incertitude entourant la titularité et la rémunération liées à une prestation « artificielle » incorporant la voix, l'image ou la ressemblance d'un artiste-interprète, alors que celui-ci n'a pas autorisé une telle incorporation.Enfin, selon la Loi sur le droit d'auteur, une « prestation » ne sera protégée que si elle est « rattachée » à une œuvre. Par conséquent, le droit des artistes-interprètes pourrait être mis en péril si ces derniers interprètent des contenus « artificiels », non protégés par le droit d'auteur.Nous recommandons donc que les prestations soient protégées et ce, indépendamment du fait que les artistes interprètent ou exécutent des contenus « artificiels », non protégés par droit d'auteur. Après tout, les prestations d'artistes interprètes sont protégées même si elles portent sur une œuvre du domaine public ne bénéficiant plus de la protection du droit d'auteur. Il serait donc possible d'étendre la protection des prestations afin de prévoir que la prestation d'un contenu « artificiel » est protégée au même titre que la prestation d'une œuvre, et ce, d'autant plus que l'article 9 de la Convention de Rome est à l'effet que « Tout État contractant peut, par sa législation nationale, étendre la protection prévue par la présente Convention à des artistes qui n'exécutent pas des œuvres littéraires ou artistiques. »Une meilleure protection des droits des artistes interprètes pourrait donc être atteinte en (i) revoyant les définitions de « prestation » et d'« artiste-interprète » au sein de la Loi sur le droit d'auteur ; (ii) introduisant les droits moraux pour les artistes-interprètes audiovisuels (par exemple, par le biais de la ratification du Traité de Beijing) ; et (iii) introduisant des présomptions de violations des droits économiques et/ou moraux des artistes-interprètes lorsque leurs prestations (ou des composantes de celles-ci telles que la voix ou l'image) sont reproduites dans un contexte d'IA générative à leur insu.Question 2: Si aucune contribution humaine ne peut être identifiée en lien avec une « prestation artificielle», nous ne recommandons pas de la protéger. Toutefois, dans la mesure où une contribution humaine est identifiable en lien avec une prestation artificielle, que ce soit : (i) par l'intégration d'une prestation, de la voix, de l'image ou de la ressemblance d'un artiste interprètes ou (ii) par une utilisation de l'intelligence artificielle par un humain qui pourrait être assimilée à celle d'un musicien instrumentiste, cette contribution humaine devrait bénéficier d'une protection.Le gouvernement pourrait aussi préciser qu'un « artiste interprète », aux fins de la Loi sur le droit d'auteur, est obligatoirement un être humain. Il pourrait également prévoir une présomption à l'effet que la voix et l'image d'un artiste interprète constituent une partie importante de sa prestation.Ceci permettrait d'avoir plus de certitude quant à l'application de la Loi sur le droit d'auteur.Enfin, il est également recommandé de modifier la définition d'« artiste-interprète » et de « prestation » au sein de la Loi sur le droit d'auteur, afin que la prestation ne soit plus uniquement rattachée à des œuvres. Le fait qu'une prestation en soit une d'un « produit de l'intelligence artificielle » plutôt que d'une œuvre ne devrait pas faire obstacle à sa protection.Question 3: Non, il n'existe pas d'approches éclairantes dans d'autres pays. Si les législations du Royaume-Uni, de l'Irlande et de la Nouvelle-Zélande ont choisi d'attribuer la titularité d'œuvres générées par ordinateur à la personne qui a pris les dispositions nécessaires à la création de l'œuvre créée, nous ne recommandons pas d'emprunter cette voie, car ces dispositions ont été introduites dans un contexte étranger à l'IA générative. Or, cette technologie soulève des questions bien plus complexes. De plus, nous n'avons pas connaissance que la question spécifique de la titularité de la prestation, de la voix et de l'image d'un artiste interprète dans un produit de l'intelligence artificielle générative ait été abordée dans quelque juridiction que ce soit.","Question 1: Il peut être difficile pour un artiste interprète :(a) d'identifier la ou les personnes responsables d'une violation de ses droits ou d'une contrefaçon de sa prestation ; et(b) d'établir que la partie qui a utilisé sa voix, son image ou sa ressemblance a eu accès à une prestation préexistante (plutôt que simplement sa voix ou son image hors prestation), que la prestation (et non simplement la voix ou l'image hors prestation) était la source de la copie et qu'une partie importante de la prestation a été reproduite.De plus, comme il n'y a pas de présomption intégrée à la Loi sur le droit d'auteur à l'effet que la voix ou l'image d'un artiste interprète constituent une partie importante de sa prestation, les critères juridiques existants pourraient ne pas permettre de démontrer qu'un produit de l'intelligence artificielle qui utilise la voix ou l'image d'un artiste interprète viole le droit d'auteur que celui-ci détient sur ses prestations.Question 2: La pluralité des intervenants, l'opacité des systèmes d'IA, et la pixellisation de certaines prestations, ainsi que de la voix et de l'image des artistes-interprètes, ce qui rend les prestations originales difficilement identifiables.Question 3: Nous n'avons pas connaissance que les entreprises commercialisant des applications d'IA prennent de telles mesures.Pour éviter que les produits de l'IA ne violent le droit d'auteur des artistes interprètes sur leurs prestations, les autorisations nécessaires pourraient être obtenues en amont des utilisations par le biais de licences.L'option d'utiliser des prestations faisant partie du domaine public ne permettrait pas d'éviter à tous coups une violation d'autres droits que le droit d'auteur, tels que le droit à la voix ou le droit à l'image puisqu'il est possible qu'un artiste interprète survive à la durée de protection de ses prestations. Le cas échéant, l'utilisation sans autorisation d'une prestation du domaine public incorporant sa voix ou son image continuerait néanmoins de résulter en une violation de ses droits de la personnalité.Question 4: Non, la Loi sur le droit d'auteur dispose de mécanismes suffisants pour déterminer la responsabilité en cas de violation de droit d'auteur.Cela dit, il serait néanmoins souhaitable qu'aux fins de la détermination de ce qui constitue une contrefaçon d'une prestation, il soit reconnu, par l'introduction d'une présomption, que la voix ou l'image d'un artiste interprète constitue une partie importante de sa prestation.Enfin, le Canada pourrait imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d'IA.Question 5: voir réponse à la question 2.Question 6: Oui. Dans son projet de règlement « AI Act », le Parlement européen a introduit une obligation de transparence, de sorte que les entités qui développent des systèmes d'IA devront publier un résumé suffisamment détaillé de leur utilisation de « données d'entraînement protégées par la législation sur le droit d'auteur », ainsi qu'une information appropriée, claire et visible qui distingue le contenu généré de l'original. Cette approche nous paraît louable, mais le Canada devrait aller encore plus loin. En outre, l'obligation de transparence canadienne devrait également s'appliquer aux prestations et à leurs composantes (voix, image et ressemblance de l'artiste-interprète), ainsi qu'aux résultats générés par ou avec IA.","La consultation publique est accueillie favorablement par nos organisations, lesquelles voient en cet exercice une volonté du gouvernement de clarifier les incidences de l'IA sur le droit d'auteur. Nos organisations ne souhaitent pas freiner l'avancement de l'IA, mais désirent préserver l'équilibre que la Loi sur le droit d'auteur sous-tend, en veillant à préserver la culture canadienne, la créativité humaine, ainsi que les intérêts des titulaires de droits d'auteur.Pour ce faire, nous recommandons que les principes regroupés sous l'acronyme « A.R.T. » (Autorisation, Rétribution et Transparence) guident les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d'auteur qui en découleront.Par ailleurs, il est important que la consultation publique ne se limite pas aux intérêts des auteurs et autres titulaires de droits d'auteur sur des œuvres, mais qu'elle couvre également les intérêts des artistes-interprètes sur leurs prestations ainsi que sur leur voix, leur image et leur ressemblance.L'IA générative bouleverse en effet grandement ces créateurs, notamment dans le contexte de l'hypertrucage (ou « deepfake » en anglais). À ce chapitre, les artistes-interprètes audiovisuels ne disposent pas de droits suffisants pour protéger leurs prestations, y compris dans le contexte de l'IA générative et de l'hypertrucage. Afin de pallier cette situation, il est recommandé d'étendre les droits exclusifs et les droits moraux de ces artistes, par exemple, en ratifiant le Traité de Beijing."
"The Screen Composers Guild of Canada, and, The Songwriters Association of Canada",Alliance / Union / Guild,N/A,"2.1.1 Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g. AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?Existing legal tests are already sufficient to determine ingesting copyrighted materials into AI programs, without permission of the owner, is an infringing activity.o  At the input level, ingesting copyright works into an AI program typically results in a permanent copy of those works being made and stored by the AI program, including for commercial purposes (e.g. supporting keyword based user prompts). As such, TDM activity directly engages the right of reproduction, and would not trigger the exception for ‘temporary reproductions for Technological Processes’ nor the fair dealing exception.o  At the output level, generative AI models are designed to create works that compete in the marketplace with the very copyrighted works they are trained on. TDM activity that results in the generation of content that derives from, emulates or copies the characteristics of specific copyrighted works could potentially infringe copyright.Generative AI content requires the making and storing of a copy of copyrighted works and the resulting work seeks to compete directly with the copyrighted source works in the marketplace.As such, the Screen Composers Guild of Canada (SCGC) and the Songwriters Association of Canada (SAC) submit that no new legal tests are required to determine whether TDM ingestion or the creation of outputs infringe copyright. On the contrary, existing legal tests clearly indicate that exceptions linked to ‘temporary reproductions’ and ‘fair use’ do not apply to TDM activity used to program generative AI programs.Nor are any new exceptions from these tests required. SCGC and SAC are deeply opposed to any additional exceptions in the Copyright Act to exempt AI companies from their legal obligations.Any additional exception could be contrary to Canada's commitments under various international treaties, such as the Berne Convention, TRIPS and CUSMA (which specify that any limitation or exception to which Canada intends to subject a copyright must be restricted to certain special cases where it is not detrimental to the normal exploitation of the work, nor causes unjustified prejudice to legitimate interests of the author).2.1.2 What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?A lack of substantive data and accurate recordkeeping are current barriers for determining the scope of infringing activity by AI programmers.At the November 14, 2023 stakeholders’ roundtable hosted by ISED and PCH, a representative of a Generative AI company confirmed that their platform is capable of ingesting “the entire internet.”  That representative also confirmed that they have the capacity and capability to track and record the specific copyrighted works ingested in that process.As such, the Screen Composers Guild of Canada (SCGC) and the Songwriters Association of Canada (SAC) submit that relevant records on TDM sources and activity must be kept by AI programmers to identify all stakeholders -- including authors (i.e. composers and lyricists), performers and any other owners of intellectual property in musical works or sound recordings ingested in the course of an AI system’s machine “learning”.-----------------------------------2.1.3  Are rights holders facing challenges with TDM activity and in licensing their works for TDM activity? If so, what is the nature and extent of those challenges?Music is a licensing business.  The key challenge facing rights holders when it comes to licensing their works for AI programming purposes is that AI companies typically do not ask rights holders for a licence before ingesting their work. By definition, we cannot licence works that are taken without our knowledge or permission.As TDM activity arguably engages numerous copyrights, various licenses are available for TDM activities. These licenses can be negotiated directly with copyright holders or obtained through collective societies. Generally speaking, AI companies do not seek these licenses before ingesting copyrighted works. This makes it impossible for copyright holders to obtain fair compensation.The Screen Composers Guild of Canada (SCGC) and the Songwriters Association of Canada (SAC) note that there are ethical AI companies who actively obtain licenses for copyrighted material before using it for TDM purposes.  This eliminates any argument from less ethical AI companies that licensing models are impractical or impossible for TDM activity.Numerous and highly respected Canadian collectives exist precisely to work with copyright users to ensure their whatever rights their specific uses engage, they are aligned with the Copyright Act. SCGC and SAC strongly submit that authors of works ingested into AI programs and platforms must be able participate fairly or equitably in all royalty revenue streams to which their work contributes.  A new right of remuneration for authors and creators whose work is used by AI developers, with or without consent, may be required.However, for such a remedy to be practical, AI companies need to be proactive and transparent about their use of copyrighted material for TDM programming, and the brief history of this technology has already demonstrated that most AI companies will voluntarily join that discussion.At a minimum, AI companies operating in Canada should be required whether by legislation or regulation, to (i) maintain accurate and transparent records of the copyrighted works ingested into their AI programs, (ii) to obtain consent in the form of a licence before ingesting it, and (iii) to pay compensation in exchange of such use.","2.2.2. Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?The Screen Composers Guild of Canada (SCGC) and the Songwriters Association of Canada (SAC) note the three broad options for managing AI-assisted and AI-generated works the consultation paper, and support Option 1:while the Copyright Act is based on a philosophy of providing incentives for human creativity —including, for example, the tying of the general term of copyright ownership to the life of a human author—SCGC and SAC respectfully submit that there would be practical benefit in clarifying, within the Act, that the author of a copyrightable work must be human.  Such a clarification would bring critical guidance and predictability to regulators, courts, creators and consumers.SCGC and SAC unequivocally reject Option 2: the objective of the Act has always been to protect human creation, not to facilitate artificial creation. The Copyright Act is meant to evolve and adapt as technology and business models change. Option 2 would turn the Copyright Act into an instrument that disenfranchises rather than protects human creators.Accordingly, SCGC and SAC support Option 1, and as noted, unequivocally reject Option 2.We respectfully encourage the Government of Canada to be guided in its determinations on this question by the Principle 5 of the Human Artistry Campaign Copyright should only protect the unique value of human intellectual creativity.Copyright protection exists to help incentivize and reward human creativity, skill, labor, and judgment - not output solely created and generated by machines.Human creators, whether they use traditional tools or express their creativity using computers, are the foundation of the creative industries and we must ensure that human creators are paid for their work.","2.1.4. Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?As generative AI programs can be manipulated and adapted for uses not originally intended, the role of those who deploy the system must be considered, not just that of the initial AI programmer. The Copyright Act is already clear on where liability lies for those who engage in unlicensed use or distribution of copyrighted material.Plagiarism is plagiarism, whether the plagiarizer uses a pen, a typewriter, or a sophisticated computer program to reproduce copyrighted material without credit, consent and compensation.","2.1.5. Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?The Screen Composers Guild of Canada (SCGC) and the Songwriters Association of Canada (SAC) respectfully encourage the Government of Canada to be guided by transparency obligations in the European Union’s AI Act, which require that AI-based systems must be transparent in their functioning so that users can understand how decisions are taken and the logic behind them. This includes providing an explanation of how an AI system arrived at its decisions, as well as information on the data used to train the system and the accuracy of the system.Similarly, transparency obligations in the US Department of State and Commerce AI Guiding Principles should serve as a model for Canada. In particular Principle 11, which requires AI developers to implement appropriate safeguards before and throughout training, on the use of personal data, and material protected by intellectual property rights, including copyright-protected content.Principle 11 further states that there should be appropriate levels of transparency on the use of datasets ingested in the AI programming process, and these organizations should comply with applicable legal frameworks.It remains the position of SCGC and SAC that a similar principal should have been included in the ISED’s Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems. We respectfully maintain that the Code should have required signatories to include an appropriate range of identifying information in the metadata of any work derived from “vast data sets” of copyrighted works ingested for TDM purposes. Absence of such a principle in the Code only exacerbates the ongoing negative impacts of generative AI on Canadian copyright holders.At a minimum, AI companies operating in Canada should be required, whether by legislation or regulation, to (i) maintain accurate and transparent records of the copyrighted works ingested into their AI programs, (ii) to obtain a consent in the form of a licence before ingesting it, and (iii) to pay compensation in exchange of such use. These measures would address many of the TDM challenges facing rights holders, while keeping Canada in alignment with both the EU and US on these critical questions."
Writers’ Guild of Alberta,Alliance / Union / Guild,N/A,The issue in my sector with TDM for the development of AI is that artists' work is being scraped and used for gen AI models that compete against the artists themselves. There should be distinction between TDM for research purposes and for commercial purposes. AI companies should not be able to mine artists' work to create generative models that the companies alone benefit from commercially while removing financial compensation from the artists.,"I'm concerned that establishing copyright ownership and authorship for AI generated works disproportionally benefits the AI companies while devaluing the rights of artists. If AI art is generated by a machine with only some prompt input by a human, why should the prompter hold copyright when anyone can use the same AI program and get it to generate something similar? Who owns the copyright of an AI output if it's not distinguishable from the work of an artist that was scraped to create the AI model? If granting copyright to AI prompters or companies means artists lose any rights at all, I'm not in favour of allowing any copyright of AI works.",Businesses should not receive any liability protection for scraping the work of artists to compete against the scraped artists. I don't see any benefit to commercial use of AI-generated artworks and the use of datasets in the arts should be for research purposes only.,"I don't think there is any ethical way to give copyright protection to AI works. The priority must be protecting the copyright of artists that are feeding the dataset. If this results in gen AI art not being commercially viable, so be it. Many artists are losing jobs in the arts sector, which indicates that gen AI art is not creating jobs, it's eliminating them."
Writers Guild of Canada,Alliance / Union / Guild,"IN YOUR AREA OF KNOWLEDGE OR ORGANIZATION, WHAT MEASURES ARE TAKEN TO MITIGATE LIABILITY RISKS REGARDING AI-GENERATED CONTENT INFRINGING EXISTING COPYRIGHT-PROTECTED WORKS?Pursuant to section 13(1) of the Copyright Act of Canada (the Act), the general rule under the Act is that the “author” of a work is the first owner of the copyright therein.Screenwriters are the authors and first owners of the copyright in their scripts. This is expressly recognized in the current Independent Production Agreement (IPA), which is the collective agreement currently in force between the Writers Guild of Canada (WGC) and the Canadian Media Producers Association (CMPA). (Please see: https://www.wgc.ca/screenwriters/resources/agreements/search_agreements/index)Specifically, Article A701 of the IPA states: “All rights negotiated under this Agreement or in any individual contract between a Writer and a Producer shall be in the form of a license from the Writer to the Producer for a specific use during a specified term of whatever right is in question. The Writer’s copyright shall not be assigned. The copyright herein referred to is the copyright in the Writer’s Script Material, which is separate and distinct from the copyright in the Feature Film or program.”In this context, the IPA includes the following warranties and indemnities.Article A709(a): “The Writer or Story Editor warrants that, to the best of his/her knowledge, information and belief the Script Materials to be provided by him/her hereunder: i) are original to the Writer or Story Editor; ii) do not infringe the copyright of any person; iii) do not defame any person; and iv) do not invade the right to privacy of any person. The foregoing warranty does not apply to material included in the Script Materials supplied to the Writer or Story Editor by the Producer, or in respect to any claim or action that arises from any change made in the Script Materials delivered by the Writer or Story Editor to the Producer after such delivery.”Article A709(b): “The Producer warrants that, to the best of the Producer’s knowledge, information and belief, any material supplied to the Writer by the Producer for the Writer or Story Editor to incorporate in the Script Materials to be provided by the Writer or Story Editor hereunder: i) do not infringe the copyright of any person; ii) do not defame any person; and iii) do not invade the right to privacy of any person; and covenants that no Script Material supplied by the Writer or Story Editor to the Producer shall be used by, or with the approval of, the Producer in such a manner as to defame any person or to invade the right to privacy of any person or to violate the provisions of the Criminal Code of Canada in with respect to child pornography, or obscenity or any like offenses.”While these provisions predate the emergence of generative AI as a viable source of script materials, the WGC takes the view that Articles A709(a)(i) and (ii), and Article A709(b)(i) are applicable in this context. Subject to the state of the law of copyright in Canada, these articles limit or prevent the use of AI-generated materials by both screenwriters and producers under the IPA.As of the date of this submission, the WGC is in the process of bargaining the terms of the next IPA, and is naturally aware of the potential impacts of recent developments of generative AI in this context.","WHAT WOULD MORE CLARITY AROUND COPYRIGHT AND TDM IN CANADA MEAN FOR THE AI INDUSTRY AND THE CREATIVE INDUSTRY?Broadly speaking, TDM sits at the front end of a pipeline in which valuable human-created material is extracted, used to train generative AI systems, and then those systems are used to create value for their developers and users. In other words, it is a process that extracts something of value from the work of human creators as “inputs”, often for little or no compensation, and then conveys that value to developers and users in the form of generative AI “outputs”. Value is transferred from one entity or entities to another entity or entities, often without the knowledge, consent, credit, or compensation of the former.In this sense, the “M” in “TDM”—i.e. the “mining”—is a deeply misleading term. In traditional mining, mineral wealth exists in the ground due entirely to natural processes, and not in any way due to human effort. Nobody “made” the iron ore in an iron mine, it existed there long before humans did, and the human effort in the iron value chain begins with its discovery and extraction from the earth.This is fundamentally not the case with “text and data mining”. In the case of TDM, the “T” and the “D” is only available for the “M” because human beings created the text and data in the first place. Moreover, they did so through expending effort, and often significant effort. Indeed, in complete contrast to the mining of minerals, the human effort involved in creating a given work under copyright is much more significant than that involved in scraping it from the Internet.Simultaneously, there is an enormous asymmetry of information available to AI developers and the creators whose works are being “mined”. In many cases, if not most, the asymmetry is total, with AI developers having ALL the knowledge available on what works are being mined, and how that information is being subsequently used, while creators have NONE of that knowledge. Many creators do not even know if or how their work has been used in TDM in the first place.Given all this, there is an enormous need for transparency in TDM, and this is a place for copyright law and policy to start. AI developers must have certain basic obligations for disclosure and reporting, to holders of copyright, to the public, or both. AI platforms should be required to comply with transparency requirements, including, but not limited to, publishing records of the copyright-protected works that were ingested into the platform.This clarity would allow creators and rights holders, once they know whether and how their work is being used, to advocate and/or negotiate for fair compensation for its use, or to consent to its use in the first place. As noted above, creators have made something of value to AI developers. We know it is valuable, because AI developers are using it through TDM, and generative AI is attracting significant financial investment and user activity. Greater clarity around TDM would allow that value chain to operate in a way that is beneficial to everybody on it, and not just those and the tail end.Broadly speaking, the WGC believes that TDM activities should be subject to the “three C’s” of consent, credit, and compensation for rightsholders and authors.Further, the WGC believes that TDM for the purposes of training generative AI is not and should not constitute fair dealing, either now or in the future.ARE TDM ACTIVITIES BEING CONDUCTED IN CANADA? WHY OR WHY NOT?As noted above, given the near-complete information asymmetry with respect to TDM, the WGC cannot say whether TDM activities are being conducted in Canada. Given the apparent ubiquity and pervasiveness of the practice, however, we would have every reason to believe that they are indeed being conducted in Canada.See the WGC’s further comments elsewhere here on the need for transparency on TDM activities.IF THE GOVERNMENT WERE TO AMEND THE ACT TO CLARIFY THE SCOPE OF PERMISSIBLE TDM ACTIVITIES, WHAT SHOULD BE ITS SCOPE AND SAFEGUARDS? WHAT WOULD BE THE EXPECTED IMPACT OF SUCH AN EXCEPTION ON YOUR INDUSTRY AND ACTIVITIES?Please see our comments above regarding transparency and information asymmetry in this context. In particular, AI platforms should be required to comply with transparency requirements, including, but not limited to, publishing records of the copyright-protected works that were ingested into the platform. Broadly speaking, the WGC believes that TDM activities should be subject to “the three C’s” of consent, credit, and compensation for rightsholders and authors. Further, the WGC believes that TDM for the purposes of training generative AI generally does not and should not constitute fair dealing, either now or in the future.Given the above, the WGC feels strongly that the Government should not create any new copyright exceptions to facilitate TDM, as a fair dealing exception or otherwise. Exceptions that allow AI companies to freely use copyrighted works for AI training purposes would erode the objectives of the “the three C’s” of consent, credit, and compensation for rightsholders and authors. Such exceptions would eliminate completely the “consent” element, and would further undermine the other two, at the very least, by either not providing for compensation of any form, as a full fair-dealing exception, or through compelled licensing, which would undermine rightsholders’ ability to negotiate compensation or withhold their rights if a deal cannot be struck. Removing the latter option from rightsholders naturally hobbles them in negotiations with AI companies. The price of a thing is grounded in the fact that the potential buyer doesn’t get to have it if the seller doesn’t agree to the price. Taking that away benefits the potential buyer and hurts the potential seller. Forcing rightsholders to make works available for TDM benefits AI companies and hurts rightsholders and authors.The WGC also opposes an “opt-out system” for the use of copyrighted works in AI training. An opt-out model would place an enormous burden upon rightsholders, some of whom are individual creators with limited resources, requiring them to monitor multiple AI platforms—or all AI platforms—and then send notice to each advising that it has chosen to opt out of the exception. What happens with regard to any copying that took place before they opted out? This would be a significant burden to place on copyright owners—again, some of whom are individual artists—vis-à-vis typically much larger and powerful corporations, and is disproportionate to the problem and with respect to the bargaining power of the parties.SHOULD THERE BE ANY OBLIGATIONS ON AI DEVELOPERS TO KEEP RECORDS OF OR DISCLOSE WHAT COPYRIGHT-PROTECTED CONTENT WAS USED IN THE TRAINING OF AI SYSTEMS?Yes. Generative AI platforms should be required to comply with transparency requirements, including, but not limited to, publishing records of the copyright-protected works that were ingested into the platform.The WGC is not currently in a position to provide further detail on exactly what that transparency would look like, given the current near-total information asymmetry discussed above. We presume that further details would be engaged in further steps in this or a subsequent government consultation process. But the principle of such transparency and the further development of how it would work is vital.WHAT LEVEL OF REMUNERATION WOULD BE APPROPRIATE FOR THE USE OF A GIVEN WORK IN TDM ACTIVITIES?Given the information asymmetry discussed above, the WGC cannot effectively answer this question, as we lack the information upon which to do so. We do not know which copyright-protected works may have been used in the training of a given AI system, and we do not have quantitative data on the value generated by the AI system based on the use of those works. In addition, see our comments above that the Government should not create any new copyright exceptions to facilitate TDM. Exceptions that allow AI companies to freely use copyrighted works for AI training purposes would presumably upend the objective of the “the three C’s” of consent, credit, and compensation for rightsholders and authors or, at the very least, the “consent” element.Further, we question the premise of the question that the Government should set, or be involved in setting, the level of remuneration that would be appropriate for the use of a given work in TDM activities in the first place. Consistent with “the three C’s”, and in conjunction with robust transparency obligations, it should be up to rightsholders and authors to negotiate with AI developers on whether, how, and for what remuneration their works can be used to train AI systems. In this sense, we submit that the Government should be empowering creators to engage with AI developers on a level playing field, rather than setting the price itself, or compelling the transaction in the first place.ARE THERE TDM APPROACHES IN OTHER JURISDICTIONS THAT COULD INFORM A CANADIAN CONSIDERATION OF THIS ISSUE?The WGC is not in the position at this time to provide a comprehensive review of the approaches in other jurisdictions on this issue. Broadly speaking, inter-jurisdictional comparisons of law and policy are highly complex and, to be done properly, involve a deep understanding of the economic, social, and political contexts of those jurisdictions and how they compare to those of Canada. Ideally, they would also consider what the outcomes of those approaches have been. In the case of generative AI, it is very early in the process and such outcomes are unlikely to be well understood, or known at all.","SHOULD THE GOVERNMENT PROPOSE ANY CLARIFICATION OR MODIFICATION OF THE COPYRIGHT OWNERSHIP AND AUTHORSHIP REGIMES IN LIGHT OF AI-ASSISTED OR AI-GENERATED WORKS? IF SO, HOW?As stated in the Government’s Consultation Paper, “Canadian copyright jurisprudence suggests that ‘authorship’ must be attributed to a natural person who exercises skill and judgment in creating the work, reflective of the fact that the Act ties the term of protection to the life and death of an author.”The WGC believes that this is correct, both as an expression of the jurisprudence and that the jurisprudence has reached the correct conclusion. It is entirely consistent with the words of the Act, as well as the policy rationales for the existence of copyright in the first place, for authorship to be attributed to natural persons—to human beings—alone, and not to generative AI, nor to any other type of non-human source.There are two generally accepted policy rationales for the existence of copyright. One sees copyright from the perspective of users, as a means to incentivize and promote the creation of works that ultimately benefit societies at large. The other sees copyright from the perspective of authors, as a natural right of a person to the fruits of their labours in the exercise of their skill and judgement. In both cases, these rationales are underpinned by the word used to describe what is copyrightable under the Act, namely, “works”. “Works” naturally involve work—human effort, without which such works don’t exist. This is fundamental to any reasonable policy rationale for copyright.Neither of copyright’s rationales justify copyrightability being vested in AI-generated “works”. Importantly, AI-generated outputs involve virtually no effort on the part of the user to create. Currently, a user simply enters basic text prompts into the generative AI and receives back complex text, visual, audio, or audiovisual outputs in return. Other types of non-text inputs may exist now or in the future, but the crucial fact remains that these inputs represent the tiniest fraction of the effort that would be required to create a similar copyrightable work by non-AI-generated means. For example, a complete novel that might require a year or more for a human to write can be spat out by a generative AI in mere minutes, or even seconds. The difference is one of orders of magnitude.Given this, there is no reason for copyright law to protect such outputs for the benefit of the user, either based on the rationale for the incentivizing of creation for the benefit of society, or the rationale for protect the right of a person to the fruits of their labour. In the latter case, there is no meaningful “labour” to protect, and in the former case, there is no shortage of AI-generated works in need of incentivizing.Similarly, as it pertains to the developers of generative AI, there is clearly no need to incentivize their work under copyright either, as demonstrated by the existing fact that copyright is currently not ascribable to AI-generated works in key jurisdictions like the United States, yet billions have poured in to AI development already, and not from any reasonable expectation that copyrightability of resulting outputs is somehow on the horizon.Given this, there is an opportunity for the Government to amend the Copyright Act to make it crystal clear that an “author” is, indeed, a natural person—a human being—and not a machine. We recommend that the Government do so. (This will be particularly important if the Government chooses to clarify that performers are human beings, as it will then be inconsistent for the Act to make that clarification, but not clarify the same issue with respect to authors.) To reiterate, however, the WGC believes it is clear that the Act as currently drafted already requires that authors are human beings, and AI cannot be an author.In addition, as stated in the Consultation Paper, “A human may contribute sufficient skill and judgment in a work produced with the assistance of AI technologies to be considered the author of the work.” We submit that the Government should amend the Act to specify the standard that such contribution of “sufficient skill and judgement” in the context of AI would be, and that this should be a high standard—or, at the very least, a higher standard—for a significant contribution of human input.The WGC is particularly concerned about the threat of a practice we call “copyright laundering”. Copyright laundering may be a particular risk for creators such as screenwriters, who work in an expensive and highly commercialized medium—in our case, film and television—and who collaborate with producers and others within an intermediary stage in the larger creative process towards a final production.In film and television production, screenwriters work with producers and/or content commissioners like broadcasters or streamers. The process begins with an original idea or existing source material, like a novel, and which is then developed into a script which ultimately goes into production to become a film or television show. This development process is a creative process in and of itself, attracting both remuneration for the work done by the screenwriter and recognition for the creativity involved, including in the form of credit on the production and critical acclaim.Copyright laundering would occur when a producer or content commission approaches a screenwriter with material from a generative AI and asks the screenwriter to rework that material to such a degree that it becomes copyrightable. Under a legal framework like the current one, the producer or content commissioner would likely know that simply producing the script generated by AI without sufficient skill and judgement from a human writer would put them at significant risk of not having a copyrightable film or television show in the end, and therefore not being able to effectively commercialize a significant investment in its production. But if the standard for “sufficient skill and judgement” from a human screenwriter is low enough, the producer or content commissioner could generate a script using AI for extremely low or no cost, and have a human writer “launder” the script, seeking to pay the screenwriter significantly less, based on the (specious) argument that they “didn’t do as much work” as if they were working from an original idea. (And without having to benefit other human artists or rightsholders through the purchase the rights to human-created source material, such as a novel.)Such a practice would not necessarily eliminate the role of human screenwriters altogether, but it could reduce the amount which screenwriters are paid, threatening the economic viability of screenwriting as a profession. At the same time, it could also diminish the creative status of human screenwriters, as audiences and others may question just how much the screenwriter—or any other artists working on the production involving AI, for that matter—actually contributed to the final work. Indeed, whether accurate or not, producers, content commissioners, and/or audiences could come to see screenwriters not as artists and creators, but mere formalistic legal requirements for copyrightable production whose skill and ideas are worth less than their existence as human beings.The issue of the economic and creative status of screenwriters and other artists must also be considered in light of the development and maintenance of a talent pool. It is possible that encroachment of generative AI into creative fields would not eliminate all relevant creative roles immediately. Many senior, established artists may remain in demand for a number of reasons, such as their name recognition, track record, and/or unique individual style. But what about more junior and mid-level creators who are trying to establish themselves? Creative skill and talent are rarely things that artists are simply born with, fully formed. They are developed over the course of a career. Like any skill, creative work needs to be practiced and honed. A unique creative voice is something that an artist often finds within themselves after significant effort to unearth it. That is a process that takes years, and is often only possible if and when the artist can financially sustain themselves while it happens, through the process of making art itself. Established creative industries provide incubators for talent, and a pipeline for younger or newer artists to earn a living through creativity while they hone their craft.If generative AI is allowed to disrupt that pipeline by rendering less experienced creators unnecessary, the short-term impacts may only be felt by those creators. But the long-term impacts will be felt by everybody, as the conveyor belt that develops and delivers talent into more senior roles shuts down. And then we will all be worse off as a result.ARE THERE APPROACHES IN OTHER JURISDICTIONS THAT COULD INFORM A CANADIAN CONSIDERATION OF THIS ISSUE?Broadly speaking, inter-jurisdictional comparisons of law and policy are highly complex and, to be done properly, involve a deep understanding of the economic, social, and political contexts of those jurisdictions and how they compare to those of Canada. Ideally, they would also consider what the outcomes of those approaches have been. In the case of generative AI, it is very early in the process and such outcomes are unlikely to be well understand, or known at all.That said, while it may be considered at first glance to be a comparable jurisdiction, the approach to authorship and ownership to AI-generated works taken in the UK represents a global outlier position, is comparable to the UK approach for authorship of cinematographic works that is also a global outlier, is inconsistent with Canadian copyright law, and should not be followed in Canada.","WHAT ARE THE BARRIERS TO DETERMINING WHETHER AN AI SYSTEM ACCESSED OR COPIED A SPECIFIC COPYRIGHT-PROTECTED CONTENT WHEN GENERATING AN INFRINGING OUTPUT?Please see our comments elsewhere in this consultation regarding transparency and information asymmetry in this context. This asymmetry is virtually total, with AI developers having ALL the knowledge available on what works are being mined, and how that information is being subsequently used, while creators have NONE of that knowledge. Many creators do not even know if or how their work has been used in TDM in the first place. This is a significant barrier.",N/A
"ACTRA (Alliance of Canadian Cinema, Television and Radio Artists)",Alliance / Union / Guild,"How does your organization access and collect copyright-protected content, and encode it in training datasets? Not Applicable.How does your organization use training datasets to develop AI systems? Not Applicable.In your area of knowledge or organization, what measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works? Not Applicable.In your area of knowledge or organization, what is the involvement of humans in the development of AI systems? Not Applicable.How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization? The Alliance of Canadian Cinema, Television and Radio Artists (“ACTRA”) currently does not use AI in its internal systems; however, in the course of business some staff use AI services such as Adobe Suite, Chat GPT, or Visme. These AI services are used by staff to facilitate ACTRA’s day-to-day operations.","What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?ACTRA’s membership is comprised primarily of performers in the audiovisual space, whose performances are often captured in video and sound recordings. TDM activities frequently include such media, incorporating large quantities of audiovisual data in datasets used to train generative AI tools that are subsequently used to generate or supplement audio and visual media. While additional clarity around copyright and TDM in Canada would be helpful, there is a substantial gap in Canadian copyright law that would need to be addressed to protect audiovisual performers: moral rights.Moral rights are those rights that deal with the identification of performers in a performance and their right to object to any distortion, and to maintain the integrity of, their work. Currently, infringement of moral rights in copyrighted performances (e.g. a film production) would be left to the producer of such work to dispute, without necessary regard to the interests of the performers.ACTRA believes that performers of audiovisual performances should have equivalent moral rights. Granting such moral rights would enable performers to exercise three fundamental rights regarding the use of their performances obtained via TDM for AI applications: consent, control and compensation.Are TDM activities being conducted in Canada? Why or why not?The datasets that AI developers are leveraging through their TDM activities, like many activities in the digital realm, are not confined to particular jurisdictions. This is especially true in the AI space, where the fast pace of development has resulted in regulators reacting rather than addressing these issues proactively. In addition, Canada is a leading jurisdiction in the research and development of AI systems. As a result, it is a certainty that TDM activities are being conducted both in Canada and on Canadian data.ACTRA highlights this issue, as allowing the use of audiovisual performances in TDM activities, combined with the non-existent protection (via moral rights) for audiovisual performers, subjects performers to risks without regulation and effective oversight. This is inconsistent with fundamental Canadian values, as vulnerable arts workers need to be protected in this rapidly changing industry.For example, AI systems trained through TDM activities can create synthetic media such as deep fakes (whether AI-assisted or AI-generated), which could not be created with the performers’ “inputs”. These deep fakes result in uncanny replications of a performer’s voice, likeness and mannerisms. Performers should have consent rights regarding, and be compensated for, the development and use of such deep fakes.Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?As noted above, audiovisual performers do not receive adequate copyright protection for their performances. Without this protection, performers are left to rely on collective bargaining agreements (or other contractual protections if they are not represented). Many performers do not have access to sophisticated legal counsel that would otherwise be able to help them navigate the intricacies of their contractual arrangements and ensure they are adequately protected.Performers also face technical difficulties, as the media in question (audio and visual production) often implicates the rights and interests of a diverse group (for example, many performers appearing in a scene or recording together). Without clear regulatory guidance, AI system developers will be able to craft arguments and otherwise rationalize their infringing use.What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?ACTRA does not provide for any licenses for TDM activities and is not aware of any of its members providing such licenses.If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?If the government were to amend the Act, ACTRA submits that moral rights should be extended to audiovisual performers, which would provide them with the necessary means to protect their performances (and thereby, their livelihood and other interests). We would also request that no exceptions be made to apply to such moral rights.Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?There is a need for AI developers to maintain records of, and disclose, the copyright-protected content that was used to train their AI systems. There is a clear need for this transparency, particularly with respect to generative AI systems, as these systems will be in direct competition with the performers’ whose data was used to train them. Accordingly, performers should have a mechanism to future-proof their performances, own their own AI datasets, and maintain control over their voice, image and mannerisms – transparency regarding the use of such information is a necessary first step towards these protections, as it would enable them to identify infringing uses.What level of remuneration would be appropriate for the use of a given work in TDM activities?It is neither feasible nor appropriate to suggest firm guidelines regarding remuneration at the outset; rather, adequate protection and transparency should be provided, which would enable a free market approach to licensing fees for the use of performers’ works in TDM activities.Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?The European Union passed the AI Act on June 15th, 2023, which proposes different rules for different risk levels. Generative AI is considered in the High Risk category.  Members of the European Parliament consider High-Risk AI as those that pose any significant risk to a person’s health, their rights or a threat to the environment. EU agrees that all Generative AI must disclose that content was AI generated and comply with transparency regulations. They are formulating a policy and, in doing so are consulting with the cultural sector (which represents 4.4% of the GDP and 7.5 million jobs) that is calling for this transparency.In the USA Congress member Deborah Ross has introduced changes to the Protect Working Musicians Act to protect independent artists from being exploited by music streaming platforms and AI developers. The proposed bill would allow independent music artists to collectively negotiate with streaming services and AI developers.The UK has constructed a pro-innovation approach, with a reactive framework designed to build and learn from experience and adapt to develop regulation. The regulatory framework is underpinned by 5 principles to guide and inform the use of AI. The five principles are:1. Safety, security and robustness,2. Appropriate transparency and explainability,3. Fairness,4. Accountability, and5. Contestability and redressThese principles are to be implemented by existing regulators, and UK government does not intend to develop a statutory regime at present, but collaborate with the regulators and track progress as AI develops.The EU copyright directive of 2019, Article 4   provides an exception or limitation to rights for text and data mining. France has recently opted out of a European Union exception in content ingestion via text and data mining. The French performing rights organization SACEM announced that they have chosen to opt out of a data mining exception that exists in the 2019 copyright directive. Users must first apply for permission to SACEM before being supplied with the works of their 210,800 authors and composers for AI learning.","Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?Regulatory uncertainty – including uncertainty regarding the application of copyright laws to AI-assisted and AI-generated works – is impacting the development of AI technologies. Without regulatory certainty, including clarity regarding performers’ rights, performers (including those represented by ACTRA) and AI developers are inherently at odds. Greater regulatory certainty would enable greater cooperation among these groups, for the benefit of all involved.Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?The Government needs to extend the definition of performance so that it is no longer tied to pre-existing works but also covers the representation of unprotected AI creations. If a performer performs a work created entirely by Generative AI, this performance must enjoy the same protections.ACTRA champions the concept of the three C’s and asserts that performers must have Consent, Control and Compensation for their likeness, voice or image to be used in any form of AI.ACTRA members’ likenesses have already been exploited in deepfakes, where their faces are imposed on someone else’s body or they are put in pornographic content doing and saying things they would never do, creating serious reputational harm and economic harm. AI technology must evolve in a way that respects human inspiration, creativity and ingenuity.These principles should be incorporated across Canada’s AI-related legislation – whether direct legislation, like the Artificial Intelligence and Data Act (“AIDA”), as well as incidental legislation, like amendments to the Copyright Act. An acknowledgement of the need to protect core, enduring human values (i.e., those that aren’t easily quantifiable) should be consistent across all such legislation.For example, as noted in ACTRA’s previous submissions regarding AIDA, AIDA’s current definition of harm considers three forms of loss, (physical/psychological, economic, property). So if it is acknowledged that economic loss is a legitimate harm, it follows that damage to an individuals’ reputation requires protection as employment opportunities are directly related to the same. As work is dependent on our reputation. Accordingly, we submitted that the definition of harm should be expanded to include damage to an individual’s reputation or dignity.Further, we recommended a broader definition of personal information that includes an individual’s personality rights, which means their likeness, image, persona and voice. And to prevent the unauthorized use of a performer’s likeness, image or voice, any exploitation of an individual’s personality rights would necessarily require consent.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?In the United States, a Washington federal court upheld the US Copyright Office’s belief that only works created by human authors can receive copyright protection. The case was initiated when computer scientist Stephen Thaler challenged the Copyright Office’s ruling on behalf of his AI DABUS System. Thaler applied to the US Copyright Office in 2018 seeking copyright protection for an AI created piece of visual art entitled “A Recent Entrance to Paradise” and was rejected.   Judge Beryl A. Howell found the work ineligible as it was “absent of any human involvement”, which she said is a “bedrock requirement of copyright”.The EU AI Act has yet to establish authorship of AI-generated works, yet it was established that companies that created AI-generated content must disclose and copyrighted material that was used to develop the AI system.United Kingdom legislation from 1988 claims that computer-generated works are eligible for copyright protection and the author/owner of the technology is held as the owner of the work.  Stephen Thaler has also applied for intellectual property protection for his AI-generated works in the UK and other jurisdictions worldwide. Various courts have ruled against him claiming he can’t patent something that wasn’t human-created. In the UK, Thaler’s initial appeal was dismissed at the High Court of Appeal, and he has now appealed to the Supreme Court and is awaiting judgement.","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?It is likely that the concept of “fair dealing” will be used as a defence for copyright infringement regarding the use of copyright-protected works as the input in TDM activities.For example, the infringing activity may be claimed to constitute “fair dealing” as it is used for “research purposes” (i.e. the development of a foundational model, many of which started out as academic endeavours). Similarly, any single instance of copyright infringement, given the size of many datasets used in TDM activities, would support this argument. This argument has not been tested in court, but there has also been a lack of guidance from the Canadian Intellectual Property Office on how such principles would apply in the context of TDM activities of generative AI generally.What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?The barriers include the fact that data mining utilizes hundreds of thousands to millions of copyrighted works to train an algorithm, which then creates various outputs. While there are instances of “memorization”, or an AI application generating an output that is nearly identical to one of its copyrighted inputs, it is almost impossible to establish all the content used to create an AI output. This is partially a function of the nature of an AI model, which relies on TDM-based training to adjust the various “weights” and “biases” (also known as “parameters) within the model, which, as a result of the statistical methods used by these models, can produce innumerable unique outputs for the same input.This issue is at the forefront of the litigation between Getty Images and Stability AI (creator of Stable Diffusion, a generative AI model), in which Getty has claimed that Stability AI infringed upon their image collection on a “staggering scale”.    Getty Images has filed lawsuits in both the US and UK courts, the outcome of which is likely to aid in determining what defines infringement of copyright by AI.When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?While ACTRA is not familiar with such measures being taken, it appears as though businesses are taking few to no measures to mitigate their risk of copyright infringement.Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Yes. Take, for example, the case of a performer’s voice and likeness being used for a pornographic plug-in for Skyrim. In this case, Ubisoft is not directly infringing any copyright interests, yet their open-source policy has enabled it and they are receiving a boost to their platform as a result. This is not a clear direct infringement, yet it is still damaging to our member's reputation and ability get future work, and is demeaning and distressing for individuals who are violated in this way, resulting in the loss of dignity.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?As noted above, there are several pending court cases where issues around copyright infringement in AI development are being put squarely before the courts. In addition, under the proposed EU AI legislation, providers of foundation models would be required to document and make publicly available a sufficiently detailed summary of the use of training data protected under copyright law.","Are there any other considerations or elements you wish to share about copyright policy related to AI?As AI development continues to advance, we should be reconsidering the context in which our laws – including copyright and privacy – were developed. ACTRA’s position, as set out in our recent submissions regarding AIDA, is that both privacy and copyright interests are implicated by generative AI, particularly in the audiovisual performance space. These implications go beyond performers, however, and are relevant for any individual with an internet presence, who will similarly be exposed to risks associated with the unauthorized use of their name, image and likeness. Set out below are the amendments to Bill C-27 that ACTRA proposed in our recent submissions for your review and consideration."
ACTRA Toronto,Alliance / Union / Guild,"In the film, television and digital media industry, we have already seen a proliferation of generative AI  digital replicas used to replace human performers. In dubbing into English, producers are using AI to translate foreign language content into English (and vice versa). They are also able to change the mouth shape of the performer to match the new language. This puts voice over performers out of work.In film & tv, we are already seeing deceased celebrities being brought back, or living celebrities de-aged. This work used to be done through prosthetics and is putting make-up and special fx artists out of work. We are also seeing the replacement of background performers or extras with digital replicas. Either scans of existing performers or new generative AI doubles are causing a large reduction in work opportunities for these performers.","The use of data scraping when it comes to using performers NIL (Name, image, likeness & persona) is rampant in the film & television industry. AI data mining occurs when companies use existing footage of a performance and use that to train AI systems. Ideally, the government would solidify NIL rights under Copyright law so that a performer has true ownership over their “brand”. Their voice print, image, likeness and persona are as unique as their fingerprint, and they should hold copyright over the use of those. Another term for this would be “personality rights” or “rights of publicity”.  The provinces of British Columbia, Manitoba, Newfoundland and Labrador, and Saskatchewan have enacted privacy legislation dealing with personality rights, which have the following traits:Quebec has additional provisions in place that we would like to see enshrined across Canada. The Civil Code of Quebec enshrines the right to privacy as an attribute of personality, and specifically says:36. The following acts, in particular, may be considered as invasions of the privacy of a person:(1) entering or taking anything in his dwelling;(2) intentionally intercepting or using his private communications;(3) appropriating or using his image or voice while he is in private premises;(4) keeping his private life under observation by any means;(5) using his name, image, likeness or voice for a purpose other than the legitimate information of the public;(6) using his correspondence, manuscripts or other personal documents.The Supreme Court of Canada also affirmed that under Quebec's Charter of Human Rights and Freedoms privacy provisions, a photographer can take photographs in public places but may not publish the picture unless permission has been obtained from the subject, except where the subject appears in an incidental manner, or whose professional success depends on public opinion. The relevant provisions of the Charter are:4. Every person has a right to the safeguard of his dignity, honour and reputation.5. Every person has a right to respect for his private life.We would like to see these enacted federally.","We firmly believe that their should be no ability to hold copyright over AI generated works. Lack of ownership would ensure that the film & tv industry was hesitant to use generative AI, as the producers/studios themselves would then not be able to hold copyright over the work. In August 2023, a US judge ruled that AI cannot hold copyright for work it creates and said copyright could also not be transferred from the AI machine to the human entity that was responsible for it. Human authorship should be a bedrock requirement of authorship and copyright. Canadian framework should mirror this belief that AI assisted or generated work cannot be copyrighted.","There must be extreme clarity on where liability lies when generative AI infringes on any copyright protected work. This must include NIL & personality rights for performers. A performance, or part thereof, given in one project should never be permitted to be used in any other project without informed consent being provided that is accompanied with appropriate compensation and built in controls and duty of care. The European Commission has some key findings that should help the Canadian government navigate these waters.","As AI technologies continue to progress at a rapid pace and make incredible advancements, AI stakeholders, courts, policymakers, and the public should keep in mind several key principles when analyzing the intersection between AI and copyright.1. When formulating new AI laws and policies, it is essential that the rights of creators and copyright owners be respected.2. Long standing copyright laws and policies must not be cast aside in favor of new laws or policies obligating creators to essentially subsidize AI technologies.3. Education is paramount in the AI space. Those leading AI projects are aware of the legal implications of using copyrighted works input material, and those that arise from AI-generated output"
Fédération professionnelle des journalistes du Québec,Alliance / Union / Guild,N/A,N/A,N/A,N/A,"Le développement des outils numériques transforme le quotidien de nombreuses industries, en particulier celle des médias.L'appropriation du marché publicitaire par les géants du numérique bouscule les modèles d'affaires de bien des médias depuis un peu plus d'une décennie.Les audiences tenues lors du projet de loi C-18 ont permis notamment d'illustrer les efforts de transformation et d'adaptation des médias ainsi que l'urgence d'une contribution financière équitable de la part des géants du numérique auprès des médias.L'un de ces géants du numérique, Google, a convenu d'une entente avec Ottawa à hauteur de 100 millions annuellement. Un pas dans la bonne direction, estime la FPJQ, mais qui demeure incomplet puisque Mera refuse toujours de contribuer et de partager à nouveau des contenus médias sur ses plateformes.Meta, et particulièrement sa plateforme Facebook, constitue pour un grand nombre de Québécois et de Canadiens la porte d'entrée principale vers des contenus journalistiques. Ce blocus, en plus de priver les médias de revenus potentiels, prive les citoyens d'informations névralgiques.Entretemps, des médias cessent leurs activités, les pertes d'emploi se comptent désormais par milliers et plusieurs régions sont à risque de devenir des déserts médiatiques. Une hémorragie qui s'étire depuis plus de dix ans et qui nuit à la démocratie canadienne.C'est dans ce contexte que les systèmes d'intelligence artificielle (IA) générative grand public ont fait leur entrée sur le marché en 2022.Comme le souligne le document de Consultation sur le droit d'auteur à l'ère de l'intelligence artificielle générative :Une des sources de données importantes des pionniers des systèmes d'intelligence artificielle (IA) générative demeurent les contenus produits par les médias. Des médias déjà éprouvés par une crise financière.Lors du dernier congrès annuel de la FPJQ, un atelier complet s'est penché sur les enjeux éthiques et de la propriété intellectuelle liée à l'intelligence artificielle (IA) générative.À la FPJQ, il nous semble essentiel que les travaux de révision de la Loi sur le droit d'auteur incluent un mécanisme de rémunération pour l'utilisation des données des médias dans un contexte canadien, pas seulement américain.Déjà aux États-Unis, lors d'une audition récente au Sénat sur l'impact de l'IA sur le journalisme, les législateurs ont convenu qu'OpenAI et d'autres devraient rémunérer les médias pour l'utilisation de leur travail dans des projets d'IA.Le NY Times a lancé au mois de décembre des poursuites, auprès d'un tribunal fédéral à New York, à l'encontre d'OpenAI, créateur du logiciel ChatGPT, ainsi que de Microsoft, son principal investisseur, pour violation du droit d'auteur.Par ailleurs, la FPJQ estime que la révision de la Loi sur le droit d'auteur doit également assurer une traçabilité des données d'entraînement des systèmes d'intelligence artificielle (IA) générative. On doit savoir d'où proviennent les données pour bâtir les systèmes et les modèles sur lesquels ils s'appuient. Cette traçabilité permettrait aussi d'apprécier plus adéquatement la qualité des contenus produits par IA générative.Il en va de la viabilité des entreprises de nouvelles et de la démocratie.La Fédération professionnelle des journalistes du Québec est un organisme sans but lucratif qui rassemble environ 1 600 journalistes dans plus de 250 médias écrits et électroniques. C'est ce qui en fait la principale et la plus représentative organisation journalistique au Canada."
Union des artistes,Alliance / Union / Guild,"Cette soumission constitue une position commune des associations et société suivantes :Artisti, une société de gestion collective canadienne représentant divers artistes-interprètes pour la gestion collective de leur droit à la rémunération équitable et leur droit à la rémunération découlant de la copie privée ainsi que tout ou partie de leurs droits exclusifs ;L’Union des artistes (UDA), un syndicat professionnel représentant les artistes de plusieurs disciplines œuvrant en français ou dans toute autre langue à l’exception de la production faite et exécutée en anglais ;La Guilde des musiciens et musiciennes du Québec (GMMQ), une association d’artistes légalement reconnue au Québec pour représenter les musiciens professionnels, notamment lors de la négociation d’ententes collectives visant leurs conditions de travail et de rémunération.Celles-ci voient le potentiel de l’IA à titre d’outil de création : plusieurs de leurs membres s’en servent d’ailleurs comme d’instruments leur permettant de livrer une prestation. Il est néanmoins essentiel d’encadrer l’utilisation de la technologie, particulièrement dans le contexte de la fouille de textes et de données (« FTD »), puisque les prestations des artistes interprètes sont actuellement utilisées à cette fin à leur insu, sans rétribution.","Une plus grande clarté et transparence permettraient de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les prestations d’artistes interprètes sont utilisées, ainsi que les rôles et responsabilités des différentes parties prenantes. Ceci permettrait également de déterminer : (i) dans quel(s) contexte(s) l’analyse informationnelle est autorisée, ou non, par le régime actuel de droit d’auteur canadien et ainsi, (ii) quelles licences et rétributions doivent être versées aux titulaires des prestations d’artistes interprètes. Des activités de FTD sont actuellement menées au Canada, afin d’entraîner des modèles algorithmiques. Les activités de développement et d’entraînement de systèmes d’IA peuvent impliquer la reproduction de contenus protégés par droit d’auteur dont des prestations d’artistes interprètes ou leur voix et leur image hors prestation, et ce, sans qu’ils y consentent ou reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d’y remédier. En outre, il est essentiel que l’autorisation (de type « opt-in » et non « opt-out ») des artistes interprètes soit obtenue préalablement à toute reproduction de leurs prestations, leur voix ou leur image, et qu’une rétribution juste et équitable leur soit versée en contrepartie de cette utilisation. L’obtention de ces consentements devra prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, un contentement distinct devra être obtenu auprès des artistes-interprètes si l’autorisation initialement consentie aux producteurs ne couvre pas la FTD, ce qui est le cas pour l’instant.À cet égard, il est également important de rappeler que les artistes interprètes qui ont consenti à ce que leurs prestations soient intégrées à une œuvre cinématographique ne peuvent présentement pas exercer leurs droits de l’article 15 (1) compte tenu de l’article 17(1) de la Loi sur le droit d’auteur et qu’ils ne peuvent pas non plus bénéficier de droits moraux à l’égard de ces prestations audiovisuelles. Afin de résoudre ces enjeux, le Canada devrait ratifier le Traité de Beijing, ce qui permettrait aux artistes-interprètes audiovisuels d’exercer un meilleur contrôle sur leurs prestations incorporées dans des œuvres cinématographiques.Les titulaires de droits face à des défis en lien avec en ce qui concerne l’octroi de licences pour les activités de FTD. En outre, il est difficile pour les artistes interprètes de déterminer quel contenu est utilisé dans le contexte de la FTD et quelle est l’ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d’imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d’IA.Diverses licences sont disponibles pour les activités de FTD impliquant l’exercice d’un droit réservé aux titulaires de droit d’auteur, à savoir la reproduction. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d’auteurs incluant les artistes interprètes ou être obtenues par le biais d’une société de gestion collective. En effet, en ce qui a trait aux artistes interprètes, la possibilité de faire des reproductions de leurs prestations aux fins de la FTD n’est généralement pas incluse dans les autorisations qu’ils ont données aux producteurs d’enregistrements sonores ou d’œuvres cinématographiques, ces autorisations visant essentiellement l’exploitation commerciale des enregistrements sonores et des œuvres cinématographiques. Il faudrait donc que des autorisations aux fins de FTD soient obtenues auprès des artistes interprètes ou de leur société de gestion collective. Les artistes interprètes ou leur société de gestion collective seraient tout à fait à même de les émettre.Pour rappel :  ces licences ne semblent présentement pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner notamment pour les artistes interprètes qui peinent à obtenir une juste compensation pour l’utilisation de leurs contenus. Comme les prestations reproduites aux fins de FTD sont des prestations fixées sur des enregistrements sonores ou audiovisuels et qu’il s’agit de prestations d’œuvres, plusieurs mécanismes peuvent être envisagés pour compenser les ayants droits visés pour cette utilisation qui est faite de leurs prestations : l’introduction d’un droit à une rémunération équitable pour la FTD ou un droit à rémunération via un mécanisme semblable à celui de la copie pour usage privé font partie de ces mécanismes.La reproduction des prestations d’artistes interprète aux fins de la FTD ne pas couvertes par les dispositions contractuelles qui encadraient la fixation de ces prestations. C’est donc dire qu’aux fins de cette activité, l’autorisation de l’artiste interprète devrait donc systématiquement être obtenue. En effet, il ne faut pas oublier que la reproduction d’une prestation aux fins de la FTD impliquera souvent la reproduction de la voix et de l’image d’un artiste interprète (des données biométriques), qui sont des attributs de sa personnalité protégés par les droits de la personnalité, le droit à la vie privée et les législations en matière de protection de données personnelles.Compte tenu de ces différentes protections législatives, il semble donc impossible d’envisager une exception pour permettre l’utilisation de ces prestations impliquant la voix ou l’image d’un artiste aux fins de la FTD puisqu’un ensemble d’autres dispositions législatives contrecarraient et contrediraient l’introduction d’une telle exception.Nous ne sommes donc pas favorables à l’adoption d’une exception générale permettant la FTD, laquelle serait, par ailleurs, également contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l’ADPIC et l’ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d’auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l’exploitation normale de l’œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur. Ainsi, si jamais le gouvernement décidait d’adopter malgré tout une exception de FTD (ce que nous ne recommandons pas), il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l’exception soit : (i) limitée à des cas spécifiques (par exemple, à des fins de recherche) ; (ii) assujettie à des conditions d’application strictes (par exemple, l’accès à l’œuvre ou objet de droit d’auteur doit être licite) ; et (iii) assortie du versement d’une juste rétribution au bénéfice des titulaires de droits d’auteur, ainsi que d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur.Finalement, cette exception ne devrait pas s’appliquer aux droits moraux, mais uniquement aux droits dits « économiques ».Nous recommandons fortement la tenue de registre ou la divulgation des contenus protégés par le droit d’auteur qui ont été utilisés pour la formation des systèmes d’IA. Il s’agit d’une obligation essentielle qui devrait être intégrée dans la Loi sur le droit d’auteur. La transparence est l’un des principes fondamentaux qui devraient guider en tout temps les développeurs de systèmes d’IA.Le niveau de rémunération approprié pour l'utilisation d'une œuvre ou d'un objet du droit d'auteur dans les activités FTD doit être juste et équitable, basé sur les utilisations faites des contenus protégés. Dans tous les cas, la rémunération devrait être arrimée avec les autorisations obtenues et prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, une rémunération distincte devra être versée aux artistes-interprètes si l’autorisation initialement consentie aux producteurs des contenus reproduits ne couvrait pas la FTD.Comme exposé plus tôt, il n’est pas recommandé d’introduire une exception de FTD au Canada. Au contraire, il est essentiel de veiller au respect de la Loi sur le droit d’auteur et des autres dispositions législatives trouvant présentement application (tels que les droits de la personnalité et ceux liés à la protection des renseignements personnels qui sont en jeux lors de la reproduction des prestations d’artistes interprètes à d’autres fins que celles initialement consenties ou la reproduction de leur voix et leur image hors-prestations) en s’assurant que l’autorisation des artistes interprètes soit obtenue et qu’une rémunération juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de FTD.Nous recommandons également qu’une obligation de transparence ou de tenue de registres soit imposée aux chercheurs et développeurs de systèmes d’IA générative, dans le contexte de la FTD.Si toutefois le Canada souhaitait, en dépit de nos recommandations et en contravention des droits de la personnalité, droit à la vie privée et droits liés à la protection des renseignements personnels qui protègent la voix et l’image des artistes interprètes, introduire une exception de FTD, il devra veiller à ce que cette exception respecte les balises internationales, soit d’application limitée et assortie d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur.À cette fin, le gouvernement canadien pourrait examiner la situation prévalant au sein de l’Union européenne, la Suisse et le Royaume-Uni.",,,"La consultation publique est accueillie favorablement par nos organisations, lesquelles voient en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA sur le droit d’auteur. Nos organisations ne souhaitent pas freiner l’avancement de l’IA, mais désirent préserver l’équilibre que la Loi sur le droit d’auteur sous-tend, en veillant à préserver la culture canadienne, la créativité humaine, ainsi que les intérêts des titulaires de droits d’auteur.Pour ce faire, nous recommandons que les principes regroupés sous l’acronyme « A.R.T. » (Autorisation, Rétribution et Transparence) guident les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d’auteur qui en découleront.Par ailleurs, il est important que la consultation publique ne se limite pas aux intérêts des auteurs et autres titulaires de droits d’auteur sur des œuvres, mais qu’elle couvre également les intérêts des artistes-interprètes sur leurs prestations ainsi que sur leur voix, leur image et leur ressemblance.L’IA générative bouleverse en effet grandement ces créateurs, notamment dans le contexte de l’hypertrucage (ou « deepfake » en anglais). À ce chapitre, les artistes-interprètes audiovisuels ne disposent pas de droits suffisants pour protéger leurs prestations, y compris dans le contexte de l’IA générative et de l’hypertrucage. Afin de pallier cette situation, il est recommandé d’étendre les droits exclusifs et les droits moraux de ces artistes, par exemple, en ratifiant le Traité de Beijing."
Union des écrivaines et des écrivains québécois (UNEQ),Alliance / Union / Guild,"Les revendications du milieu artistique et culturel ne visent aucunement à réprouver l’utilisation de l’IA. On reconnaîtra les avantages et les avancées importantes que cette technologie représente dans plusieurs secteurs mais son utilisation et son déploiement doivent être encadrés par une structure transparente, équitable et respectueuse des artistes et de l’industrie culturelle.Utilisation courante selon les supports d’information et de communication.Outil de création complémentaire à la pratique.Recherche et documentation.","La clarté ou la transparence demeure une problématique majeure, mais on aurait toutefois tort d’en faire l’unique facteur de réflexion. Réduire l’objectif de la consultation à la clarté pourrait mener à la fixation de dispositions dans la Loi sur le droit d’auteur, au détriment des titulaires de droits.Le besoin de clarté et de transparence concerne d’abord le fonctionnement de l’IA et non l’application de la Loi. L’Union des écrivaines et des écrivains québécois (UNEQ) souligne le risque encouru par une uniformisation et une simplification des lois internationales qui pourraient mener à des exceptions menaçant les droits d’auteur.En concertation avec d’autres associations du milieu culturel, l’UNEQ recommande déjà, dans le cadre de la révision de la Loi sur le droit d’auteur, que les questions de l’utilisation équitable et de l’exception à des fins pédagogiques soient prioritairement définies plus clairement. Les pratiques croissantes de FTD ne viennent qu’accroître la nécessité de mieux définir les exceptions intégrées à la Loi et d’en circonscrire la portée pour protéger les œuvres littéraires et artistiques.La FTD soulève de nombreux enjeux qui découlent à la fois des intrants (les textes et les données utilisés par l’IA générative) et des extrants (les produits générés par l’IA). L’UNEQ recommande qu’un groupe de travail constitué d’experts soit mis sur pied afin de répondre aux enjeux légaux, éthiques et économiques que représentent l’IA générative pour les titulaires de droits. Une révision trop hâtive et précipitée de la Loi sur le droit d’auteur risquerait non seulement de contourner ces enjeux sans y répondre, mais plus encore, d’entraîner des problèmes supplémentaires et irréversibles.L’UNEQ est d’avis que des licences de droits d’auteur doivent nécessairement être mises en place pour encadrer l’utilisation, par l’IA, des œuvres protégées par la Loi sur le droit d’auteur. L’analyse de structures déjà existantes en matière de traçabilité, d’autorisations, de mesures d’indemnisation ou de compensation en gestions collectives demeurent des pistes de solutions qui méritent d’être explorées et adaptées pour répondre aux différents enjeux liés aux FTD.L’UNEQ est d’avis que les recommandations issues de l’examen parlementaire de la Loi, en 2021 - « élargir les objectifs autorisés en vertu de l’exception d’utilisation équitable pour inclure le FTD ; modifier l’exception d’utilisation équitable pour la rendre aussi ouverte que le fair use américain ; modifier l’exception relative aux reproductions temporaires pour procédés technologiques de la Loi pour couvrir le FTD ; et créer une nouvelle exception dédiée spécifiquement pour TDM » – constituent de réels dangers pour l’avenir de la création littéraire et artistique.L’UNEQ tient à rappeler que les recommandations formulées par les titulaires de droits lors de cet examen demeurent tout aussi pertinentes, sinon plus, dans le contexte de la FTD : clarifier l’utilisation équitable, notamment dans le domaine de l’éducation ; augmenter le plafond des dommages-intérêts préétablis ; veiller à ce que le Canada respecte ses obligations découlant des traités internationaux ; promouvoir le fonctionnement d’une Commission du droit d’auteur efficace.L’UNEQ recommande que les développeurs de systèmes d’IA tiennent des registres et déclarent quelles sont les œuvres protégées qui ont été utilisées pour la génération de contenu et pour nourrir leur système.L’UNEQ invite le gouvernement à confier les recommandations et les ajustements de rémunération aux acteurs du milieu culturel. Une fixation de barèmes tarifaires et d’échelles d’indemnisation ne devrait pas relever des instances politiques, mais découler de négociations entre les titulaires de droits et les utilisateurs (ou de leurs représentants). Le rôle du gouvernement devrait se limiter à mettre en place l’obligation de rémunération et à s’assurer que les négociations se déroulent de bonne foi entre les parties prenantes.Les approches étrangères en matière de FTD et de droits d’auteur peuvent certes inspirer la réflexion et l’analyse, mais « rappelons que le Canada, premier signataire de la Convention de 2005 de l’UNESCO pour la protection et la promotion de la diversité des expressions culturelles, a traditionnellement joué un rôle de leader en la matière. Il doit aujourd’hui poursuivre dans cette voie. »(Commentaires de la Coalition pour la diversité des expressions culturelles dans le cadre de la Consultation sur l’élaboration d’un code de pratique canadien pour les systèmes d’intelligence artificielle générative. Présenté à Innovation, Sciences et Développement économique Canada, 14 septembre 2023).",,,"Depuis le lancement de la consultation du gouvernement canadien à propos du droit d’auteur et de l’intelligence artificielle (IA), l’Union des écrivaines et des écrivains québécois (UNEQ), comme plusieurs organismes culturels et associations professionnelles, travaille à faire entendre la voix des artistes et des titulaires de droits, dont les revendications s’opposent à celles des développeurs de systèmes d’IA. Faut-il rappeler que « les lois et les règlementations sur le droit d’auteur au Canada sont conçues pour assurer la reconnaissance des créateurs et autres détenteurs de droits d’auteur » et qu’« une protection efficace des droits d’auteur est essentielle à l’expression culturelle, à l’engagement des citoyens et à la croissance économique stimulée par l’essor de l’économie du savoir » ? En regard de ses propres engagements, nous mettons le gouvernement canadien en garde contre les dangers et les risques considérables que des modifications à la Loi pourraient entraîner.**De l’utilisation d’œuvres protégées par le droit d’auteur aux fins de l’entraînement des systèmes d’IA**Le secteur culturel, déjà affaibli par les exceptions intégrées à la Loi sur le droit d’auteur en 2012, demande au gouvernement de ne pas en élargir la portée et de n’ajouter aucune exception supplémentaire à l’égard de l’utilisation, par les systèmes d’IA générative, des œuvres protégées par la Loi. Plus encore, il importe de préciser et de circonscrire l’application des exceptions déjà existantes afin que des interprétations trop larges et erronées ne permettent aux développeurs et aux utilisateurs de s’en prévaloir et d’utiliser les œuvres protégées sans autorisation, ni rémunération. De l’avis de l’UNEQ, le respect du droit d’auteur ne freine en rien le développement technologique, au contraire : une création riche et diversifiée, reconnue et protégée par un cadre législatif efficient, ne peut qu’être bénéfique pour tout développement technologique, culturel et social.** De la titularité et la propriété des droits en ce qui concerne le contenu produit par l’IA **Les critères qui déterminent si une œuvre peut être protégée par la Loi sur le droit d’auteur sont déjà clairement énoncés et un contenu généré par un algorithme ne saurait y répondre. Prévoir un mécanisme d’analyse exhaustive dans le processus de génération de contenu, où l’artiste utilise accessoirement l’IA dans le cadre de sa propre création : oui. Modifier les critères de protection pour permettre à l’IA d’être considérée au même titre qu’un·e créateur·rice : non.** De la responsabilité, particulièrement si le contenu produit par l’IA viole les droits d’auteur d’œuvres existantes **La majorité des artistes qui pourraient être affectés par la violation de leurs droits d’auteurs sont loin de disposer des ressources requises à la résolution de litiges, surtout lorsque ceux-ci les opposent à des entreprises comme Microsoft, Google ou Amazon. Se présumant inattaquables, les géants garantissent actuellement à leurs utilisateurs une pleine indemnité en cas de plainte ou de poursuite pour violation de droits d’auteur. Loin de prétendre que la responsabilité d’une violation n’incombe pas aux développeurs, l’UNEQ est néanmoins d’avis que les utilisateurs devraient plutôt être sensibilisés et conscientisés. En ce sens, le gouvernement canadien devrait prévoir des dispositions pénales exemplaires et en garantir l’application en soutenant concrètement les artistes et l’industrie culturelle dans le cas de violations de droits d’auteur."
The Writers' Union of Canada,Alliance / Union / Guild,N/A,"Question: What would more clarity around copyright and TDM in Canada mean for the AI industry and for the creative industry?Clarity in the Act around the responsibilities of industrial users of professionally created content is essential for the maintenance of existing markets and the creation of valuable new ones.We have seen how lack of clarity around education as a category of fair dealing has led only to over-reach, costly litigation, greater confusion, and a broken market for published work in educational settings.Text and Data Mining (TDM) activity requires industrial scale copying of created works. It must be regulated by strong and clear guidelines stemming from the Copyright Act.Question: Are TDM activities being conducted in Canada? Why is it the case or not?It is very difficult to answer this question authoritatively, because as we’ve seen from the prominent TDM activities resulting in AI services, much of that TDM and training work is done unadvertised and quietly without engaging with or even informing the creators whose work is being used.That said, we are reasonably sure TDM activities do take place in Canada as Large Language Model research has been happening at Canadian universities for a very long time.Question: Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?The main challenge facing rightsholders around licensing of work for TDM is that there is simply no initiative from within the TDM sector to engage in licensing, or even to inform the creative sector about their work. The Books3 dataset was revealed by an investigative report in the press, but otherwise the training and datasets used for the training are essentially behind a curtain.Creative professionals can be reasonably sure their work is being used because the outputs of AI Chat services show clear and deep familiarity with the work, but the lack of transparency in TDM does not indicate good faith engagement.There are mechanisms in place that could have been used by TDM companies to engage with and seek permission from professional creators. Licensing collectives and the Copyright Board have become too easy to avoid or circumvent through vague and bad faith claims of fair dealing. This points to a fundamental weakness in Canada’s Copyright Act. The fence that is supposed to define and protect our intellectual property has been so riddled with exceptions, it no longer functions as a fence.Over a decade of undermining the Canadian market for rights under copyright has created the impression that there is no marketplace for rights, and that they can simply be ignored.Question: What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?There are both direct and collective licensing models already in existence, and the potential for TDM-specific licenses to emerge. The Writers’ Union of Canada has developed new contract terms to ensure our members reserve their rights around TDM and Artificial Intelligence. The creative sector is nimble and able to adapt to new technology and new uses of our work, and we are willing participants in most functioning markets. With good faith negotiation and bargaining, there is a zero percent chance a licensing structure that works for all parties would not emerge.Question: If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would the expected impact of such an exception on your industry and activities?Any new exception for TDM and/or AI training will have a negative impact on creative professionals. Such an exception would further undermine exclusive rights conferred by the Act, would remove any potential for emerging markets, and would damage existing models for monetization and control of cultural work.TWUC opposes any amendment to the Copyright Act that introduces new exceptions to the exclusive rights conferred by the Act. TDM and AI activities using creative work are acts of copying, and as such fall under the exclusive right of creators. There exists an evolving market for these rights, and an exception would disrupt that natural evolution and destroy a market.Furthermore, TWUC believes the Copyright Act must now take on the question of AI outputs that directly compete with the work of human creative professionals. We believe the Act should privilege the original work of human creators in all instances of conflict with AI outputs.If this work to clarify the Copyright Act is not done, Canada is inviting yet another round of costly, time-consuming, and ultimately inconclusive litigation similar to what we’ve seen around educational copying. As was shown with the SCC decision in Access Copyright v. York University, the Copyright Act must be clear and unequivocal in its definitions, and regulators such as the Copyright Board must be given functional authority, or the whole rights market breaks down under legal challenge.Question: Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?It is essential for transparency both from a market perspective and a moral rights perspective that TDM and AI developers be obligated to keep comprehensive records and disclose their use of copyright-protected materials.We are already seeing allegations that infringed work was accessed from pirate sites in some cases of AI training. To not require complete transparency only encourages further infringing activities.A functioning market for TDM and AI licensing depends on the tracking of use and value. Given the technological complexity and sophistication of such operations it would be disingenuous to argue that comprehensive record-keeping and disclosure are burdensome requirements.Question: What level of remuneration would be appropriate for the use of a given work in TDM activities?Fair and reasonable price points evolve through market functionality. Without fully understanding the details of the use of a work and the value generated by that use, it is impossible to place an accurate price. A level-playing field with effective regulation will foster negotiation and bargaining that will arrive as price points, and allow for the evolution of those price points as uses change.What is inappropriate is allowing undeclared, unpermitted, and uncompensated use of intellectual property at industrial scale.Question: Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?As with educational copying, TWUC considers the UK model for TDM licensing and permissions to be a workable example when building a framework in Canada. The UK model allows for growth of a rights market around TDM and AI, and has shown no signs of inhibiting the growth of AI development.","Question: Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?We do not see any inhibition on the rapid development and growth of AI systems. It would appear that questions of copyright and ownership of intellectual property are not of a high priority for AI developers.Should they be a high priority? Absolutely. Market considerations around AI inputs and outputs are not restricted to the provision of the service. A market for AI cannot be allowed to develop without consideration for the IP used in both inputs and outputs.Question: Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?TWUC believes it is a foundational principle of copyright protection that it be granted to works demonstrating individual human judgement and skill. Allowing for copyright protection to AI outputs with minimal to no human creativity involved would quickly concentrate market power for content in the hands of the few largest AI firms, much in the same way advertising revenue was concentrated in just a few tech platforms due to a lack of effective regulation around the sharing of news content.Governments are now in the position of trying to pull back revenue and control for media rightsholders from an intransigent tech sector. We must learn from that lesson and place proper guardrails and regulations that privilege human creation.Question: Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?Professionally created Canadian cultural works play an outsized role in defining Canadian reality and values to the world. To safeguard that work, and keep it from being obscured by an avalanche of AI-generated content that purports to define this country, Canada should put in the work to develop our own strong policy. The UK example of granting copyright protection to computer-generated works should not be followed. Ongoing conversations in the US and UK around privileging human creation are instructive but only a starting point, and suffer from having to be reactive against a starting point at which AI-generated content may be considered equal to human-made content.  TWUC believes this conversation should start from an agreement that human-generated content is the intended target for rights under Copyright.","Question: Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?TWUC is concerned that any Canadian test for infringement is inadequate without complete transparency in the TDM or AI process. TDM and AI developers must be subject to transparency requirements, and providers must be required to keep comprehensive records of inputs and outputs for any rightsholder or court to have a reasonable chance of determining infringement.Without transparency requirements and discoverable source records, original creators are disadvantaged in protecting and exploiting their rights. One can anticipate the creation of a book series that is radically similar to a human-created series, and that then competes for market share without ever revealing that it is explicitly derivative from the human work. Under copyright as humans have designed it, that scenario is an actionable infringement, but if the infringing input cannot be proven the human rightsholder is unfairly disadvantaged.Question: What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?Lack of transparency. Lack of record-keeping.Question: When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?TWUC cannot comment on other business practices, but we are recommending that all authors insist on AI-specific rights definition and reservation in author contracts and agreements.Question: Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?TWUC believes infringement in AI process would take many forms throughout both input and output stages. We believe rightsholders should be able to seek joint and several liability between all actors in the AI process, from LLM creator, the AI platform, the application provider, and end user of AI generated content. This scenario should be no different than the various liabilities at any stage of any other instance of copyright infringement.Question: Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?As above, Canada should put in the work to develop our own strong policy. The UK example of granting copyright protection to computer-generated works should not be followed. Ongoing conversations in the US and UK around privileging human creation are instructive but only a starting point, and suffer from having to be reactive against a starting point at which AI-generated content may be considered equal to human-made content.  TWUC believes this conversation should start from an agreement that human-generated content is the intended target for rights under Copyright.","New Exceptions would Damage Existing and Emergent MarketsThe Writers’ Union of Canada (TWUC) believes that creative content uses required by AI must be negotiated within a market for licensing rather than through a damaging new exception (or exceptions) to copyright protection. To be clear, TDM activities involving copyright works infringe the rights of copyright-holders under the Copyright Act unless they are specifically permitted by the rightsholder. Any call for a new exception for TDM and AI activities is in fact a request to excuse infringements that have already happened and continue to happen in TDM and AI training.TWUC is concerned that with each new technologically driven “use” of creative content comes a call for a new exception to the exclusive rights of those who create that content. This exception-focus throws the traditional purpose of copyright completely out of balance and privileges the desires of industrial users over the rights of creators. The end-result is what has been described as a Copyright Act “like a pasta strainer”; legislation so full of exceptions and loopholes that there remains simply no motivation on the part of users to seek permission or pay for the content they use.The reflex to create ever greater exceptions is a market destroyer, as has been amply proven over the last decade by Canada’s ill-advised adoption of education as a fair dealing category. That change to the Act has done nothing to provide students or their instructors with more affordable access, but it has transferred hundreds of millions of dollars of earned income away from the cultural sector.The content uses required by developers of artificial intelligence must be negotiated in the context of a respectful market for licensing. Though they often hide their motivation behind claims of serving the public interest, these are enormously powerful and wealthy corporate entities primarily driven by a profit motive. They can and should be expected to operate in a licensing environment.Licensing is not a barrier to innovation. Innovation does not mean free riding on the work of others, nor should it; yet it would under new exception. Licensing preserves the integrity of copyright by giving creators an element of control over when and how their works are used. Licensing also provides legal certainty to good faith users, and keeps disagreements at the bargaining table where they belong, and not in court."
The Canadian Federation of Library Associations,Association,"Libraries, archives and museums (LAMs) support AI research in the development of training datasets for use in AI models, particularly those used to train language models. Libraries provide access to large corpora of text and facilitate the licensing of content for AI purposes. Canadian university libraries informally report that researchers are stymied by scholarly publishers’ poor tools and high licensing costs for AI research. These tools are expensive, proprietary, and lack the functionality researchers need. Licensing costs for TDM activities are now a revenue stream for large multinational publishers, requiring libraries to pay multiple times for use, albeit different uses, of the same content. Such actions exemplify the drive to commodify all uses and thereby shrink the commons, threatening the public good and upsetting the Copyright Act’s balance between users and rightsholders.Some publishers block the non-consumptive use of published works for AI training, while at the same time collecting data and usage patterns of their paying customers to develop AI systems for further commercial purposes (Yoose & Shockey, 2023), threatening privacy and equity standards. Researchers often need access to a wide variety of data sources in order to protect against bias so high costs and extra licenses needed for TDM access can inhibit research.Libraries are centres of copyright expertise within many organizations, and are called upon by researchers to provide assistance in understanding the copyright implications of an AI research project. Researchers and librarians want to ensure the responsible development of AI and this includes ensuring that copyright is considered and respected. Most potential training datasets are not neatly packaged up, analyzed for copyright issues, and made available under a legally vetted licence. Instead, most training datasets are either vast in size, custom built for training a specific model, or for transfer learning. (Transfer learning is common in LAMs and occurs when researchers use an already trained model and then introduce a small new dataset in order to refine the model so that it better accomplishes a specific task.) Consequently, the use of most training datasets requires a fair dealing assessment in order to mitigate the risk of infringement. Librarians provide copyright guidance to researchers on their proposed use of training datasets, and their use of generative AI systems to create new works. This guidance is needed as the current formulations of sections 29 and 30.71 of the Copyright Act lack clarity for a researcher to know if the training of AI models with their proposed dataset is copyright infringing. Clarity through a specific exception would assist researchers in their AI projects as well as libraries in providing copyright guidance.In libraries and educational institutions, human input is significant in the development of AI models and datasets. Many developers practice human centred explainable AI, centring the human in AI development, letting us understand and contest generative AI outputs and the decisions underlying those outputs (Ehsan et al., 2023). Thus, to mitigate bias in generative AI models, we need diverse and inclusive datasets. Market solutions providing datasets that are curated and licensed by rights owners is insufficient and public domain materials and openly licensed materials lack sufficient diversity for bias-reduced training of AI models. Thus AI models must be trained on all kinds of works, including unlicensed copyrighted works.Technological neutrality helps navigate the copyright implications of using datasets containing copyrighted works to train generative AI models. Both the Summary to the Copyright Modernization Act and Supreme Court jurisprudence reminds us of the importance of technological neutrality in preserving the balance between authors and users in the digital environment (Entertainment Software Association v. Society of Composers, Authors and Music Publishers of Canada, 2012, paras 7-8). Technological neutrality implies that Canada’s core copyright understandings must be consistently applied “in a manner that appropriately balances the rights and interests at stake – maintaining in the face of technical change, the steady pursuit of copyright’s policy goals” (Craig, 2017, p. 612).Generative AI is an evolving technology which enables the analysis and production of information at a speed and scale impossible for human beings. Such technology disrupts our current copyright framework and raises questions about how, or if, this technology implicates the exclusive rights of copyright owners. However, using the lens of technological neutrality allows for copyright to adapt to new disruptive technologies and lets us “maintain normative vigilance as conditions change” (Craig, 2017, p. 617) rather than constantly extending copyright owners’ exclusive rights when the activities of new technologies do not actually engage the copyright owner’s legitimate interests. A work that is copied to be reduced to a collection of discrete elements, or underlying facts and ideas, for training an AI model is not copied for human enjoyment and is not engaging with the author’s interests nor with an incentive to create. A technologically neutral functional equivalence approach tells us that copies made for training AI models do not implicate exclusive rights. To argue otherwise risks entertaining the concept that the acts of reading and memorization of works engages exclusive rights in an infringing way.There is concern in the research community about training data and mitigating the risk of copyright infringement, but also about ensuring transparency and non-bias in training data. Many of these same researchers are concerned about the impact of the generated products on rightholders and are working on solutions to attribute, or link, training data to the generated works to provide greater transparency to the user. To do this effectively will require that training datasets properly identify the source of each discrete element of content in the dataset.Canadian LAMs use generative AI tools in multiple ways. For example, university libraries and archives are using computer vision AI and generative AI tools to create extensive metadata for existing analogue image collections. LAMs also use generative AI models to create basic metadata for each document in large scale digitization projects.Generative AI holds out great promise to enable libraries and archives to provide new access points and greater descriptive metadata to their collections than is currently possible. Generative AI transcription tools, such as Whisper, when trained with specific datasets incorporating content from the collections of libraries or archives, extracts information from audio files (e.g. oral histories and interviews) about the subject matter and the people involved. For example, these tools can extract the titles of all the poems recited and the types of questions asked by the audience in a poetry reading recording; this type of description is too labourious and time consuming without the aid of AI.Film and media archives use generative AI to move beyond simple descriptions and allow researchers to engage with film in ways we never did in the past, and assist with a wide range of accessibility needs (Mason, 2023). These endeavours are too time consuming for humans to carry out, but generative AI makes it feasible for libraries and archives to provide rich metadata and vastly increased discoverability and access to collections. When utilizing generative AI tools for enriching descriptions and access, the original works are usually in analogue format. Therefore these works need to be converted – copied - into a digital format so that they can separately be ingested into the AI system for individual analysis. These copies are not necessarily for TDM purposes or for dataset training purposes, nor are they being made under the preservation and obsolete format provisions of the Copyright Act. For libraries and archives to use generative AI tools to enhance discoverability and access, they must be confident that the copies they make to utilize the promise of generative AI are not considered compensable or infringing.Recommendations:1. Provide clarity around training dataset content by encouraging training datasets to have sufficient metadata such that each content element is identifiable.2. Ensure that any Copyright Act exception for the creation of non-consumptive copies for the purpose of informational analysis is broad enough to allow LAMs and other users to make non-consumptive copies of works. This would include the ability to circumvent a TPM to make such copies, or for purposes of utilizing technological tools such as generative AI to create metadata and enable superior discovery of those works.ReferencesYoose, B., & Shockey, N. (2023). Navigating Risk in Vendor Data Privacy Practices: An Analysis of Elsevier's ScienceDirect (Version v1). SPARC. https://doi.org/10.5281/zenodo.10078610Ehsan, U., Wintersberger, P., Watkins, E.A., Manger, C., Ramos, G., Weisz, J.D., Daum, H., Reiner, A., Riedl, M.O. (2023). Human-centered explainable AI (HCXAI): Coming of age. Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems. https://doi-org/10.1145/3544549.3573832Entertainment Software Association v. Society of Composers, Authors and Music Publishers of Canada. 2012 SCC 34. https://scc-csc.lexum.com/scc-csc/scc-csc/en/item/9994/index.doCraig, C. J. (2017). Technological neutrality: Recalibrating copyright in the Information Age. Osgoode Legal Studies Research Paper Series, 186. http://digitalcommons.osgoode.yorku.ca/olsrps/186Mason, I. (2023, November 15-17). Organizing within LAMs to address AI [Conference Presentation]. AI4LAMs Conference, Vancouver, BC, Canada.","Text and data mining (TDM) involves the automated identification of patterns within vast datasets, playing a crucial role in the advancement of artificial intelligence (AI). TDM entails creating non-consumptive duplicates (copies that are utilized for purposes other than the works' original objective (eg. reading)) of materials, some of which may be subject to copyright, but are used for technological purposes such as web caching or data processing purposes, like TDM. The legal status of TDM lacks clarity, and the absence of a specific TDM exception in the Canadian Copyright Act hinders researchers' efforts and impedes progress by requiring extensive copyright analysis to ensure compliance.The comments below build upon our community’s previous submissions and statements, which offer additional examples illustrating the crucial role that libraries play in this domain(CFLA, 2023; CFLA, 2018; Portage, 2018).Many of the questions that TDM analysis pose are central to larger issues that libraries are struggling with as our collective works move from traditional formats like print where we can rely on copyright laws and exceptions, to digital access where fundamental user rights are eroded under licensing terms and weakened by technological protection measures (TPM). The suggestions and remarks below are embedded into the wider framework of safeguarding the overarching goals of promoting fair access to knowledge and information for the 'public good' (Liber, 2020; IFLA, 2020). These goals are directly impacted by any alterations Canada may make to its copyright legislation to responsibly and equitably address technological advancements such as Generative AI that use TDM.It is crucial to recognize that generative AI and TDM analysis are distinct tools. TDM is an analytical tool which involves the automated identification of patterns from extensive datasets. Certain TDM applications involve a large corpus of textual data. It is important to articulate that the library community support for TDM is based upon applications of this technology that do not attempt to encroach on the vested copyrights of the original expression of a work, but to facilitate analysis that unearth patterns, information, and correlations, from the facts and ideas behind the works. Librarians and archivists believe this non-expressive/non-consumptive use of a work should be protected in copyright legislation through an exception. Any limitations or regulations applied to TDM will significantly impact the future shape and value of generative AI among other forms of analysis of digital works.As stated in previous submissions (CFLA, 2021), the library community is familiar with the limitations and chilling effects that current copyright legislation imposes. Libraries are finding efficiencies and technologies to keep up with the proliferation of all formats of works (National Lottery Heritage Fund, 2023). However, restrictive licensing, digital locks and TPMs erode well-established user rights and inhibit access. In one example of how such restrictions affect scholarly work, a Canadian-led group of researchers was forced to retract a paper that had been accepted for publication on COVID-19 vaccine hesitancy because, while the law allowed it, the database contract overrode the statutory rights of the researchers; they had not secured a licence to mine a database of news articles used in the study (RetractionWatch, 2021; CFLA, 2023). Libraries acknowledge the need for mechanisms that allow for and incentivize a market for TDM data, but these incentives cannot come at the expense of basic user rights to the original publication or access to the facts and data of the expression. The non-consumptive nature of these analytical uses of works is an important concept to build into any technologically durable copyright policy.As outlined in this Consultation’s Paper, two general directions exist that address TDM within copyright legislation in other jurisdictions. The library community supports the introduction of a specific TDM exception. This approach provides a practical basis for users and a solid framework for libraries to support research and creativity; but we caution against overly restrictive language potentially leading to unexpected obstacles as technology and expression evolve. Many of Canada’s key trading partners already have a specific exception for TDM, including Japan, Singapore, UK, and the EU. The library community supports an exception that applies to both commercial and non-commercial research which includes both the reproduction right and communication right. Japan's 2018 TDM exception, based on Article 30-4 of its Copyright Act, specifies that non-consumptive copies do not infringe the rights of the copyright owner. The Japanese exception permits TDM for both commercial and non-commercial purposes and prohibits rights holders from making TDM reservations(Ueno, 2021). Additionally, it nullifies contractual clauses attempting to restrict TDM.Libraries should be able to override contract restrictions that thwart statutory rights and copyright exceptions so that vendors cannot make TDM reservations and/or fair dealing reservations. Singapore's 2021 TDM exception also allows for commercial and non-commercial TDM, explicitly forbidding contractual overrides. Similar to Singapore’s 2021 Computational Data Analysis amendment, this exception must apply to contracts governed by Canadian law or governed by foreign law “where the choice of foreign law is wholly or mainly to evade any copyright exception”(Kang, 2021).To safeguard the integrity of the balance of user rights a TDM exception needs to be supplemented with illustrative language within the fair dealing framework. Adding the words “such as” to the purposes given in S.29 of our Act will allow users to confidently apply basic user rights across creative expression (CFLA, 2023). For example, the use of illustrative language in the US has established a solid legal basis within their fair use framework for non-consumptive research, such as TDM, on copyrighted materials. Legislation that anticipates fair and diverse access to information requires an approach that does not over-inflate the expressive capabilities of machine generated output or undervalue the importance of access to the widest possible scope of information that will enable unbiased applications of this form of analysis.Contrary to licensing as a viable solution for TDM, libraries argue, as articulated by the International Federation of Library Associations (IFLA), that the right to access content should inherently encompass the right to engage in text and data mining.""[T]he right to read... content should encompass the right to mine. Further, the sheer volume and diversity of information that can be utilized for text and data mining, which extends far beyond already licensed research databases, and which are not viewed in silos, makes a licence-driven solution close to impossible"" (IFLA, 2013).Since research is often conducted by international teams, CFLA recommends the development of an international TDM instrument at WIPO to ensure that cross border research is not hampered by patchworks of national legislative barriers. The vast and diverse range of information available for TDM, extending beyond licensed research databases and not compartmentalized, makes a license-driven solution nearly impractical.Recommendations1. Create a specific exception for TDM. The library community supports the creation of a specific exception that would ""facilitate the use of a work or other subject-matter for the purpose of informational analysis"".2. Further facilitating TDM: prohibit contract override and allow circumvention of TPMs for any non-infringing purpose. CFLA recommends introducing an exception that prevents contracts from overriding copyright exceptions for non-infringing purposes. This provision should apply to all future and pre-existing contracts. 3. Make fair dealing purposes illustrative. CFLA supports recommendations in the 2019 Copyright Review related to the enumerated list of purposes under Section 29 of the Copyright Act. 4. Support the creation of a specific international exception for TDM.ReferencesCARL-ABRC Fair Dealing Comparison Chart (2018). https://www.carl-abrc.ca/wp-content/uploads/2018/07/Fair-dealing-comparison-chart.pdfCFLA-FCAB Brief to the Government of Canada Consultation on a Modern Framework for AI and the IoT (2021). https://cfla-fcab.ca/wp-content/uploads/2022/01/CFLA-CARL-Brief-Artificial-Intelligence-and-the-Internet-of-Things.pdfCFLA-FCAB Statement: Copyright and Text and Data Mining (TDM) Research (2023). https://cfla-fcab.ca/wp-content/uploads/2023/07/CFLA_FCAB_Statement-on-Text-and-Data-Mining-Research-1.docx.pdfIFLA. IFLA Statement on Libraries and Artificial Intelligence (2020). https://www.ifla.org/publications/ifla-statement-on-libraries-and-artificial-intelligence/IFLA. IFLA Statement on Text and Data Mining. https://www.ifla.org/publications/ifla-statement-on-text-and-data-mining-2013/Kang, A. (2021). Coming Up in Singapore. https://www.lexology.com/library/detail.aspx?g=1ce9c997-22a1-4953-bd0b-68a95d31bc89Liber. (2020). Text and Data Mining. https://libereurope.eu/wp-content/uploads/2020/11/TDM-Copyright-Exception.pdfNational Lottery Heritage Fund. Artificial Intelligence. https://www.heritagefund.org.uk/about/insight/research/artificial-intelligence-digital-heritage-leadPortage. (2018). Brief to INDU Committee on TDM. https://www.ourcommons.ca/Content/Committee/421/INDU/Brief/BR10245456/br-external/PortageNetwork-e.pdfRetractionWatch. (2021, July 30). A very unfortunate event. https://retractionwatch.com/2021/07/30/a-very-unfortunate-event-paper-on-covid-19-vaccine-hesitancy-retracted/Ueno, T. (2021). The Flexible Copyright Exception for ‘Non-Enjoyment’ Purposes. GRUR International, 70(2), 145–152. https://doi.org/10.1093/grurint/ikaa184","The current Copyright Act has achieved a certain balance that would be disrupted by including AI outputs (CFLA, 2023). The current Copyright Act has achieved a certain balance that would be disrupted by including AI outputs. The Copyright Act safeguards works crafted by human authors, including the underlying computer programs of AI. The development and adoption of AI technologies is not inhibited by the current lack of copyright protection of AI-generated works. However, the lack of a policy framework for generative AI is having an impact on creators, and could be addressed in a number of ways outside of copyright.In Canada, copyright serves to protect the expression of human creativity, encompassing both skill and judgment. Outputs from mechanical and routine processes do not meet the originality standard set by the unanimous CCH decision of the Supreme Court of Canada (CCH Canadian Ltd. v Law Society of Upper Canada, 2004). Without expressive agency and intellectual effort, the outputs of AI processes should not be accorded similar copyright protection as works by human creators. Carys Craig underscores that ""authorship involves expressive agency, a quality inherently lacking in AI (Craig, 2021)."" Granting machines the status of rights holders is contrary to the current provisions in the Copyright Act.The outputs of AI processes without significant human intervention represent mechanical exercises devoid of skill and judgment, contrasting with the exercise of skill and judgment in developing an algorithm. Consequently, a computer program is protected by the Copyright Act. Unlike human authors, AI processes do not rely on copyright incentives to produce new works (Gervais, 2020). Expanding protection of intellectual property rights to outputs generated by AI machines could upset the balance of IP protection and discourage other stakeholders.AI processes possess the ability to generate works more rapidly and systematically than human authors. The substantial output facilitated by AI has the capacity to displace human creativity and introduce economic disruptions, disadvantageous to human authors while favoring the swift and serendipitous outputs of machines. One of the primary purposes of copyright is to strike a balance between the rights of authors and the broader public interest, particularly in education, research, and access to information (WIPO, 1996). The extensive output enabled by AI has the potential to disrupt the economy by placing human authors at a disadvantage. If subjected to a comprehensive spectrum of copyright protections, this volume-driven ""autoship"" could marginalize human authors' outputs and undermine society's right to access facts and information that would otherwise remain in the public domain. Giving the full duration of copyright protection to AI-generated works could result in copyright overreach on a massive scale, allowing some AI companies the potential ability to crowd out human creators in such areas as music (Obeebo Inc., 2019).On the matter of authorship, CFLA currently advocates that outputs of AI processes remain unenclosed and open to the public. As cautioned by Craig and others, extending full copyright protection to AI outputs poses a threat to the equilibrium of copyright and challenges the value Canada places on human expression (Craig, 2021; Copyright Review Board, United States Copyright Office, 2022.)The Copyright Act should remain as is with regards to human authorship. Granting copyright protection to artificial intelligence (AI) outputs could disrupt the intricate and nuanced equilibrium established in the Copyright Act. The Act currently safeguards works crafted by human authors, encompassing the computer programs that form the foundation of AI.In circumstances where sufficient human expressive agency is added to an AI-generated work (e.g. the output of a generative AI process has been substantially re-edited in Photoshop), as the U.S Copyright Office notes works could be afforded copyright protection under certain circumstances (United States Copyright Office, March 2023). The granting of any such protection would be judged on a case-by-case basis, and copyright ownership claims could be based on documentation of the exercise of human skill and judgment dedicated to the revision of the AI generated work.Possible ways to make clear the origins of AI-generated works include the addition of metadata that identifies the work as AI-generated. For example, the private company Stability AI is currently working on a tool that will tag image content generated with their tool with metadata that discloses the AI origin of the work, which could be protective both to distinguish AI generated work from human expressive content and also protect against “deep fakes (Stability AI, 2023).” If AI generated works are marked in some way it will be easier to trace the public domain copyright status of AI outputs, to distinguish them from works that have copyright protection.The Canadian Intellectual Property Office (CIPO) should refrain from granting copyright registration to AI created works, and refrain from acknowledging AI machines as co-authors or single authors of works. CIPO should be guided by the work done by the Copyright Office in the United States, which produced “Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence in March 2023 (United States Copyright Office, 2023).” This document makes it clear that human authorship is necessary for copyright registration and protection, unless significant human input is made to the resulting output.AI Authorship Recommendations1. Artificial intelligence authored works should not be protected by copyright.2. The Canadian Intellectual Property Office (CIPO) should refrain from granting copyright registration to AI created works, and refrain from acknowledging AI machines as co-authors or single authors of works without the applicant showing significant human input has been made to the outputs.3. While CFLA recognizes that generative AI can be disruptive to creators, the issue of possible compensation for creators of material used to train AI machines should be separate from the Copyright Act.ReferencesCCH Canadian Ltd. v Law Society of Upper Canada, 2004 SCC 13, [2004] 1 SCR 339.CFLA Copyright Committee. (2023). CFLA Statement: AI and Copyright and its application in Cultural Heritage Institutions. https://cfla-fcab.ca/wp-content/uploads/2023/07/CFLA-FCAB_Statement_on_AI__Authorship-1.docx.pdfCraig, C. J. (2021). AI and Copyright., in Florian Martin-Bariteau & Teresa Scassa, eds., Artificial Intelligence and the Law in Canada. Toronto: LexisNexis Canada.Copyright Review Board, United States Copyright Office. (2022, February 14). Second Request for Reconsideration for Refusal to Register A Recent Entrance to Paradise. (Correspondence ID 1-3ZPC6C3; SR # 1-7100387071).” https://www.copyright.gov/rulings-filings/review-board/docs/a-recent-entrance-to-paradise.pdfGervais, D.(2020). The Machine as Author. Iowa Law Review. 105 (2062), 2053–2106.Obeebo Inc. (2019). Comments on Intellectual Property Protection for Artificial Intelligence Innovation., submitted to USPTO Request for Comments on Intellectual Property Protection for Artificial Intelligence Innovation. https://www.uspto.gov/sites/default/files/documents/Obeebo-Inc_RFC-84-FR-58141.pdfStability AI. (2023). Comment from Stability AI. U.S. Copyright Office.https://www.regulations.gov/comment/COLC-2023-0006-8664U.S Copyright Office. (2023, March 16). Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence. Federal Register, 16191-16192https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence World Intellectual Property Organization. (1996) WIPO Copyright Treaty. Geneva.","CFLA’s posits that non-consumptive copies of works used to train AI machines are allowable uses under fair dealing. Thus, on the matter of infringement in training data also see our Text and Data Mining recommendations regarding a TDM exception, contract override provisions and adding illustrative purposes to fair dealing.AI introduces a host of opportunities for misuse and exploitation of Ai's power to pursue illegal endeavours such as privacy intrusions, large scale copyright infringement, illegal collection of data and other actions. These issues are significant from a public policy perspective, and must be addressed along with the copyright implications of AI.The Copyright Act already provides legal remedies for copyright infringement in works created through generative AI. If an AI-generated output is determined to be substantially similar to an already existing human created work, it can be subject to a copyright infringement claim which would be decided through the courts. Additional clarification in the Copyright Act is not needed. The question of who would be considered liable (e.g. those providing access to the generative AI product or service, the programmer, or the end user) exists on a continuum and needs to be evaluated by the courts. Generative AI outputs should not have copyright protection and should remain in the public domain. Courts must also protect against copyright misuse (Twigg, 2012), so rights holders seeking protection in areas such as style, ideas, facts and data do not overreach the statutory limits of copyright and encroach on the public domain.As derivative works created by AI could be influenced by a number of factors, including a dearth of training data, infringement by users of AI services in many circumstances may be unintentional. Also, some generative AI services such as ChatGPT disclaim responsibility for similarity to content that is produced by their tools, and thus do not guarantee that similar material will not be created for different users of their service (OpenAI, 2023). Incidental copyright infringement might also be recognized as a possible defence when it comes to accidental infringement in AI-generated works. For example, many AI generated artwork outputs are somewhat random, and keywords used can only guide outputs. In Section 30.7 of the Copyright Act, the “incidental inclusion” provision states: “It is not an infringement of copyright to incidentally and not deliberately: (a) include a work or other subject-matter in another work or other subject-matter; or (b) do any act in relation to a work or other subject-matter that is incidentally and not deliberately included in another work or other subject-matter (RSC,1985, c. C-42).”Libraries would like to see the ongoing development and use of generative AI centring transparency in how AI models are trained, algorithms are used, and in the design and intentions behind AI tools. Transparency is essential to protect and inform users about how generative AI tools make decisions, especially when it comes to certain areas such as healthcare. This transparency goes far beyond creator and copyright issues in terms of impact on Canadians.A lack of transparency regarding training data is an obstacle to determining if a non-consumptive copy of a specific work was used in the AI-training process.Using metadata tags to track training material could help remedy this situation. AI developers should keep records of where training data came from, and be required to disclose training data summaries in response to claims of infringement. Infringement claims should be based on the similarity of AI-created outputs to training materials that have been ingested, not based merely on non-consumptive copying of content, and infringement should be decided in a court of law. However, transparency requirements need to remain flexible, not be retroactive, and allow sufficient time for AI developers to plan and implement.Some generative AI companies that used creative copyright-protected works to train their machines, such as Stability AI, have taken steps to create tools allowing for creators to opt-out of the inclusion of their work in the companies’ models going forward (Heikkilä, 2022). The ability to opt-out of training data should remain a private ordering and not be legislated. Legislating TDM to allow opt-outs will have significant unintended consequences by limiting the potential sources of data on which AI tools can be trained, thus contributing to existing issues of bias and inequality in AI-generated outputs as well as having serious long term effects on the future reliability of AI machines in certain applications such as health care, autonomous vehicles, etc (Craig, 2021, p.3; Creative Commons, 2021, p.6). Copyright infringement liability should be determined in the courts. Liability for copyright infringement regarding outputs could lie with the developer, the AI company, or the user, or lie on a continuum. Additionally, liability when it comes to generative AI goes far beyond copyright when it comes to “high risk” consumer applications such as medical uses or self-driving cars, and the evaluation of whether user error or a defect was present in the design of the AI (Long, 2023).The threat of liability will have an impact on cultural heritage institutions that are mandated to preserve, disseminate, and provide access to knowledge, culture, and history. These public good institutions need clear protection from liability so that they can continue their mission. With so little case law in the area of AI liability many jurisdictions may take a “wait and see approach” before implementing legislation, and Canada may be wise to follow suit (CRS, 2023).The AI Act in the European Union offers guidance. It stipulates that any image, audio, or video content displaying a noticeable similarity to authentic or truthful content (a ‘deep fake’) must be noted as having been generated through automated means unless it is for some allowable purpose (European Commission, 2021). It may be useful to have identification mechanisms such as metadata for AI generated creative content in order to identify outputs created via generative AI and to distinguish them from copyrighted works, as well as having the ability to identify “deep fakes” (Barney & Wigmore, 2023). As mentioned in the Text and Data Mining section of our response, a number of Canada’s key trading partners have a specific TDM exception, including Japan, Singapore, UK, and EU. The library community supports an exception that applies to commercial and non-commercial research, and includes the reproduction right and communication right such as Japan's 2018 TDM exception specifying that non-consumptive copies do not infringe the rights of the copyright owner (Ueno, 2021). The Japanese exception permits TDM for commercial and non-commercial purposes, prohibits rights holders from making TDM reservations and nullifies contractual clauses restricting TDM (Ueno, 2021). Singapore's 2021 TDM exception also allows for commercial and non-commercial TDM and forbids contractual overrides (Kang & Oh, 2021).Recommendations:1. Please refer to our TDM section.2. A mechanism for judging copyright infringement in generative AI outputs already exists and thus infringement should be determined in the courts.3. Liability regarding possibly infringing AI outputs may reside with the developer, the AI company, or the user, or lie on a continuum.4. There needs to be a consideration of incidental inclusion when it comes to generative AI outputs.5. With so little case law in the area of AI liability many jurisdictions may take a “wait and see approach” before implementing legislation, and Canada may be wise to follow suit.ReferencesBarney, N., & Wigmore, I. (2023, March 21). What is Deepfake AI? https://www.techtarget.com/whatis/definition/deepfakeCRS. (2023, September 29). Generative Artificial Intelligence and Copyright Law. (Legal Sidebar LSB10922) https://crsreports.congress.gov/product/pdf/LSB/LSB10922Copyright Act, RSC (1985, c. C-42). https://laws-lois.justice.gc.ca/eng/acts/C-42/Craig, C. (2021). Joint Submission of IP Scholars, Re. Consultation on a Modern Copyright Framework for Artificial Intelligence and the Internet of Things. https://digitalcommons.osgoode.yorku.ca/reports/226:Creative Commons (2021). Submission to Government of Canada Consultation on a Modern Copyright Framework for AI and the IoT. https://wiki.creativecommons.org/images/f/f6/Creative_Commons_submission_Canada_consultation_AI_and_the_internet_of_things.pdf European Commission (2021, April 4). Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts (COM/2021/206 final). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:52021PC0206Heikkilä, M. (2022, December 16). Artists can now opt out of the next version of Stable Diffusion. MIT Technology Review. https://www.technologyreview.com/2022/12/16/1065247/artists-can-now-opt-out-of-the-next-version-of-stable-diffusion/Kang, A. & Oh, P. (2021, September 20). Coming Up in Singapore. https://www.lexology.com/library/detail.aspx?g=1ce9c997-22a1-4953-bd0b-68a95d31bc89Long, R.E. (2023, March 17). Artificial Intelligence Liability. Center for Internet and Society. https://cyberlaw.stanford.edu/blog/2023/03/artificial-intelligence-liability-rules-are-changing-1OpenAI terms of use (2023, November 14). https://openai.com/policies/terms-of-useTwigg, M. (2012). Copyright Misuse: Protecting Copyright in Canada from Overreach and Abuse. Dalhousie Journal of Legal Studies, 21(1). https://digitalcommons.schulichlaw.dal.ca/djls/vol21/iss1/6/Ueno, T. (2021). Flexible Copyright Exception for ‘Non-Enjoyment’ Purposes. GRUR International, 70 (2). https://doi.org/10.1093/grurint/ikaa184","Copyright law should not be utilized as a tool to tackle the broader societal challenges that may result from the effects of generative AI on society. Nor should AI innovation be constrained in Canada by laws that are inflexible and have fewer exceptions than other competing jurisdictions, such as the US, which has an expansive fair use doctrine for AI developers and researchers to rely on.AI possesses the capacity to revolutionize numerous occupations beyond individual creators, and such disruptive innovations have been seen throughout human history such as the printing press, automation in industry, and the digital disruption of the internet, to name a few examples. Addressing the resultant innovative disruption by supporting training for new opportunities in jobs related to AI development or by supporting worker retraining through organizations like community colleges, universities and public libraries, should be approached at an economic and society wide level (Library Copyright Alliance, 2023). As well, the Canadian government should invest in more grants and support for Canadian creative industries and for creators in the long term.As it currently stands there is a huge swath of information that is unavailable to Canadian higher education researchers and smaller independent AI researchers because of technological protection measures and prohibitive licensing fees to access some data sets. This includes licensed library resources that in many cases require additional text and data mining agreements to be able to be used by institutional researchers for TDM purposes. Researchers may need access to many sets of data in order to complete a project, and there is a real risk that these research projects might not be realized. There is a societal risk of a regime of monopolistic access to data, where large AI or data companies are the only ones that can afford to gather, purchase or assume the risk of accessing data sets (Internet Archive, 2023). Democratic access is reduced under licensing regimes. It is in the public interest for Canadian AI researchers to have robust exceptions when it comes to TDM.References:Library Copyright Alliance. (2023, July 10). Library Copyright Alliance Principles for Copyright and Artificial Intelligence. https://www.librarycopyrightalliance.org/wp-content/uploads/2023/06/AI-principles.pdfInternet Archive. (2023, Nov. 1). Internet Archive’s Public Comments in Response to the Copyright Office Study on Artificial Intelligence. Comment from Internet Archive. U.S. Copyright Office. https://www.regulations.gov/comment/COLC-2023-0006-8836"
ACT | The App Association,Association,"Our member companies are small and medium-sized businesses (SMBs) that use GAI to assist technology development and business operations. These companies entrust GAI platform providers to take reasonable steps to avoid possible infringement and other liability for themselves and their platform users. Since SMBs often lack resources to protect themselves, it is important that the GAI platform providers and government entities provide GAI users with guidance and basic resources to operate within the law. We provide further detail in our answers to following questions","1. What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?Due to the potential for generative artificial intelligence (GAI) to train on, and output, data that is covered by intellectual property (IP) protections, ACT | The App Association agrees that GAI platforms and their users require clear policy guidance on how Canada will evaluate liability associated with text and data mining (TDM) to train GAI platforms and with the use of its potentially IP infringing outputs by a platform user.For small business software developers, such as App Association members, GAI platforms are advanced technical tools that are invaluable to their creative and innovative processes that save costs and time by streamlining repeatable tasks and optimizing limited resources. Software developers have been using AI tools that heavily rely on human intervention to deliver a desired output for years, but AI tools are reducing, and are very likely to continue to reduce, the need for human instruction and intervention. For example, software developers use AI to improve the software coding process; support training a new generation of strong software developers; complete repeatable tasks; detect common mistakes, issues, and risks in the software development process that would otherwise require manual interventions; and run quality assurance checks that reduce the chance of human bias and error. GAI tools are different from traditional AI tools in that they have an independent process that mimics cognition to develop new outputs. For software developers, GAI platforms not only seamlessly predict and complete lines of code, but they produce outcomes by training on various resources, including internet archives, data laundering sources, and even platform user inputs.Much like a human brain, AI systems train on data to understand patterns and create rules that help them make decisions. Like a human brain, GAI might output, in part or in whole, an image, writing, wordmark, or other IP protectable work that it was trained on. Where a GAI system does produce an infringing work, App Association members are concerned about the liability of a GAI user that unintentionally incorporates the infringing output in their final product. The law is still developing on this issue, and the outcome of ongoing proceedings in Canada (and in other important jurisdictions) is likely to influence the speed of innovation across sectors increasingly looking to operate as efficiently as possible. For example, if it is revealed that GAI platforms are, in some cases, effectively copy-and-pasting data, the effect can be catastrophic because of the amount of work that has already been conducted using GAI systems.App Association members operate with minimal resources and are most acutely harmed by unpredictable copyright outcomes related to liability. The interdependent relationship between a GAI platform and its users is important, and today GAI platforms are essential for small business technology developers to compete. As this type of relationship grows, clear, reliable, and strong guidance for GAI platforms and its users to advance an understanding of the legal bounds of TDM activity will be imperative to protecting IP, as well as supporting investment and innovation. Since the law for GAI and copyright is still developing, we urge the Government of Canada (GOC) to take a fact-finding role at this time, and to make its findings public to inform the debate about future policy changes needed to address GAI and copyright, should any be needed. Canadian policy changes should be based on well-demonstrated systemic problems (and not edge use cases or hypotheticals that exemplify possible uses and capabilities of AI outside what we presently understand). As Canadian courts examine and define the boundaries of using AI, we urge the GOC to seek industry input on an ongoing basis to inform the development of detailed and guidance, and potential changes in policy, related to copyright and the use of GAI.2. Are TDM activities being conducted in Canada? Why is it the case or not?Yes. In general, researchers and companies have been using TDM practices to analyze large data for years and, when done in good faith, these practices are an economical and efficient way to leverage information. TDM activities related to GAI technology are occurring both in Canada and around the world, and we support GOC evaluating and publicizing its findings as to the extent and nature of TDM activities it is observing in Canada to inform the public debate.3. Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?Currently, there is no standard licensing practice for TDM activities as related to AI, and specifically, GAI. Yet, IP rights holders have certain tools at their disposal to protect their public-facing IP-protected works, including ones that themselves use AI. For example, rights holders may deploy exclusion protocols (ex. robots.txt) that notify search engine crawlers and miners that they are prohibited from accessing certain data.4. What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?TDM licenses exist as written agreements between private parties or as embedded codes in a website, digital work, or digital representation of a work. In practice, there is no standard TDM license or common practice. GOC should evaluate the ecosystem and, based on systemic issues and ambiguities identified, develop appropriate guidance to ensure that copyright licenses for TDM activities do not strip the ability for those activities to benefit the public good.5. If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?While it is imperative that copyrighted works are strongly protected under Canadian copyright law, it is equally important that innovation and creativity is not stunted by restrictive laws that curtail the benefits of essential and advanced technological tools, including AI tools. TDM activities are used to research, inform, educate, and, as a result, expand the ability of stakeholders to grow critical and new markets. Therefore, GOC should ensure that a “fair dealings” analysis is applied to TDM activities on a case-by-case basis. With the advent of GAI, courts have yet to carve out and define unique nuances of GAI platforms and their TDM activities. Other long-standing industries have been using TDM tools in order to advance, discover, and build upon existing works. GOC should not alter existing, or create new, copyright laws or regulations unless systemic problems are clearly identified; instead, GOC should look to generate helpful guidance addressing TDM activities and potential copyright infringement in alignment with relevant Canadian court decisions.6. Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?Since AI systems may store mined content in their internal database, it is possible to require their developers or owners to keep records of content that is copyright protected. However, disclosure requirements may be taxing dependent on the amount of content trained on and stored in the AI system’s internal database. We urge GOC to hold off on creating strict disclosure requirements for AI systems at this time; instead, GOC should partner with the private sector to encourage that AI systems should take reasonable steps to ensure that they are not infringing upon copyright protected content.If an AI provider reasonably knows that copyrighted content was infringed by the AI or its user, the provider should take reasonable steps to remedy the situation, and such reasonable steps could be outlined in public guidance laid out by GOC. The App Association commits to collaborating with GOC to develop and socialize copyright and AI guidance for AI providers and its users.7. What level of remuneration would be appropriate for the use of a given work in TDM activities?N/A8. Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?Some countries have rigid TDM restrictions that are antithetical to Canadian law, many of which create unnecessary hurdles to innovation that are not in the public interest. We urge GOC to rely on its own legal regime and the opinions of its stakeholders to determine proper approaches to TDM activities, and to take action to address demonstrated harms/problems for the Canadian economy and copyright system.","1. Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?While Canadian copyright law does not explicitly state that AI-assisted and AI-generated works require human intervention to be copyrightable, courts have interpreted copyright “authorship” to require a natural person exercising skills and judgement to create the work. This understanding is consistent with significant jurisdictions, including the United States, EU, and UK. While these jurisdictions specifically reject works that are wholly constructed by AI, Canadian courts have not made this distinction. In fact, the Canadian Intellectual Property Office (CIPO) has accepted AI as a co-author to an artistic work in at least one registration. “SURYAST” (Artistic) Ankit Sahni, Can 1188619 (1 December 2021) registered. While CIPO registrations are not precedential due to a lack of substantive review, this system has, at times, gone against the understanding that Canadian copyright protection should only be awarded to natural persons. GOC should work to provide stakeholders with stronger guidance on elements of copyright protection, including authorship.2. Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?GOC should provide stakeholders with clear guidance on what works can be registered in compliance with understandings from Canadian jurisprudence. Currently, the CIPO has accepted at least one registration for which AI was enlisted as a co-author, while judicial interpretation suggests that only natural persons can be authors of a copyrighted work. GOC is strongly advised to provide stakeholders with clarity on this matter unless and until courts state otherwise. 3. Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?We encourage GOC to monitor jurisdictions like the United States, EU, and UK that are currently gathering stakeholder input and considering further guidance for their stakeholders. We note our community’s concerns with the U.S. registration system as it pertains to AI, which is presently unworkable for its stakeholders. As it stands, the U.S. Copyright Office (USCO) requires applicants to disclaim AI-generated content that is more than de minimis. This standard for registration does not consider the various uses of AI across different forms of expression, nor does it ask the more important question of whether and how much human authorship was applied in the development of a work seeking copyright registration. The modified registration requirement has caused the USCO to make a series of misguided judgements on whether a work should be properly registered based on its determination of what constitutes AI-generated content. Based on recent registration decisions, the USCO is unconvinced that an individual prompting GAI to produce an output amounts to human input. This inflexible standard does not account for the technological advancements that have already taken place and will take place in the future nor does it inquire into the narrowness of the prompts and resulting AI-generated outputs. As AI advances to undertake more complex analysis, it will still never fully operate without human intervention.If the CIPO does implement a more substantive review process for copyright registration, we urge the agency to avoid drawing similar rigid conclusions that mischaracterize the role of AI as a creator rather than a tool for creation, which requires human intervention to operate. Under a more substantive review process, the CIPO should consider the amount and level of “human authorship” rather than the amount of content generated by GAI when making registration determinations. We urge the CIPO to avoid broad tests that do not adapt with the onset of advanced and emerging technologies. Human authorship should be the threshold issue when determining copyright registration and should be determined on a case-by-case basis. Canada’s copyright registration system should not disregard the importance of allowing its stakeholders to utilize advanced tools, like GAI, that incent copyrightable intellectual and creative human expressions.","1. Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g. AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?Some stakeholders have expressed misguided concerns about the effectiveness of existing copyright laws and tests (i.e., fair dealings). These concerns are born out of growing pains caused by novel copyright disputes surrounding the use and TDM activities of AI. We urge GOC to refrain from modifying current copyright laws or developing new regulation without assessing all stakeholder concerns and allowing courts to make determinations on these issues. And in the interim, we encourage the GOC to empower and require the CIPO to provide stakeholders with a working guidance on copyright implications of AI.2. What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?The current barrier to determining copyright infringement by AI systems is the lack of guidance framework for AI providers and its users. If GOC can provide stakeholders with a clearer understanding on how AI impacts the infringement analysis and what steps are necessary to reasonably mitigate such infringement, it will be in a better position to assess if such infringement has occurred. In its guidance, GOC should consider how the scope of training datasets might affect the infringement analysis. Whether developing copies of training datasets for AI is fair dealings will depend on the type of AI and its training process. GAI is different from its predecessors in the way it gathers, stores, and processes data. However, courts across jurisdictions have provided significant guidance to show that the extraction and use of large datasets, including copyrighted material, for learning purposes leans towards a finding of fair dealings (or an equivalent analysis) in many circumstances. Still, a fact-sensitive component for a fair dealings analysis is imperative to maintaining a just and successful copyright system. We encourage GOC to support a flexible guidance on a fair dealings analysis that makes clarifications to the fair dealings analysis as it relates to TDM activities for AI systems.3. When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?We are not aware of specific strategies that AI providers are utilizing in order to avoid liability for copyright infringement of AI-generated works, who are still unclear about when TDM activities constitute infringement. For this reason, we urge GOC to provide a working guidance on for AI providers and their users to take reasonable steps to mitigate and avoid copyright infringement.4. Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?As discussed above, GOC should consider developing a working guidance addressing AI-generated works and Canadian copyright law. Such an AI guidance should not be final or narrow while stakeholder concerns and court disputes are still being considered.5. Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?Canada should develop its own liability regime based on the concerns of its stakeholders and developing jurisprudence on AI. Other countries are similarly gathering input and considering what actions to take now, which can also be informative to GOC’s efforts. At this time, we would not recommend that GOC consider the liability regime of any one country, even if legal and policy mechanisms are similarly structured to Canada’s copyright framework.",N/A
Association des réalisateurs et réalisatrices du Québec (ARRQ),Association,"Nous sommes l’Association des réalisateurs et réalisatrices du Québec (ARRQ), une association professionnelle qui s’emploie à la défense des intérêts et des droits professionnels des réalisateurs et réalisatrices qui oeuvrent principalement en français et en toute autre langue que l’anglais notamment dans le secteur du cinéma, de la télévision, du web, de l’animation et de la publicité, quant à leurs conditions de création entre autre par le biais de la négociation d’ententes collectives.Nous soutenons également les principes évoqués pas la CDEC dans son mémoire, lesquels visent à préserver la créativité humaine. Ces mêmes principes guident nos réponses à ce questionnaire.Notre association voit le potentiel de l’IA à titre d’outil  : plusieurs de nos membres s’en servent d’ailleurs comme source de recherche ou de point de départ de leurs processus créatifs. Il est néanmoins essentiel d’encadrer l’utilisation de la technologie, particulièrement dans le contexte de la fouille de textes et de données (« FTD »), puisque le contenu des créateurs est actuellement utilisé à cette fin à leur insu, sans rétribution.","- Une plus grande clarté et transparence permettraient de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les œuvres et autres objets de droit d’auteur sont utilisés, ainsi que les rôles et responsabilités des différentes parties prenantes. Ceci permettrait également de déterminer : (i) dans quel(s) contexte(s) l’analyse informationnelle est autorisée, ou non, par le régime actuel de droit d’auteur canadien et ainsi, (ii) quelles licences et rétributions doivent être versées aux titulaires d’œuvres et d’autres objets de droit d’auteur.- Oui, des activités de FTD sont actuellement menées au Canada, afin d’entraîner des modèles algorithmiques. Les activités de développement et d’entraînement de systèmes d’IA peuvent impliquer la reproduction de contenus protégés par droit d’auteur (œuvres et autres objets de droit d’auteur tels que des prestations), sans que les titulaires de droits y consentent et reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d’y remédier. En outre, il est essentiel que le consentement (de type « opt-in » et non « opt-out ») des titulaires de droits soit obtenu préalablement à toute reproduction de leurs contenus protégés, et qu’une rétribution juste et équitable leur soit versée en contrepartie de cette utilisation. L’obtention de ces consentements devra prendre en compte les particularités de chaque contenu reproduit.- Oui. En outre, il est difficile pour les titulaires de droits d’auteur de déterminer quel contenu est utilisé dans le contexte de la FTD et quelle est l’ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d’imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d’IA.- Diverses licences sont disponibles pour les activités de FTD impliquant l’exercice d’un droit réservé aux titulaires de droit d’auteur, à savoir la reproduction. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d’auteur ou être obtenues par le biais d’une société de gestion collective. Ces licences ne semblent toutefois pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner pour les titulaires de droits d’auteur qui peinent à obtenir une juste compensation pour l’utilisation de leurs contenus. Afin de remédier à cette problématique, plusieurs mécanismes peuvent être envisagés, tels que l’introduction d’un droit à une rétribution équitable pour la FTD ou un droit à rétribution via un mécanisme semblable à celui de la copie pour usage privé.- Nous ne sommes pas favorables à l’adoption d’une exception générale permettant la FTD, laquelle serait d’ailleurs contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l’ADPIC et l’ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d’auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l’exploitation normale de l’œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur. Ainsi, si jamais le gouvernement décide d’adopter une exception de FTD (ce que nous ne recommandons pas), il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l’exception soit : (i) limitée à des cas spécifiques (par exemple, à des fins de recherche) ; (ii) assujettie à des conditions d’application strictes (par exemple, l’accès à l’œuvre ou objet de droit d’auteur doit être licite) ; et (iii) assortie du versement d’une juste rétribution au bénéfice des titulaires de droits d’auteur, ainsi que d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur. Finalement, cette exception ne devrait pas s’appliquer aux droits moraux, mais uniquement aux droits dits « économiques ».- Oui, nous le recommandons : il s’agit d’une obligation essentielle qui devrait être intégrée dans la Loi sur le droit d’auteur.- Le niveau de rémunération doit être juste et équitable, basé sur les utilisations faites des contenus protégés. Dans tous les cas, la rémunération devrait être arrimée avec les autorisations obtenues et prendre en compte les particularités de chaque contenu reproduit.- Comme exposé plus tôt, il n’est pas recommandé d’introduire une exception de FTD au Canada. Au contraire, il est essentiel de veiller au respect de la Loi sur le droit d’auteur en s’assurant que le consentement des créateurs soit obtenu et qu’une rétribution juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de FTD. Nous recommandons également qu’une obligation de transparence ou de tenue de registres soit imposées aux chercheurs et développeurs de systèmes d’IA générative, dans le contexte de la FTD. Si toutefois le Canada souhaite introduire une exception de FTD, il devra veiller à ce que cette exception respecte les balises internationales, soit d’application limitée et assortie d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur. À cette fin, le gouvernement canadien pourrait examiner la situation prévalant au sein de l’Union européenne, la Suisse et le Royaume-Uni.",,,"La consultation publique est accueillie favorablement par notre association, laquelle voit en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA sur le droit d’auteur. Notre association ne souhaite pas freiner l’avancement de l’IA, mais désire préserver l’équilibre que la Loi sur le droit d’auteur sous-tend, en veillant à préserver la culture canadienne, la créativité humaine, ainsi que les intérêts des titulaires de droits d’auteur. Pour ce faire, nous recommandons que les principes regroupés sous l’acronyme « A.R.T. » (Autorisation, Rétribution et Transparence) guident les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d’auteur qui en découleront."
Association nationale des éditeurs de livres (ANEL),Association,"L’Association nationale des éditeurs de livres (« ANEL ») [https://www.anel.qc.ca] se réjouit de répondre à la consultation d’Innovation, Sciences et Développement économique Canada (« ISDE »), initiée en octobre 2023, sur le droit d’auteur à l’ère de l’intelligence artificielle générative (« Consultation »).L’ANEL regroupe la grande majorité des maisons d’édition de livres francophones au pays. Leur secteur s’appuie sur le droit d’auteur, en particulier sur les droits exclusifs permettant d’autoriser ou d’interdire l’utilisation d’œuvres et d’accorder des licences moyennant rémunération pour leur utilisation.À l’ère de l’intelligence artificielle (IA) générative, il est fondamental pour le Canada de soutenir l’innovation et la créativité humaine, d’encourager l’offre légale et d’améliorer la capacité du secteur du livre à contrôler l’exploitation des œuvres. Tous les acteurs(1) du marché, qu’ils soient de l’éducation ou des technologies, doivent être encouragés à soutenir les intérêts légitimes des créateurs canadiens au bénéfice de l’innovation, du savoir, de l’éducation, du rayonnement, de la diversité et de l’économie du pays.Depuis plus de trente ans, l’ANEL et ses partenaires multiplient avec succès les actions en faveur de l’édition canadienne de livres de langue française. Avec la plus grande fédération d’associations d’éditeurs au monde, l’International Publishers Association (« IPA ») [https://internationalpublishers.org/about/], l’ANEL promeut l’édition mondiale comme vecteur de développement économique, culturel et social en valorisant la liberté de publication, le droit d’auteur, l’alphabétisation, l’éducation, l’accès universel au livre et la diversité culturelle. Au Canada, l’ANEL est membre de la Coalition pour la diversité des expressions culturelles (CDEC) [https://cdec-cdce.org/fr/a-propos/] et, avec l’Union nationale des écrivaines et écrivains (« UNEQ ») [https://www.uneq.qc.ca], elle a créé Copibec [https://www.copibec.ca/fr], la société québécoise de gestion collective des droits de reproduction,  qui offre aux utilisateurs d’œuvres et aux titulaires de droits d’auteur des solutions simples et adaptées à leurs besoins comme des licences d’utilisation, des autorisations à la pièce, la gestion de droit d’auteur et de redevances, une plateforme numérique pour le milieu de l’enseignement ou des services aux élèves ayant des déficiences perceptuelles.Avec Québec Édition, son comité dédié au rayonnement international, l’ANEL et ses partenaires soutiennent activement l’exportation de livres canadiens par la tenue de kiosques collectifs dans des foires et salons internationaux, par l’accueil de cohortes d’éditeurs, de libraires et de journalistes étrangers, et par différents projets soutenant la profession.Concrètement, l’ANEL promeut les œuvres canadiennes dans tous les pays francophones et favorise leur traduction en Allemagne, en Argentine, en Chine, en Égypte, en Espagne, aux États-Unis, au Mexique, en Islande, en Suède, en Serbie et en Turquie, pour ne nommer que ces pays. Dynamique, contemporaine, universelle et variée, l’édition canadienne francophone bénéficie d’un succès hors du commun au Canada comme à l’étranger :Chaque maison d’édition a sa propre stratégie de commercialisation internationale, mais deux grands modèles ressortent : la cession de droits – les droits de commercialisation du livre sont cédés à un éditeur étranger – et la distribution directe qui est en progression. Peu importe le modèle, plus la littérature d’ici se fait connaître à l’international, plus elle séduit les lecteurs, plus elle se fait remarquer par les jurys, plus elle est primée et plus elle se vend sur tous les continents, sans oublier le Canada.À l’occasion de la présente Consultation, nous verrons combien le succès de l’édition canadienne francophone et de toutes langues est voué à l’échec sans le respect des principes fondamentaux du droit d’auteur et des engagements internationaux du Canada en la matière.(1) À l’instar du document et du formulaire d’ISDE auxquelles l’ANEL répond à l’occasion de la présente Consultation, l’utilisation du masculin se veut neutre et inclusive de tous genres.(2) À titre d’illustrations récentes :","Il est essentiel pour le secteur du livre canadien de pouvoir continuer d’accorder – ou de refuser d’accorder – des autorisations et de négocier une rémunération pour l’utilisation d’œuvres protégées, comme « données d’entraînement » pour la fouille de textes et de données (« FTD ») ou pour d’autres utilisations.Le Canada ne doit surtout pas introduire à la Loi sur le droit d’auteur d’exception ou d’exonération permettant de reproduire ou de s’approprier autrement, sans autorisation, les œuvres protégées afin de faciliter l’IA générative, que ce soit sa création, son exploitation ou les produits et services qui en découlent. Au contraire, le Canada doit encourager le marché naissant d’octrois de licence pour activités de fouille de textes et données (FTD) en exigeant des développeurs de systèmes d’IA de tenir des registres et de divulguer les contenus protégés par le droit d’auteur utilisés pour la formation de leurs systèmes.Selon la Convention de Berne [Voir https://www.wipo.int/wipolex/fr/text/283695] liant le Canada, toute adaptation à l’encadrement du droit d’auteur doit avoir pour but premier de permettre aux titulaires de droit de continuer à contrôler l’exploitation de leurs œuvres et non de réduire la portée de leurs droits pour satisfaire d’autres industries.L’ajout d’une exception permettant l’utilisation non autorisée d’œuvres protégées par le droit d’auteur pour former et/ou produire des résultats et d’autres applications d’IA générative serait clairement en contradiction avec le test en trois étapes du paragraphe 9 (2) de cette convention, car elle porterait injustement atteinte aux intérêts légitimes des auteurs et des éditeurs, les empêchant d’exercer leurs droits d’exploitation des œuvres par le biais d’autorisation. Une telle exception permettant la FTD serait non seulement contraire aux engagements du Canada en vertu de la Convention de Berne, mais aussi du paragraphe 10 (2) du Traité de l’OMPI sur le droit d’auteur (WCT) [Voir https://www.wipo.int/wipolex/fr/text/295159], de l’article 13 de l’Accord sur les aspects des droits de propriété intellectuelle qui touchent au commerce (Accord sur les ADPIC) [Voir https://www.wipo.int/wipolex/fr/text/305756] et du paragraphe 20.64 (1) de l’Accord Canada–États-Unis–Mexique (ACEUM) [Voir https://www.international.gc.ca/trade-commerce/trade-agreements-accords-commerciaux/agr-acc/cusma-aceum/text-texte/20.aspx?lang=fra], pour ne nommer que ces textes.La Loi sur le droit d’auteur confère notamment aux titulaires le droit exclusif de reproduire leurs œuvres ou toute partie substantielle de celles-ci, et d’autoriser de tels actes. Lorsque des œuvres protégées par le droit d’auteur sont intégrées dans des systèmes d’IA générative, ces droits sont engagés. La permission de les utiliser est tout aussi importante que la compensation pouvant en découler, en particulier lorsque la production du système d’IA peut concurrencer l’œuvre originale, s’y substituer ou préjudicier le droit moral de l’auteur.C’est au marché du livre et de l’IA de trancher ces questions, et non au gouvernement de le faire.Le document de la présente Consultation évoque la Directive européenne de 2019 exigeant des États membres qu’ils prévoient deux exceptions pour la FTD : l’une pour les institutions de recherche et de patrimoine, et l’autre pour toute autre personne et à toute autre fin dont les titulaires de droits peuvent « se retirer » (opt-out).  Or, toute suggestion canadienne de régime de retrait (opt-out) pour la FTD serait à la fois injuste, controversée et impraticable. L’introduction d’une exception qui donnerait aux titulaires de droits la possibilité de « se retirer » (opt-out) d’une telle exception renverserait le droit d’auteur. Au Canada, le droit d’auteur est un système d’opt-in : aucune formalité n’est requise pour qu’une œuvre bénéficie de sa protection. Exiger des titulaires de droit qu’ils informent les services d’IA qu’ils s’opposent à l’utilisation de leurs œuvres serait une formalité incompatible avec le droit canadien et violerait les obligations internationales du Canada.Dans d’autres juridictions, un régime de licence obligatoire a été suggéré pour la FTD. Or, les licences obligatoires privent les titulaires de droits d’auteur de leurs droits exclusifs d’autoriser ou d’interdire la reproduction de leurs œuvres par des services voulant cannibaliser leur travail au profit d’un contenu substitut qui leur est préjudiciable.Respectueusement, la question de savoir quand et comment les ayants droit devraient être rémunérés lorsqu’ils permettent l’utilisation de leurs œuvres comme inputs de systèmes de formation d’IA générative devrait pas, non plus, relever du gouvernement. La rémunération appropriée pour l’utilisation d’une œuvre donnée doit faire l’objet de négociations entre les titulaires de droits et les plateformes d’IA générative, être déterminée par le marché, la Commission du droit d’auteur ou les tribunaux. S’il peut y avoir des cas où les titulaires de droits conviennent avec un service qu’une compensation n’est pas nécessaire, ce n’est pas au gouvernement de trancher cette question, car il ne ferait qu’entraver les négociations et empêcherait le marché de développer ses propres solutions.Sur le marché, Publishing Perspective publiait récemment un article concernant l’action du New York Times contre OpenAI et Microsoft parallèlement aux actions en justice de l’industrie de l’édition de livres. On y relate que certains éditeurs, comme le Times, intentent des actions en justice, tandis que d’autres négocient une compensation avec OpenAI, Microsoft ou Google. Déjà, des éditeurs comme l’Associated Press et Axel Springer (Politico, Business Insider) ont conclu des accords commerciaux pour concéder sous licence leur contenu à OpenAI. [Voir https://publishingperspectives.com/2024/01/ai-copyright-challenges-now-include-a-new-york-times-lawsuit/] Ce n’est pas au gouvernement d’intervenir dans ces négociations ou ces litiges commerciaux.Le Canada doit encourager la créativité et l’investissement des Canadiens et s’abstenir de les exproprier de leurs droits d’auteurs afin de répondre aux besoins d’entreprises et de leurs activités commerciales. Sa législation sur le droit d’auteur doit permettre aux titulaires de négocier librement les conditions d’utilisation auxquelles ils consentent. Des autorisations notamment pour la reproduction, l’adaptation et la communication au public d’œuvres protégées doivent continuer d’être requises, sans oublier le respect des droits moraux. Si un produit de l’IA plagie une œuvre protégée, ses ayants droit doivent pouvoir continuer d’invoquer des infractions au droit d’auteur.Enfin, nous reviendrons sur la nécessité d’obliger les développeurs de systèmes d’IA à la tenue de registres et à la divulgation de contenus protégés à la rubrique « Violation et responsabilité en matière d’IA », une obligation en phase avec la Convention de Berne selon laquelle toute adaptation à l’encadrement du droit d’auteur doit avoir pour but premier de permettre aux titulaires de droit de continuer à contrôler l’exploitation de leurs œuvres.",,,"Nous avons vu que le secteur du livre insistait sur l’importance de ne pas changer la législation pour permettre à l’industrie de l’IA d’utiliser sans autorisation des œuvres protégées et pour accorder un droit d’auteur aux produits de l’IA ne résultant pas d’apports originaux humains.La législation canadienne sur le droit d’auteur doit plutôt soutenir l’innovation et la créativité humaine en encourageant l’offre légale, l’octroi de licence et en responsabilisant tous les acteurs de son marché, qu’ils soient de l’éducation ou des technologies de l’IA.Il ne faut surtout pas aggraver la situation par l’introduction de nouvelles atténuations et exceptions. Au contraire, le Canada doit réviser la Loi sur le droit d’auteur pour mettre un terme aux interprétations arbitraires du secteur de l’éducation et aux dommages sans précédent qui en découlent pour le secteur du livre, comme énoncé par un autre comité de la Chambre des communes(3)  recommandant qu’auteurs et éditeurs de livres puissent de nouveau recevoir leur juste part de l’utilisation de leurs œuvres publiées dans le secteur de l’éducation.Les auteurs et les éditeurs de livres souffrent toujours, en effet, de changements très controversés apportés à la Loi sur le droit d’auteur en 2012, particulièrement l’introduction d’exceptions ayant eu pour résultat de susciter des débats et de priver injustement les ayants-droits de redevances essentielles. Dans ce dossier, soulignons que la décision de la Cour suprême du Canada dans Université York c. Canadian Copyright Licensing Agency (Access Copyright) [2021] CSC 32 n’a pas clarifié les dispositions législatives en cause : elle a encouragé certains utilisateurs à repousser injustement les limites de celles-ci, faisant perdre aux auteurs et aux éditeurs des revenus légitimes considérables. Ces pertes, chiffrés à plus de 200 M sur dix ans, se poursuivent tant que le gouvernement canadien ne résout pas cette problématique pourtant si simple à régler.À cette fin, il suffit au gouvernement d’adapter la Loi sur le droit d’auteur pour préciser que :En conclusion, les ayants-droits du livre canadien ont urgemment besoin d’un cadre réglementaire protégeant plus adéquatement leur création, leur innovation, leur investissement et leur travail.  Le Canada doit s’empresser d’améliorer la Loi sur le droit d’auteur pour cesser de les priver injustement de revenus légitimes à l’occasion de l’utilisation d’œuvres dans certains établissements d’enseignement.Rappelons que cette priorité est soutenue par les fédérations internationales du livre et par la Coalition pour la diversité des expressions culturelles (« CDEC ») qui réunit, au pays, les principales organisations de professionnels anglophones et francophones du secteur culturel, soit plus de 360 000 créateurs et professionnels et 2 900 entreprises, tous sont outrées que le Canada enfreigne ses obligations internationales en droit d’auteur.À l’occasion de la présente Consultation, rappelons que la première des six priorités urgentes de la CDEC est de modifier les dispositions relatives à l’utilisation équitable dans le contexte de l’éducation afin qu’elles ne s’appliquent que lorsqu’une œuvre n’est pas disponible dans le commerce en vertu d’une licence accordée par le titulaire des droits ou une société de gestion collective. Cet automne, la CDEC énonçait ce qui suit :«  Les membres de la CDEC ont établi un ordre de priorité pour six recommandations qui doivent être prises en compte à l’automne, mais souhaitent également rappeler que six autres recommandations devraient être prises en compte à moyen terme.(…) Le secteur culturel a été bouleversé par l’accès croissant aux contenus culturels par l’Internet au cours des années 2010 puis par la révision de la Loi sur le droit d’auteur en 2012, qui a ajouté plusieurs exceptions qui ne respectent pas les obligations internationales du Canada. Le secteur culturel a été bouleversé par l’accès croissant aux contenus culturels par l’Internet au cours des années 2010 puis par la révision de la Loi sur le droit d’auteur en 2012, qui a ajouté plusieurs exceptions qui ne respectent pas les obligations internationales du Canada.Le marché des droits, qui était déjà bouleversé par le numérique, est en train de s’effondrer.La récente conclusion de la Cour Suprême du Canada dans le litige opposant Access Copyright à l’Université de York porte gravement atteinte à la capacité des créateurs à faire valoir leurs droits et à recevoir une juste rémunération pour l’utilisation de leurs œuvres. Le gouvernement doit modifier la Loi de toute urgence afin de réaffirmer son engagement à assurer une rémunération équitable aux titulaires de droits. Nous estimons qu’aucune consultation n’est nécessaire avant le dépôt d’un projet de loi. Au-delà des emplois et de la contribution de la culture à notre économie, c’est la vitalité du secteur et la diversité des expressions culturelles qui sont en jeu. Pendant ce temps, les entreprises qui donnent accès aux contenus culturels en ligne ont réalisé des profits sans précédent. Elles ont les moyens de mieux rémunérer les titulaires de droits pour la valeur qu’elles tirent des contenus protégés par le droit d’auteur. » (4)Lorsque les dispositions relatives à l’utilisation équitable dans le contexte de l’éducation seront précisées et que d’autres priorités du secteur culturel seront réalisées dans la Loi sur le droit d’auteur, le Canada devra par ailleurs responsabiliser davantage l’industrie de l’intelligence artificielle par des obligations de transparence essentielle au développement d’un écosystème d’IA équitable et sûr. Autrement, le marché des droits va poursuivre sa chute et des modèles d’IA générative vont continuer de se développer de manière opaque, injuste, illégale et au mépris des créateurs, des entrepreneurs, de la culture, de l’innovation, du savoir, de l’éducation, du rayonnement, de la diversité et de l’économie de notre pays.-(3) Rapport du Comité permanent de la science et de la recherche sur le soutien à la commercialisation de la propriété intellectuelle, Novembre 2023, Pages 45 à 47 et Recommandation 10 [Voir : https://www.ourcommons.ca/documentviewer/fr/44-1/SRSR/rapport-7](4) [Voir : https://cdec-cdce.org/fr/publications/recommandations-urgentes-et-a-moyen-terme-de-la-cdec-pour-la-revision-de-la-loi-sur-le-droit-dauteur/]"
Association of Canadian Publishers,Association,"Canadian book publishers that are members of the Association of Canadian Publishers have begun to use AI-assisted tools for proofing text and audio, translation, audiobook narration, and illustration.Proofing tools in particular have localization issues as they do not reflect Canadian orthography or style.It is inevitable that additional tools for processes like sales data analysis and inventory management will be adopted by the sector as they come to market.At least one notable Canadian author has co-authored a book with generative AI: Stephen Marche’s Death of an Author was written with the assistance of ChatGPT, Sundowrite, and Cohere, and has been widely reviewed.There are parties that are publishing large quantities of AI-generated books; however, they are not affiliated with our organization’s members.","What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?Some legal professionals (including some cases seen in other jurisdictions) take the position that copyright does not apply to TDM activities, due to the application of existing exceptions in the copyright act and the nature of the technical processes involved. ACP rejects these interpretations on the basis that the training of generative AI models on works of creative expression is not simply a matter of “data mining.” While data itself is not subject to copyright protection, the expressive qualities of the texts in question are. These expressive aspects are key to the success of any large language model AI and the use of those expressive aspects are an infringement of copyright. Introducing an exception for TDM would not pass the three-step test under the Berne Convention:* A blanket exception for TDM/generative AI training would be the picture of “overly broad” in scope and reach and would not be limited to “certain special cases:” it would enable a wide range of uncompensated uses.* A TDM exception robs rightsholders of a real and potential source of substantive income: publishers are already being approached for TDM licences by the developers of generative AI and there is a developing licensing market for these uses.In undermining creators’ moral rights, and creating a new source of market competition for the sale and licensing of creators’ own works, an exception would do disproportional harm to rightsholders, most of whom are independent working artists and small to medium sized enterprises.* TDM is a process that extracts value from creative works, and in doing so has the potential to undermine the market for the works that are copied and used in the course of this activity. ACP’s position is that copyright is triggered during these processes. The application of copyright will allow:* The continued development and establishment of a functional rights market for TDM activities* The protection of authors’ moral rights to the integrity of their works* The protection of creative livelihoods and the viability of future creative workAre rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?Some rights holders, specifically university and scholarly publishers with large catalogues of valuable works, are being approached for TDM licences. Other than negotiating a fair price in the absence of established precedents, they face no particular challenges in making their works available and licensing their works when appropriate.The Copyright Clearance Center (CCC) in the United States has offered TDM licences for the use of literary and artistic works for several years.Many Scientific, Technical and Medical journal publishers have been offering TDM licences in Canada for a long time. In the absence of a clear copyright regime, smaller rights holders are simply not being approached for licences. This is a decision made by AI operators to avoid licensing.In the case of book publishers, works are being accessed for TDM activities via pirated datasets that are circulating online. Thousands of in-copyright Canadian-authored and Canadian-published books appear in the “Books3” corpus that has been used without permission or compensation by Meta, Bloomberg, and others to train commercial generative AI products. The use of this dataset is already subject to several lawsuits in the USA.In some cases, publishers may not hold TDM rights to begin with, as they were not contemplated when author contracts were signed. This is not an insurmountable challenge, as authors and publishers are able to negotiate contract amendments with authors, and stand ready to offer licensing solutions. The largescale renegotiation of contracts that allowed publishers to issue books in digital format is a precedent for this adaptation.What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?The ACP members who have been approached for TDM licenses are tailoring those agreements to the specific needs of the licensor.Some writers and artists believe that licensing their works to train generative AI systems would be sowing the seeds of their own obsolescence. They do not wish to do it and will not tolerate being compelled to do it. Only a free market that can establish the financial value of a licence will address this concern.  Ultimately, if an author or publisher determines that licensing their works for TDM activities undermines their work or harms the market for their works, they must remain entitled to exercise their exclusive rights to say no.The ACP disagrees with any suggestion that a compulsory collective licensing regime might be appropriate for TDM uses.  The ACP favours a negotiated, non-compulsory licence regime for TDM uses. Canada, like all developed countries, has well-established collective licensing organizations that are able to negotiate, collect, and remit compensation to rights holders at scale as appropriate. In many circumstances, especially when rights holders already hold large volumes of high-value content, it may be preferable for licensing to be negotiated outside of a collective society, and the law should allow for this.If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?No new exceptions for TDM activities are required.  New exceptions that undermine the opportunity to develop a market, or that undermine rights holders’ option to not licence works for development of AI, are unacceptable under the Berne Convention’s three-step test.Such exceptions would devalue writers’ and publishers’ investment in intellectual property. This would be an attack on the livelihoods of authors, publishers, and everyone affiliated with our industry.Systematic unlicensed uses already undermine the rights and interests of authors and publishers, and new legislation or policy should rein in these practices, rather than giving them legitimacy.Unintended consequences of copyright exceptions are inevitable, so legislation must be crafted with care, and reviewed and updated regularly. Despite Canada’s commitment to reviewing the Copyright Act every five years, the recommendations of these reviews have not to date been adopted, with the last major revision to the Act having taken place in 2012.Existing exceptions should be tightened and potentially reworded to clarify that TDM is not allowed under an exception to copyright infringement. The creation of generative AI was not a seriously contemplated use of the temporary reproductions for technological processes exception when it was introduced in 2012. However, this exception, which is necessary to the functioning of many digital goods and services, is now being used to justify the unlicensed training of AI using in-copyright materials.Existing penalties for infringement are insufficient to the challenge of regulating the use of in-copyright material at scale by the world’s largest corporate interests. Legislation should clarify that remedies for infringement of copyright in AI development include measures up to and including deletions or take-downs of AI systems and platforms, as well as damages.Moral rights – the rights of authors to attribution, integrity, and association – must be protected. When an author’s permission is not granted, generative AI has a high risk of undermining these rights due to its ability to create works derivative of, or in the style of, works that have been used in the training process.Legislation should clarify that machine-readable reservations of TDM rights must be respected by AI developers.Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?Disclosure of the use of copyright-protected content is essential to a functioning rights marketplace, and to the enforcement of copyright. Transparency with respect to works used to train or develop AIs is essential to the ability of rights holders to exercise and protect their rights, including the moral right of attribution. It is unacceptable for AI developers to claim that this information is proprietary, while not respecting the rights of the creators and publishers of the works themselves. Government policy should include appropriate record keeping and disclosure provisions.What level of remuneration would be appropriate for the use of a given work in TDM activities?Remuneration must be negotiated between the rightsholder, or an agent acting on their behalf, and the user. It should not be prescribed by the government.Remuneration under a direct licensing model must be set through negotiation between the author, publisher, and licensor.Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?The transparency principles proposed in the European Union AI Act are a good starting point, but are not yet finalized at the time of submission. The European Union AI act proposes that only AI models that are trained in compliance with EU law may operate in the EU. Such a provision is essential to avoid a “race to the bottom” through simply training models in jurisdictions with blanket exceptions, such as Japan and Singapore.","Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?Uncertainty surrounding authorship has not substantially impacted the adoption of the tools currently available for use by book publishers. These tools are generally being used in support of human creativity, not as a replacement for it. In the rare cases where Canadian book publishers are using wholly machine-generated content, they have assumed the risks and enjoyed the benefits of publishing content deemed to be in the public domain.A human creator using generative AI as a tool in creating new work may be considered the author if the act of creation would meet or surpass the originality tests set out by the Supreme Court of Canada in CCH Canadian Ltd. v. Law Society of Upper Canada.Otherwise, ACP believes that works that are purely AI-generated do not attract copyright protection under existing Canadian law. Unless new case law were to contradict this, no legal clarification is necessary on this point. Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?Clarification or modification of copyright ownership and authorship of AI-generated works is not necessary. Should case law develop that undermines the principle of creativity as a uniquely human trait, clarification of these principles would be required, but existing legal precedents and scholarly articles suggest that this is an unlikely outcome.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?The approach adopted by the United States Copyright Office, in which “a work containing AI-generated material will also contain sufficient human authorship to support a copyright claim,” when a human applies their creativity to the manipulation of AI-generated content in such a way that ‘‘the resulting work as a whole constitutes an original work of authorship,’’ is consistent with our position. Additionally, most parties to international copyright treaties reserve copyright protection to human creators. (See https://www.govinfo.gov/content/pkg/FR-2023-03-16/pdf/2023-05321.pdf#page=3 )","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?ACP does not have concerns about existing legal tests at this time, but this is contingent on case law developing in a way that protects creator rights.Our position is simple: infringement through an AI system’s output must be technologically neutral. If a work would be deemed to be infringing if it had been created by a human, it must be deemed to be infringing if it is created by a machine. This principle extends to any derivative work produced by a machine. Large language models easily generate derivative works (adaptations, sequels, translations), each of which are infringements of copyright, and require permission from the original rightsholder. In some cases, they also infringe through direct plagiarism of works used in the training process, though this depends on the nature of the model.What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?Most AI systems developers do not disclose the sources they use to develop their systems. In practice this makes it impossible to determine whether copyright-protected content was accessed when generating infringing outputs. While many developers argue that citation of training sources is impossible, at least one model (Wordtune Spices by AI21 Labs) cites sources alongside its output.The use of pirated resources such as the Books3 corpus by major generative AI developers further complicates this issue. Books that have never legally been made freely available on the internet are included in these compilations.When commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?Many commercial AI providers have offered to “shield” end users from copyright liability by paying their legal fees. This practice sends the wrong message to users and places an extremely high burden on rights holders: to enforce one’s rights, one must be willing to engage in legal action against the world’s largest and wealthiest technology companies.In what may be a strategy to make it harder to be held to account for copyright infringement, most LLM developers have modified their systems so they will no longer respond with specifics when prompted to disclose their sources. This violates authors' moral right of attribution.ACP would prefer these businesses assume the risks and liabilities of their actions by licensing to cover both training and output. Such licences would be a more appropriate risk mitigation strategy and could shield businesses and AI users from liability under certain circumstances.Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Liability under current copyright law should be vested in the owner of the platform that generates infringing work.Terms of use that pass the liability for infringement on to the author of a prompt are a legal fiction, given that only a court of law can assign liability.There is an onus on developers to train and build AI tools that do not infringe copyright. Existing tools like Midjourney and ChatGPT already have robust protections that seek to prevent them from generating inappropriate content; surely such protections can be extended to limiting their ability to generate infringing works.ACP believes that existing legislation that provides legal remedies against pirate websites should apply to AI applications as well.","Canada still has the opportunity to create a regulatory regime for AI that centres and continues to support the value of human creation and sustain our vital cultural industries. It is imperative that the livelihoods of writers and artists, and the ongoing investments of the publishers that bring their works to Canadians, are protected, if not enhanced, by a copyright policy that allows them to share in the economic value that generative AI will inevitably build on the foundation of their work. The sacrifice of this principle in favour of the convenience of AI developers would be devastating for our cultural industries, and will impoverish our culture for the benefit of a handful of corporate interests.Books are among the highest-value types of content for the training of generative AI. They are broad and rich in linguistic expression, and contain both stories and data that have been subject to the highest levels of editorial and scholarly scrutiny. AI models will be better – less biased, more factual, more representative of Canadian culture – if they are trained on Canadian books, but this process must not be done in a way that removes incentives for future human creativity.Canada has long enjoyed a cultural policy framework that has used a variety of tools, from copyright to subsidy, foreign investment regulation, and cultural diplomacy, to encourage the creativity of our citizens and find their work its rightful place on the world stage. This sector must not be placed at risk for the sake of convenience; “go fast and break things” may be an effective way to develop software, but it has no place in the governance of a functioning democracy.Copyright legislation, and AI policy, must always be considered in the context of its broader cultural, social, and economic implications. Artificial intelligence will likely be the greatest disruptor in these fields since the dawn of the internet. It represents a great opportunity, and a great threat. The accelerated pace of change, and the convenience of AI developers, is no excuse to disregard these consequences. Even within the context of a relatively narrow review of copyright policy, all implications should be considered, including ethical questions; cultural sovereignty; impacts on human rights; compatibility with labor laws; economic impacts, including negative impacts and impacts on distributive justice; privacy issues; and the impacts of AI on reliability of information.This submission has been endorsed by Books BC, the Book Publishers Association of Alberta, SaskBooks, the Association of Manitoba Book Publishers, the Ontario Book Publishers Organization, the Association of English-language Publishers of Quebec, the Atlantic Publishers Marketing Association, and the Literary Press Group of Canada."
"Association québécoise de l’industrie du disque, du spectacle et de la vidéo (l’ADISQ)",Association,"Fondée en 1978, l’Association québécoise de l’industrie du disque, du spectacle et de la vidéo (l’ADISQ) représente près de 200 entreprises québécoises indépendantes, œuvrant dans tous les secteurs de la production d’enregistrements sonores, de spectacles et de vidéos, dont des producteurs, des maisons de disques, des gérants d’artistes, des distributeurs des disques, des maisons d’édition, des agences de spectacles, des salles et diffuseurs de spectacles, des agences de promotion et de relations de presse.Notre organisation n’a donc pas pour rôle de recueillir et encoder le contenu protégé par le droit d’auteur dans des ensembles de données d’entraînement ni d’utiliser l’ensemble des données d’entraînement dans le développement des systèmes d’IA.La présente consultation nous invite spécifiquement à nous positionner sur le sujet de l’intelligence artificielle (IA) générative et la question du droit d’auteur. Avant tout, il est important de rappeler que nous composons avec un important manque d’informations sur ces questions. En effet, il existe derrière une majorité des processus liés à l’IA une importante opacité. Toutefois nous pouvons affirmer qu’aujourd’hui, il y a peu ou pas de mesures prises pour atténuer les risques que le contenu généré par l’IA viole les droits d’œuvres protégées par le droit d’auteur. En 2023, chacun.e a pu constater les avancées majeures faites dans le domaine de l’IA générative, développements qui se sont donc notamment appuyés sur une utilisation d’œuvres protégées par le droit d’auteur, et comme nous le verrons, sans autorisation des ayants droit.Au sein de l’industrie musicale, de la création à la consommation de musique en passant par la production et la diffusion, l’intelligence artificielle est présente à différents niveaux. La chercheure Joelle Farchy observe ainsi que  « La musique est l’industrie culturelle où les propositions d’intelligence artificielle sont les plus avancées. Tout au long de la chaîne de valeur, trois applications majeures mobilisent de larges corpus de données qui alimentent des algorithmes : au niveau de la production, afin de connaître le marché pour prédire ou provoquer le succès ; au niveau de la consommation, dans la recommandation de certains morceaux auprès des utilisateurs ; en amont, enfin, lors du processus de création. »Pour plusieurs acteurs du secteur musical, l’IA constitue un outil de travail au service de la créativité humaine. Elle peut, par exemple, être utilisée pour aider à l’écriture des textes, la composition, l’arrangement et la production de musique, ou encore à l’amélioration de la qualité du son. Toutefois, à notre connaissance, peu d’enquêtes ont été menées au Canada sur l’utilisation de l’IA au sein de l’industrie musicale.","La FTD réfère à un ensemble de procédés techniques automatiques d’analyse s’appliquant à de grands corpus de contenus numériques, pouvant inclure des textes, des données, des sons, des images ou d’autres éléments, ou une combinaison de ceux-ci.La première étape de la FTD consiste à collecter ces données, appelée input ou intrant, et parmi lesquelles on trouve des œuvres protégées. Ce processus implique des copies et reproductions de ces données. Ensuite, celles-ci sont soumises à un prétraitement. Celui-ci inclut leur nettoyage et parfois une transformation dans un format spécifique pour faciliter l’entraînement du modèle d’IA. À partir de ce moment, la phase d’apprentissage peut être réalisée à l’aide d’un algorithme d’apprentissage automatique. Il s’agit d’apprendre au modèle développé à comprendre les structures et les relations dans les données collectées lors de la première étape. Le modèle est ensuite capable de générer de nouvelles données, appelées output ou extrant, qui partagent des caractéristiques similaires à celles utilisées pour l’entraînement.Les vastes corpus de données moissonnées en ligne constituent en quelque sorte la matière première des outils et logiciels d’IA. La valeur économique des IA génératives repose en grande partie sur la qualité des données qui ont été utilisées. Or, les œuvres protégées qui constituent des œuvres professionnelles de qualité sont particulièrement intéressantes.Nous avons donc une utilisation de contenus protégés sans autorisation, génératrice de valeur pour les outils et les logiciels d’IA qui soulève de nombreuses questions :Ces questions illustrent l’absence de transparence autour des processus liés à la FTD. Par exemple, lorsqu’une chanson des BB chantée par Michael Jackson est publiée, on comprend qu’une utilisation non autorisée, du corpus de ce dernier a été faite pour entraîner une IA et on apprend cela seulement au moment de la publication de l’œuvre. Ce manque de transparence affecte le présent processus de consultation. Il nous est en effet difficile de répondre à plusieurs questions et à formuler des recommandations éclairées s’appuyant sur des données probantes.Du fait de la présence d’un nombre important d’entreprises spécialisées dans ce domaine d’activités sur le territoire, il est clair que des activités de FTD sont menées au Canada. Toutefois, il est difficile de donner plus de précisions sur cette question.La transparence est un incontournable, que ce soit pour le législateur qui doit s’assurer que l’IA respecte minimalement l’ensemble des règles que nous nous sommes fixés comme société, pour les ayants droit en lien avec le respect de leurs droits, qu’ils soient patrimoniaux ou moraux, mais également pour le citoyen qui a le droit de savoir d’où viennent les produits qu’il consomme. Pour s’assurer que l’IA et ses développements soient responsables, éthiques et tout simplement en conformité avec le droit, la transparence est un préalable.Nous sommes favorables à la tenue de registres et à l’obligation de divulguer les contenus protégés par le droit d’auteur, enregistrements sonores et performances, qui ont été utilisés pour la formation des systèmes d’IA. Ces registres doivent être facilement accessibles et consultables.Ce besoin de transparence fait consensus au sein du milieu culturel. Par exemple, la Human Artistry Campaign qui regroupe plus de 150 organisations musicales à travers le monde souligne que la confiance et la transparence sont essentielles au succès de l’IA et à la protection des créateurs. En juin dernier, un regroupement important de créateurs et titulaires de droits européens a appelé à la mise en place d’obligations de transparence pour garantir l’utilisation licite des contenus protégés par le droit d’auteur.On retrouve également cette demande au sein du grand public. Le 27 novembre 2023, l’IFPI a publié les premiers résultats d’une étude réalisée à l’échelle internationale auprès des amateurs de musique sur leurs points de vue concernant l’IA. La grande majorité des répondants (73 %) se disent d’accord avec le fait qu’un système d’IA devrait clairement indiquer toute la musique qu’il a utilisée pour s’entraîner.Certaines législations se sont positionnées sur cette question de la transparence. L’Union européenne a ainsi ajouté dans la directive sur l’IA sur laquelle elle travaillait une obligation pour les entreprises d’IA à « rendre publique un résumé suffisamment détaillé » des contenus qu’elles utilisent pour l’entraînement de leurs algorithmes. Le 8 décembre dernier, les États membres et le Parlement européen sont parvenus à un « accord politique » en vue de l’adoption de cette législation européenne sur la propriété intellectuelle.Aux États-Unis, le président Joe Biden a signé un décret posant un ensemble de règles et de lignes directrices en matière d’IA. L’ordonnance exigera plus de transparence de la part des entreprises d’IA sur le fonctionnement de leurs modèles. Parallèlement, deux membres de la Chambre des représentants, Anna Eshoo et Don Beyer, ont déposé un projet de loi intitulé l’AI Foundation Model Transparency Act exigeant que les entreprises d’IA divulguent les sources de données utilisées pour former leurs modèles. Le projet de loi ordonnerait à la Federal Trade Commission  de collaborer avec le National Institute of Standards and Technology afin d’établir des règles de rapport afin d’assurer la transparence des données de formation.Les entreprises d’IA ont la capacité de mettre en place cette transparence. La fonction même de la FDT est de réaliser une analyse fine des données qui ont été récoltées. Dès lors, les logiciels en place devraient être capables d’identifier les œuvres protégées. En outre, il existe déjà des outils permettant cette transparence : les model cards qui documentent l’architecture et le fonctionnement des IA. Certaines sociétés comme OpenAI et Meta ont déjà commencé à en publier. Ceux-ci documentent par exemple les objectifs de l’IA et le contexte dans lequel les modèles sont destinés à être utilisés ou encore les données qui sont utilisées pour entraîner l’IA, ainsi que l’origine de ces dernières.Comme nous l’avons expliqué dans notre schématisation de la FTD, ce processus implique un acte de reproduction qui concerne notamment des œuvres protégées. Or, dès qu’une partie importante d’une œuvre est reproduite, communiquée ou publiée , les conditions et les limites de cette utilisation doivent être constatées dans une licence.Pourtant, cette reproduction est présentement réalisée sans l’autorisation des ayants droit et encore moins de rémunération, alors que les plateformes d’IA générative tirent d’importants bénéfices des œuvres utilisées. Les titulaires de droits font donc face à des défis en ce qui concerne l’octroi de licences pour leurs œuvres utilisées dans le cadre des activités de FTD. Pour l’ADISQ, les titulaires de droits d’auteur doivent disposer de leur droit exclusif comme ils l’entendent.Selon l’étude de l’IFPI, 76 % des répondants, la musique ou la voix d’un artiste ne devraient pas être utilisées ou ingérées par l’IA sans autorisation.Dans ce cadre, nous nous opposons à l’introduction de toute nouvelle exception pour l’utilisation de contenu protégé. Ces dernières années, le droit d’auteur, et donc sa capacité à assurer un contrôle et une rémunération juste à l’ensemble des ayants droit, a considérablement été fragilisé, notamment par l’introduction d’une myriade d’exceptions sous le gouvernement Harper en 2012. L’introduction de nouvelles exceptions ou l’élargissement de la portée de celles existantes constituerait une nouvelle atteinte au droit d’auteur et viderait un peu plus celui-ci de son sens.La Loi sur le droit d’auteur actuelle est suffisamment claire et neutre technologiquement pour fournir un cadre dans lequel la FTD peut se développer tout en permettant au milieu culturel d’assurer que les droits d’auteurs soient respectés.Le document de consultation suggère qu’en raison de la grande quantité de données impliquée dans la FTD, « l’obtention de toute autorisation nécessaire auprès des titulaires de droits pour reproduire des œuvres ou d’autres objets dans le cadre de ces activités pourrait représenter un fardeau important. »  Selon nous, il apparait hautement problématique de vider le droit d’auteur de son sens et de permettre une utilisation massive sans autorisation ni rémunération des productions culturelles (qui constituent la matière première de la FTD), sous prétexte que le respect de ce droit d’auteur constituerait un fardeau important. Notre secteur n’a pas à supporter gratuitement les développements de l’IA.En outre, comme le rappelle la CDEC, des modèles de licence d’utilisation à des fins de FTD existent. Des modèles de licences peuvent donc être facilement mis en place, celles-ci pouvant notamment être négociées par des titulaires de droits d’auteur, des regroupements de ceux-ci ou encore des sociétés de gestion collective.Le gouvernement, qui souhaite être proactif sur ce sujet, pourrait aider le marché à trouver des solutions de licence pour les utilisations de FTD et contribuer à la mise en place de mécanismes efficaces garantissant le respect des droits d’auteur. Par exemple :",,,"L’ADISQ est membre de la Coalition pour la diversité des expressions culturelles et appuie entièrement le contenu et les recommandations du mémoire de celle-ci.Pour conclure, il est important de rappeler ce qu’est la Loi sur le droit d’auteur, à savoir une loi de nature économique qui crée un cadre permettant le contrôle et la rémunération des titulaires de droit pour les différentes utilisations qui sont faites de leurs œuvres. Cette loi, qui organise la rétribution des auteurs, compositeurs, interprètes et producteurs pour leur travail, est vitale pour l’industrie musicale. En effet, sans un contrôle permettant une rémunération suffisante pour ces derniers, il n’y a pas de musique.Nous souhaitons réitérer que le droit d’auteur ne représente pas un frein au développement technologique et à l’innovation. Au contraire, il constitue un incitatif à la création au fondement d’industries culturelles et créatives qui, outre leur rôle social et culturel fondamental, ont des retombées importantes pour notre économie. Nous sommes conscients des apports sociétaux et économiques que peut amener l’IA. Toutefois, ces développements doivent se faire de manière responsable et éthique en accord avec les principes dont nous nous sommes dotés comme société. Les développements de l’IA doivent coexister avec un droit d’auteur qui contribue à l’épanouissement de notre culture afin de créer un cadre qui soit profitable pour l’ensemble des parties en présence.Dans ce contexte de changement technologique rapide où l’IA va prendre de plus en plus de place dans notre écosystème musical, voire le chambouler, un ingrédient essentiel demeure intouchable : une Loi sur le droit d’auteur qui protège adéquatement les ayants droit.Or depuis 2012, moment où la LDA a passablement été mise à mal, des mises à niveau demeurent encore et toujours urgentes pour le milieu musical canadien.Les trois principales demandes de l’ADISQ en regard de la révision de la Loi sur le droit d’auteur qui visent à assurer une juste rémunération aux ayants droit pour leur travail sont :Il est crucial que la Loi sur le droit d’auteur soit modernisée non seulement pour corriger les erreurs du passé, mais aussi pour garantir qu’elle soit équitable et en accord avec les pratiques internationales, et ce, peu importe le véhicule que vous choisirez de prendre. Les entreprises qui offrent un accès aux contenus musicaux, ainsi que les fabricants d’appareils permettant la copie de musique, ne sont que quelques exemples d’entreprises qui ont les moyens de mieux rémunérer les titulaires de droits pour la valeur qu’ils tirent du contenu protégé par le droit d’auteur. Toutes les solutions que nous proposons sont basées sur des revenus générés par le marché lui-même, et non par les fonds publics.En 2019, nous avons eu l’occasion de présenter nos demandes en vue d’assurer une juste rémunération des ayants droit dans le cadre d’un mémoire déposé par la Coalition pour une politique musicale canadienne. Nous souhaitons réitérer ici l’importance de ces demandes. Nous considérons que celles-ci devraient constituer la priorité du gouvernement canadien en matière de révision du droit d’auteur."
Association québécoise de la production médiatique (AQPM),Association,"L'Association québécoise de la production médiatique (AQPM)  représente, conseille et accompagne plus de 160 entreprises québécoises de production indépendante en cinéma, télévision et web. À titre d’entrepreneurs, nos membres sont présents à toutes les étapes de la création d’une œuvre, de son développement à son rayonnement sur le territoire national, à l’international, et sur tous les écrans. Ils permettent ainsi à des milliers de créateurs, d’acteurs et de techniciens d’exercer leurs talents et de partager sur toutes les plateformes, en français et en anglais, des histoires qui reflètent notre identité culturelle. Elle négocie également les ententes collectives applicables avec les syndicats professionnels, de techniciens, de créateurs et d'artistes-interprètes en vertu de la Loi québécoise sur le statut de l'artiste.Pour le moment, l'AQPM effectue une veille stratégique sur ces questions, elle est particulièrement soucieuse de l'utilisation de l'IA pour la production de scénarios ou de textes puisque les producteurs doivent garantir l'originalité des contenus. De plus, l'l'utilisation de la voix ou de l'image des interprètes est une question pertinente pour les producteurs. L'AQPM s'intéresse également à  l'IA comme un procédé pour alléger ou favoriser des processus administratifs ou créatifs.","L'AQPM reconnaît les dangers amenés par l'IA de même que son potentiel notamment pour soutenir le potentiel créatif.Mais comme nous l'avons souligné préalablement, cela doit s'inscrire dans la transparence.Il est important d'imposer une obligation de divulgation et de tenue de registres afin de connaître les activités de FTD qui utilisent des œuvres protégées  par le droit d'auteur ou des performances que ce soit à des fins d'entraînement des systèmes que de création de contenus générés par l'IA. Pour le moment, il est difficile de connaître de cerner l'ampleur de ces utilisations.Le mécanisme de gestion collective des œuvres serait approprié pour gérer l'utilisation des œuvres protégées et leur reproduction pour la formation des systèmes d'IA de même que pour la rémunération des ayants droit. Certaines sociétés de gestion le font déjà comme le Copyright Clearance Center par exemple.Il nous apparaît tout à fait inacceptable d'introduire dans la loi une exception en matière de FTD même pour des fins de recherche.  Souvent ces recherches mènent à la création de start up avec des objectifs purement commerciaux. De plus, on a vu l'impact avec les géants du web qui possèdent des moyens financiers colossaux de reproduction des quantités phénoménales d'œuvres et de bâtir des monopoles sans compenser adéquatement les ayants droit. Le Canada doit éviter de s'engager dans cette voie sans compter que la capture de milliers de performances, d'extraits vidéos en reproduisant la voix et l'image des interprètes, pose des enjeux de protection de renseignements personnels et de vie privée qui dans ce dernier cas, irait à l'encontre du Code civil du Québec. Sans compter l'incidence sur la capacité de ces artistes à capitaliser sur leur talent pour gagner leur vie.  On mesure encore mal tous les développements possibles de cette technologie et il y a là une occasion pour les titulaires de droits d'explorer de nouveaux marchés et des occasions d'y générer des revenus importants.La Loi sur le droit d'auteur comprend aussi une protection au niveau du droit moral garantissant le droit à la paternité de l'œuvre, mais également à son intégrité et à ne pas être associé à un produit d'une manière pouvant compromettre sa dignité et sa réputation. Accorder une exception pour une reproduction massive des œuvres rendra tout simplement impossible le contrôle sur leur utilisation.",,,pas pour le momentMerci d'avoir entrepris cette consultation
Canadian Association of Broadcasters,Association,"The members of the Canadian Association of Broadcasters (CAB) are meaningful players in the Canadian cultural economy and are uniquely situated as both users and creators of creative content. This dual perspective enables the CAB to appreciate the motivation of the Government to encourage innovation in generative AI as a means to increasing efficiency and economic growth while also ensuring that creators receive the necessary protections for their underlying works that is essential to incentivizing creativity and the cultural economy in this country. In large part, the CAB’s members are in exploratory and experimental phases of engagement with generative AI.","The CAB supports the retention of copyright protection in works that would be otherwise subject to such protection, and does not support a general exception for text and data mining (TDM). The mere existence of generative AI systems does not support the removal of the copyright protection that automatically arises in Canada when original works are created and fixed in a material form. Copyright is a creature of statute, and the Copyright Act states at section 27(1) that “[i]t is an infringement of copyright for any person to do, without the consent of the owner of the copyright, anything that by this Act only the owner of the copyright has the right to do.” Accordingly, the question is whether these generative AI systems are doing anything that only the copyright owner has the right to do.The technological methods employed to undertake text and data mining in a given situation must be considered in answering the question of whether the use of copyright protected works by generative AI systems is infringing. There may be activities in connection with TDM that, based on the technological methods employed, do not infringe copyright. For example, generative AI systems that engage processes akin to reading the underlying works, much the same way search algorithms read underlying content in order to produce meaningful search results, may not result in copyright infringement. To be clear, this concept of “reading” has to be fully evaluated to determine whether it in fact triggers liability. If generative AI systems are engaged in making reproductions, it may be possible that such reproductions are subject to existing copyright exceptions such as fair dealing at section 29 or the technical process exemption at section 30.71. The answers to these questions lie with the creators of AI systems and are not readily available to the end-users.If creative works are being engaged in a manner that triggers copyright protection, the owners of the copyright in those works should be entitled to compensation for that use. The existing neighbouring rights regime in the Copyright Act provides an operational example of how copyright owners can be paid for the use of their works even in situations where it may not be possible for them to deny access to their works. Performers and sound recording makers are entitled to be paid equitable remuneration when published sound recordings containing performances are performed in public or communicated to the public via telecommunication. This payment is made to the designated copyright collecting society in the case of sound recordings of performances. The amount of the payment is determined either by way of direct negotiation between the user and the rights holder and/or the collecting society or, in many cases, through the administrative process carried out by the Copyright Board of Canada. If it is determined that generative AI systems are engaging the copyrights of the underlying works being used to train those systems, payment could be made to the underlying rights holders via a system of equitable remuneration similar that already in place for published sound recordings.","The question of whether works created through generative AI systems should themselves be subject to copyright protection is directly tied to the concept of the author in the Copyright Act. The Act provides at section 13.1 that the author of a work is the first owner of copyright in that work. The Act does not define, author, per se, though it does indicate at section 5(1)(a) that copyright will only subsist in works if the author was “a person”. In addition, as highlighted in the Consultation paper, “Canadian copyright jurisprudence suggests that 'authorship' must be attributed to a natural person who exercises skill and judgment in creating the work, reflective of the fact that the Act ties the term of protection to the life and death of an author.” To date, Canadian copyright law appears to only provide protection for human-generated works.In the case of works wholly produced by generative AI systems, that is those generated by a system that has received only cursory instructions from an AI user, there is no natural person who has exercised the necessary skill and judgment required to meet the preconditions of authorship and thereby give rise to copyright protection in the autogenerated work. The computer program will have made the creative decisions independent of any human interaction. Whereas, until recently, computers and software used to generate creative outputs have been viewed as a tool used by authors exercising considerable skill and judgment in connection with the creation of a work, new generative AI systems can be instructed without the exercise of skill and judgement that gives rise to copyright protection in Canada. Accordingly, AI work products that can result from basic instructions that lack a level of skill and judgment exercised by traditional authors should not receive the same protection afforded to human-generated works.Moreover, it is essential that works wholly produced by generative AI systems do not benefit from compensation through existing royalty channels, as this would serve to undermine the existing system that compensates human rightsholders for their creative labours.","If one starts with the proposition that the underlying works used to train AI systems are subject to copyright protection, it follows that, under existing copyright law, those works could be infringed by the AI systems themselves as well as by the end users of the AI-generated works. As the Consultation paper rightly points out, it will be near impossible for end-users to know which works were used by the AI systems and who the copyright owners of those works could be. Therefore, it would be unreasonable to put the onus on the end-user of the AI-generated works to avoid involuntary infringement. Only the providers of the AI systems that are inputting the underlying works into those systems have the potential to know what works are being used. In this way, only the creators of the AI systems should be liable for infringement that occurs as a result of the inputs they chose to rely upon and the way they manipulate those inputs.At section 38.1(1)(a), the Copyright Act provides statutory damages of between $500 and $20,000 per work infringed for commercial purposes. The application of this provision to the underlying works used in generative AI systems could quickly lead to absurdly high damages for end users who have no knowledge of or ability to determine whether and to what extent copyright is engaged by the generative AI systems. If the Government accepts the end-users have no knowledge of the underlying copyrights that may be engaged by their use of generative AI systems, it will be important to clarify that statutory damages do not apply in the case of AI generated works for individual or commercial users and further to ensure that such users are statutorily indemnified by the generative AI system owner or licensor against any and all copyright claims.","The CAB’s members are active participants in the Canadian cultural economy, as both creators of original content and as users of copyright protected works. The promise of generative AI in the context of broadcasting is nascent but may yield benefits for Canadian private broadcasters and their audiences. CAB members are currently exploring the potential of generative AI in their businesses and are keen to see how the Government shapes the rules surrounding this area of innovation.The CAB advocates for continued copyright protection in the underlying works used to train AI systems. Where AI systems are infringing that copyright through the technological processes they employ, the owner of copyright in the underlying works deserves to be paid for that use. If applicable, the use of the protected materials may be subject to an exception under the Copyright Act, in which case the use would be permissible. The nature of generative AI is such that the end-user has no knowledge of the copyright protected works that may have been infringed by the AI systems in the production of these works, and therefore it is not reasonable or fair for the end-user to be liable for any copyright infringement that results from that use. The providers of the AI systems are uniquely positioned to know which works are engaged and to make the necessary payments. The statutory damages framework in the Copyright Act should therefore be amended to preclude its application to end users of works produced by generative AI and end users of generative AI should be protected by a statutory indemnity."
Canadian Association of Research Libraries,Association,"Technical aspects of AI, particularly generative AI, are rapidly evolving. The Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems along with pending legislation will provide a framework for AI systems. Until communities of practice are established for the evolution and use of AI tools, guided by court decisions which will likely draw on the principle of technological neutrality, the research library community believes that the government should not restrict the use of AI, unintentionally or otherwise, as to do so would hamper innovation.","Text and data mining (TDM) is not a new concept; post secondary students and researchers in Canada have long utilized non-generative AI systems that rely on TDM and also use TDM as a research practice. However, the legal status of TDM currently lacks clarity, and the absence of a specific TDM exception in the Canadian Copyright Act hinders researchers' efforts and impedes progress by requiring extensive copyright analysis to ensure compliance. A new statutory provision should be implemented to confirm that the use of a work or other subject matter for the purposes of TDM does not infringe copyright and is thus noncompensable (i.e., any remuneration would be separate from nonconsumptive TDM). The exception should apply to all users and allow commercial and non-commercial uses and allow retention and sharing of copies used for TDM.In addition, to assist developers and users of AI more broadly, the fair dealing exception (Section 29) should be amended to make the list of purposes illustrative. It should also be made clear that fair dealing is not subject to contractual obligations, that authors and publishers cannot prevent the use of fair dealing (e.g. opting their works out of an LLM training set), and that TPMs can be circumvented for non-infringing purposes. These changes help maintain the Supreme Court of Canada’s description of the provision in CCH v LSUC, that the “fair dealing exception is always available” (para 49) and that, “the availability of a licence is not relevant to deciding whether a dealing has been fair” (para 70).For context, research libraries typically license electronic resources with mostly non-negotiable terms of use that may prohibit activities including TDM. Publishers and their intermediaries hold the balance of power in this environment. It should not be necessary for users to obtain a secondary license for non-infringing activities, including TDM.A number of Canada’s key trading partners already have a specific exception for TDM, including Japan, Singapore, United Kingdom, and the EU. In addition, research shows that providing copyright exceptions or other clarifications of the law to permit TDM is associated with increased publication of scientific research in the countries that make the change (Pijipvideo, Empirical Study Pt 2: Impact of Research Exceptions on Scientific OutputJoan-Josep Vallbé, - May 23, YouTube (July 24, 2023), https://www.youtube.com/watch?v=2bs_e7QRDHo&list=PLuk2SmOxN5RI1z40tC6qDxV 6uQdq-kqLq&index=4; Michael Palmedo, The Impact of Copyright Exceptions for Researchers on Scholarly Output, 2 Efil Journal 114 (2017)). CARL supports an exception that applies to both commercial and non-commercial research, as legislated in Japan and described by the Canadian Federation of Library Association's submission to the current consultation.","Research libraries reflect the risk tolerance of their parent institutions and the adoption of AI tools could be hampered by uncertainty surrounding ownership of AI works. For example, concerns about copyright infringement could deleteriously impact decisions about selecting and using AI tools to support teaching, research, and other library services.AI generated works do not meet the threshold for copyright protection as they do not involve a human exercise of skill and judgment (e.g., CCH Canadian Ltd. v Law Society of Upper Canada, 2004 SCC 13, [2004] 1 SCR 339, paras 16, 24, etc.) and should not be protected by copyright. CARL supports the recommendation from A Modern Copyright Framework for Artificial Intelligence: IP Scholars' Joint Submission to the Canadian Government Consultation (September 26, 2021) https://ssrn.com/abstract=4115848 that Sections 2 and 5 in the Copyright Act be changed to confirm that “author” is a natural person and that copyright does not subsist unless created by a human being.AI assisted works are an inevitability. Responsible uses and best practices are emerging that take into consideration the difficulties in acknowledging the use of AI tools in a new creation. This is not an issue that should be addressed by the Copyright Act.","Current provisions in the Copyright Act already address infringement and liability related to copyright when a substantial portion of a work is reproduced as an AI-generated output. Before considering any amendments to the Act that pertain to the scope of permissible TDM activities, the courts should be provided an opportunity to consider any emerging issues, including those related to AI, and provide analysis and guidance for any legislative changes.Copyright is one of multiple policy instruments that can provide appropriate controls related to AI systems, but not the most effective one for issues related to remuneration.","The potential uses of generative AI cross all areas of research library mission and operation. Libraries will play a critical role as AI continues to evolve and can offer supports related to data discovery, data management, and preservation (IFLA report, 2023), as well as AI literacy itself.Research libraries support copyright literacy in universities and their staff understand how the balance between protecting creator rights and facilitating the exchange of ideas and promoting creativity benefits society as a whole. While consultation on AI and copyright is important and CARL is pleased to engage in this process, it is critical to point out that not all provided questions are related to the purpose and intent of copyright law. Issues related to author remuneration and record keeping should not be legislated or addressed in the Copyright Act. Any new copyright regulation of AI should not negatively impact the public’s right and ability to access information, knowledge, and culture. In addition, any new copyright regulation of AI should maintain the appropriate balance of rights and interests in Canada’s copyright system, consistent with a robust principle of technological neutrality.CARL endorses the following submissions related to copyright and AI:2023 CFLA Consultation on Copyright in the Age of Generative Artificial Intelligence2021 Craig, Carys J. and Amani, Bita and Bannerman, Sara and Castets-Renard, Céline and Chapdelaine, Pascale and Guibault, L. and Hagen, Gregory R. and Hutchison, Cameron J. and Katz, Ariel and Mogyoros, Alexandra and Reynolds, Graham J. and Rosborough, Anthony D and Scassa, Teresa and Tawfik, Myra, A Modern Copyright Framework for Artificial Intelligence: IP Scholars' Joint Submission to the Canadian Government Consultation, https://ssrn.com/abstract=41158482021 Keller, Liwah and Yuan Stevens. Innovation and Balance. Submission to the Government of Canada’s Consultation on Copyright, AI, and IoT. https://cippic.ca/sites/default/files/File/CIPPIC_Submission_-_AI_+_IoT_Consultation_-_2021Sept17.pdfIn summary, Canadian research libraries posit that:AI generated works do not meet the threshold for copyright protection.A new TDM exception should be implemented and apply to both commercial and non-commercial uses.Current provisions in the Copyright Act already address infringement and liability, and provide a mechanism for claims related to an AI-generated output, when that output closely replicates an original work that is already protected by copyright.The government should not restrict the use of AI, unintentionally or otherwise, until court decisions can guide legislative change. To do otherwise would hamper innovation and the emergence of responsible practices."
Canadian Authors Association,Association,These questions are not applicable to our organization.,"TDM directly engages copyright law in Canada since it involves reproduction of copyright-protected works and creators’ moral rights. Right now, the unauthorized use of such copyright-protected works is contrary to the Copyright Act, unless such use falls within one of the enumerated fair dealing exceptions, and then, only if the six-part legal test is satisfied. Some commentators allege that TDM is only “reading” the text, the way a human would read a book. However, the analogy is facile and false since machines are capable of verbatim regurgitation and manipulation of the works they ingest. By setting policy affirming that TDM requires Copyright Act compliance, and/or amending the Copyright Act to clarify that TDM does require compliance with the Act, would create the clarity that is needed to ensure balance between users and creators.Providing this clarity ensures:a. costly litigation will be reducedb. marketplace solutions will emergec. Canadian content makers will maintain control and receive fair remuneration for the use of their creations in AI training, for exampled. no new exception should be created for TDM activitiesYes, TDM activities are being conducted in Canada. Examples include:a. Books3b. Cohere AI platformc. Media monitoring requiring TDM activityd. LLM research at Canadian universitiese. Globe and Mail: algorithm for front page storiesf. NovelAIThe primary challenge facing rights holders in licensing their works for TDM activities is lack of clarity regarding TDM and the Copyright Act. In the United States, the CCC, Copyright Clearance Center, is a copyright collective providing support for rights holders and engages in direct TDM licensing. This does not exist in Canada. The only collective for writers, publishers and artists, Access Copyright has recently been hollowed out due to failure by the government to remedy the devastating effects of the educational purposes fair dealing exception introduced in 2012, and to remedy the Supreme Court of Canada decision that copyright tariffs are not enforceable.Because TDM activity is not transparent about which works are used by which data mining companies, rights holders, publishers and Access Copyright have no clarity about whose works are used, for how long and for what purpose. Thus, mechanisms in Canada for creators to obtain compensation for the use of their copyright-protected works has been completely undermined in the last decade by a number of factors: by the decimation of the sole collective agency, Access Copyright, as a direct result of the federal government’s unkept promises to fix the Copyright Act; by the vague wording of the educational purposes exception that prevents educational institutions and related parties from engaging in legitimate licensing processes; and by the gap in the law perceived by the Supreme Court of Canada in holding that Copyright-Board certified tariffs are not mandatory. It is completely untenable for creators to resort individually to litigation to enforce their rights against TDM businesses, even smaller ones, when they have no means to prove the infringements due to lack of transparency. For individual creators to sue the large, foreign, largely US-based platforms is unsustainable.It is essential for rights holders that there be a rights market as there are in other jurisdictions, where the licensing process is working, and creators have the ability to control when their works should or should not be used and to participate in the compensation process when AI systems use their work.Rights holders face immense obstacles in licensing right now, because they are being kept in the dark as to which of their works are being used by which TDM companies.In the AI market with its surge in development, there are many types of licenses and models emerging to address the diverse TDM needs of different companies. Examples include: media monitoring, scientific data, and text based creative data. Opportunities for both collective licensing and direct licensing should be available for creators.It is vital that the Government recognize that Canada’s cultural industry will unequivocally be negatively impacted by generative AI and that safeguards need to be put in place. Safeguards include clarifying the Copyright Act to ensure that TDM activities are part of the exclusive rights of creators and there should be no exception created for TDM activities in this Act. The Government would thereby ensure rights holders can effectively license, and enforce their rights, including whether or not they wish to allow their work to be used in TDM activities. The Government should observe case studies such as Britain’s Intellectual Property Office, in 2022, which issued a limitless copyright exemption to AI tech companies, without having to obtain permission. This faced tremendous backlash by creators and Parliamentarians.The Department of Industry: Innovation, Science and Economic Development (ISED) shares responsibility for guiding policy relating to copyright with the Canadian Heritage Ministry. Thus, any changes to the copyright landscape must be framed by balancing innovation and Canadian creators’ needs and rights.It is essential that AI developers maintain complete records and disclosures regarding what and how content was used, as well as evidence of permissions granted. AI developers possess the ability to do this and must provide detailed reporting and data analytics ensuring all copyrighted material is clearly identifiable and referenced, whether it has been used in training or excerpted (in whole or in part) in any resulting AI output or product. Use of any copyrighted material at any stage in the process must be compensated through the application of a mandatory license to be paid per use by the developer and/or user of the tool.Any approach to the authorship of AI-assisted or AI-generated works must be predicated on detailed and precise tracking and documentation of underlying sources, whether or not they are explicitly quoted or footnoted. If unlicensed, copyrighted materials have been used in an AI-assisted or AI-generated work, there should be requirement that both the original rights-holders (e.g. authors, publisher) and the relevant tariffing / licensing agency should be automatically notified of such a proposed use, together with an option for the author to refuse to license that use, or even to refuse it altogether (given the existence of each author's legal right to exercise 'moral rights' over their own material.) Exercise of any ""fair dealing"" exception should be confined within specific statutory defined limits for fair dealing (still to be defined and embodied within an amended Copyright Act), and must be accompanied by evidence of compliance with a mandatory tariffing regime.The process of obtaining copyright clearances, such as for film/tv/audiovisual or multi-media uses, is already well understood. AI tool users making use of such content should be required to respect existing law and regulations, obtaining necessary licenses and clearances in order to use such materials. Failure to respect such rights and processes should be understood as a breach of copyright, with appropriate remedies.The use of metrics on use cases, intended length of use, and intended use of the AI system itself needs to be established as part of the remuneration process. The market for TDM is evolving as are the offerings and costs of various licences for AI training purposes. When the rules around TDM use are fair to both developers and creators, the market will define the level of remuneration for TDM activities.Canadian tariffing agencies must also be empowered with the right and legal standing to act on behalf of their represented content creators in pursuing remedies for breach of copyright. It would be challenging for individuals to summon the resources to pursue their legal rights when confronted by large institutional, organizational, or corporate infringers of those rights. Further, to avoid undue regulatory and process burden on developers, users, creators, or rights administrators, development of a common, automated settlement tool would enable the simple financial settlement of an established tariffing scheme (built around an e-commerce kind of framework), such that non-exceptional license clearances can be automatically settled.1. United Kingdom: could serve as a framework for Canada with its balanced approach and growth of a rights market, fair compensation for creators and a growing AI sector.2. United States: CCC Collective Licensing","Canadian law is certain that although the owner of a copyright-protected work (literary, artistic, musical, and so on) can be humans, corporations, or other legal entities, only a human can be the author of that work. As discussed below in response to Question 2, Canadian Authors Association clearly advocates that no change to the law should be enacted to disturb that certainty.While Canadian Authors Association recognizes that some forms of AI technology (such as editing and organizing tools) can be useful tools for writers, CAA is not in favour of creating any form of exception or protection for the AI technology sector. CAA is much more concerned about protecting the position of creators than that of the AI technology industry, which by reason of its sheer size and generally aggressive approach to ingestion, already has a dominant position in the marketplace.The consumption by AI technology businesses of copyright-protected literary works infringes both the reproductive rights (permission to copy and to benefit from copying) and the moral rights (attribution, integrity and association) of the humans that created the ingested works. The human creators are individual and virtually helpless to assert the infringement of their rights against AI industry players. This certitude creates a heavy imbalance between the rights of creators and users within the copyright landscape. Any form of legislative protection for AI technologies would therefore concentrate even more power in the hands of large technology platforms, which already dominate content discovery and distribution. Therefore, CAA is strongly opposed to introducing any such legislative protection. The diversity of Canadian cultural discourse would be even further diminished if any protections for the AI technology industry were introduced.In conclusion, CAA maintains that fully AI-generated works are not and should not be copyrightable.Copyright law in force in Canada today recognizes that human creativity and expression is essential to attracting copyright protection. It is imperative that the articulation by humans of original creativity remains at the heart of Canadian copyrightable works. The legislation should not be changed to alter this well-established principle, to which Canada is bound pursuant to international treaties. Human skill and judgement must be exercised in order to attract copyright protection pursuant to the law right now, reflecting the policy perspective that human expression is vital to Canadian cultural discourse. Put another way, to leave the Copyright Act unaltered in this respect sends a strong message to AI technology developers that that AI-generated products are not capable of attracting copyright protection. Many such AI-generated works are regurgitations of human input and therefore to grant them status as copyrightable works would infringe upon the reproductive and moral rights of the humans whose works were digested without authorization.As is currently the law in Canada, determining whether a work attracts copyright should continue to focus on the human’s creative processes and the skill and judgement they exercised in making decisions as to the selection, assembly and organization of elements that ultimately are incorporated into the creative work. If a creator uses AI as a tool to create a copyright-protected work, the portion of the work that was created by AI tools should not automatically be deprived of copyright protection. That’s because human skill and judgement were used in deploying the tool to assist with the creation of the work. The Government may choose to clarify or modify the copyright and authorship definition, either through setting maximum limits on percentages of AI- assistance and AI – generated work creators use at the outset to create their work, or using terms like “a substantial proportion of the work must be human-generated” which gives courts the mandate to exercise their discretion.The Canadian federal government is uniquely positioned to set the stage for a strong, sovereign cultural policy in Canada. AI technology needs no assistance from the federal government to proliferate and thrive in Canada. AI platforms are concerned with profit, not the promotion of a distinctive Canadian cultural voice. The federal government has already pledged hundreds of thousands of dollars to help AI-industry players, without providing the necessary balanced financial incentives to inherently disadvantaged Canadian creators. To compound this imbalance with policies favouring AI-industry players would further stifle the Canadian voice. A strong Canadian voice is necessary not only to maintain and encourage future sovereign cultural identity and diversity, but also, for a strong democratic system.CAA is aware that the UK government proposed to create an exception for AI-created works, exempting them from having to seek permissions to use copyright-protected work. The backlash against the proposal reached international news and serves as a cautionary tale: governments in charge of copyright and creative policy should not favour technology at the expense of creators. Canadian law explicitly endorses technological neutrality.Further, the Canadian government itself can learn from its own experience. In creating an indiscriminate fair dealing exception for educational purposes in 2012, the government upended the tenuous balance between the rights of users and creators to the benefit of users – mainly the very large educational sector – and at the expense of creators, a loss currently estimated to be $200 million. Introducing any legislation that would further upset the already heavily imbalanced fair dealing provisions in the copyright landscape would further silence Canadian voices, stifle our culture, and thereby threaten our democracy.","There are very real concerns. The current legal framework for fair dealing exceptions within the Canadian Copyright Act has resulted in wholesale and uncompensated copying of copyrighted works; the Supreme Court of Canada has acknowledged that the current wording of the Act fails to define specific, enforceable limits for ""fair dealing"" while, at the same time, it deprives individual creators of the right to pursue remedies for breach through the tariffing agencies that were meant to collect for the use of their material. The combined findings that tariffs were not mandatory, and that the tariffing agency Access Copyright lacked ""legal standing"" to act for breach on behalf of its licensed users had the unfortunate effect of leaving Canadian creators without a just option to defend their rights against breach.It is against this backdrop that creators must assert their rights.It is therefore critical that AI tools maintain detailed and specific tracking concerning all source materials used to train, or as ongoing inputs to the tool and its subsequent applications, whether by original developers or by subsequent users of the tool. Absent such mechanisms, identifying or enforcement of any infringement would be impossible.In this context, it could be observed that extending the term of copyright, as Canada has recently done, while depriving authors of the ability to enforce those rights, is at best, flawed. Unenforceable rights are no rights at all.The process of obtaining copyright clearances, such as for film/tv/audiovisual or multi-media uses, is already well understood. AI tool users making use of such content should be required to respect existing law and regulations, obtaining necessary licenses and clearances in order to use such materials. Failure to respect such rights and processes should be understood as a breach of copyright, with appropriate remedies.However, Canadian tariffing agencies must also be empowered with the right and legal standing to act on behalf of their represented content creators in pursuing remedies for breach of copyright. It would be profoundly unjust to deprive creators of their legal remedies arising from sweeping and generalized uses of their copyright-protected materials merely because they cannot, as individuals, summon the resources to pursue their legal rights when confronted by large institutional, organizational, or corporate infringers of those rights.The most obvious barrier facing creators in determining whether an AI system accessed or copied their copyright-protected work without their consent is that they have no way to prove such infringement. Lack of transparency is a critical obstacle. Therefore, TDM and other AI-industry players must be required to maintain detailed tracking of multiple generations of documents that derive from compounding sources. Overcoming barriers such as these will require robust mechanisms for watermarking licensed sources as well as for detecting infringements of copyright. AI systems must have discoverable and traceable source records and be obliged to make them available to creators. A deemed infringement provision could be added to the Act so that an AI-industry business that fails to keep such records or make them available would be deemed to have infringed the copyright of the creator seeking the remedy. A provision could be added enabling a creator to pursue their rights against any or all of the parties profiting from the unauthorized use of their copyright-protected work: the TDM and other AI-industry business, the platform on which the regurgitated work was published, and/or the end user of the regurgitated work.Canadian Authors Association is not aware of what measures AI-industry businesses are currently taking to mitigate their liability risks. Such businesses have their own vital interests at stake in the protection of their own intellectual property, as well as for the avoidance of direct or indirect liability arising from their failure to address such risks. This should motivate them toward the development of robust tracking and detection mechanisms that align with emerging public, governmental and industry-wide mechanisms, including a Canadian-made code of conduct, as well as any framework necessary for international treaty obligations.Absolutely, there should be greater clarity. It should also be a general principle that no copyright can be granted for a generated work that is found to have infringed (or substantially infringed) existing copyrighted materials.Transparency is required to allow for rights holders to meet the evidentiary burden of proving their work was ingested by an AI platform – discoverable and traceable source records. Conversely, if the onus of proof is on the alleged infringer, the creator of a disputed work must be able to refer to a common and certified master record in defence of a balance of probabilities (or beyond reasonable doubt, if a criminal code test is necessary.)All rights holders should be able to seek remedies, whether individually or jointly and severally, against Large Language Model creator / operator, AI platform / application provider, and end user of AI generated content.1. United Kingdom: could serve as a framework for Canada with its balanced approach and growth of a rights market, fair compensation for creators and a growing AI sector.2. United States: CCC Collective Licensing",The copyright system is already broken mainly due to the introduction of the educational purposes exception.
The Canadian Bar Association,Association,N/A ,"While some jurisdictions have proposed limited text and data mining (TDM) exceptions to copyright liability for artificial Intelligence (AI) training purposes, the CBA Section does not propose such an exception.We note that following criticism from creative industries, the United Kingdom (UK) reconsidered a key outcome of its thorough consultation, to widen and replace its existing limited TDM exception that allows for reproduction of copyright works for the purpose of computational analysis for non-commercial research, with a broad TDM exception that allows reproduction for any purpose by anyone, and to database rights with a rightsholders’ option to opt-out. The UK House of Lords Communications and Digital Committee’s Report recommends that the UK Initial Public Offering (IPO) pause its proposed new TDM exception to conduct an impact assessment of the creative sector and if negative effects are found, to pursue alternative approaches. In its response to the Committee’s Report, the UK Government confirmed that it would “not be proceeding with a broad copyright exception for TDM”. Rather, the Government committed to “work with users and rights holders” to discuss “copyright licensing for inputs”, with the hope of producing a “voluntary code of practice”, and foster growth and partnership between the tech and creative sectors. The UK IPO set up a working group made up of representatives from the technical, creative and research sectors, with terms of reference published on its website.The CBA Section suggests that any amendments to current legislation in Canada would be premature at this time, as the current regime appears more likely to strike a proper balance between copyright holders and users. Until there is clear evidence calling for legislative change, the CBA Section believes restraint is appropriate.Sections 29 of the Copyright Act already prescribes sufficient exceptions for fair dealing for the purpose of research, private study, education, parody or satire.Fair dealing in Canada differs from other jurisdictions such as the United States, in that the purpose of the fair dealing must first comply with S.29 of the Copyright Act before fairness of such dealing can be established. The Supreme Court of Canada in Law Society of Upper Canada v. CCH Canadian Limited laid down 6-non-exhaustive factors for conducting a fair dealing analysis as contemplated by Section 29 of the Copyright Act, being “the purpose of the dealing, the character of the dealing, the amount of the dealing, the nature of the work, available alternatives to the dealing, and the effect of the dealing on the work.” The Supreme Court of Canada further explained that fair dealing “must not be interpreted restrictively, and the word “research” must be given a “large and liberal interpretation in order to ensure that users’ rights are not unduly constrained and is not limited to non-commercial or private contexts.” As such TDM, for the purpose of research, private study, or review, may fall within the definition of fair dealing under the Copyright Act.Furthermore, Section 30.71 of the Copyright Act provides a suitable exception to infringement for the temporary reproduction of works that are essential parts of a technological process, for the duration of that process and where “the reproduction’s only purpose is to facilitate a use that is not an infringement of copyright”.Should further advances to technology necessitate consideration of a TDM exception, the CBA proposes that there should be an in-depth study of approaches, and conditions/restrictions on the application of the section, which should be carefully studied and considered for Canada. Canada appears to be headed in the right direction, with the proposed Artificial Intelligence and Data Act (AIDA) and the Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems.The CBA Section proposes that any proposed text and data mining regulation should carefully address at least three categories of text and data: (1) personal information that can be linked to an individual that does not fall into category 3 (Personal Information); (2) works with copyright protection that do not fall into category 3; and (3) documents that are filed with a court, tribunal or other government entity that may have copyright protection:1. Personal Information should not be collected from sources that are third parties to the collector, AI developer, and/or user, unless it is for a proscribed use or in a proscribed manner. The risk of misuse of AI in targeting human behaviour is high and this type of data collection should be highly regulated.The CBA Section recommends additional study of the acceptable uses of Personal Information in AI models: in particular, the study of the types of personal information that is a risk of misuse in AI models.2. Content protected by copyright should be required to be licensed or explicit permission provided for the use of copyright material. The availability of copyrighted material on the internet should not be assumed to authorize its ingestion and reproduction for AI training models, and rights holders should not be required to affirmatively opt out of such uses. These protections are particularly important for works in the creative arts and software programming.In the alternative or in addition, AI developers should keep records of or disclose what copyright-protected content was used in the training of AI systems. Such transparency and accountability measures are critical to rights holders, who are otherwise unable in practice to determine when and how their content has been accessed and reproduced for such purposes. While we do not propose an amendment to the Copyright Act to provide for such obligations, we note that Bill C-27, The Artificial Intelligence and Data Act (AIDA), currently at consideration in committee in the House of Commons, gives the Governor in Council power to make regulations on topics such as transparency and record keeping obligations. The government has indicated that it intends to hold consultations on this topic, and we urge them to consider such obligations at that time. This aligns with the Bill's purpose of establishing Canadian requirements for the design, development, and use of AI systems.3. Documents that are filed with a court, tribunal, or other government entity, even if they are subject to copyright protection, should be permitted to be collected for training AI models without the need for a license or explicit consent. The collection of this category of text and data will assist AI models in the legal field and will support access to justice. The costs of legal fees to clients could be reduced by allowing for the use of AI models on documents in this category.","Although there is no explicit statutory requirement for human authorship in Canada, the provisions of the Copyright Act, coupled with Canadian jurisprudence clearly suggest that human authorship is a requirement for copyright. Therefore, works created entirely by AI will not qualify for copyright protection.The Supreme Court of Canada explained the Canadian standard for originality in Law Society of Upper Canada v. CCH Canadian Limited as one that “originates from an author and is not copied from another work” and is “the product of an author’s exercise of skill and judgment”, such exercise not being “so trivial that it could be characterized as a purely mechanical exercise” and “will necessarily involve intellectual effort.”This does not mean that AI cannot be used as a tool by a human author and use of such will not render a work uncopyrightable under Canadian law. Technological tools have been used for some time by creators in a variety of media.Currently, there is no need for changes to the basic definitions and requirements for copyright to accommodate technological changes in the generative AI field. These should continue to apply to works created by human authors using AI as a tool in the creative process.Apart from works created by humans with the assistance of AI technology, it is possible for generative AI to produce content following prompts by its users. Users may also further modify works generated by the AI technology or adapt the AI technology itself to meet a specific creative use. With the advancement of AI systems, it is also possible for AI to independently generate creative works with little or no human involvement in producing output. The endless possibilities by which AI can be involved in the creative process with or without human involvement in the input and output process, has created inter-jurisdictional uncertainty as to how these works should be treated, whether they can be considered original or copyrightable, and how the authors and first owners of the work should be identified.When registering works, the Canadian Intellectual Property Office (CIPO) currently generally requires disclosure of the human author who created the work. CIPO has also registered copyright in a work which listed a human and an AI painting application as co-authors of the artistic work, an approach which received international attention and some criticism. Although CIPO does not conduct a substantive examination of claims made in applications for copyright registration, it would be useful to require disclosure if any elements of the work were created entirely by AI, with no human intervention, in which case that particular element may not be copyrightable. We note that courts in Manitoba, Yukon and the Federal Court similarly require disclosure of when AI was employed in producing court documents, and more Canadian courts may follow suit.The CBA Section does not believe that it is currently necessary to clarify that copyright protection applies only to works created by humans, about which the applicable language of the Copyright Act and case law is clear.Because solely AI-generated works do not qualify for copyright, we do not support attributing authorship of AI-generated works to the person who arranged for the work to be created, which would require overturning the requirement of human creativity in copyrighted works. Such approach has been taken in countries like the UK, where the Copyright legislation allows for authorship of computer-generated works by the person who undertakes “the arrangements necessary for the creation of the work”. Recent consultation in the UK supported no changes to the existing law for computer-generated works without a human author. In Canada, there is also no clear legislative intent or jurisprudence that allows for authorship by computer systems or AI, and this is not likely to change soon.The CBA Section does not support creating a new and unique or sui generis right or set of rights for AI-generated works as there is insufficient evidence to suggest that such approach would fully address the presented issues or maintain the proper balance between the rights of owners and users and the public interest.","A. Existing laws are generally sufficient at this time to address AI liability, but developments should be monitoredThe Copyright Act and existing Canadian case law provides the necessary legal tests for establishing infringement with respect to: 1) inputs, that is, ingestion and use of copyrighted materials by test data management (TDM) and training of machine learning models, and 2) outputs, where the AI-created work evidences infringement of a substantial part of a copyrighted material.With respect to inputs, TDM undertaken to feed training of machine learning models, at least in many cases, requires reproductions of the training material. If that training material includes copyright-protected works and other content, and if such reproductions are unauthorized, infringement is clear. Whether such use will be exempted from liability by the fair dealing exception is a case-by-case determination. It should be noted that where the ultimate use is commercial and such use may compete with the ingested content, the application of the fair dealing exception to such activity becomes less tenable.B. Canada's current copyright framework is for the most part preferable for nowBecause AI is an evolving technology, the ramifications of which remain to be seen, application of existing fair dealing provisions provides the most flexible and resilient approach, which can evolve if needed to accommodate economic and technological developments. The established body of existing Canadian case law also bodes in favour of not replacing Canada’s existing fair dealing provision with an alternative untested and completely undeveloped in Canada, such as the US fair use doctrine. For this reason, we believe the existing fair dealing exception is also preferable to attempts to legislate a statutory TDM exception.With respect to outputs, that is, AI-created works, in at least some scenarios, there will be strong evidence of liability, such as where an output is substantially similar to existing content, and it could likely be demonstrated that the AI system was trained on the pre-existing content. Similarly, where users’ prompts to AI systems result in AI-generated outputs that contain substantial parts of existing content, it could likely be determined that: i) reproductions of existing content has occurred at the input stage, and ii) the output is likely infringing. Where there is strong evidence of AI creations borrowing from a particular creator’s catalogue (if the output bears an uncanny resemblance to the music of Drake, for example), it would be more likely to establish that it was trained on the creator’s catalogue (thereby likely infringing at the input stage), but whether the output infringes a particular work may be more difficult to establish. In this space, it will be useful to closely follow development of case law to see whether the common law, applying interpretive principles such as technological neutrality, continues to adequately protect copyrighted content, or whether statutory adjustments are necessary. For now, the CBA Section finds that the flexibility and resilience of the current copyright framework, and leaving it to Courts to apply the current framework on a case-by-case basis, appears to be a more prudent approach than trying to legislate what may be static and quickly outdated solutions for a rapidly evolving field. Outside of the copyright field, the government may want to consider codifying a federal tort of appropriation of personality, or in the case of commercial artists, a federal right of publicity, to protect artists whose likeness or voice is commercially exploited through AI “deepfakes” that, although not necessarily infringing a particular work or song, can exploit the artist’s entire professional catalogue of work. This will also assist because copyright infringement may be difficult to prove in cases where training data has not been copied in the traditional or copyright sense; however, the works of an author have still been used to train the AI. AI platforms should not benefit financially from a prompt that says, “Write me a song in the style of Drake,” for example, where the AI has been trained on the catalogue of Drake, regardless of whether the catalogue itself has been copied within the meaning of the Copyright Act, and whether or not the resulting AI output infringes a specific work.C. Transparency and accountability requirements can address barriers to barriers to determining whether an AI system accessed or copied a copyright-protected contentWith respect to both inputs and outputs, it can be difficult to determine whether an AI system accessed or copied specific copyright-protected content. For this reason, it would be useful for the government to consider rules establishing transparency and accountability for the use of copyrighted content in AI training. As noted above, we do not propose amendments to the Copyright Act, but in the context of rulemaking on The Artificial Intelligence and Data Act (AIDA), the government should consider whether AI Developers and creators of training datasets should maintain records of which content they have ingested, how it was procured, and how it is used in development of AI-generated content, and disclose such information when requested by rightsholders. It is noteworthy that the Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems, introduced in September 2023, includes transparency among the outcomes to which developers and managers of advanced generative systems have committed.",N/A
Canadian Civil Liberties Association,Association,N/A,"TDM is a necessary step in training generative AI models. But in the case of generative tools that spit out poetry, music, and illustrations, the “T” and “D” that need to be “M’d” are actually human-made works of art, work that has sprung from the boundless creativity of human minds. There is already something dispiriting about the way generative AI can flatten pre-existing creative works into “text” or “data” for harvesting, and just because these models need lots of data does not mean that that data should be mined with such little regard for the creatives whose work fuels it.Standardizing TDM usage rights is thus a crucial step toward respecting copyright holders of creative works. These platforms should obtain licenses, pay licensing fees, and bear primary liability for copyright infringement. If platforms lack these licenses, or if no prior authorization is granted, then platforms should be liable for the unauthorized acts of communicating these copyright-protected works to the public, including making them available to the public. Further, standardization of usage rights can create helpful benchmarks for transparency and accountability in how companies approach TDM. This means establishing effective complaint and redress mechanisms along with human oversight of what may otherwise be an automated process. Establishing strict standards of disclosure for users and effective complaint processes for copyright holders can protect individuals when TDM is occurring, and if copyright holders’ work is being used unlawfully. One such model Canada can look to for protecting rights of copyright holders during TDM is that of English-Corpora.org. In this model, the accessible content has limitations to how it can be used when downloaded. To quote McCracken and Raub (2023), “the vendor manages the limitation of copyright by removing 5% of all the content. Doing this through removing the last 10 of every 200 words, the vendor has created a collection that essentially has no resale value but is still fully valid for linguistic analysis and research.” English-Corpora's model is appealing for many reasons: it creates safe access to content that does not risk delivering the full licensed text collection; vendors would not need to create their own portal to control access to the data; and patrons would have the tools to work on more than one data set and establish reproducibility. Overall, the goal of whatever regulatory scheme is implemented should further protect the rights of the creator and owner of the copyright.We acknowledge that in some cases, those who wish to train generative AI models may find it necessary to seek exceptions to copyright protections. However, these exceptions should be limited in scope to protect copyright holders' rights and interests. This is consistent with TDM regimes around the world. Though they vary by jurisdiction, countries like Japan, Singapore, Estonia, and Germany allow copyright exceptions for non-commercial uses and research purposes. Both exceptions balance the interests of users and copyright holders: they understand the benefit and value that generative AI research may create for society, while also ensuring that copyright holders derive financial reward from the use of their work in commercial contexts. To balance the moral rights of the owner and the interests of the developer, ISED should implement regulations that require the developer to recognize the use of the owners’ works in non-commercial and research applications. Another option that could be implemented into the law is a fair use and fair dealing exception that is followed in the United States. This is where the exceptions to the copyright law regarding TDM are determined by a test of proportionality and includes assessing the purpose and character of use, the nature of the copyright, the amount and substantiality of the portion taken during the TDM process, and the effect of the use on the potential market. However, this still needs to consider whether granting this exception to commercial uses would grant a disproportionate amount of control to the technology sector, giving them inordinate power over the creators of copyrighted works. There needs to be attention given to the economic rights of the owner of the copyright so that the law does not allow too many exceptions that the owner can no longer derive financial reward from the use of their work. Moral rights are also an important consideration in TDM and to balance the rights of the owner with the user of their work, regulation should be implemented that requires the user to recognize the use of the owner’s work.","When it comes to generative AI, there is uncertainty surrounding authorship and ownership for copyright purposes. This uncertainty stems from the separation between types of AI-generated works, and from the difficulty of trying to fit these works into current models of authorship and ownership.For the first issue, it would be helpful to break up the legal definition for copyright purposes into two categories. One category would be ‘works created solely by AI systems that have no human contribution.’ Under the current copyright laws, these works would not be protected by copyright. The second category would be ‘human works that were made with the assistance of AI.’ If following approaches taken by other jurisdictions, these works could be protected by copyright, if it can be proven that a level of ‘sweat of the brow’ and ‘modicum of creativity’ are demonstrated in the works by a human being. This means that it would need to be determined in law what level of effort of skill, labour, and creative pursuit is necessary to fulfill these two categories, in a sufficient manner to allow for copyright protection (This approach is addressed within Nova Productions v. Mazooma Games [2007] EWCA Civ 219).The concept of originality has also been considered internationally when addressing how copyright protection is created for a work. Originality is an important factor for copyrighted material and this concept should continue to be considered when works of AI are being analyzed because without ensuring that originality is present, works of AI would merely be a compilation of publicly available or already copyrighted materials. The case of Eastern Book Company v. D.B. Modak (2008) 1 SCC 1. addresses the importance of originality as a guiding principle. This case states that to grant copyright, it would need to be proven that there was expertise, judgement, or skill used in the creation of the work. The case of Rupendra Kashyap v. Jiwan Publishing House Pvt. Ltd., coming out of India, also addresses this issue of originality when considering creations or systems of AI. This court describes how originality could be broken down into the following factors to determine whether its work is original: whether the expression and idea are inherently linked; whether the author applied expertise and effort; whether the least possible level of imagination is present in the work; and whether the resultant work is a product of only work and skill. Both courts in Canada and India have been clear on their view of copyright protection: originality is essential to grant this protection. Without it, there is nothing that the copyright can attach to, and this would be the same result for AI-generated works. That said, the issue of authorship and ownership of AI systems and works still exists and needs to be addressed to answer the question of who will hold the copyright if originality is found in AI-generated works, and consequently who will be held liable for potential issues of infringement.Although many cases support this traditional view that copyright protection shall only be granted to human-made works, and that our legal ideas of authorship can only exist within this framework, this does not mean that things cannot change. Canada’s living tree approach to our legal system supports reconceptualizing definitions of authorship within the realm of copyright to better suit the technological present and the current needs and interests of society. Redefining authorship to allow for AI-generated works to fit under current copyright frameworks is another approach that can be taken by the Canadian government. For this, Canada could apply the concept of the “work made for hire” doctrine. This doctrine states that “the individual who created the work is always considered to be the author of the work, regardless of whether the work was created in an employment or independent contractor relationship,” but that the producer’s employer is the first owner of the copyright of works created by an employee in the course of employment (Moskal, 2021). This approach could change how ownership was determined as it would classify AI as employees of whatever company was utilizing the system. Although this doctrine slightly changes the traditional method from granting the ownership of the copyright to the author of the works, to instead granting the ownership of the copyright to the employer of that individual, the work for hire doctrine allows for a more viable solution to issues of infringement and liability that arise with AI-generated works or AI systems. The validity of the work for hire doctrine is supported by Beloff v. Pressdram (1973) 1 All E.R. 241 (Ch. D). It is a solution to honouring the ideas of originality, creativity, and labour that exist in traditional copyright law, while also allowing the legislation surrounding copyright to evolve with the creation of new technology to promote societal evolution and creation.Although this doctrine has benefits that support the creation of new technologies and provides an answer to the ownership of copyright if it is granted, there are issues with this work-made-for-hire approach to ownership. For one, it could over-reward users, programmers, and companies. It could also allow companies to own every piece of work that the AI program could produce, which has the potential to lead to access inequality issues, where copyright is being obtained at unprecedented rates and access to autonomous AI systems becomes impossible. For these reasons, there would still need to be limits placed upon what can be copyrightable works under this new definition of ownership. A solution would be to still separate AI works into the two above-noted categories, where copyright protection and ownership was only granted over the AI works that were created by humans with the assistance of these AI systems and not solely AI-generated works. This approach has been contested because of the potential issues flagged above, but it is evident that the other option of immediate entrance into the public domain could create issues down the line with liability and infringement. If there is no classified owner over AI systems, then there will be no one to hold liable for infringement over other copyrighted works. Another approach that is taken for authorship is to grant it to the programmer, in instances where the developer of the AI system is in direct control of their development. This is supported by similar regimes in Hong Kong, India, Ireland, New Zealand, and the United Kingdom. It would need to be determined through law the specific control that a programmer has over their AI system to be able to hold authorship of works created from that system. This would take the place of the human contribution, only if there is a specific vision of the works that the AI will produce. This approach is addressed and supported through the example of “The Portrait of Edmond Belamy”, which was a work created using an AI system that used a data set of 15,000 portraits and sold for massive profits at auction. This is an example of what experts are arguing against allowing copyright protection over, as its creation is evidence of an AI system that has been “designed to access so many variations of input data that developers cannot even imagine what kind of outputs it will lead to” (Budden, 2022). The regimes that support authorship being granted to the programmer support it on the grounds that the result from the AI technology is not too remote from the work of the programmers. It must be ensured that the pattern used by the AI system is discernible to the programmer and not just the AI system; as the basics of copyright law or creative input and labour are lost the moment that the programmer cannot foresee every possible output of the system (Chaudhary, 2022). Granting authorship to the programmer can still fit into the work for hire doctrine if the programmer created the AI system during their employment, giving any copyright ownership to the employer of the programmer.","Currently, there is an issue with determining if an AI-generated work has infringed existing copyright, when there are autonomous AI systems that create works beyond the ideas thought of by the programmer. When AI can create and act without input or supervision of a human source, it becomes very difficult to catch infringement unless the programmer or company that is using the AI system is actively keeping record of the sources used in creating its works. One way infringement prevention has been considered internationally is through requiring the implementation of a record-keeping system for anyone involved in the development or deployment of AI systems. An approach to this kind of record keeping is outlined in article 12 of the European Union’s AI Act. It states that “high risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems are operating. Those logging capabilities shall conform to recognized standards or common specifications” (EU AI Act, 2023). The Act also states that logging should also include that it the ability to record the period of use, note the reference database which input data has been checked by the system, the input data for which the search has led to a match, and any identification of natural persons involved in the verification of the results. A similar model to this one outlined in article 12 of the EU’s AI Act would be helpful in Canada for limiting infringement and delineating clearer liability standards.Further, to help determine liability when copyright has been infringed, AI works could be divided into two categories. The first would be work created by a human and aided by AI. In this scenario, the liability would be with the creator of the works. In this type of creation, the use of the AI system by the individual is the acceptance of being liable for the content that is used to create the work. The second would be the work generated solely by AI, which is the main focus of debate with infringement and liability. This is because it is harder to track the works that are being infringed. In this case, the work-made-for-hire doctrine could be the solution for liability: it would be clear who holds liability for the AI system’s work, as they would be the ones who would be directly benefiting from it. The employer would be able to implement a record-keeping system to combat infringement and liability, by ensuring that all works used are lawfully accessed. Liability could also be limited by writing exceptions into the law, like exceptions proposed with respect to TDM. Stating specific exceptions to infringement can allow the government to balance the interests of the creators of copyrighted works and those using AI systems to create works to ensure that there is no unreasonable prejudice against the interests of the rights holder, while outlining circumstances where users of copyrighted works would not need prior authorization or payment of royalties. This approach would be based on the de minimis doctrine where the impact on the rights holder is determined to be too minimal to qualify as an infringement occurring, along with the socially beneficial nature of the work.",N/A
"Canadian Council of Archives/Conseil Canadien des archives, with the endorsement of l'Association des archivistes du Québec, and the Association of Canadian Archivists",Association,"The holdings in Libraries, Archives and Museums (LAMs) are a major source of documents for AI researchers in their development of training datasets for use in training AI models, particularly those datasets used to train large language models. Canadian archival holdings are a rich treasure trove of records in all formats that serve as the raw material for scholars, students, and ordinary citizens. Archival institutions have eagerly embraced the opportunities provided by the Internet to digitize and make our holdings available online. When digitized, traditional records can be mined for valuable historical information. For example, fur traders’ journals document decades of weather patterns, relations between indigenous people and settlers, and early commercial activities; and tax rolls record the names of residents, which are of great interest to family historians. In addition, archival institutions are acquiring born-digital records and research data sets from their parent institutions and private donors.Transparency and ensuring non-bias in training datasets is of concern to LAMs because of our public service mission. Although it may be onerous, it is very desirable to create the metadata to be able to identify and link the training datasets to the generative AI output created by the AI tool. This metadata will provide transparency and oversight to the users, and also for the creators and rightsholders whose works are used in the datasets in a non-consumptive way.Canadian LAMS are also beginning to use some of the emerging generative AI tools for their own purposes. Archives can use AI tools to generate basic metadata, transcriptions, and create important access points for all manner of digitized documents, thereby providing greatly improved access to our holdings for their researchers and the General Public. (See Pavis, Mathilde. Artificial Intelligence: a digital heritage leadership briefing, 2023 https://www.heritagefund.org.uk/about/insight/research/artificial-intelligence-digital-heritage-leadership-briefing.). Along with many other materials, Canadian archives include a large volume of orphan works (works for which the rights holder is unknown or unreachable) on a wide variety of topics and archivists and researchers would benefit greatly from more clarity on whether or not orphan works can be digitized to enable this kind of improved access. The newly created metadata that can be produced by generative AI will unlock access to the content of archival holdings that goes well beyond what is possible with the limited human resources currently available in archival institutions.Recommendations:","Libraries, archives, and museums (LAMs) are unlikely to be AI developers, so LAMs don’t need an exception that permits them to use copies to train machines. LAMs are more likely to be asked to make copies of their holdings for AI developers upon request. If so, the fair dealing provision (s 29) of the Copyright Act (CA) may well serve, with some changes. The changes proposed below build upon provisions that are part of the balance between the rights of copyright owners and the interests of users already established within the CA.Before describing the proposed changes, it is important to note that provisions such as fair dealing and the exceptions for LAMs are fundamental to the balance inherent in a well-functioning copyright system. Canada’s approach to the challenges of AI must begin with established principles. The Supreme Court of Canada (SCC) has established that exceptions are not just loopholes, but users’ rights (CCH v LSUC 2004 SCC 13 para 48), and we steadfastly defend their presence (particularly the fair dealing provision) as a fundamental principle. Since fair dealing is not limited to particular user groups, rights, formats, or categories of protected matter, everyone can benefit from it to access and use copyrighted material without authorization or payment, provided that the dealing is fair as determined by the SCC’s two-step test.As beneficiaries of fair dealing, LAMs already can make copies upon request for the purpose of research. Provided that TDM is appropriately defined to be clear that it is included within a broad and liberal interpretation of research, making copies for TDM falls within one of the allowable purposes of fair dealing. That uncertainty would be clarified if the fair dealing provision were amended by adding TDM or computational data analysis to the list of authorized purposes, OR by making the purposes illustrative rather than exhaustive, i.e., “fair dealing for purposes such as research, private study,...do not infringe copyright.” A further condition would require the LAM to inform the requester that the copies were provided for research only, that any further uses may require the permission of the rights holder, and that it is the responsibility of the requester to obtain any necessary permissions. Admittedly, the scope of fair dealing may have to be clarified through litigation, since the limited case law cited in the consultation paper does not address situations where the copied images were used to train a machine.Since users’ rights are fundamental to a balanced copyright system, constraining them through contractual agreements undermines the system. Thus, the Copyright Act must be amended to provide that any contractual provision contrary to the exceptions in the Act shall be unenforceable.The proposed amendments would provide legal clarity for both LAMs and AI developers by enabling LAMs to provide copies to AI developers to be used in the training of machine learning models.Recommendations:Having sufficient metadata that would identify and link the training datasets to the generative AI output created by the AI tool would be highly desirable. Requiring AI developers to provide such metadata would provide transparency to the users of AI tools, and to the creators and rightsholders whose works are used in the datasets in a non-consumptive way. In order to ensure transparency and clarify rights issues, generative AI output should always be tagged as such.RecommendationThe possibility of a more general exception to permit TDM falls outside the scope of the archival community’s direct interests. If, however, such an exception is needed, the provisions of Singapore’s Copyright Act pertaining to computational data analysis (sections 243-244) are well thought out in terms of scope and appropriate safeguards. Its strengths are:","In Canada the basic principle is well established that copyright is automatic for original creations that include human skill and judgement, as specified in the Supreme Court decision (CCH Canadian Ltd. v. Law Society of Upper Canada, 2004 SCC 13, para. 25). The output that results from the generative AI mechanical process cannot meet this requirement for skill and judgement and is therefore not protected by copyright. The humanly created algorithm does meet the requirement and is protected by copyright.The current principle of not assigning copyright protection to generative AI output does not at all appear to be limiting the rapid development and adoption of AI technologies. The lack of certainty is, however, having a profound effect on creators and how they view their future prospects from both an economic and social standpoint. We believe that assigning full intellectual property rights to the output of generative AI processes is inappropriate. LAMs have a long history of advocating for clarity in the Copyright Act and we believe this issue must be addressed in the legislation, to provide as much clarity as possible. Even with the current constraints and uncertainties, AI is profoundly disruptive in many ways, particularly to the creative communities. Assigning copyright protection to AI output would very negatively affect the work of creators and their contribution to society, resulting in a negative effect on incentive to create. Extending copyright protection to AI output calls into question the value we place on human creativity and expression.AI processes can be programmed to create mass output that could quickly monopolize the creative space, thereby disrupting in profound ways human creative activity, the copyright balance, and the marketplace.The rapid development and dissemination of AI has already created considerable disruptions to the creator community, and these will continue to be a major problem. Creators contest that the ingest of their works in the creation of the AI training models without attribution, permission, or financial compensation is a serious problem that will affect them in many ways. But fair dealing and/or a TDM exemption would permit data mining for research purposes of the millions or billions of documents in the data sets used for training.The prospect of directly compensating creators within the structure of the Copyright Act raises many thorny problems. Copyright law should not be used to address broad societal problems and challenges. However, copyright law is not the only way that we can reward creators. We recommend that the Government create a system outside the copyright regime to reward and acknowledge creators for the part their work plays in generative AI, such as a program in which AI developers are required to contribute to a fund that will be plowed back into the creator community to support a broad spectrum of Canadian creativity. (Other examples of this type of scheme are Canada’s Public Lending Rights, Telefilm). The details of how such a program would work would have to be carefully considered, with input from the creator community, and the outcomes would have to include mandatory contributions by those developing the training datasets, and money paid out to the creator community. This would help redress the balance between human creators and the potential dominance of large corporate AI in the marketplace and the creation landscape. Such a program would enhance Government efforts to ensure support for Canadian creators and creative industries, while simultaneously fostering Canadian AI competitiveness, innovation, and support for maintaining overall access to Canadian creation, all of which are important public policy objectives.Recommendations:With further study and careful consideration, it is possible to consider very limited rights for AI outputs in particular circumstances, a variation of what is sometimes referred to as “thin copyright”, such as the limited rights sometimes accorded to databases. But these should be very limited in both scope and duration.Recommendation:","At present, there is no requirement for AI developers to provide metadata that would identify and link the training datasets to the generative AI output created by the AI tool. Requiring AI developers to provide such metadata would assist in determining whether protected material had been copied when generating an infringing output, in addition to providing transparency to users of AI tools, and to the creators and rightsholders whose works are used in the datasets.RecommendationsIt is clear that there should be greater clarity on where liability lies when AI-generated works infringe copyright-protected works. The current liabilities for copyright infringement should apply, but the issues will be clarified through litigation. Resolving the potential continuum of responsibility that arises with the actual situations in the litigation will be a more realistic approach, rather than rushing into a legislative solution that may have unintended consequences. The solutions must be consistent with the public policy issues discussed in other sections of this questionnaireRecommendations","Diagnose and Understand the ProblemsIn this submission, we have pointed out some areas of deep concern, but have not necessarily proposed concrete or well-developed proposals of how they could or should be addressed. Expedient short-term solutions are not always the best way to proceed with problems arising with rapid change, as the hasty legislative “solutions” can create a whole set of new and unintended negative consequences. Diagnosing and understanding the problems is the important first step in finding viable solutions and this requires time and careful consideration. Further Consultation Must extend beyond Copyright Stakeholders. We believe that it is crucial that public policy and legislation concerning Artificial Intelligence should be undertaken only after wide public consultation and discussion that includes broad public policy concerns such as protection of privacy and personal information, and other human rights. It is clear AI is introducing significant disruption to current realities, and it is important to remember that this disruption is taking place not only in the commercial marketplace, but also in research and in many other spheres of public life. Across the globe, we are struggling to understand the impacts of this rapidly evolving technology. Despite its many benefits, there are many public interest issues that are of concern to LAMs, concerns that go well beyond copyright—for example machine learning bias, misinformation, privacy issues, data breaches, and protection of freedom of expression. The Archival Community believes that all these issues require careful examination and public consultation that extends beyond this consultation and its copyright concerns. We believe it’s just too early to know how to deal with some of these complex and rapidly emerging problems.Any changes to policy and legislation, be it copyright or other initiatives, must safeguard the public interest and privacy considerations. Effective public consultation with public interest groups and the broad General Public on the complex issues surrounding AI must take place. It is not only copyright stakeholders and those with a vested interest in the marketplace who should be part of the discussion. Copyright concerns for AI must not be addressed in isolation and without reference to broad public concerns, including the professional, economic, and social disruptions that come with AI. These are extremely important issues for archivists because of the nature of our holdings and our public service mandate. Broad public consultation and discussions are required to develop sound public policy and legislation that will avoid decision-making that is solely market-oriented. The public good will be served by such consultations that are in line with Open Government policies and processes already in place in the Canadian government.AI is developing at a galloping pace, but we must avoid knee-jerk reactions that do not take into consideration the broad range of public policy issues that are intricately connected to this emerging technology.Only Litigation Will Solve Some Problems We believe that some of the thorny issues around AI will only be clarified through litigation. This is inevitable in any environment of rapid change. Allowing the litigation to follow its course may be helpful in seeing clearly where the problems are. Recommendation:"
Canadian Electroacoustic Community,Association,N/A,"""What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?""More clarity would provide increased security for both the AI and creative industries: confidence within the AI industry that the risk of unwanted, unexpected, or unnecessary legal challenges will be low; and confidence within the creative industry that AI will not be trained on an artist's own work to essentially and effectively replace that artist.""Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?""Yes. This is essential, at least in the early stages of developing a framework for the ethical use of AI (i.e. over the coming 5 to 10 years), in order to not only track and monitor what works are being used to train AI systems, but, importantly, to allow for investigations into the relationships between such 'training' works and any AI outputs, in the hopes of establishing and measuring ethical use standards.","""Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?""Yes. However, the primary issue here, it seems to me, is that 'reproduction' of copyright-protected work is no longer an appropriate or adequate measurement in this new context of AI-training and its impact on AI outputs. Thus, either:a) Copyright law needs a new extension and new framework to tackle this new form of use; or,b) If copyright law cannot be extended beyond reproduction etc. of copyright-protected work, then copyright law is not the correct context for establishing a legal framework for the training of AI in creative practices, and a new legal framework must be established.","""Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?""Focusing only or primarily on the ‘reproduction’ of a copyright-protected work is insufficient and inadequate. One of the main uses of AI in creative contexts is to produce new works that replicate the style of existing content. This means that, as soon as a human creator produces a creative work, AI is then immediately able to create an infinite number of works that directly replicate the human creator’s creative style, which is a central and essential aspect – or even THE essential aspect – of an artist’s creative communication with their audience, through a personal artistic ‘signature’ – all without the AI directly ‘reproducing’ the original artwork.In the absence of bespoke protections in this new environment, this would have the same consequences as having an artist’s work immediately fall into public domain upon its release, and a single output by any artist would immediately defeat the need for any further work by that same artist (as AI would be able to self-generate an infinite amount of content in that artist's style).It is possible, therefore, that traditional copyright is the wrong approach, and that a new bespoke framework should be developed for TDM and AI etc.""Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?""Yes. As discussed in the consultation text, there are a number of parties who might bear partial or complete responsibility – or, on the other hand, none at all – for copyright and other ethical transgressions. It is essential for all parties involved that these degrees of responsibility be established with clarity.",N/A
Canadian Independent Music Association (CIMA),Association,"N/AN/AIn the music business, AI-generated content is not pervasive in the generation of music or audio content. While some may use an AI system for inspiration or ideas, the more typical use of AI systems is in the marketing and image generation that accompanies audio content. We strive to keep it this way.To mitigate the risks associated with the use of AI, music businesses are both expected to read and comply with the terms and conditions associated with the use of an AI system. Music companies also ensure they have errors and omissions insurance, to prevent against unforeseen liability or perceived infringement of copyright-protected works.However, beyond music companies, artists themselves are also at risk of copyright infringement through user-generated content which proliferates online. The ""Fake Drake"" example is at the core of this issue, whereby the song ""Heart on My Sleeve"" gained significant traction by using artificial intelligence to imitate the vocals of Drake and The Weekend. To counter such circumstances, copyright legislation must be strengthened to include protections for an individual's identity and likeness. This will mitigate risks not only for creators and rights holders, but also for the broader public.All the above is central as to why copyright policy must be focused on the work of humans.As it relates to the music business in Canada, CIMA presumes that AI systems are developed through the acquisition of fragments of publicly available works. Large language models ingest entire works into the model and then draw upon fragments to generate new works. By virtue of the making available of content broadly, humans are involved in the development of AI systems but the making of music itself.That noted, the quantity of original data that can be found in AI generated work begs the question of storage. For the cultural industries, and notably in the music industry, we understand that AI systems must go beyond text and data mining activities to also include the storage for an extended period of time. This storage and use are not typically compensated, and thereby contravenes either commercial agreements, existing copyrights, or both.Some technology companies claim that because they are storing vectors they are not making a copy. We believe this is not a sufficient excuse. Copying is copying, not storage, especially given that all forms of music storage are already mathematical representations (including sheet music).It should also be noted that with respect to human involvement in the development of AI, technology companies have already admitted to the necessity of utilizing content protected by copyright. In a submission to the UK House of Lords, OpenAI recently stated that developing and training AI models without the use of copyrighted material is ""impossible,"" and that ""legally, copyright law does not forbid training"" (https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai). We disagree with this interpretation.Finally, it's important to understand that user input into AI systems do not get incorporated into the models. The models are static because adding any new data points necessitates recalculating all of the vectors in the entire model — a process that, in a large model, takes weeks, not daysAs mentioned previously, AI systems are not typically used in the core business of making music recordings, with some exceptions. The more pervasive use of AI generated content is in the development of marketing tools, such as written copy or images.This noted, contemporary artists have begun to explore the use of AI systems in the creation of music as a tool in the broader musical and creative process. Notwithstanding any potential infringements of copyrights and commercial agreements, CIMA is largely supportive of the use of artificial intelligence as a tool in the creation of content.Put simply, music has long been created using evolving technologies. All instruments are examples of technological development, and technological innovation has co-existed with music creation forever. Keyboard instruments were an innovation that helped standardize western music theory. Fretted instruments were once a technology innovation. Wound-pickup electric guitars are a technological innovation. Drum machines are an innovation. Virtual drummers that make human like variations in tempo are arguably an example of artificial intelligence applied to music creation. The use of an AI system in support of the creation of a musical work is an extension of the use of technology broadly in recorded music.CIMA notes the effect of AI on the music business, notably for platforms like Spotify and Deezer. With the ability to use AI systems to generate massive quantities of sound recordings, or white noise, music platforms have already and will continue to consider changes to payment distributions. The quantity of AI generated music has also shifted the algorithms which govern music platforms and have made the idea of a world in which AI-generated music is the default content increasingly possible.While these issues go beyond the scope of Canada's copyright regime, CIMA believes that the Government of Canada must consider these market forces as it considers the regulation of AI systems broadly, including through the potential amendments to the Copyright Act.","CIMA's position is that the current copyright regime is sufficiently clear around the issue of TDM. We assert that TDM is a licensable right, unless it clearly falls under a fair dealing exception, such as non-commercial research purposes. The current text on the fair dealing exception under the Act provides sufficient clarity on this question.CIMA does note, however, that the issue of data laundering under the guise of fair dealing has increased as an issue in Canada. We have observed that content accessed in an institutional setting, presumably for research purposes, is being used by commercial entities which fund scientific research. This, obviously, is a contravention of the fair dealing exception, both in the spirit and in the text of the Act, and requires further enforcement and study.CIMA does not have a clear sense of the amount of TDM activities currently being conducted in Canada, as it relates to the music business. This noted, we wish to point the Government to a subsequent issue, not asked in this consultation, which we believe is germane to the topic of AI and copyright. For the generation of music content, CIMA is concerned about the storage of datasets derived from TDM which can be used in the creation of sound recordings and content.CIMA is not currently aware of any TDM licenses certified by the Copyright Board of Canada related to the music sector. We are aware that licensing of works for TDM activities occurs in cultural industries beyond music, as cited by Access Copyright in their submission to the 2021 consultation on copyright, AI, and the Internet of Things, but this issue has not yet been raised in the independent music business.While CIMA is not aware of specific copyright licenses currently available in the music sector related to TDM activities, we note that TDM is itself licensable as an exclusive right. Therefore, market-negotiated licenses are available.CIMA is concerned that generative works are drawing on a large number of discrete fragments to generate new works. Our position is that TDM is a licensable activity to construct the models, and therefore, there is no need for a TDM exception under the Copyright Act.In terms of impact, we are concerned about the potential for death by a thousand paper cuts. The regulatory system must rebut a world in which derivative works are developed on a mass scale, all using small enough fragments, such that infringement may become virtually impossible to prove without sufficient rules for data provenance, transparent record keeping and source attribution.Yes, AI developers must track and be able to disclose what copyright-protected content was used in the training of AI systems. Fundamentally, all scientific and academic research functions in this way – we believe the same should be applied to the developers of AI systems, in and beyond an academic environment. These obligations represent some of the only, tangible ways for rights-holders to ensure their work is not unduly or improperly used. In short, we believe that the principles of data provenance and source attribution are key to the obligations on AI developers.Remuneration is dependent on use, especially in the context of scientific research beyond the scope of fair use. That noted, CIMA again raises the emerging issue of data laundering, wherein data collected under the guise of an academic or research purpose is used for commercial purposes by the funder of the initial project. Remuneration must account for this issue, should enforcement not increase.CIMA also notes that Canada has a long and robust history of music licensing agreements. Given the success of this work, including in licensing to and for digital services, this framework should underpin the Government's copyright approach on AI.CIMA points the Government of Canada to the consideration of this issue in Japan and our equivalent organisation, the ICMJ. As we understand it, the exception in the copyright regime directly incorporates the language of the third step in the Berne three-step test:As CIMA understands it, the Berne three-step test states that limitations and exceptions cannot be overly broad, cannot rob rightsholders of a real or potential source of income that is substantive, and/or do disproportionate harm to the rightsholders.The Government must implement all three steps of this test in its consideration of a TDM exception to the copyright regime in Canada, as it is a signatory to the Berne Convention.CIMA also notes that the approach taken by Singapore, which allows across-the-board TDM for any purpose, commercial or otherwise, with few royalties paid and little accountability. We believe this approach would be both in contravention of Canada's position on the Berne Convention and would undermine the music rights licensing market in our country.","N/ACIMA posits that the current jurisprudence of Canada's copyright regime is sufficient clear on the ownership and authorship of copyrightable work. Put simply, copyright is for the benefit of human creators: this requirement should be consistently applied.CIMA acknowledges the complexity of the amount of human involvement necessary to trigger the copyright regime. It is our position that for the creation of sound recordings, a human's contribution must be musical in nature in order for the work to be copyrightable. Put tangibly, if the only input from a human is the text prompt for the creation of a sound recording, this is not a musical contribution. If, however, an artist uses AI to augment the sound the individual created using an instrument, this would represent a musical contribution.CIMA believes this delineation is already clear, and continues to be confirmed by jurisprudence and other practices, including the decisions of the USA Copyright Office on a similar issue.CIMA points the Government of Canada to the OECD Principles on Artificial Intelligence, adopted in May 2019 by OECD member countries (including Canada). The principles ""promote a human-centric approach to trustworthy AI"" and call for respect of human ""freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognised labour rights"" throughout the AI system lifecycle.Canada is also signatory to other agreements and declarations which address copyright and AI broadly, including:G20 New Delhi Leaders' Declaration (9-10 September 2023) recognized the importance of respecting intellectual property rights in the building of digital public infrastructure (https://www.g20.org/content/dam/gtwenty/gtwenty_new/document/G20-New-Delhi-Leaders-Declaration.pdf).G7 Digital & Tech Ministers' Statement (7 September 2023) on the Hiroshima AI Process committed to developing guiding principles for the development and deployment of advanced AI systems, including consideration for copyright and data protection (https://www.politico.eu/wp-content/uploads/2023/09/07/3e39b82d-464d-403a-b6cb-dc0e1bdec642-230906_Ministerial-clean-Draft-Hiroshima-Ministers-Statement68.pdf).Leaders of the G7 agreed on 30 October 2023 to the Hiroshima Process International Guiding Principles for Organizations Developing Advanced AI System, which provide that organizations should ""implement appropriate data input measures and protections for personal data and intellectual property,"" further noting that ""[a]ppropriate transparency of training datasets should also be supported and organizations should comply with legal frameworks."" (https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-principles-advanced-ai-system).The Hiroshima Process International Code of Conduct for Organizations Developing Advanced AI Systems, which calls on such organizations to ""implement appropriate safeguards, to respect rights related to privacy and intellectual property, including copyright-protected content."" (https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-advanced-ai-systems).CIMA also notes that the United Kingdom studied the implementation of a TDM exception and decided to not pursue this. We would welcome this outcome in Canada.","CIMA raises the issue of the term 'substantial' in this legal test. To articulate our concern, we raise this concept: CIMA would acknowledge that individual fragments of sound recordings used in the creation of an AI-generated sound recording would not represent a substantial part of a new creation. However, should multitudes, potentially hundreds or thousands of these fragments across different copyrightable works be used, we do not believe the current regime to be clear as to at which point they become substantial in aggregate.This issue is, in part, why CIMA proposes that AI system developers be required to keep records of the content used in the training of an AI system. Understanding of data provenance and source attribution would allow rights-holders to have the ability to determine if their work was used for this purpose.When considering whether an AI-generated work infringes copyright, one must also look at what copyrighted works were included in the training dataset used to construct the AI model, and the model itself which stands between the input source material and the output creation of new works. TDM for the training of AI models consists of compiling the training dataset, converting its contents to vector form and arranging it in high-dimensional space. Depending on the specific facts and circumstances, a trained model itself could therefore be viewed as one or more of the following: an infringing derivative work, an infringing compilation, or an infringing reproduction. The important point is not to limit the infringement analysis to just the output, but to also consider the input sources and the AI model itself.In the music industry, there is no, current industry standard in labelling and keeping records. Fundamentally, these two tenets are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output.As we have stated elsewhere in this consultation, CIMA believes active and consistent record keeping and disclosure rules are necessary to prevent against the black hole of potential copyright infringement by AI systems. This must go beyond watermarking to also include an audit trail.CIMA raises for the Government of Canada that some music businesses are exploring a poison pill approach in the generation of their music to prevent against this issue. Some artists and music businesses attempt to include data in their sound recordings that will be detectable should that content be used in an AI-generated work. This system is of interest, but fallible, and does not represent a sustainable, industry-driven solution to the issue of copyright infringement by AI-generated outputs. This risk is most apparent in the visual arts, including through the Getty legal case regarding watermarking in the United States.CIMA believes that if AI is used in the generation of commercial content, the publisher of this work should be liable for any copyright infringements committed by the system. If an individual is a customer of an AI service, and not generating content for sale, the individual should not be personally liable. The onus should continue to be on the AI company.If the Government of Canada believes the current system is unclear or not in alignment with the position above, CIMA believes greater clarity on liability would be worth articulating.","While AI-generated work has not proliferated in the music business to the degree it has in others, CIMA is greatly concerned about the use of cultural work in AI-generated content in perpetuity. At its core, CIMA believes that a rightsholder continues to have interest in their work throughout its licensed or unlicensed use in AI systems. The right to authorize the use of copyrightable content in TDM derived work must be considered and added to the Canadian copyright regime to solidify this position.As the consultation paper notes, cultural work put into an AI system and turned into a new piece of content still includes identifiable, and copyrightable work. The right to license work for this purpose must be articulated in Canada's copyright regime."
Canadian Media Producers Association (CMPA),Association,"A. Technical EvidenceThe use of AI in the production sectorCanada’s independent producers embrace the possibilities of Generative AI when used responsibly, ethically, and lawfully. These principles include respecting the rights in the content being used to train the systems and recognizing the importance of human expression in copyright-protected works and other subject-matter. For CMPA members, AI is a tool that supports – but does not supplant – human creation.There is a need to distinguish between AI tools that assist with the creative and production process and those that use existing copyright-protected works and other subject-matter to generate content that competes in the market. Technologies using some form of machine or artificial intelligence in the production of film and television projects are not new. Editing, visual effects (VFX), and computer-generated imagery (CGI) often employ AI-technology to make shows more realistic. AI can be used to streamline location scouting and budgeting, financial forecasting, and modelling. It can also assist with camera automation and scene optimizations, visual effects, colour-correction, sharpening detail, and sound mixing, among other things. When used responsibly, AI can provide tremendous value to the creative and production process and ultimately produce a better product on the screen. AI, like other tools, can also be used to support the creative process by handling routine, repetitive and sometimes menial tasks in production and post-production. Producers and their suppliers routinely use a range of technological tools, including AI, to create and produce film, television, and digital media content. This saves production costs, time and resources that can be used elsewhere. As we understand it, these tools are not the sorts of technology that is the subject of this Consultation. Instead, the Consultation is focussed on Generative AI, meaning diffusion models and large language learning models that can generate high-quality text, images, music, and other content based on the content they were trained on. While Generative AI can be useful to automate monotonous tasks, like writing an email or designing layout, it does raise different copyright policy implications than the first-generation AI tools mentioned above. As noted in the Consultation, the TDM used in the training of Generative AI systems involves the reproduction of large quantities of data and copyright-protected works. This raises a number of issues.First, the “inputs” into TDM are often copyright-protected works, for which no licences or permissions are sought. Consequently, there is little, if any, compensation flowing to rightsholders for the use of their works.Second, the data and works used to train Generative AI technology is a black box. Rightsholders have no insight or information about whether their works or other subject-matter were used to train a specific system. This creates not just licensing and enforcement problems for rightsholders, but also issues with respect to unknown biases, authenticity, attribution, and overall trustworthiness of these systems for users. Third, Generative AI can output high-quality content that competes with the market for rightsholders’ works. To date, AI-generated videos remain relatively primitive and short and as a result, we have not seen a public Generative AI platform that is producing high-quality full-length television shows or feature films. However, we expect that as the technology advances this type of application will develop.Fourth, AI can generate deepfakes, holograms, stand-ins, voiceovers, and reproduce an actor’s voice and/or likeness or a writer’s style. While not necessarily triggering copyright per se, these uses are copyright-adjacent and must be considered when examining the copyright policy implications of Generative AI.","B. Text and Data Mining: No New Exceptions are RequiredThe Copyright Act is technologically neutral, meaning that copyright law has developed and should continue to develop in ways that are independent of any particular technology. Existing copyright laws are adequate to encourage innovation in the development of Generative AI and ensure that rightsholders are properly compensated when their rights are engaged. As noted in the Consultation, there are two possible exceptions to copyright infringement that could apply to TDM activities: fair dealing under section 29 and the exception for temporary reproductions for technological processes in section 30.71. Both exceptions, or user’s rights, are available to Generative AI developers. It is our view that these exceptions are sufficient to allow certain uses of copyright-protected works in TDM, as appropriate. As such, no new exceptions are required.Fair dealing for the purpose of research under section 29 of the Act is flexible enough to allow certain TDM required for certain AI uses (i.e., the “inputs”) if determined by a judge to be “fair” based on the facts. A fair dealing assessment will balance the interests of rightsholders and users on a case-by-case basis, by considering several factors, including the purpose, character and amount of the dealing, the nature of the work copied, alternatives to the dealing and the effect of the dealing on the work. Implementing any sort of specific TDM exception would require a careful examination and balancing of all these factors. Various TDM exceptions around the world have attempted to incorporate some of these safeguards into the exception itself, such as requiring the use be for “non-commercial research only” (UK) or the “sole purpose of research” (France), making the uses available only for certain organizations such as not-for-profit partnerships, public libraries, archives and museums (France). Other TDM exceptions create conditions on the use: for example, the exception is only available if there is lawful access to the original work (UK) or if the first copy is not infringing (Singapore), the use does not “unreasonably prejudice the interests of the copyright owner in light of the nature or purposes of the work or the circumstances of its exploitation” (Japan); the copy is accompanied by sufficient acknowledgement (UK), the copies are not shared (UK) and numerous other conditions. Importantly, none of these TDM exceptions have been able to provide the level of balancing between rightsholders’ and users’ interests that Canada’s fair dealing exception can provide.Additionally, we have not seen any evidence that a new exception for TDM is necessary. Generative AI platforms are flooding the market and there is no evidence that the current copyright framework is disincentivizing innovation in the field. To the contrary, several platforms appear to believe quite strongly that the training of their systems does not infringe copyright. Google, Microsoft, OpenAI, Adobe and Getty are all indemnifying their users against copyright claims that might result from the use of their platforms and the distribution of content generated by them. [See for example, Adobe’s indemnity, which reads: “ With Firefly, Adobe will also be offering enterprise customers an IP indemnity, which means that Adobe would protect customers from third party IP claims about Firefly-generated outputs”, Google’s indemnity here: [https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification], and Microsoft’s here: https://www.microsoft.com/en-us/licensing/news/microsoft-copilot-copyright-commitment].The Consultation suggests that “clarity” might be required. But introducing an exception in the name of “clarity” now would mean the Government is merely anticipating the impact of rapidly changing technology in a developing market. We caution the Government on moving quickly to provide broad exceptions for TDM when the technology is changing so rapidly, its potential impacts cannot readily be known and the market is developing.In fact, the introduction of an exception would disrupt a burgeoning licensing market for the use of copyright-protected works and other subject-matter for TDM in Generative AI. There is no reason to believe that copyright owners and Generative AI developers cannot enter into voluntary licensing arrangements as long as the parties are willing to negotiate. In some industries, direct voluntary licensing is already happening. OpenAI has entered into some licence agreements to pay for content to train its models, such as the photographs, video, graphics, music and “high-quality training data” provided by Shutterstock [https://investor.shutterstock.com/news-releases/news-release-details/shutterstock-expands-partnership-openai-signs-new-six-year] or the literary works provided by the Associated Press [https://www.ap.org/ap-in-the-news/2023/chatgpt-maker-openai-signs-deal-with-ap-to-license-news-stories#:~:text=ChatGPT-maker OpenAI and The,AP's archive of news stories]. These types of market-based solutions represent the desired outcome: they both respect copyright owners’ rights by providing market-determined compensation and facilitate the training of Generative AI systems.Voluntary licensing is both feasible and desirable. The Government ought to take a laissez-faire approach and let the market work itself out. The fair dealing exception ought to be fit to handle the analysis for appropriate cases. Until and unless the market, Canada’s courts, or the Copyright Board exposes a real gap with respect to Generative AI that needs to be addressed, there is no valid policy reason to introduce any exception for TDM. Notwithstanding various examples of direct, voluntary licensing in the market, rightsholders are facing challenges in licensing their works for TDM activities. The biggest barrier is caused by the lack of information available to rightsholders in terms of the content that is being used to train Generative AI systems. This information asymmetry causes an imbalance of power between rightsholders and system developers, which is generating market inefficiencies and may ultimately cause potential market failure. A simple fix to this problem is the imposition of transparency principles, which have been implemented in various jurisdictions around the world. We discuss these principles in more detail below.","C. Authorship and Ownership of Works Generated by AIClarity on the question of authorship and ownership of works generated by AI is desirable, but it remains too early to determine what that solution should be. It is the CMPA’s view that this issue requires further study and consultation before the Government makes any anticipatory changes to the Copyright Act.Certain generative AI outputs must attract copyright protection. From a copyright policy perspective, AI tools ought to be able to produce content that is protectable and exploitable, provided there is an exercise of skill and judgment in its creation. As noted in the Consultation, while the Copyright Act does not explicitly define the word “author”, case law suggests that authorship must be attributed to a human who exercises skill and judgment in creating the work. Moreover, since the Government’s last copyright consultation on AI in 2021, there seems to be a generally accepted international consensus that human authorship is a bedrock requirement for copyright protection and that content generated by AI without any human involvement is not, and ought not be, protected by copyright. The existing standard of originality for copyright protection, which requires the exercise of skill and judgement that is not trivial or purely mechanical, remains appropriate for AI-generated works. No other higher standard of originality need be introduced for AI-generated content. As noted in CCH v. The Law Society of Upper Canada, “A standard requiring the exercise of skill and judgment in the production of a work…. provides a workable and appropriate standard for copyright protection that is consistent with the policy objectives of the Copyright Act”. The current (low) standard of originality ensures that authors are not undercompensated for their work and that authors and other rightsholders do not face unnecessary and prohibitive bars to licensing, other exploitation opportunities, and infringement claims. Any push for a higher standard of originality for copyright protection ought to be rejected outright.As noted above, AI tools are routinely used in the creation and production of audiovisual productions. Producers make significant investments into their productions and must have certainty that these investments are protected and capable of being exploited on an exclusive basis.There have been some recent U.S. examples of content produced by generative AI systems where copyright protection was denied, despite the exercise of hundreds of hours of work by the creator/users, including experimenting through extensive prompting and inputting numerous revisions. (See for example, Jason Allen’s artwork, “Theatre D’opera Spatial,” created with Midjourney.) These examples illustrate some of the challenges producers and other rightsholders will face with the current uncertainty around authorship and ownership of AI-generated works. Generative AI output must be protected by copyright to prevent others from exploiting the portions of audiovisual productions that may be generated by AI. If it is not, others will get a free and possibly deceptive ride on the creation, production and marketing costs related to those portions. If these investments and output are not protected by copyright, there will be little incentive for producers to use AI tools in the creation of their productions.One of the approaches to the question of authorship and ownership identified in the Consultation is that the Government clarify that copyright protection applies only to works created by humans. While the CMPA remains of the view that human authorship should be a requirement for copyright protection, this approach leaves open the possibility that those portions of works that were generated by AI would be ineligible, or excluded, from protection. Rightsholders would be required to parse out the individual pieces of their work that were generated by AI and make claims only for those portions that were not. Indeed, the U.S. Copyright Office appears to be requiring copyright registration applicants to disclaim and disclose AI-generated content that is more than de minimus. If similarly applied in Canada, these types of developments would be prohibitively rigid for producers, not appreciate the use of AI as a tool in the creative process, ignore the significant contributions of human creators, and disregard the exercise of skill and judgment in the creation of a work. As it applies to audiovisual works, which are the product of dozens (if not more) individual contributions, each of which may have used some AI tools in their creation, this is unworkable.Another possible approach is to attribute authorship to the person who arranged for the work to be created. The Consultation indicates this would be a similar approach to the United Kingdom, but it is also similar to the sound recording maker’s right in section 18 of the Copyright Act pursuant to which “the person who makes the arrangements necessary for the first fixation of the sounds” has a copyright in the sound recording.This approach may ultimately provide the requisite clarity but requires significant further study and consultation to ensure the appropriate rights and protections are put in place, particularly given that such an approach could apply to various types of content, different stakeholders, and different industries.The Government’s third approach suggests creating a new and unique set of economic rights for AI-generated works to a person who did not provide any original contribution to such works, such as an AI developer, deployer or user. While the Consultation likens this to the maker’s right, this approach alone would not solve the question of copyright ownership in AI-generated works that do have original contribution. A layering of rights may be appropriate, but more evidence and consultation would be required to establish the rights and policy implications.The CMPA proposes that no changes be made to the Act at this time to address issues of authorship and ownership of AI-generated works. However, the question is deserving of further study as the technology, Canadian case law and international consensus develops. We propose that the Government continue to monitor international developments, and actively participate in ongoing discussions, maintain a watching brief and continue to consult with all stakeholders on whether and what changes to the Act are necessary to clarify authorship and ownership of AI-generated works and provide certainty in the marketplace.","D. Infringement and LiabilityAs previously discussed, the CMPA’s primary concern about existing legal tests for demonstrating that an AI-generated work infringes copyright is that it is difficult, if not impossible, to determine whether the system that generated the work was trained on or had access to the allegedly infringed work. The content used to train any particular Generative AI system is a black box. Rightsholders have no idea whether their works have been reproduced or whether any alleged similarity to their works are mere coincidence. This creates problems not just for demonstrating infringement, but also impedes licensing opportunities. The current legal test for establishing infringement in Canada includes a requirement that the plaintiff establish a “causal connection” between the allegedly infringing work and the original work; in other words, that the defendant had access to the original work. But without some knowledge or information about what’s inside the box, rightsholders plaintiffs are left to infer or make assumptions about whether their work was copied. Various lawsuits launched in other jurisdictions illustrate the issue. In a Stability AI/Midjourney case launched in the US, the defendants claim that the rightsholder plaintiff could not proceed with infringement allegations unless she identified with specificity each of the works she believes were used as training ‘inputs’ for the alleged infringing system. [https://fingfx.thomsonreuters.com/gfx/legaldocs/byprrngynpe/AI COPYRIGHT LAWSUIT mtdruling.pdf] Rightsholders will also undoubtedly face similar evidentiary issues as many datasets used to train Generative AI systems are purportedly destroyed after the initial training is complete.In terms of licensing opportunities, developers of Generative AI systems can take advantage of the balance of power that shifts to them because of that information asymmetry. The developer quite clearly has all the information, making transacting difficult and inefficient at best. At worst, licensing transactions are impossible and may cause the market to fail.The answer to this information asymmetry is not to create new exceptions or change the legal test for establishing infringement. Instead, the Government must help balance out that negotiating power by incorporating certain transparency requirements into Canadian law, whether through the Copyright Act, the Artificial Intelligence and Data Act (AIDA) or otherwise. At a minimum, the core requirements should include obligations on providers of Generative AI systems to: disclose that the output content was generated by AI; design the model to prevent it from generating illegal content; and publish information about the copyright-protected content that was used to train the system. [See for example, the EU AI Act, as summarized in the press release: Artificial Intelligence Act: deal on comprehensive rules for trustworthy AI | News | European Parliament (europa.eu)]The imposition of transparency requirements will assist rightsholders in their licensing activity and determining infringement. But transparency requirements will also assist users in assessing the validity of data, biases inherent in any given system, and help ensure these systems are responsible, lawful, safe, transparent, accountable, and non-discriminatory.","E. Conclusion/Comments/SuggestionsThe CMPA agrees with the Government that additional evidence and consultation is necessary to inform policy decisions in the area of Generative AI. As such, we applaud this important consultation. We also maintain that the Government should take a very measured approach in its consideration of whether any legislative change is required to deal with issues on Generative AI at this time. Good policy requires good evidence, and enacting legislative change to deal with theoretical issues resulting from nascent technology does not make good policy. The one clear issue that demands immediate attention is the lack of available information about the content being used to train Generative AI systems. We ask the Government to implement transparency requirements on all developers of Generative AI systems similar to those that are currently being implemented in the EU.Otherwise, we encourage the Government to exercise restraint in the area of Generative AI, keep a watching brief as these technologies develop, publish any evidence received as part of the Consultation and seek comment on policy considerations based on such evidence."
Canadian Publishers’ Council,Association,,"Our principal concern will always be the upholding of rightsholders’ rights – both authors/creators and publishers – as the market for AI-generated content evolves. It is critical that rightsholders’ consent be obtained for training AI systems. In our view, training AI systems involves multiple reproductions and adaptations of works. There is no question that copying is involved when works are downloaded for training purposes, when works are copied and compressed into AI models, and in many cases the outputs from systems training on publishers’ materials are reproduced verbatim or are adaptations that include substantial parts of ingested materials because the AI systems’ “memorization” capabilities (1).Further, in our view, the models training, the models ts that are trained using publishers’ works, and many of the outputs would infringe copyright, subject to any defenses such as fair dealing for the purpose of research (discussed below). It must be borne in mind that a work is reproduced when it is copied in “any material form”. This means that a work is reproduced even it is encoded in any language or notation (including tokens generated during AI training) or is stored in a compressed form from which publishers’ works can be perceived by or with the aid of a machine or device (2). Thus, training AI models using unlicensed publishers’ works implicate the reproduction right because of the three different processes involved in training AI models and providing services using them that generate outputs. Further, operators of generative AI systems that produce synthetic outputs that contain reproductions of all or any substantial parts of publishers’ works may also infringe the authorization right and/or the making available rights under the Copyright Act (3).With that said, any litigation necessary to vindicate publishers’ exclusive rights would be costly and would likely take many years from when a case is commenced until it is ultimately resolved by the Supreme Court. In the interim, many AI operators including the very large platforms will likely continue to exploit publishers’ works without consent or providing any form of compensation. Further, publishers would be unable even to collectively license their works for training purposes using the Copyright Act’s tariff system because of the unfortunate decision by the Supreme Court that held that even certified tariffs are not mandatory. While the law is clarified by the courts, AI operators may continue to unfairly copy publishers’ works and thereby compete with publishers’ commercialisation of their publications and undermine their own adoption of AI systems.We note that France’s National Assembly Bill aimed at regulating artificial intelligence by copyright (5) would expressly require the authorization of authors or rights holders for training or exploitation of artificial intelligence systems.For the above reasons, the CPC recommends that the law be clarified to provide an express right of publishers to authorize the use of their works in AI systems that are trained or made available for commercial purposes (“commercial AI use”). Further, to avoid providing foreign AI operators an advantage over Canadian operators, the training authorization right should apply to any AI systems that make the service available in Canada.As noted above, some uses of publishers’ works could fall within a fair dealing exception. The Supreme Court has construed the fair dealing exception for research and the fair dealing factors as user rights. Under the Supreme Court precedents, the exception for research may include activities that are not limited to non-commercial or private contexts and can include those that “facilitate” research and even large scale infringements can, in certain instanced, also be considered to be fair (6). However, publishers view the research exception as intending to promote the goal of research conducted by human beings and do not accept that training machines even to facilitate research by human beings is compatible with the human centric goal of research under the fair dealing exception. However, the law on this has not yet been settled in Canada.Of course, all fair dealing determination are questions of fact and “a matter of impression” and are left to the courts. Therefore, publishers recommend that the clarified exclusive right to authorize commercial AI use not be subject to any fair dealing exception.The CPC strongly objects to any TDM exception. It would be impossible to properly calibrate such an exception to take into account all of the evolving AI business models and uses of publishers’ works for AI purposes. Further, given the evolving market for publishers’ own exploitation and licensing of their works for AI purposes, any TDM exception would undermine market forces and effectively create an uncompensated compulsory license. A TDM exception could violate Canada’s TRIPs and other treaty obligation that prohibits any exceptions to copyright that would violate the Three Step Test.It is also critical that companies developing AI systems be required to accurately track, retain and disclose content sources used for AI training, without any attempt to rely on existing exceptions (e.g., Research, Education) to circumvent this requirement. In the absence of this protection, it is impossible for rightsholders to know if their works have been ingested for training purposes, given the vast scope of inputs into Generative AI models, and the ‘black box’ nature of their modeling.There are several ways to help promote transparency.First, there should be a Bill of Discovery right to enable rights holders to obtain disclosure as to whether their works were used to train AI models.Second, amendments could be made to Canada’s draft Artificial Intelligence Act (AIDA) to expressly include transparency requirements on persons who make available or manage a general-purpose system along with the other transparency requirement currently being proposed by the Minister. AIDA should also require such persons to respect Canadian copyright laws regardless of where the training and deployment of the AI systems takes place if the AI system is deployed in Canada. Publishers also view the unlicensed use of their copyright content to be very damaging and recommend that the term “harm” in AIDA expressly include the economic and moral harms to authors and publishers associated with generative AI systems.It is only in these ways that rightsholders can be assured of the opportunity to participate in the value chain created by use of their content for Generative AI. TDM activities are undoubtedly being conducted in Canada, in a broad range of applications that include media monitoring and scholarly research, especially in as Large Learning Models. Some of our members are developing their own AI solutions. For example, Thomson Reuters offers services called “Westlaw Precision” and “CoCounsel” which jumpstarts AI assisted legal research. A second offering built on Open AI’s GPT-4 provides legal professionals with document review, legal research, contract analysis, compliance and other functionality. Most of our members would also engage with existing AI platforms such as OpenAI’s ChatGTP.The principal challenge here is ensuring that exclusive rights under copyright law are respected. This includes tracking and disclosure of content use for ingestion into AI models, as mentioned above. Many providers of generative AI systems have disregarded copyright rights in the hopes they can become well established and eventually forestall having to pay for their unlicensed uses of works. The sooner the law is clarified, the easier it will be for publishers to license their works including for uses in Canada.Existing licencing mechanisms, both direct and collective, are available today to cover content licencing needs for AI model ingestion. For example, the Copyright Clearance Center (CCC) offers TDM licences for the use of literary a works. Many scientific, technical, and medical publishers (STM publishers) offer TDM licences in Canada. An example is Elsevier’s TDM licence which permits non-commercial research (7). Taylor & Francis offers a TDM license which can also include a license for commercial purposes.Further there are market developments that illustrate that developers of generative AI systems can develop AI systems using their own content or content that has been properly licensed from others. Examples are Getty Images (which uses its extensive library of licensed images), Adobe (with its Firefly generative AI model that is trained on Adobe Stock images, openly licensed content, and public domain content) (9), Meta’s AI image generator (which was trained on public facing Facebook and Instagram images) (10), and, as noted above, Thomson Reuters services called “Westlaw Precision” and “CoCounsel” (which are trained on its own proprietary content and public domain content it makes available).We believe it is critical that market forces be allowed to develop to facilitate appropriate licencing models for AI content ingestion, based on the framework exclusive rights provided by copyright law. It must be remembered that a TDM exception will provide no remuneration or compensation to authors or publishers. The copyright law provides a market framework by which market prices are set for the uses of copyright works. A TDM exception would operate extremely unfairly by undermining publishers’ own ability to exploit their works including for AI purposes. It would also, effectively, operate as a very unfair wealth transfer mechanism from authors and publishers to AI companies, many of which are very large and well funded companies. (Continued in Comment Section)","At this point in time, there is no evidence of an adverse impact on the development or adoption of AI technologies due to the copyright status of generated works. However, rights holders would be concerned providing copyright protection for works created entirely by computer generated content.We are of the view that the Supreme Court of Canada originality test is fit for purpose and would adequately address the copyright status of AI-assisted works. We believe that copyright should be reserved for human-created works that meet the test of originality. AI-generated works that have NO human intervention should not be protected by copyright.The approaches in the UK and other countries that provide protection for computer generated works were conceived before generative AI was introduced and would potentially provide protection for works created without the requirement of originality, which would not be appropriate.","There are no compulsory requirements for GenAI engines to record and disclose the datasets that are ingested for AI training purposes. In the absence of this requirement, it is difficult to determine what copyright-protected content has in fact been used. This adversely affects the ability of publishers to negotiate licenses or seek legal redress. We recommend the approach being adopted in the EU under the draft Artificial Intelligence Act (AIA) that would require transparency, except to the extent a creator uses its own works for training purposes (12). CPC members are vigilant only to use their own works or works that are licensed. This is not the practice of the large Generative AI companies like OpenAI, Meta’s LLM, or Google. There are instances of AI-generated content, derived from AI training from copyright-protected works, being fraudulently marketed as being authored by the creator of that copyrighted work (e.g., Clare Duffy lawsuit in U.S.) The extensive litigation in the United States shows that AI companies reject that outputs from their content infringe copyright. Some outputs clearly reproduce all or a substantial part of input data. The New York Times suit (referred to above) is a good example. However, grey area is where the outputs are derived from the training data, but specific outputs may not actual meet the test to be a reproduction under the Copyright Act. For example “style” may not be protected by copyright. But, generative AI systems are capable of and do produce output in the “styles” of authors, artists, and other creators. Further, “facts” are not protected by copyrights. But, here again, generative AI systems can wholly ingest facts as part of the ingestion of works and use these facts in output in ways that could complete with the publishers, a good example being a publication that is comprised of compilations. In a broader sense, all generative AI content is derived from copyright works or a mixture of copyright works and works in the public domain (such as where the copyrights have expired) or works that have been licensed.This “derived” content is extremely valuable and it would be very unfair for the copyright works to be appropriated to generate massive profits for AI companies with no control or compensation to publishers and other creators. A major challenge with the existing copyright law is that while a specific output may not be derived and reproduce a specific input, when taken in the aggregate many outputs would be derived from the aggregation of unlicensed copying of publishers’ and other creators’ copyright works.It is undoubtedly for this reason that France’s National Assembly Bill aimed at regulating artificial intelligence by copyright (13) would provide for compensation to be paid to authors for all generative AI content whose origin cannot be determined (14).This issue is an especially important one for Canadian publishers as, to date, much of the training of LLMs has been done in the United States. This leaves Canadian based publishers with few remedies in Canada for output that is largely derived from copyright works including where specific outputs are not infringing. Also as generative AI systems will often return different results from specific text based prompts, it may be difficult to make out a case of reproduction by relying solely on a specific output.CPC publishers therefore recommend that the Copyright Act be clarified so that all outputs of generative AI systems that are derived from copyright works, individually or in the aggregate, used without a license be deemed to be infringing reproductions.Footnotes(1) See, Exhibit J to the Complaint by the New York Times against OpenAI and Microsoft; also, Extracting Training Data from ChatGPT.(2) The Copyright Act makes it an infringement to reproduce a work (or a substantial part of a work) in any “material form”. This is a technologically and media neutral term that would make any copying into a form of storage a reproduction, regardless of the form of notation or encoding. See, Apple Computer Inc. v. Mackintosh Computers Ltd. (1986), 28 D.L.R. (4th) 178 (Fed. T.D.), varied (1987), 44 D.L.R. (4th) 74 (Fed. C.A.), affirmed [1990] 2 S.C.R. 209; Canadian Broadcasting Corp. v. SODRAC 2003 Inc., 2015 SCC 57, Robertson v. Thomson Corp., [2006] 2 S.C.R. 363; Labrecque (O Sauna) c. Trudel (Centre Bellaza, s.e.n.c.), 2014 QCCQ 2595.(3) If the outputs are copied by users, then the AI operators infringe the authorization right. If copies are only made available for viewing, then the AI operators my be liable under the making available right. See,Society of Composers, Authors and Music Publishers of Canada v. Entertainment Software Association, 2022 SCC 30.(4) York University v. Canadian Copyright Licensing Agency (Access Copyright), 2021 SCC 32 (“York”)(5) France National Assembly Bill No 1630 online @ https://www.assemblee-nationale.fr/dyn/16/textes/l16b1630_proposition-loi ““Article L. 131-3 ""The integration by artificial intelligence software of intellectual works protected by copyright into its system and a fortiori their exploitation is subject to the general provisions of this Code and therefore to the authorization of authors or rights holders"".(6) Society of Composers, Authors and Music Publishers of Canada v. Bell Canada, 2012 SCC 36; York(7) https://www.elsevier.com/about/policies-and-standards/text-and-data-mining/license(8)Getty made an AI generator that only trained on its licensed images – The Verge(9) Adobe Firefly – Free Generative AI for creatives(10) Meta’s new AI image generator was trained on 1.1 billion Instagram and Facebook photos | Ars Technica(11) There is a precedent for this. See ss. 29.4(3), 30.1(2P of the Copyright Act.(12) ""4. Providers of foundation models used in AI systems specifically intended to generate, with varying levels of autonomy, content such as complex text, images, audio, or video (“generative AI”) and providers who specialise a foundation model into a generative AI system, shall in addition: c) without prejudice to national or Union legislation on copyright, document and make publicly available a sufficiently detailed summary of the use of training data protected under copyright law.” EU AI Act (draft Compromise Amendments) May 9, 2023(13) France National Assembly Bill No 1630 online @ https://www.assemblee-nationale.fr/dyn/16/textes/l16b1630_proposition-loi(14) Article L. 121-2 ““Moreover, in the event that a work of the mind is generated by an artificial intelligence device from works whose origin cannot be determined, taxation intended to promote the creation is established at the benefit of the body responsible for collective management designated by amended article L. 131-3 of this code.“This taxation is imposed on the company which operates the artificial intelligence system which made it possible to generate said “artificial work”","Continued from TDM Section...If these or any other companies want to use AI works for training they should negotiate fair agreements and pay publishers for inputs the same they do for other inputs.Clearly content creators such as authors and publishers would want TDM activities to be conducted under licence only, and not under any newly-conceived exceptions. The expected impact is clear, and consistent with existing law: the protection of rightsholders’ exclusive rights and the concomitant opportunity to ensure proper compensation for use of their content. These rights and their safeguarding are the foundation that supports the creative industries broadly, and publishing in particular, and is the legal framework that encourages creative endeavours which in turn are critical to Canadian culture and voices. Moreover, this approach reinforces the notion that human creativity is at the heart of what Copyright has been established to protect, and will continue to be the critical input for the cultural sector even as Generative AI exerts more influence in the market for content. Lastly, it is only when AI Developers engage in appropriate licencing mechanisms that fulsome investment in AI development will continue, and consumer confidence in AI outputs will be strengthened.However, notwithstanding the foregoing, any TDM exception should not apply unless (i) the exception is purely for non-commercial research, (ii) the work used is not infringing and is not in breach of any license or contractual prohibition, (iii) any copying must be ephemeral, (iv) the resulting output cannot reproduce all or any part of the work used for training, (v) the copyright holder must be notified before the work is used, and (vi) there is no circumvention of any technological protection measure (TPM) or violation of the rights management information (RMI) provisions of the Act.We also note that Canada is obliged by international treaties (including the WCT and WPPT and the CAUSMA) to provide the latter protections, and any TDM exception must respect these obligations as well as the Three Step Test.Further, we recommend that if a TDM exception is to be proposed it should be subject to these conditions:This requirement is absolutely critical to the evolution of legitimate AI industry in Canada and beyond Clear and discoverable records of content use, with full disclosure requirements, must be the foundation for this framework, in order to protect rightsholders’ rights and ensure their ability to participate in the value chain that AI is developing. In the absence of such safeguards, human-based creativity is put at risk and may become increasingly marginalized.Market-based licencing mechanisms must be allowed to develop in this sphere. If the playing field is balanced between rightsholders and AI systems via the markets created by the system of exclusive rights , the price will set itself via negotiations.. The appropriate price should always be the price that is (or would be) negotiated by a willing buyer and a willing seller."
Colleges & Institutes Canada,Association,N/A,"Enhancing Copyright for Canadian CollegesAn important first step to supporting AI use in higher learning would be creating a clear exception for text and data mining (TDM). Adding this exception would modernize Canada’s copyright scheme and maintain the fundamental user-creator balance.The Supreme Court of Canada has provided that the proper copyright balance, “lies not only in recognizing the creator’s rights but in giving due weight to their limited nature.” The Court has also previously cautioned against tilting this balance in a way that limits creative innovation in the public domain, to support long-term interests in Canadian society. Text and data mining and AI have already proven to be useful tools for enhancing education and research.For example, the OER Studio at Fanshawe College is using generative AI to create chapter summaries, assessment questions, and supplementary learning materials from the primary content included in an Open Educational Resource (OER). The OER Studio also hopes to build on this by using AI to create more resources, such as audio-visual case studies and adaptive learning modules.In college applied research, TDM supports the planning, data collection, analysis, processing, design, prototyping, and developing new products and services for industry. Examples of AI applications in applied research projects include:Fleming College’s Centre for Advancement in Mechatronics and Industrial Internet of Things is working with industry partners to develop AI-based customer service solutions, customer satisfaction analyses, and automatic checkout processes. As part of their Digital Sea Project, Cégep de Matane is using AI to recognize, classify, and characterize different marine species. These processes help identify species that are commercially valuable and cases where stock of certain species may be scarce, which can assist in better protection and conservation efforts. Boosting Education and Innovation with Text and Data MiningUsing TDM in college learning and research promotes creative solutions and efficient project outcomes. Put simply, if a user has lawfully accessed information and copyrighted content, the right to read should also encompass the right to mine. While several other jurisdictions (details below) having already enacted provisions clarifying TDM, Canadian researchers and learners risk being left behind when it comes to AI-driven research and education without government action.The Copyright Act provides an allowable purpose for TDM of copyrighted works under the fair dealing exceptions for research and education. However, like other infringement exceptions in the Act, the ability to use TDM under fair dealing is not evident. Without specific language on the lawful use of TDM in the Copyright Act, this lack of clarity could negatively impact or prevent prospective research.Enacting a specific TDM exception for copyright infringement would provide legal certainty for college learners and industry partners. Several jurisdictions have already enacted some form of TDM exception, including the United States, European Union, Japan, the United Kingdom, Singapore and more. For instance, Singapore recently enacted a specific statutory exception for TDM, even though TDM could have been permitted under their existing fair use provisions. Singapore preferred to add a stand-alone TDM exception to increase legal certainty for the AI industry and promote their plans to make Singapore a global AI hub. While other jurisdictions move forward with TDM exceptions, a comparative lack of certainty will put Canada at a disadvantage and could stifle AI research and development.Canada can also learn from other jurisdiction’s experiences and ensure a new TDM exception properly supports Canadian innovation. For instance, the United Kingdom introduced a TDM exception in 2014 but limited the exception to non-commercial research. Following a recent consultation, the UK Intellectual Property Office (UKIPO) announced plans in 2022 to extend the TDM exception to commercial purposes, providing a comparative advantage for the UK in AI research and development. The UKIPO highlighted this expanded exception would benefit researchers, AI developers, cultural heritage institutions, and the wider public, by speeding up the TDM process and AI development.Creating a specific exception in the Copyright Act for TDM would ensure Canadians can access the full research, innovation, and educational benefits from AI. In addition, by creating this exception for both commercial and non-commercial purposes, Canada will be empowering colleges and their innovation partners, while supporting a competitive Canadian AI industry. CICan recommends the Copyright Act be amended to add a specific exception to infringement for text and data mining (TDM), which applies to both commercial and non-commercial purposes.Complementary Amendments to Facilitate Text and Data MiningIn addition to enacting a specific infringement exception for TDM in the Copyright Act, additional amendments would also help bolster TDM in Canada’s copyright framework.First, the Government of Canada could also reinforce TDM amendments by making it clear that no exception to copyright can be overridden by contract. Certain contractual obligations can often interfere with a college’s lawful use of copyright exceptions. College libraries spend thousands each year to licence content that supports current education and training needs. However, licencing contracts often forbid TDM, even though colleges are paying for access to the material and these activities are permissible under fair dealing.The Copyright Act must ensure that when works are accessed legally and the uses do not infringe on one of the exclusive rights of the author, the Act should not be overridden by contract. The law should clearly provide no contract can deem a lawful activity as copyright infringement when activity is permissible under the Act. This will guarantee Canadian researchers and learners can gain the full benefits from emerging technology, such as AI, and content they to which they are paying for access.CICan recommends the Copyright Act be amended to clarify that no copyright exception can be overridden by contract.Second, to ensure any TDM exceptions can be fully leveraged by users, the Copyright Act should also be modified to allow technological protection measures (TPMs) to be circumvented for any non-infringing use. Technological protection measures too often act as a barrier to the lawful use of copyright exceptions. Under the present law, circumventing a TPM is considered infringement, even when the use of the underlying material is lawful. This has effectively obstructed the legal use of materials for research and education.Technological protection measures are especially problematic when colleges are implementing learning supports for persons with disabilities. For instance, in several provinces, providing closed captioning for those with a hearing impairment is an accessibility requirement, but colleges and users are unable to break digital locks to implement this support for the students who require it. To avoid continued use of TPMs to obstruct the legal use of materials, including for activities involving emerging AI technology and TDM, the Government of Canada should amend the Copyright Act to make it explicit that circumventing a TPM for a lawful and required use is not infringement.CICan recommends the Copyright Act be amended to allow for the circumvention of technological protection measures for any non-infringing purpose.","Authorship and Ownership of AI-Generated WorksAs AI becomes widely used and develops rapidly, questions regarding authorship and ownership are often central to designing policy and legislation around this technology. Colleges specialize in partner-driven AR&D to solve technology, business, health, and social innovation challenges. When these projects conclude, the IP developed remains with the partner/client for any commercial purposes. Generally, any IP retained by colleges is only used for academic and research purposes. However, providing clarity on this point in the law is important for understanding ownership questions over certain research methodologies, such as AI algorithms and statistical methods.As the Government considers these questions, it should be noted that several instances throughout the Copyright Act provide “authors” of copyrighted works in Canada are human. Any future amendments to the Copyright Act surrounding AI should be framed around this central notion.CICan recommends any future amendments to the Copyright Act pertaining to artificial intelligence (AI) should remain consistent with the central notion that authors of copyrighted material are human in Canadian law.","Copyright Infringement and Liability on Artificial IntelligenceFinally, any approach to copyright infringement and liability concerning generative AI should consider the legal distinctions between authorizing infringement and simply using AI technology. The Supreme Court has provided, “a person does not authorize infringement by authorizing the mere use of equipment.” This distinction should be considered in developing any liability approach, to ensure researchers and learners are not punished for merely using AI.CICan recommends any approach to copyright infringement and liability concerning generative artificial intelligence (AI) remain consistent with the legal distinctions between authorizing infringement and using technology, to ensure users are not punished for using AI.","IntroductionOver 95% of Canadians and 86% of Indigenous peoples live within 50 kilometers of a public college, institute, cégep, or polytechnic. As Canada’s most accessible post-secondary education network, colleges are critical to tackling many challenges facing Canada, including skills for the future economy, the drive to net-zero emissions, and housing shortages. Colleges serve as local gateways to the innovation ecosystem for thousands of small and medium enterprises (SMEs) and other partners, specializing in applied research that solves technology, business, and innovation challenges.Ensuring Canada’s copyright framework is balanced and responsive to emerging technologies is important to colleges, their students, faculty, and staff, and their research and innovation partners. Copyright legislation affects the way students and educators can access and use copyright-protected materials. This ultimately impacts teaching, learning, and research. The Supreme Court of Canada has been clear that the Copyright Act must maintain an equitable balance between rights for creators and users. In the age of generative artificial intelligence (AI), copyright law must bolster a supportive environment for AI research and innovation in Canada.Colleges and Artificial Intelligence: Empowering Education and Applied ResearchCanada’s colleges are embracing AI’s potential to enhance teaching, learning, and applied research. Generative AI supports students and teachers by strengthening communication processes, personalizing student support, and creating innovative educational resources.Canada’s colleges are already integrating AI into programs and into pedagogy. For instance, colleges offer several courses, workshops, and programs focused on AI. The college sector is eager to continue integrating AI technology into classrooms to advance teaching and learning. For example, Algonquin College is encouraging faculty to use generative AI in their classrooms to increase learner productivity and efficiency, stimulate creativity in brainstorming activities, support writing and editing, and increase classroom accessibility by catering to various learning styles. In addition, college applied research & development (AR&D) refers to a range of innovation activities delivered through partnerships between colleges and a private firm, not-for-profit or community organization. Several CICan members have related specialized research hubs for AI, including Durham College, the British Columbia Institute of Technology (BCIT), Niagara College, Saskatchewan Polytechnic, and the Cégep de Sept-Îles. Through AR&D projects, colleges support their partners with product and prototype development, process improvement, commercialization readiness, and technology adoption. Generative AI has the potential to enhance efficiency and creativity in college AR&D.ConclusionAs AI development is poised to impact every sector and industry, Canada’s colleges are embracing its potential to strengthen teaching, learning, and research. By providing accessible and high-quality education, the college system is at the forefront of training the workers who will enhance productivity and innovation with AI technology. Our labour market needs diverse, resilient, nimble, and sophisticated workers who can work alongside AI.As AI becomes widely used and filters into several aspects of education and training, colleges must be able to confidently access the technology and resources that support innovative and responsive education. Copyright law should not hinder AI development, but instead, embrace and empower the potential it holds for learners and researchers.Beyond this consultation, any potential changes to the Copyright Act, pertaining to AI or otherwise, should be conducted in accordance with a comprehensive parliamentary review. The Government is urged to consider the recommendations put forth in this submission to support creative and innovative education in the age of generative AI."
Digital Media Association (DiMA),Association,"First and foremost, Digital Media Association (“DiMA”) appreciates this opportunity to contribute to the Canadian government’s consultation via the Ministry of Innovation, Science and Economic Development as it examines “Copyright in the Age of Generative Artificial Intelligence.” DiMA represents the leading audio streaming services and innovators– Amazon, Apple Music, Feed.fm, Pandora, Spotify, and YouTube. Together these services connect millions of fans across the nation and around the world with essentially the entire history of recorded music, providing unique listening experiences and constantly innovating to strengthen the connection between artists and fans. While DiMA’s member companies differ in size and business model, the revolutionary services they have built rely on the guidance provided by the current Canadian copyright laws that allow our members the flexibility that is critical to continue to innovate and develop global audio platforms that drive the recorded music industry’s revenues and have returned the music industry to growth. DiMA’s members are proud of the services they have built and their substantial efforts to provide legal access to music and reduce piracy while ensuring a dynamic and engaging experience for fans. DiMA members encourage fans to legally engage with copyrighted content. Equally, DiMA members partner with rightsholders to protect that content online. Over the last decade, streaming has played a central role in the resurgence of the music industry and we urge extreme caution with regard to any legislation or recommendations from the government that may upend (even inadvertently) the reliability that existing copyright laws provide.Audio streaming services launched in the mid-2010s in Canada. Since that time, the growth has been remarkable, with benefits to Canadian music fans, creators, and rightsholders. The state of the music industry in 2024 represents a true sea-change from the circumstances of just a decade ago, when the music industry was faced with declining revenues and struggling with how to get people to pay for music. DiMA’s members and their rightsholder partners changed that trajectory. “Over six in ten (63%) that have stopped illegally downloading music now use streaming services.” Russell Feldnman, Number of Britons illegally downloading music falls, YouGov (Aug. 2, 2018), available at https://yougov.co.uk/topics/arts/articles-reports/2018/08/02/number-britons-illegally-downloading-music-falls; see also Joost Poort et al., Global Online Piracy Study, 48, Univ. of Amsterdam (July 2018), available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3224323 (in 13 countries studied by the University of Amsterdam, streaming is the most commonly used channel to access music, ahead of digital downloads and physical copies).And such beneficial and robust voluntary partnerships between DiMA members and rightsholders have and should continue to be leveraged to work through AI-related concerns. Voluntary partnerships forged between services and rightsholders are the most direct and effective measures toward addressing the challenges raised by AI-generated content.Further, DiMA continues to support industry-wide efforts to facilitate adequate identification or information regarding music via metadata, including for AI-related creations. The growing influx of music, along with historic metadata challenges, has led to persistent, challenges throughout the industry at-large to accurately identify works, creators, and rightsholders in order to efficiently and correctly process royalties at the speed of digital commerce.In this regard, DiMA submits that the initial responsibility to identify the use of AI in music via metadata must rest with the rightsholders or owners of those works, who are in a position to know how they were created. Any subsequent obligation on distributors to include identifiers must require those identifiers to be built in before they reach the streaming services, in a way that services can ingest and deploy in their own systems. There is not a meaningful or practicable way for streaming services to identify these works on an individualized basis, let alone at scale, nor is it appropriate to make the service, rather than the source of the work, responsible for ascertaining how a work was made. Rather, the responsibility of streaming services is to ingest data provided to them and be a good steward of that data as it moves through the supply chain.Whatever amendments (if any) to the Canadian Copyright Act result from the present consultations, these should not burden music streaming services nor create new obligations, for example with respect to monitoring the validity of AI labels or watermarking and/or ensuring compliance with new labelling rules related to AI-generated content.","The digital music industry has long been vexed by data challenges. The growing influx of commercially released music, along with historic challenges around creating timely, standardized identification of works at the source and flowing that data through multiple stakeholder systems, has led to persistent challenges throughout the industry in accurately identifying works, creators, and rightsholders in order to efficiently and correctly process royalties at the speed of digital commerce. Whereas generative AI has the potential to be a force multiplier to help address those data challenges, new data requirements relating to AI-generated content may also confound these challenges if not carefully tailored. There are two existing exceptions to copyright infringement that could potentially apply in the context of TDM activities: (1) the fair dealing exception for research in section 29; and (2) the exception for temporary reproductions for technological processes in section 30.71. Current uncertainty as to whether and to what extent these exceptions would apply to TDM activities could stifle innovation in the field of AI.DiMA submits that any potential exception to copyright infringement for TDM activities should seek a balance between industry interests so as not to stifle innovations while also protecting certain creator rights. Consequently, in the instance that a TDM exception is created, it must:","AI can now create content that is difficult to distinguish from content created by humans. Although the Copyright Act does not explicitly define the term “author,” Canadian copyright jurisprudence suggests that “authorship” must be attributed to a natural person who exercises skill and judgment in creating the work. This is in line with the approach in other jurisdictions, including the United States. DiMA supports an approach whereby copyright authorship is attributed to the person, natural or corporate, who makes arrangements for the creation of the work, which should be interpreted in a manner consistent with existing Canadian copyright law principles, such as the exercise of skill and judgment by a natural person.DiMA believes that this approach adheres to the fundamental principle of technological neutrality, which provides that the Copyright Act should not be interpreted or applied to favour or discriminate against any particular form of technology. Further, this approach promotes certainty for the courts and market participants.","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?DiMA members believe that existing copyright laws, including copyrightability (originality, de minimis contributions, scenes a faire, and the idea/expression dichotomy); and infringement (questions of unlawful appropriation, substantial similarity, safe-harbors, and causation), are well-equipped to address novel issues raised by AI technology. Accordingly, DiMA asserts that new legislation to amend Canadian copyright law is neither necessary nor appropriate at this time. Existing legal doctrines as well as the use of contracts can and should be employed to consider liability questions arising from the creation and distribution of AI-generated music.What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?This is a highly technical question, and the answer may vary from one AI model to the next, and over time. In that context, there is generally no way for streaming services to know whether any given sound recording or musical work was created with the use of AI, let alone whether such use resulted in copyright infringement. Streaming services provide fans access to millions of songs. They must not be made the arbiters of the legal status of music delivered to them by third parties, whether due to the use of AI or otherwise.Moreover, the use of a particular streaming service by a third party to train an AI model likewise should not lead to a finding of liability for the streaming service in the event the AI model is found to have engaged in infringing conduct. There is often no way for streaming services to know whether AI is training from their platforms, or how to block any such use at a technical level. While services work to detect and prevent uses that violate their terms of use, services must not be held liable for the actions of third parties. Instead, existing Canadian copyright law and precedent should be the default framework with which to analyze these complex, fact-specific questions.Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?To the extent the outputs of a generative AI model are found to be infringing, such findings must not create direct or secondary liability for third parties who distribute such materials in good faith. In the case of music streaming, services should not be held liable for merely distributing the music delivered to them by their label and digital aggregator partners to fans. DiMA’s members must not be tasked with being the arbiter of what is or is not created by or using AI, or being the enforcer of AI-related mandates that are reliant on the action or inaction of others, for example, regarding data labeling. DiMA opposes amendments to the Copyright Act that would unduly burden music streaming services by creating new obligations or liability for streaming services and other intermediary stakeholders in the music supply chain, where such liability should rest with the creator of the content itself. In particular, DiMA opposes the creation or expansion of new notice-and-takedown rules that would expand liability or impose monitoring obligations on streaming services for AI-related activity. DiMA’s members must not be required to proactively determine which of the millions of songs on their services were created using AI, and which of those songs may represent an act of infringement. To do so would, among other concerns, generate costs that could degrade the consumer music streaming experience to the detriment of all stakeholders in the music ecosystem, as well as raise concerns about the technological neutrality of the music streaming in Canada.",
Entertainment Software Association of Canada,Association,"Q – How does your organization access and collect copyright-protected content, and encode it in training datasets?A – Video game companies can be sources for generative AI training input, creators of generative AI output, developers of generative AI models and users of third-party generative AI software tools. To this end, some companies use image, text, and code generator technological tools (including proprietary, licensed third-party and open-source software), to generate output such as content generation, ideation, concept testing and development, generating mock virtual worlds or generating computer-controlled character dialogue.Q – In your area of knowledge or organization, what is the involvement of humans in the development of AI systems?A – Humans are always involved in the development of AI systems related to the creation of games.There are myriad uses of AI in video games that would evidence a level of creativity that meets the current legal standard for copyrightability, i.e., of a human who exercises skill and judgment in creating the work. For example, some game companies use image, text, and code generator technological tools (including proprietary, licensed third-party and open-source software) to generate output, such as content generation, ideation, concept testing and development, generating mock virtual worlds or generating computer-controlled character dialogue.Copyright eligibility for machine-assisted output with the requisite human creative contribution is the right policy result. It incentivizes creativity and innovation which, in turn, spurs the creation of new types of work. We recommend the government avoid rigid rules for determining human authorship and should instead look at whether the human's use of AI is done with sufficient creative control and in such a way that the output reflects the product of human creativity. The focus should be on both the quantitative and qualitative aspects of human contribution.Q – How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?A – AI technology has been deployed in games for over two decades as useful tools for a variety of purposes, such as background and terrain generation, processing or analysis of data within the game, or quality control. Although certain uses of generative AI have launched questions of copyrightability and authorship, it is important to remember that AI technology is and should be treated as any other software tool with respect to copyright protection.Generative AI technology gives video game companies the opportunity to elevate the game experience for players and be responsive to their expectations while supporting the programmers, artists, writers, musicians, and others that are integral to game development in ways that allow those creatives to focus less on tedious tasks and more on meaningful projects that will ultimately enrich the gameplay experience.Video game companies have long utilized AI within games and consider generative AI to be instrumental for developing and operating the next generation of video games. AI is used to improve content creation, art generation, animation, sound and music, natural language processing (for example, natural speech and responses from non-player characters within the game), as well as automating repetitive and tedious tasks on the developer side.Some ESAC members use generative AI tools to accomplish all the tasks listed above in amuch more efficient manner. Current generative AI tools have the potential to improve workflow and reduce game development costs. If game development becomes easier companies will seek to do more, be more innovative and productive.Generative AI tools also allow artists to spend more time on the truly creative aspects of making in-game artwork, while freeing up time from the more tedious, less creative tasks, such as, fleshing out backgrounds once the artistic direction has been set. Scripting an open world game usually runs more than 100,000 lines of dialogue, and is often supported in at least 5 languages. One example of the use of generative AI in games would be a scriptwriting tool that frees writers to spend their valuable time on the core game plot and narrative rather than on ""barks"", a term for non-player character (NPC) dialogue, which are often short and tedious though intelligent barks can nonetheless be a central feature of player immersion in video games because the more responsive they are to players, the better and more realistic the gameplay experience.","Q – What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?A – The current legal framework has been designed to adapt to new technologies and has been able to work through unique questions that come up as a result of new technologies. In light of this, the existing legal framework should have a chance to work.Q – If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?A – The current legal framework has been designed to adapt to new technologies and has been able to work through unique questions that come up as a result of new technologies. In light of this, the existing legal framework should have a chance to work.Q – Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?A – Consistent with our position that the government should encourage a robust marketplace for emerging technologies, such as generative AI, we believe that the mandated disclosure of the use of copyrighted works used in machine learning needs careful consideration and balancing of priorities, especially when the AI developer owns or licenses the works at issue or the resulting output, or when mandated disclosure could jeopardize confidential information, trade secrets or other protected data.Mandated disclosure of the use of copyrighted works used in machine learning needs careful consideration and the balancing of objectives of such a requirement, which will differ in different contexts, such as closed AI models versus AI models used by the general public. If the purpose is to enable the ability of copyright owners to enforce their exclusive rights, then there would appear to be little justification for the imposition of a transparency and disclosure requirement on a developer of a non-public-facing AI system that is trained on the developer's own works, internal, licensed or legally accessed data, or on an implementer of a foundation model that fine tunes the model on its own works. In these types of situations, transparency and disclosure mandates should not apply.Transparency and record-keeping mandates with respect to generative AI models alsoraise questions of feasibility. Any requirements should be narrowly tailored to the particular purpose. Training materials for foundational models may constitute millions, or even billions, of data entries, the maintenance of which becomes onerous for developers. And to the extent that a developer or publisher is also a user of open-source or other third-party software, an attenuated chain of responsibility becomes burdensome and does not substantially advance the goals that spurred the demand for such mandates in the first place. We would therefore recommend that any such mandates must consider both feasibility and relevance to the objective they seek to achieve.","Q – Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?A – No legislative change is needed. We think that a work containing AI assisted content should be eligible for copyright protection, and the current legislation permits this. Copyright laws and regulations are already drafted to address the advent of new technologies. ISED should refrain from taking categorical and formalistic approaches to the eligibility of AI assisted content for copyright protection, especially when the technology is still evolving. We also ask that government be wary of calls to mandate either the marking of expressive works or new disclosure requirements that could result in the disclosure of confidential information and instead allow different creative industries to take the approach that works best for their stakeholders.We believe that if there is sufficient human contribution to either the input or the output, consistent with existing legal principles, the resulting work should be eligible for copyright protection.We recommend the government avoid rigid rules for determining human authorship and should instead look at whether the human's use of AI is done with sufficient creative control and in such a way that the output reflects the product of human creativity. There are myriad uses of AI in video games that would evidence a level of creativity that meets the current legal standard. The focus should be on both the quantitative and qualitative aspects of human contribution.Q – Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?A – No. The UK uniquely has a provision for protecting computer generated works where there is no human author, this approach is not recommended, or needed. We recommend the government avoid rigid rules for determining human authorship and should instead look at whether the human's use of AI is done with sufficient creative control and in such a way that the output reflects the product of human creativity. There are myriad uses of AI in video games that would evidence a level of creativity that meets the current legal standard.We believe that if there is sufficient human contribution to either the input or the output, consistent with existing legal principles, the resulting work should be eligible for copyright protection.","Q – Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?A – No. The current law is sufficient and we do not think new legislation on copyright liability is needed (at this time). Current principles of copyright liability can and do apply to new technologies and new technological uses. Canadian copyright law remains an adequate framework within which to analyze legal questions involving generative AI, such as authorship, ownership, and liability for infringement, given the current state of the technology.At this point, there is no reason to believe that existing statutory and common law doctrines based on fact-intensive inquiry are insufficient to address complex questions of access to content/training data, protection and ownership of the resulting output and use.Q – Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?A – No. The current law is sufficient and we do not think new legislation on copyright liability is needed (at this time). Current principles of copyright liability can and do apply to new technologies and new technological uses. Canadian copyright law remains an adequate framework within which to analyze legal questions involving generative AI, such as authorship, ownership, and liability for infringement, given the current state of the technology.At this point, there is no reason to believe that existing statutory and common law doctrines based on fact-intensive inquiry are insufficient to address complex questions of access to content/training data, protection and ownership of the resulting output and use.",N/A
FICPI Canada,Association,"FICPI appreciates that the Government has solicited diverse views in the present Consultation and, as such, wishes not to express views on aspects of the questionnaire that do not relate specifically to those in the IP profession or relating to IP policy in general. In particular, FICPI wishes not to provide responses to ""Technical Evidence"" questions.","The first category of the Consultation relates to text and data mining (TDM) and the training of machine learning models using, inter alia, copyright-protected content.The Government has indicated an interest in maintaining balance between innovation and incentives to creativity and asks whether amendments should be introduced in the Act to clarify how the copyright framework applies to TDM activities and, if so, what those amendments should be.The Consultation first queries ""what would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?"". FICPI appreciates that increased clarity and thus certainty would likely be favoured by industry. However, FICPI stresses that the Copyright Act should not be amended to address all specific circumstances or technologies, and must maintain flexibility to permit the courts to address future technological development. As recent history has proven, technological progress is increasingly rapid and any attempts to address specific technological innovation in the Copyright Act would inevitably lead to the need to constantly amend the Act to again catch up with technology.Conversely, FICPI is of the view that the Copyright Act already addresses copyright concerns relating to generative AI, such that legislative amendments to the Act are not yet required.The Consultation suggests that two existing exceptions to copyright infringement could potentially apply in the context of TDM activities: 1) the fair dealing exception for research in section 29; and, 2) the exception for temporary reproductions for technological processes in section 30.71.The Consultation notes that certain respondents in the earlier 2021 consultation favoured expansion of the fair dealing provision. FICPI, however, stresses that any further amendments to the fair dealing provisions should be considered only insofar as they would increase harmonization with international norms (i.e., to bring fair dealing closer to other jurisdictions' fair use provisions) generally, and not in response to specific technological innovations.In other words, FICPI endorses the view of several respondents to the 2021 consultation who noted that the Copyright Act already fairly balances interests between creators and users and contains broad provisions that enable courts to make reasonable decisions to maintain that balance. If TDM activities are being undertaken for purposes relating to research, for example, those TDM activities would be non-infringing if deemed to fall under section 29 of the Act.Similarly, FICPI encourages the Government to allow courts to determine if particular TDM activities would be permitted under Section 30.71. However, FICPI would oppose statutory amendment of Section 30.71 for the mere purpose of addressing TDM.FICPI notes, however, that Section 30.71(c) recites the requirement that ""the reproduction exists only for the duration of the technological process""; however in certain cases where generative AI systems are continuously trained, there may be an argument that the duration of the technological process is indefinite.The Consultation has asked several other questions better directed to the AI industry and creators, rather than IP practitioners. Amongst these include questions of available licenses, record keeping requirements and remuneration. FICPI wishes not to provide direct responses to these issues but urges the Government to recognize that developers of generative AI tools may be foreign entities using Canadian-owned copyrighted content; could be Canadian entities using foreign-owned content, or a blend of these. Therefore, to the extent possible, the Government must take a position that does not disadvantage Canadians and, preferably, seeks to adopt an approach that is in harmony with its international counterparts.","The second category relates to issues of granting copyright to AI-generated content, and furthermore to questions of authorship and ownership of such content.As with its suggested approach in respect of TDM, FICPI is of the view that the Copyright Act already addresses authorship and ownership of content created wholly or in part by generative AI.As the consultation notes, ""Canadian copyright jurisprudence suggests that 'authorship' must be attributed to a natural person who exercises skill and judgment in creating the work...""The threshold applied by courts in determining whether ""skill and judgement"" are required in the creation of a particular work remain applicable and sufficient in the consideration of generative AI. As the consultation notes, in a great deal of current generative AI systems, ""[t]he creation of a work or other subject matter by AI may involve some degree of human input, either by programmers or users instructing an AI application to perform its task."" These inputs are colloquially referred to as ""prompts"" to the AI application.The current Act and existing jurisprudence therefore already empower courts to consider whether those who prompt a system could be considered authors. In particular, courts are already empowered to evaluate whether a specific prompt, or set of prompts, required the human to exercise sufficient skill and judgement in the creation of the work.To the extent that a work was wholly created by generative AI without any prompt at all, it remains possible for a party to argue that a human was involved in the creation of the AI application itself. Again, FICPI believes it should be left to the courts to determine whether such humans exercised skill and judgement attributable to creation of the work. This evaluation can already be conducted under the existing provisions of the Act.Furthermore, if the Government were to enact a legislative bar to copyright protection for generated works, this will inevitably cause a lack of clarity in the marketplace. Generative AI systems are already sufficiently sophisticated to create works that appear to be human-created, and this level of sophistication will only increase. Therefore, users will be in an unfortunate position to not know which works are protected by copyright and which are not. Furthermore, there will inevitably be infringers to copyrighted works that deny infringement on the argument that a work could have been generated by AI, which would place an undue burden on creators to prove a work was not created by AI.FICPI therefore urges the government to maintain the status quo and allow courts to address these issues as cases arise.","The third category relates ""to the use and commercialization of AI systems and the liability for any infringement that occurs. This includes questions regarding the determination of the persons liable when AI-generated outputs infringe copyright-protected works.""The Consultation notes that ""[g]iven the novelty of AI technologies, Canadian courts have not yet rendered decisions regarding liability for infringement that may result from the use of AI, either through the inputs used to train an AI or through the outputs generated by an AI system in the form of works.""The Consultation also notes that the Government has received very little stakeholder feedback on this discussion topic.As mentioned earlier, FICPI strongly urges the Government to permit issues to actually arise, and to allow courts to render decisions under the existing provisions of the Copyright Act before enacting potentially unnecessary amendments thereto.With respect to the specific proposals discussed in the Consultation, FICPI suggests that any additional burden placed (e.g., record keeping) that is outside of international norms would likely decrease Canadian competitiveness.","This response to the Consultation paper: Consultation on Copyright in the Age of Generative Artificial Intelligence (the ""Consultation""), is being submitted on behalf of FICPI Canada.As you are aware, our organization, FICPI (the Fédération Internationale des Conseils en Propriété Intellectuelle), comprises more than 5000 intellectual property attorneys in private practice in 86 countries. FICPI Canada is a self-governing national association of FICPI and represents the interests of Canadian intellectual property professionals. Our membership includes senior professionals at most major Canadian intellectual property firms. Our clients span all types and sizes of businesses, including multi-national corporations, small and medium size enterprises, and individuals.The ConsultationThank you for taking the time to consult with stakeholders in respect of Canada's copyright framework and its applicability to generative AI technology.The Consultation was distributed via the Innovation, Science & Economic Development (ISED) website. The website also explains that ""The Government continues working toward amending the Copyright Act for the benefit of all Canadians.""The Consultation considers three primary topics: Section 2.1 relates to text and data mining (TDM); Section 2.2 relates to authorship and ownership of works generated by AI; and Section 2.3 relates to infringement and liability regarding AI.The Consultation notes that ""[the Government of] Canada remains mindful of approaches taken by its international partners that could serve the needs of a functioning copyright marketplace"" and that ""the Government will aim to balance two main objectives: a) To support innovation and investment in AI and other digital and emerging technologies in all sectors in Canada… b) To support Canada's creative industries and preserve the incentive to create and invest provided by the rights set out in the Canadian Copyright Act (the Act), including to be adequately remunerated for the use of their works or other copyright subject matter.""FICPI endorses the Government's objective to balance technological innovation and investment with the rights of creators.FICPI believes that it is premature to consider amendments to the Copyright Act merely to address concerns relating to generative AI. FICPI is of the view that the Copyright Act already addresses copyright concerns relating to generative AI, and that it already empowers courts to balance competing interests to determine how to address specific issues arising in the use of generative AI. FICPI urges the Government to allow the courts to exercise their role respecting statutory interpretation before pre-emptively circumscribing specific generative AI exceptions within the Act.We would welcome the opportunity to consult further on additional consultations. Additionally, while FICPI opposes statutory amendments at this time, it welcomes consultation on any proposed amendments. We thank you again for the opportunity to participate in the consultation process and for considering these remarks.Please do not hesitate to contact us should you have any questions."
IMPF – Independent Music Publishers International,Association,"IMPF (Independent Music Publishers International Forum) represents 200 of the world's leading independent music publishing companies. We are engaged in international AI related policy discussions, and have submitted to enquiries in the United States, the European Union (""AI Act""), the United Kingdom and Australia. In October 2023, we published ethical guidelines on generative Artificial Intelligence welcoming technological developments in as far as they improve our business and the capacity to assist the writers we represent. These guidelines are aimed to enhance the relationship between the creative side, in our case writers and music publishers, and tech companies providing AI applications. This should ultimately enable transparent collaboration for the benefit of all stakeholders including users of AI applications. Given the rights we represent our comments concern musical and literary works only.We welcome this timely consultation. A legally, politically, and commercially successful AI ecosystem depends upon all relevant parts working in tandem for this common goal. The fundamental starting point for the collaboration is compliance with the law, in this case mainly copyright law but also other rules such as data protection and unfair competition.Tech companies providing AI applications (run by various, sometimes third-party entities selling datasets, ultimately for commercial purposes) scrape the internet to collect data for machine learning. This involves many rights which require express permission by rightsholders including copyright for the reproductions. In our view such requirement is not superseded by any of the potentially available exceptions (e.g., text and data mining, temporary copying, fair use depending on the jurisdiction). In the absence of binding Canadian court decisions on the application of exceptions, general copyright rules apply and the express permission by the creator and the rightsholder is required. In any case, an exception would only apply to copyright but not to other rights such as data protection and unfair competition rules.Additionally, data scraping is often expressly prohibited in the Terms and Conditions of the scraped websites; this constitutes a legally binding express prohibition which needs to be respected.","Text and data miningThree preliminary observations on the application of text and data mining (TDM) exceptions in the machine learning process:Clarity around copyright legislation and TDM in Canada is important but it is for judges to interpret the law. We are concerned about the separation of power if the interpretation of existing laws is moved from judges to policymakers.Text and data mining exceptions should not be used to avoid requesting licences. We urge caution should government decide to amend legislation to cater for the asserted needs of a specific sector to the detriment of another sector.Licensing constitutes the general manner in which the use of human creative talent is permitted. The music publishing industry has been licensing novel uses in response to technological developments from mechanical musical boxes through radio to music streaming for centuries. However, in order to provide such a license, it needs to be requested in the first place, providing details of the requirements of AI service provider, including the potential uses of the output generated on the basis of our creative works. Evidently, it is the choice of the creator and/ or the rightsholder whether or not to allow specific uses. And under which conditions. Observations on licensing are academic if such licences are not requested in practice.We note that the consultation asks about the details of potential licenses and the potential level of appropriate remuneration. We are concerned about the potential competition law aspect of this question. In general, licensing conditions depend on the individual creator or rightsholder as well as the musical and literary works in question. Any negotiated licence needs to reflect the actual value of an individual song for the creator and/or rightsholder as well as the individual user.The requirement for such express permission should not be circumvented by ""offshoring"" the machine learning process to countries setting themselves up as copyright havens. Government should consider guidance to ensure that tech companies do not manipulate jurisdictional rules to flout domestic copyright requirements. Any such guidance should also consider copyright infringements committed by AI service providers in the past; we note that most available AI applications are based on datasets of creative works which have already been ingested, mostly without permission.Record keeping is an important element of transparency. AI service providers, including AI developers and mere dataset providers should be obliged to keep records of, or disclose what copyright-protected content was used in the training of AI systems.Internationally, we note that many governments are looking into national approaches without any clear approach crystallising (in particular given the absence of court decisions). However, we refer government to the many useful ethical guidelines put forward by rights holders' organisations in various creative sectors such as photo libraries or the Human Artistry Campaign.","Authorship and ownership of works generated by AIWe are concerned about the possibility of the perverse situation should AI service providers copy musical and literary works without remuneration for the creator or the rightsholder, generating competing works protected by copyright, competing with the original music they have unduly copied.Questions of authorship or ownership in relation to AI require a clear differentiation between AI-assisted and AI-generated works.Copyright rewards the expression of human creativity and talent, which self-evidently is lacking without human input. A work generated by an artificial intelligence application without any human input, is currently not protected by copyright.To our knowledge this is the case everywhere in the world. For example, in India, where an AI application has been registered as a co-owner of an AI generated painting (""Suryast""), human contribution was required to establish copyright protection in the first place. It was not possible to register the AI application (Raghav) as sole owner of the AI generated painting; a human creator was required to establish copyright protection. Based on philosophical, historical, and legal justifications of copyright (amongst others as a human right under the Universal Declaration of Human Rights) most jurisdictions do not grant copyright protection for purely AI generated works, amongst many the United States (Copyright Office memorandum concerning the registration of copyright) and the European Union (CJEU jurisprudence focusing on the author's own intellectual creation expressing their personality).However, we note the practical challenges in establishing whether a work is created by a human with the assistance of an AI application or generated without any human involvement. A human will invariably be involved at some stage, even if only ""prompting"" the AI application. The main challenge however is the delineation between AI assisted works and AI generated works.We suggest that government provide clarity for instance by issuing guidance on the differentiation between AI assisted or AI generated works and their respective copyright situation.In this context, it is worthwhile referring to the need of adequate labelling of AI generated works as such. This will particularly ensure the protection of consumers to make an informed decision on what product or service they want to acquire. Aside from personal preferences, consumers might reject AI generated works due to their high energy costs and the environmental impact of their production.","Infringement and liability regarding AIWe note the challenges to establish copyright infringement by AI generated output. In the absence of record keeping, it is impossible for rightsholders to determine whether an AI developer has used their works (to our knowledge no technological approach exists yet to obtain such information a posteriori). The commercial attractiveness of AI generated output depends mainly on high quality datasets of creative works. Record keeping of the musical and literary works ingested in the machine learning process is key in this regard as well. It constitutes good business practice to provide information about the constituent parts of a product or service (similar to the requirements on fair trade clothing, where the source of every part of the final product has to be notified to qualify for fair trade certification).Infringement by the output of AI applications presumably follows ""normal"" copyright enforcement rules when identifying infringement of previous works or derivative works. We note that a variety of natural or legal persons can be solely or jointly liable including the developer of a generative AI model, the developer of the system incorporating that model, end users of the system but also third parties providing the datasets; and more generally, the person/entity ultimately benefiting from the AI generated output. Government might address the scope of potentially liable persons and entities.We suggest that measures which business can take to mitigate risks of liability for infringing AI-generated works consists in simply complying with the law, i.e., by obtaining the required permissions. We note the related discussions in the United Kingdom: original plans to introduce a specific exception for text and data mining for any purpose including machine learning were abandoned in early 2023 and replaced by discussions on a code of good practice between all stakeholders. Such a code of practice can only be successful if participants agree on the overriding principle of compliance with existing laws (including but not limited to copyright).","We note the importance of personality or publicity rights to address the situation where AI is used to imitate a person's likeness, voice, or image. When a distinctive voice of a professional singer is widely known and is deliberately used in order to sell a product, this constitutes misappropriation. It is important to note that the resulting damages can be economic or otherwise (such as damage to their reputation or goodwill or causing distress)."
International Confederation of Societies of Authors and Composers (CISAC),Association,"The International Confederation of Societies of Authors and Composers (CISAC) welcomes the opportunity to engage with the Canadian Government in its request for comment in the framework of the Consultation on Copyright in the age of generative Artificial Intelligence.CISAC is the leading worldwide organisation of authors' societies. We represent more than 5 million creators from all geographic areas and all artistic repertoires (including music, audiovisual, drama, literature, and visual arts) through our 225 members. The position of CISAC is not just a reflection of its members, but of its long history centred on defending the livelihood of creators and supporting creativity for future generations.This submission delves into legal and policy concerns surrounding generative AI and specifically examines three critical areas:The goal is to offer insights into emerging issues within the framework of foundational copyright principles while pinpointing opportunities to enhance the current state of play.I. IntroductionGenerative AI stands as a double-edged sword for the creative industry, offering immense potential while simultaneously posing significant risks. When leveraged to support human creativity, this technology emerges as a powerful ally that the creative industry should embrace and foster in partnership with the AI development community.At the same time, generative AI poses existential threats to the creative sector. To improve its capabilities, this technology heavily relies on the use of vast volumes of copyrighted works. The methods employed, such as data scraping and web crawling, often gather content indiscriminately, raising concerns about the unauthorized use of copyrighted material for AI training. This process disrupts the balance of copyright law by favoring AI technologies at the expense of creators' rights and livelihoods. The lack of transparency from AI companies regarding dataset acquisition exacerbates this imbalance. The overreliance of AI companies on the blanket assumption that such a use is ""fair"" or otherwise subject to an exception without proper validation poses a threat to the essence of copyright law.Also, while AI serves as a facilitative tool in the creative process, it must be recognized as an extension of human creativity, not as a replacement. This distinction is vital in preserving the integrity of copyright law and the livelihoods of creators.This submission seeks to chart a prudent course within Canada's copyright landscape and to foster a dialogue that harmonizes technological innovation with the preservation of creators' rights in the evolving AI landscape.","II. Text and data miningA. The use of copyright in training AI systemsThe use of copyright-protected material to train AI systems has become a pivotal aspect within the realm of AI development. A vast amount of copyright protected works – such as images, texts, music, videos, or other creative content – is ingested into AI models and used to identify patterns, generate new content, and/or perform various tasks.The acquisition of such data often occurs through indiscriminate ""data scraping"" and ""web crawling"" methods, without seeking authorization from rightsholders. Further, this process remains mainly unchecked, due to a lack of transparency as to what materials have been used to train AI models to date, and how these materials have been collected and curated.Artists and creators using the online space to promote and disseminate their works often remain unaware that their works have been assimilated into AI models for training. This prevents them from authorizing (or prohibiting) such usage and from asserting their rights to be compensated. It is therefore essential that AI developers keep detailed records of works used, alongside the platform through which they were accessed and make this information available to rightsholders (see section IV A). The obligation to keep accurate records should arise from the start of the development, training, and design phase to provide a full chain of use.To properly address these challenges, several approaches could be considered, as elaborated below. This includes requiring fair licensing practices between creators and AI developers using copyrighted works for training data as well as imposing transparency reporting requirements on AI developers to disclose their training datasets.B. Inapplicability of TDM exceptionsThe essential balance within copyright law between private rights and public interests sometimes requires the application of exceptions to exclusive rights of creators. These exceptions must operate within defined boundaries to safeguard creators' ability to benefit from their creations.AI developers tend to rely on exceptions like fair use or text and data mining (TDM) to access and use data from the internet for training AI models. However, extending such exceptions to encompass the commercial use of copyrighted works as training data for AI may undermine creators' rights and may challenge the delicate balance inherent in copyright law. Unlike traditional uses covered by exceptions, AI training goes beyond mere analysis or extraction, and results in the production of content that may compete with or replicate the original works, thus affecting the economic incentives and rewards that creators derive from their works.This diverges significantly from the intended scope of exceptions to copyright, which according to the principle of the three-step test recognized in the Berne Convention, consists in allowing specific uses that do not conflict with the normal exploitation of the copyright-protected works and do not unduly prejudice creators' ability to benefit from their works.Introducing new exceptions should be carefully weighed to ensure they do not unduly harm creators' rights or disrupt the balance between private rights and public interests. It also raises concerns about potential breach of international treaties and fundamental principles underlying copyright law. Therefore, we strongly recommend refraining from adopting new TDM exceptions that permit AI systems to commercially exploit copyright works without rightsholders' authorization and remuneration.C. Licensing of works used for training purposesThe use of copyright-protected works by AI encompasses making copies or reproductions of copyrighted material for analysis and learning purposes. Even if this reproduction is for computational processing rather than human consumption, it still falls within the realm of copyright control.This emphasizes the importance of obtaining appropriate authorization or licensing to ensure compliance with copyright law. Ensuring fair voluntary licensing practices between creators and AI developers becomes imperative in this context, ensuring that creators are fairly compensated for their contributions to AI-generated outputs.Collective management organizations (CMOs) hold a unique and advantageous position to facilitate the development of licensing schemes for the use of copyright protected works by AI. Their comprehensive experience on licensing vast amounts of works for digital uses such as Internet streaming, their efficient infrastructure, and their capacity to balance interests make them well-suited to drive the development of effective and fair licensing schemes for AI use.","III. Authorship and ownership rights related to AI-assisted and AI-generated contentThe issue of copyright protection for AI-generated content is complex and multifaceted, as demonstrated by recent decisions across the world. As a preliminary remark, a distinction needs to be made between the AI-assisted content, which should continue to benefit from authors' right/copyright protection, and the purely AI-generated content, whose protectability seems largely unjustified under the current copyright regime.In the United States, the US Copyright Office (USCO) took a significant step in that direction by refusing to register several works, particularly on the grounds that the work in question was created by AI without any creative contribution from a human being. A subsequent decision of the US District Court of Columbia(Thaler v. Perlmutter et al, No. 1:2022cv01564 (D.D.C. 2023)) emphasized the significance of human authorship in copyright protection. These rulings stressed that AI-generated content lacking creative input from a human actor does not meet the threshold for copyright protection. Such decisions align with the fundamental principle upheld by US Courts, according to which human authorship forms an essential element for copyright protection.Similarly, in Europe, the concept of originality is a critical factor for determining copyright protection of AI-generated works. The extent of human involvement in the creative process and the level of autonomy of the AI system are pondered by the Courts as key elements in assessing the protectability of AI-generated content under copyright law. This is based on a meticulous case-by-case evaluation to ascertain whether the role of AI is merely supportive or contributes substantially to the creation of an ""original"" work.These recent decisions show that the current status quo regarding protection for AI-generated content remains rooted in the principles of human authorship and original expression. Both are pivotal aspects entrenched within the essence of copyright, which is incentivizing and rewarding human creativity. In navigating the challenges posed by AI-related innovations, any consideration should build upon the inherent values of incentivizing and rewarding human creativity and fostering an environment that encourages innovation while safeguarding the rights of creators.Ongoing legal developments in other jurisdictions and case law involving AI-generated content will provide valuable insights into the nuances and complexities of this rapidly evolving context. It is therefore advisable to refrain from any amendment to the current legal framework in Canada unless future developments expose a clear gap or defect related to the applicability of the existing rules to AI-generated content.","IV. Liability for infringementA. Transparency and record-keeping as fundamental requirements for enforcementPreserving and enforcing creators' rights in the evolving AI landscape will not be possible unless AI developers are transparent about what data they use to train the AI models. At present, rightsholders are unable to identify whether their copyrighted works have been fed into existing AI models. Transparency and record-keeping requirements are essential to ensure that rightsholders can enforce their rights, negotiate licenses, ensure fair compensation for the exploitation of their works and pursue claims for copyright infringement.Further, such requirement serves as a cornerstone for accountability and trust within the AI ecosystem. By mandating transparent record-keeping, developers are held accountable for the origin and usage of the data utilized in training AI models. This transparency establishes a level of trust between creators, rightsholders, users, and developers by ensuring clarity regarding the incorporation of copyrighted material.Overall, it is imperative that AI developers keep and make readily available to rightsholders detailed and accurate records of the works they use for training, the works' origin, and the existence of any licenses authorizing such use. Such obligation should go back to the start of the development, training and design phase to provide a full chain of use.AI developers assert that such an obligation with respect to foundation models would constitute a significant burden for the development of AI technologies. We, however, maintain that transparency is a basic standard for any business that operates in the digital environment and processes vast amounts of data every day. AI services already maintain record keeping practices for internal purposes, such as validating records, removing biases or deciding on the need for additional datasets. These transparency standards should be urgently extended to the ingestion of copyright-protected works into the data pool, as well as to the outputs of the generative AI.The discussions in the European Union around the EU AI Act highlight the significance of transparency and disclosure requirements for AI developers in relation to copyrighted works. The proposed provisions within this legislation emphasize the need for AI developers to disclose relevant information regarding the copyrighted works used during the training of their AI models (see EU AI Act Final Text, Recital 107, Art. 53(d)).Once a clear and broad principle of transparency and record keeping is recognised, established copyright principles will apply to determine where liability for infringement attaches. The expectation is that Canadian courts will navigate these complexities by applying established copyright principles to ascertain liability, ensuring that copyright protections are upheld in the rapidly evolving landscape of AI technology and content generation.B. Technological standards for identification of works and authorsAs for the future of developing better and more accurate technological standards to aid in the proper identification of works and authors, there is ample precedent for the development of such technologies. For years, CISAC, rightsholder groups, and many other organisations managing rights on behalf of creators internationally, have channelled their resources into developing and improving technical measures and infrastructures for enabling creators to receive their fair share from their creative efforts. This has included the creation of reliable systems such as industry standard ISWC and ISRC identifiers, among other similar tools, which ultimately streamline the task of confirming copyright authorship in works.We believe that further collaborative efforts between AI developers and rightsholders are essential to improve the infrastructure surrounding works identification, and that such collaborations should be encouraged and facilitated at the policy level.","V. ConclusionThe intersection of copyright and AI training requires a delicate balance between fostering innovation and respecting creators' rights. To navigate this evolving scenario, it is paramount to develop comprehensive approaches that ensure legal compliance, ethical treatment of copyrighted content, and preservation of human creativity.Given the rapid pace of change in this field, CISAC believes that a factual assessment of the issues raised by AI technology must necessarily precede any legislative reform in Canada. Apart from insights gathered from industry stakeholders, the interpretation of fundamental copyright principles by both Canadian and international courts will be essential to inform future adoption of legislative measures.Respecting copyright law emerges as pivotal for regulators to secure the future of creativity in a fast-evolving technological landscape. Above all, it is imperative that AI technologies be developed and utilized in a controlled manner and do not undermine the overall functioning of the copyright system nor the interest of rightsholders.Opportunities presented by AI should not come at the expense of creators' rights. Striking a balance between innovation and copyright protection is essential to ensure that AI enriches society without replacing human creativity.We would once again like to thank the Government of Canada for the overall thought and attention it has given to the intersection of generative AI and copyright. We appreciate the opportunity to submit these comments and look forward to working with the Government and other stakeholders on these issues in the future."
Music Canada,Association,"1. Music Canada is the trade association for Canada’s major labels: Sony Music Entertainment Canada, Universal Music Canada and Warner Music Canada. Our members help Canadian artists reach their creative goals, engage with fans around the globe, and help them find commercial success. We welcome the opportunity to engage in these Consultations.Our members constantly invest in and adopt new technologies and innovations, and work with artists to develop and use new tools to advance the creative process. This includes working with AI technologies, from the use of machine learning to better understand user behaviour and preferences, to systems that assist in the creative process. Tools driven by AI play an increasingly important role in the artistic process in the music sector -- including in audio mixing, automated mastering, computer-aided orchestration, and elsewhere. AI is a tool that can help unlock an artist’s creativity or find efficiencies in processes, but it is not a substitute for the human element of creativity.While these submissions will delve deeper into the specific questions posed by these consultations, the principles of the Human Artistry Campaign (humanartistrycampaign.com) are the fundamental guideposts. We, alongside hundreds of organisations from around the world (including many from Canada) representing music, literary, sports, entertainment, and other sectors have agreed to these principles. We urge policymaker and AI developers to take into account these principles:(i) technology has long empowered human expression, and AI will be no different;(ii) human created works will continue to play an essential role in our lives;(iii) use of copyrighted works and the use of voices and likenesses of professional performers requires authorization and free-market licensing from all rightsholders;(iv) governments should not create new copyright or other IP exemptions that allow AI developers to exploit creations without permission or compensation;(v) copyright should only protect the unique value of human intellectual creativity;(vi) trustworthiness and transparency are essential to the success of AI and protection of creators; and(vii) creators’ interests must be represented in policy making.2.1 Government should be attuned to how systems are trained and how they obtain those worksWhile sometimes it might look like it, generative AI is not magic. Its outputs are only as good as the creative works it’s trained on. These systems are not able to generate vocal clones that sound like Drake or produce images that look like the works of Norval Morrisseau if it had not copied and retained a reproduction of the artist’s voice or the painter’s painting in some digital form. The fact that AI models can produce identical copies of copyrighted lyrics or copyright images make this point clear. For example, a recent lawsuit by The New York Times includes exhibits to underscore that OpenAI and Microsoft’s LLM’s which power ChatGPT “can generate output that recites Times content verbatim, closely summarizes it, and mimics its expressive style"".We caution the government to pay close attention to the language used by developers in explaining what works their systems train on or how their systems learn. From observing consultations in other jurisdictions, we have noticed a tendency of developers to adopt language which characterises their ingestion and use of works as falling outside the legal understanding of a “reproduction” or language which suggests that a statutory exemption to copyright is in play. They may use words like “learning,” “migration,” “memorization,” or “simulations,” instead of words that describe what their systems do to learn: make “copies” and “reproductions.” They will talk about the speed at which their systems learn and they will point to different digital formats to try to escape the traditional understanding of copyright and how infringements arise. They often use phrases like “publicly available” (which is entirely different from being in the public domain), or assert that their systems use works to merely “educate” the model or drive “research” for further AI systems. In our view, these are attempts to get ahead of copyright infringement suits -- where they will argue that they do not need to license the reproduction, ingestion, and use of the copyrighted works that are essential in training their models.We also recommend that the government pay attention to how sources of works used to train systems are described. Generative AI systems are typically trained on multiple sources, often from websites whose terms of service forbid scraping or reproducing their information -- and without authorization from the copyright owner. We have noted that developers will often not disclose their sources or if they do, they do it in nonspecific and vague terms. For example, OpenAI claims that it acquires data to train ChaptGPT from “three sources of information: (1) information that is publicly available on the internet, (2) information that [they] license from third parties, and (3) information that [their] users or our human trainers provide.”It is our understanding that generative AI models typically ingest vast sums of information from the internet. And because low quality inputs lead to low quality outputs, they will scrape the web for professional content -- such as high quality images, music, and text. In order to make the most accurate impersonation of an artist or an artist’s work, they are motivated to scrape the copyright work from the highest quality sources, like digital streaming platforms.Typically, the commercial relationship between rightsholders and digital platforms will include terms which state that their intellectual property can only be accessed by a user for personal and non-commercial use. But generative AI training accesses these works and makes productions outside of what is permitted under these licences. Generative AI systems will also access pirated sources -- but taking content from pirated sources is still stealing and harms the underlying work and creator.Just because a system is trained on third party data sets which are purportedly open does not mean that those sets permit licensing for AI training purposes. There are wide reports of datasets that are licensed for non-commercial, research, or scientific purposes -- and yet they are used for obviously commercial purposes in subscription based AI models.Some developers will claim that they only train on “ethical sources,” such as public domain content, stock libraries, etc. -- but in reality, this is often merely their own mistaken belief. Datasets often contain copyright protected works and they are not licensed for AI training. Just because something is “publicly available” on the internet does not mean that it is in the public domain, free of copyright, or that it need not be licensed.We urge the government to not be lulled by this type of language designed to deflect from the provenance of data and how it is used by models and systems. AI developers and the lucrative industry that has built around them should be held to the same standard as other industries. Their business model should not be built on the backs of creators without their consent, compensation, or credit.2. 2 Not all AI Developers Ignore Creator Rights and Licensed Markets are EmergingIn spite of the concerns flagged above, markets where content is properly licensed and creators are fully compensated are emerging, and government can play a role in helping ensure that these markets continue to develop and flourish.The major recording labels are leading the way in the market based partnerships where ethical AI is a tool and artists are kept at the centre of the initiatives:--The launch of YouTube’s AI incubator in partnership with Universal Music Group which brings together a group of leading UMG artists, songwriters and producers, Google DeepMind technologists, and YouTube and UMG experts to explore AI-related musical tools and products. This project is predicated on human creativity and takes into account the interests of creators and copyright holders.--Sony Music Entertainment’s debut project with David Gilmour (of Pink Floyd), Legacy Recordings, and Vermillio, where the artist invites fans to remix music from the album Metallic Spheres and its cover art, using AI-powered tools (Vermillio is a generative AI platform that empowers creators and protects their work using authenticated AI);--Warner Music Group’s use of AI technology, with the consent of the estate of legendary French artist Edith Piaf, to recreate the artist’s voice and image for an animated biopic. This project uses AI technology trained on hundreds of voice clips and images spanning decades to help capture her story and impact authentically.Other industries are similarly making collaborative progress. For example, Getty Images has launched Generative AI by Getty Images, which trains its library on licensed photos and compensates the artists whose images were trained. Shutterstock has licensed its image, video, and music libraries to OpenAI for training and established a Contributor Fund that compensates artists for their creative inputs. And other leading tech companies are reportedly negotiating licensing arrangements with rightsholders. In July, The Associated Press reportedly reached a deal with Open AI to license its archive of news stories. A voluntary market which allows for AI innovation and compensation to creators is emerging and growing.If the Government wishes to see these types of marketplaces develop and thrive, ones where creators receive credit and compensation, and retain consent and control, while AI developers continue to create exciting and world changing technology, then we must ensure that t existing intellectual property protections remain robust. How to do that is discussed through these submissions.","3.1 Ingestion of copyright works and sound recordings to train systems constitutes infringementGenerative AI can only generate what it has already seen and learned from, and in order for it to produce quality outputs, it needs quality inputs. In many cases, those inputs are sound recordings found on digital platforms. Rightsholders to those sound recordings must be able to choose whether to grant or refuse permission for their use. The IP rights engaged in the use of training AI systems with sound recordings is not uncertain. It engages a copyright owner’s exclusive rights, which are the building blocks of a fair and competitive market.While the technology behind AI is new, using recorded music to make new music is not new. The tech of sound recording reproduction has evolved from analog digital mixing, sampling, and encoding techniques. Generative AI systems built on sound recordings is just another use and too must be licensed.3.2 Exceptions to copyright infringement must be decided on a case-by-case basisSome AI developers will argue that copies made during ingestion are “ephemeral” and not subject to copyright. In practice, copies are made throughout the training process: first in compiling and cleaning datasets, and then in model and development fine tuning. It’s often necessary to keep copies of the dataset on hand through different iterations of the process. All of these are unauthorised reproductions.Some will argue that the use of ingestion copies is fair dealing. In Canada, fair dealing is fact specific and determined on a case-by-case basis. But unauthorised reproduction of works by AI developers to develop models that produce AI-generated works that compete with the input works is presumptively unfair. There is a market ready and willing to license these uses. Each of these factors indicates that this copying is presumptively unfair. But ultimately, whether an infringement is permitted by fair dealing must be assessed on a case-by-case basis.3.3 “Opt out” systems are ineffective and place an impossible burden artists and rightsholdersAI developers may also advocate for “opt out” systems, whereby copyright owners would have to take positive action to “opt out” of their works being used by systems and models. Such an approach would fly in the face of the foundation of copyright, which is a permissions based, “opt-in” regime. Copyright owners have certain exclusive rights set by the Act.Opt-out regimes would place undue burdens on artists and creative rightsholders. It is effectively a game of whack-a-mole, where creators are required to patrol AI datasets and models, most of which lack the requisite transparency and accountability to even begin taking steps for enforcement. Opt-outs burden the wrong party.3.4 TDM activities can and should be licensed by rightsholdersThe recording industry is ready and willing to license the use of their recordings for compensation that matches the value of the use of their works. It has the infrastructure and proven track record for licensing large catalogues of music.The music industry has built a marketplace where massive amounts of copyrighted works, performances, and sound recordings are licensed every day to a variety of platforms and technologies. Record labels routinely and directly license new technologies and evolving uses of music – including for sampling in other recordings, for sync licenses that permit use in TV shows, films, and in advertising. They also license recordings to social media and UGC sites (e.g, YouTube, Snapchat, Instagram, TikTok), fitness services (Apple Fitness+, Peloton), and other emerging and evolving business models. There is no need for compulsory collective licensing to license these works.3.5 Compensation for TDM activities must be determined in a competitive marketplaceCompensation for TDM activities must be determined in a free and competitive marketplace. Policy choices that remove competition or distort the market – such as compulsory licences, collective licensing through government intervention, or exceptions without proof of market failure – must be avoided.The recorded music marketplace has a proven track record of negotiating compensation for different uses of music. The majority of record industry revenues are determined in the marketplace. Organisations and individual rightsholders can license on a collective basis, provided that such collective licensing is done without compulsion or intervention and consequently reflects a fair and voluntary marketplace.3.6 Challenges in licensing TDM activities emanate from AI developers, not creative rightsholdersRightsholders face challenges in licensing their works for TDM activities primarily because AI developers have built models and systems trained on their copyright without seeking permission from rightsholders. Some AI developers operate under the mistaken belief that all uses are exempt from copyright liability. Currently, there is almost no way for rightsholders to know if and how their content was used. This makes it extremely difficult for copyright owners to exercise agency over how their works are used and whether they receive compensation or credit.Some AI developers argue that their systems are trained on such vast quantities and sources of text and data that they could not be burdened with licensing those works. But everyday, millions of sound recordings and copyright works containing multiple rights are licensed and they have metadata which allows their licensing and compensation to be easily administered and tracked. This is no different.Some AI developers argue that the economic requirements of licensing will harm AI innovation. This type of thinking nearly wiped out the music industry 15 years ago, but fortunately licensed streaming services are driving revenues back to creators as music has commercial value again. AI developers’ reluctance to compensate rightsholders to train their systems on high quality recordings does not justify the creative industries subsidising them.Some developers argue that the value of a license for training owed to an individual artist would be so small that creators are not likely to benefit. Even if negotiated marketplace rates were individually small, there is no justification for why AI companies should get to keep that compensation.3.7 Approach in other marketsThis past year, the UK rejected plans for a broad TDM exception. The Parliamentary DCMS committee recommended that “the Government … not pursue plans for a broad text and data mining exemption to copyright,” and that “[it] should support the continuance of a strong copyright regime in the UK and be clear that licences are required to use copyrighted content in AI. . . . [T]he Government should act to ensure that creators are well rewarded in the copyright regime.” In January of 2024, the UK Government response to that report stated that: “the reproduction of copyright-protected works by AI will infringe copyright, unless permitted under licence or an exception. …[T]he Government instead committed to develop a code of practice on copyright and AI, to enable the AI and creative sectors to grow in partnership. This supports the Government’s ambition to make the UK a world leader in research and AI innovation, while ensuring that the UK copyright framework continues to promote and reward investment in creativity.”While Japan has implemented a TDM exception, there are clear guardrails to ensure that it does not enable or permit the free and unfettered use of copyright-protected content to develop AI models and to ensure Japan’s compliance with its international treaty obligations. In particular, the use of copyright-protected content is not permitted where the use would “unreasonably prejudice the interests of the copyright owner.” The plain text of the provision and the three-step test enshrined in international treaties make clear that views that the exception permits the wholesale ingestion of copyright works and other protected subject matter for the development or training of an AI system are mistaken.The EU has two provisions for TDM exemptions. Article 3 provides a TDM exemption for scientific research conducted by non-commercial organisations or cultural heritage institutions. Article 4 provides for TDM exemptions for commercial uses, subject to an opt-out provision requiring a machine-readable opt-out request from the rightsholder. Both of these exemptions apply only where there was lawful access to the copyrighted works in question.Canada should continue to work with its international counterparts to promote policies that protect copyright and creators internationally. Canada should oppose broad and novel copyright exemptions that would violate international treaty obligations.3.8 Developers should be required to maintain records of training and ingestion copiesAI developers and creators of training datasets should be required to collect, retain, and disclose records regarding the material used to train their models. Absent such requirements, it is virtually impossible for rightsholders to discern how their works were used in the development and operation of these systems. In order to ensure the safety of these systems, and to have functioning copyright frameworks, AI systems must be accountable for the works they ingest and are trained on.Complete recordkeeping of copyright works, including how they are used to train AI systems and to generate outputs is essential. The government should require the maintenance of auditable records, as many AI companies are not currently voluntarily providing sufficient information about the data they have used. Similarly, AI developers and deployers who use third party training datasets or pre-trained models should obtain, keep, and make available necessary data from upstream sources. [Please see pdf of submission for full recording keeping specifics]","Given that the technology for training AI models at this time necessarily requires making copies, we are not seeking changes to the Copyright Act with respect to authorship or ownership. However, that position may change depending on how the technology and methods of ingestion evolve. Copyright owners may need further clarity to confirm that ingestion of copyright is the exclusive right of the copyright owner for them to exercise or authorise others to do so.4.1 Outputs created with the use of copyright works and sound recordings can be infringingIngestion copies used to develop AI models that generate audio outputs are just a new method to process sound recordings. The output is not a recording of a new performance. While AI systems process sound recordings in a more sophisticated and obscure manner compared to analog means, it is still a type of remixing of the copyright owner’s sounds and as such can be infringing depending on the circumstances.In addition to infringement of rightsholders’ exclusive rights through use of inputs, outputs may also be infringing. When AI outputs are identical to pre-existing sound recordings or when the outputs include identifiable portions of pre-existing sound recordings, the exclusive right of the copyright owner in the sound recording is engaged. Even where the human ear can’t identify the full or partial copies of the pre-existing recordings in the outputs, the outputs can still be infringing.4.2 Works generated solely by AI without any human involvement do not warrant copyright protection or new forms of protectionsCopyright protection exists to incentivize and reward human creativity, skill, and judgement, and as such, it should not be awarded to content that is generated without any human creativity. Human artistry provides a unique value and remains fundamental to the creation of creative works such as music. Extending copyright to generative AI outputs created without any human authorship risks devaluing human creators and flooding the marketplace with machine-made content, making it harder for consumers to find and support the human-made works from artists they love. Large volumes of AI-generated works are already being dumped into the marketplace. Moreover, this puts human artists at risk of infringing the myriad of works made instantaneously by machines.AI-generated music is already diverting the flow of royalties and fan engagement away from human creators. Our industry is working to combat AI-generated tracks that are followed by bots designed to create “fake listens” on streaming platforms, a method of automatized streaming manipulation that siphons royalties away from legitimate creators. Our members are working with digital platforms and others to prevent this issue, but it is another example of resources being expended by creators to combat those who game systems at the expense of human creators.There are currently more than adequate incentives to encourage the continued development of generative AI, as demonstrated by the extraordinary amount of investment in AI technologies and the companies behind them. Such companies already benefit from patent law, copyright in computer code, and other incentives that spur such extraordinary investments. Fundamental changes in copyright law or new sui generis regimes protecting AI generated works are demonstrably unnecessary.","5.1 Concerns about existing legal tests for demonstrating that an AI-generated work infringes copyrightOur copyright framework is generally sufficient to address the copyright related issues that have arisen to date in connection with generative AI. That said, as the technology continues to evolve, the Copyright Act may need to be amended to ensure that copyright owners retain exclusive rights over the ingestion of their copyrighted works or subject matter and authorise others to do the same.At present, the most significant impediment for rightsholders to determine whether AI-generated work or systems infringe their copyright is the lack of information on when and how their intellectual property is copied and used to train the AI system and models. AI developers must be required to keep detailed records regarding training inputs and other information (as more fully discussed in our submission on TDM issues). Any such measures should also include appropriate disclosure requirements and penalties for non-compliance.These requirements are not only necessary for transparency as an end goal itself, but are also vital to promoting accountability, facilitating licensing, and enabling effective enforcement which helps to maintain the incentives for creating, distributing, and marketing the new sound recordings and other creative works that Canadians enjoy.Moreover, record keeping would help the government better understand the potential biases of systems or how other essential rights may have been infringed, such as privacy rights of individuals and whether these systems are safe.5.2 Need for Labelling of Generative OutputsWorks generated solely with AI should be labelled and identified as such, as well as any works that are substantially modified with AI to mimic a sound recording artists’ name, image, voice, or likeness without authorization. Labelling is particularly important where the risk of deception is high or a human is being impersonated or mimicked. The public interest warrants consumers understanding what is real and created with the involvement of a human or what is made purely by machine. This labelling should be tamper resistant and include digital watermarking and metadata identification.5.3 Government must be mindful of the risk of AI launderingCanada, alongside its other major trading partners, has the opportunity to set policies that avoid an international “race to the bottom.” AI developers should not be able to import AI models into Canada that were trained on infringing ingestion copies in a jurisdiction where that training was not prohibited. AI companies should also not be able to claim that their training met a fair dealing exception, but then sell access to those systems to companies who will use them for presumptively unfair commercial purposes.The EU AI Act has taken a leadership position on this issue, stating that the Act applies to any model placed in or put into service in the EU, regardless of whether they were developed and/or trained in- or outside the EU.International consistency will help protect the human element of creativity and create a marketplace where ethical AI can flourish. Canada has an opportunity to be a leader on this front.5.4 Clarity on where liability lies when AI-generated works infringe existing copyright protected worksWho is liable for copyright infringement is, as always, determined on a case-by-case basis. However, anyone who reproduces a substantial part of a copyrighted sound recording, communicates it to the public by telecommunication, or publicly performs it is an infringer. Copyright enforcement regularly contemplates multiple infringers depending on the facts, and in the case of AI, it could include the model developer, the system developer, and the users of the system which generates infringing outputs.5.5. Existing legal protections for rights of publicity must be modernised to protectCanadians from harmful deepfakes and vocal clonesGenerative AI has made such significant advancements that very real “deepfakes” and vocal clones of artists, athletes, politicians, celebrities, and everyday individuals can be made with little effort and with such close mimicry that it can be hard to tell whether it’s real or not.For recording artists, unauthorised deepfakes steal and manipulate their voice and image without their knowledge or consent. They create unfair competition and threaten their reputation. An artist’s voice and image is their livelihood. When an artist’s voice or visual likeness is cloned, they are robbed of their identity, reputation, and relationship with their fans, who don’t know if the images they see or the music they hear is authentic or simply AI-generated. Athletes, celebrities, and public figures face similar threats.But while the music industry’s concern centres on protecting artists’ reputations and careers from such theft and manipulation, similar digital assaults on government representatives and politicians raise potentially grave national harms. Beyond the theft and manipulation of their voice and image lurk serious risks to national security, impacts on our markets, and threats to our democratic institutions. And everyday Canadians are also susceptible to having their voice and image clones by bad actors looking to exploit them online.Canada’s current privacy and publicity laws which offer some shields to these harms were designed for a time when we were worried about a celebrity’s image being used without their permission to promote a product in a magazine. But today, misappropriating one’s voice or visual likeness through AI-generated deepfakes is much more invasive and convincing, and can be carried out on a massive scale, around the world, in a matter of minutes. Virtually anyone can do it at any time – with publicly available code and common hardware. Once one discovers the deepfake of their face or voice, they face a long and slow process in court with an unpredictable and difficult outcome. By then, the damage has been done.The government has the opportunity to harmonise and solidify existing piecemeal provincial and common law protections by legislating the following:(i) A federal publicity right so that Canadians can protect how their voice and visual likeness is used. The right can be licensed or assigned where and how they choose. And there can be reasonable limits on this prohibition (e.g., where the use is essential to news, public affairs, parody, satire or other expressly limited purposes).(ii) Create a cause of action restricting not only the unauthorised deepfakes themselves but also the creation and dissemination of AI systems and models whose main purpose or function is to create misleading deepfakes or vocal clones.Opponents to a modernised publicity right may argue that such guardrails will stifle innovation or chill free speech. But bad actors putting words or messages in the voice of a human artist or politician against their will or without their knowledge or consent has nothing to do with innovation. And it’s not an exercise in free expression to steal someone else’s face or voice and make them say what you want. Digital disclaimers or labelling will not be enough to reverse the large majority of harms caused by these misappropriations.Interestingly, in response to the US Copyright Office’s Notice of Inquiry (“NOI”) of August 30, 2023, there was even a consensus among a number of AI tech companies who filed responses to the Inquiry that a new US federal right of publicity ensuring that individuals can control their voice and likeness is necessary to address the unique threats of generative AI.To allow the positive uses of this technology to continue, deepfakes or vocal clones created with an individual’s consent would continue to be permissible. For example, individuals who wish to preserve their image and voice in the case of medical situations, or who wish to license their image, name or likeness for specific purposes, will still be able to do so where and how they choose.We encourage the government to closely examine the motives of organizations who seek permissionless “innovation” at the expense of others.ConclusionPlease note that our submission has also been provided to department officials in pdf form as it contains extensive footnotes citing secondary materials. That pdf delivers the same comments as provided in this online form.We appreciate the opportunity to contribute to the government’s consultations on generative AI and copyright. We welcome any questions or requests for further information.","[Please note that we have provided to department officials a pdf of our submissions which includes full footnotes with secondary sources supporting our comments]We applaud the government’s work to help ensure Canada is a leader in responsible AI and we welcome the opportunity to engage in these Consultations.Our major label members constantly invest in and adopt new technologies and innovations, and work with artists to develop and use new tools to advance the creative process. This includes working with AI technologies, from the use of machine learning to better understand user behaviour and preferences, to systems that assist in the creative process. Tools driven by AI play an increasingly important role in the artistic process in the music sector -- including in audio mixing, automated mastering, computer-aided orchestration, and elsewhere. AI is a tool that can help unlock an artist’s creativity or find efficiencies in processes, but it is not a substitute for the human element of creativity.But because music is widely and easily accessible in ways that other works are not, we have also been early targets of unauthorized reproduction of and training on the copyright works and recordings of music labels, publishers, and songwriters, and on the performances of recording artists and their voices. While licensed music services have been employing and continue to develop different technologies to protect their platforms from unauthorized access, web scrapers still manage to bypass these blocks in order to reproduce and train their systems on the music of creators. Music creators have been among the first in the creative industries to feel the harms of generative AI that does not respect their intellectual property and right to protect their agency, voice, and image.The fake Drake and the Weeknd track that was released last spring made one thing abundantly clear: AI models and systems have already ingested massive amounts of proprietary datasets without authorization from the source of the data or rightsholders. While developers will argue that this is essential to innovation, or that it’s fair because it’s for “research” or to “educate” AI systems -- there is nothing “fair” for the artists whose voices were cloned or their images taken without their permission.But with the risks of AI, there is also great promise, and it is not too late to set the course for ethical and innovative AI markets. Major labels are working with companies who are willing to respect the rights of artists and creators -- and they’re finding exciting ways to bring world-changing AI to consumers and new tools to help artists achieve career and creative goals. Markets where creative works are licensed and where creators receive commensurate compensation are developing. The government has the opportunity to set policies that encourage the ethical development of this exciting new marketplace, which if managed properly, will elevate our creative industries while also developing AI tools capable of solving some of the world’s most pressing challenges. Innovation in AI and a thriving creative industry can be mutually enriching, rather than mutually exclusive.Progress in AI innovation and adequate copyright protection that fuel the creative industries are not mutually exclusive. On the contrary, AI processes that depend upon the “input” of protected works or subject matter derive their purpose and value from those works or subject matter. Accordingly, a reduction in the protection of works or sound recordings (for example by broadening or introducing new exceptions to copyright), would in turn reduce incentives for their creation, ultimately harming innovation and investment in this area. Supporting thriving creative sectors through adequate legal frameworks should be a central pillar of any policy aimed at stimulating developments in AI. In short, our members must retain control over whether and how their recordings are used in AI processes.As the Government develops policies around generative AI and copyright, we urge it to ensure that artists and the businesses that invest in them are incentivized to continue producing creative works that are essential to the human experience and the quality of our lives.Thank you again for the opportunity to participate in these consultations."
Music Publishers Canada,Association,"1. INTRODUCTIONMusic Publishers Canada (“MPC”) is a membership-based organization that ensures the views of music publishers working in Canada are heard. It is our mission to create business opportunities for our members and to promote their interests and those of their songwriting partners through advocacy, communication, and education. Music publishers invest in thousands of Canadian songs and songwriters that are heard daily on the radio, on streaming services, in video games, and in film, television, and other screen-based productions around the world.MPC recognizes that artificial intelligence has the potential to be enormously beneficial when it is implemented in a responsible and ethical manner, and MPC embraces that potential. In the music space, AI has the potential to support the valuable work of human creators, which in turn enriches Canadian culture and society. Our members are already exploring the benefits of this new technology.However, the astonishing rate of both acquisition (or sometimes appropriation) of copyright-protected datasets and content on the input side, together with the development of generative AI models on the output side, pose serious risks for Canada’s creators and the companies that invest in them.Copyright is the key protection that allows MPC’s members to control and be paid for the use of their music. Copyright ensures that our members can share in the value if a third party wishes to use their music and ensure that the value is not appropriated solely by the user.When an AI company uses music that has been scraped from the Internet without authorization, whether for training or other purposes, it prevents rights holders from controlling and realizing value for the use of their works. It also contributes to the destruction of a developing market for the licensing of copyright-protected content to AI developers before the market can flourish. Further, the development and commercialization of unlicensed AI model inputs and generative AI products can—and, in many ways, already are—creating serious market distortions, raising concerns about fair competition.Human creation and expression, and their contributions to Canadian culture, must not be sacrificed at the altar of rapid technological progress. To strike the appropriate balance, Canada must approach generative AI in ways that respect creators and copyright and incentivize human expression. AI companies, like other commercial users, require permission from copyright owners to use copyright-protected content through negotiated licences.The development of public policy surrounding AI is in its infancy. That gives the Government an important opportunity to lead the world in maintaining strong respect for copyright and the rights of creators.2. THE USE OF AI IN THE MUSIC INDUSTRYMPC’s members embrace technological change and invest in innovation. We know that there are already uses of AI in the music space. For example, AI is used to analyze and predict the audiences for an artist’s music and to identify and target emerging artists. AI technology has also long played a role in the recording studio, including automation tools that can augment human-mixed recordings or even assist in the process of creating brand-new audio mixes.But a new market is also developing for the licensing of music and other works to be used as training materials for generative AI models. Reported examples of the licensed use of copyright-protected content by AI companies include the following:a) Meta’s MusicGen tool was trained on 20,000 hours of licensed music from ShutterStock and Pond5 [https://techcrunch.com/2023/06/12/meta-open-sources-an-ai-powered-music-generator];b) Stability AI’s new generative audio model, Stable Audio, was trained on a dataset provided under a licensing deal with a provider of stock music [https://stability.ai/stable-audio];c) Universal Music Group (UMG) announced a collaboration with YouTube to experiment with generative AI tools predicated on human creativity and that account for the important interests of creators and copyright holders [https://www.latimes.com/business/technology/story/2023-08-21/youtube-universal-music-ai-artificial-intelligence];d) UMG has also announced collaborations with generative AI developers to explore how their technology can promote and enhance the creative process, such as with Endel, an AI tool that allows artists to generate content from their own sound recordings, and with Bandlab, the world’s largest social music creation platform;e) The generative AI imagery used during U2’s new live show at the Spherem reportedly uses legally-ingested artwork by Es Devlin to spectacular effect.As we discuss in more detail in the text and data mining section of this submission, large-scale licensing of copyright-protected works can be practicable and effective.3. AI DEVELOPERS USE EXISTING WORKS AS TRAINING MATERIAL WITHOUT AUTHORIZATIONAI developers obtain training material from multiple sources, including by scraping vast troves of content from the Internet and via pre-existing data sets. In many cases, the content is obtained without authorization from the rights holders and the AI developer does not disclose the source of the content.This poses unique challenges in relation to musical works, which can be taken from the Internet in a variety of formats, including digital audio and audiovisual files containing musical works, song lyrics in text format, musical tablature and sheet music, MIDI files, and more.Web-scraping occurs on a vast and indiscriminate scale and inevitably yields vast amounts of copyright-protected content. Scraping typically occurs without authorization of rights holders. In fact, it can be performed on webpages that, themselves, host and make available pirated content.For example, it is reported that the training set used to train Google’s T5, Meta’s LLaMA, and other generative AI models, was trained using scraped content, including a subscription-based digital library, Scribd [https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/]. OpenAI, a leader in generative AI, has also stated that its experience training AI models has involved “the use of large, publicly available datasets that include copyrighted works” [https://www.uspto.gov/sites/default/files/documents/OpenAI_RFC-84-FR-58141.pdf].AI developers may also acquire training material from datasets collected and made available by third parties, some of which contain copyright-protected content obtained through large-scale web-scraping. A notable example is the Common Crawl dataset [https://commoncrawl.org/], which is a publicly available collection of large-scale web data used as the primary training corpus for most major LLMs. OpenAI has reported that 60% of the training data for its GPT-3 model was drawn from Common Crawl [https://arxiv.org/pdf/2005.14165.pdf].From a copyright perspective, copying works to create a dataset, making the dataset available to be viewed and downloaded on the Internet, and exploiting the dataset to train, re-train, and fine-tune an AI model are each a separate and distinct exercise of a protected right.4. LICENSING AND TRANSPARENCY CAN MITIGATE LIABILITYThe Consultation asks, “What measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works?”The best and most appropriate way to mitigate liability risk is for AI developers and dataset aggregators to obtain prior permission to exploit rights holders’ works, in accordance with Canadian copyright law and policy. The Government can incentivize that in two important ways.First, a market is already developing for the licensing of music to AI companies. The growth and maturation of that market ought to be encouraged. Licensing large catalogues of music, including to new and disruptive technology companies, is what music publishers, copyright collective societies, and other rights holders do. MPC’s members, and the collective societies that represent them, have extensive experience negotiating bespoke licence agreements for the use of their repertoires by technology companies.  MPC implores the Government to permit the nascent market to develop and flourish, and not to eradicate it by introducing new or modified copyright exceptions for text and data mining or other AI activities.Second, AI developers and data aggregators involved in any stage of training or testing AI models should also be required to disclose the dataset used to train or test the models and maintain complete and detailed records of that data. This requirement would ensure transparency and promote a functional licensing market, disincentivize unauthorized use of copyright-protected works, and restore the appropriate copyright balance by enabling rights holders to be compensated for the use of their works and to pursue enforcement options against infringers.Certain market developments underscore the importance of ensuring that AI companies comply with existing copyright laws and norms. OpenAI, which as noted above has acknowledged training its models using vast amounts of protected content, is receiving massive investment from Microsoft, reportedly in the amount of $10 billion. In turn, Microsoft, Google, and other deployers of AI products have announced a commitment to indemnify users of certain of their AI products, if the users are sued for copyright infringement in connection with the use of those products. [https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/]. These developments, combined with the prospect of AI companies seeking to perform TDM activities in territories with the weakest copyright protections, suggest that, left unchecked, AI companies will continue to seek a competitive advantage built on a rampant neglect for the rights of creators and rights holders.","1. TDM SHOULD BE LICENSED, NOT EXEMPTThe Copyright Act is intended to achieve a balance between promoting the public interest in the encouragement and dissemination of original works and obtaining a just reward for the creator or, more accurately, to prevent someone other than the creator from appropriating whatever benefits may be generated [Théberge v Galerie d’Art du Petit Champlain inc, 2002 SCC 34 at para 30].This balance requires that AI developers obtain permission and pay for the use of copyright-protected works as AI training materials. TDM activities should not be given special status by introducing new copyright exceptions or modifying existing ones. In fact, a TDM exception would likely put Canada in breach of its international treaty obligations.Copyright works add value to the AI training process. There is no legal or factual reason to allow AI developers to appropriate that value exclusively to themselves, especially by scraping online content on a vast and indiscriminate scale. To derive fair value for the use of their repertoires, music publishers routinely grant licences to technology companies. AI developers should be no different. The nascent market for licensing music to AI developers should be encouraged, including by requiring AI companies to disclose, and maintain records of, all their training data.Finally, MPC urges the Government to reject any suggestion that TDM should engage a mere right of remuneration or be subject to an opt-out model.2. NO NEW EXCEPTION FOR TDMTo maintain the proper copyright balance, the Government must reject calls for a categorical copyright exception for TDM. Rights holders must be able to control, and realize value for, the use of their works as AI training material, in accordance with Canadian copyright law and policy. Indeed, the ability to grant licences is central to the livelihood of creators and rights holders, and it is “a hallmark of copyright” [Euro-Excellence Inc v Kraft Canada Inc, 2007 SCC 37 at para 117].Copyright content is a particularly valuable form of training material for an AI model. The quality of an AI model’s output is proportional to the quality and quantity of its training materials. Copyright works are the products of human skill and judgment and the investment of time and resources. As such, many copyright works feature qualities that make them particularly valuable for use as AI training materials: nuance, richness, contemporary relevance, reduced “noise”, integrity, reliability, and formatting consistency. All of this helps AI models turn out high-quality content that will attract and retain users. OpenAI has acknowledged that, if protected works are not used for training purposes, it would “lead to significant reductions in model quality.” [https://www.uspto.gov/sites/default/files/documents/OpenAI_RFC-84-FR-58141.pdf, at footnote 33.]Rights holders must be entitled to control the use of their works as AI training material and share in the value created when they are used. That is best achieved through copyright protection and licensing.Calls for a new copyright exception for TDM must be rejected. A new exception would eliminate the nascent licensing market before it can flourish and deprive rights holders of value for the use of their works as AI training material. An exception would appropriate the entirety of that value for the benefit of AI developers and data aggregators.A categorical TDM exception would also violate the three-step test of the Berne Convention, violating Canada’s international treaty obligations. This test limits permissible exceptions to certain special cases that do not conflict with a normal exploitation of the work and do not unreasonably prejudice the legitimate interests of the author” [Berne Convention for the Protection of Literary and Artistic Works (1979) at art 9(2)]. A categorical exception for TDM would not be limited to “special cases”. It would also eradicate the developing market for licensing works as AI training material, thus interfering with the normal exploitation of works and prejudicing the legitimate interests of rights holders.Affording special status to TDM would also violate the principle of technological neutrality, which requires that copyright law operate consistently, and not favour or discriminate against any particular form of technology [Canadian Broadcasting Corp v SODRAC 2003 Inc, 2015 SCC 57, para 66].The Consultation Paper notes that the existing exceptions for fair dealing and temporary reproductions for technological processes could potentially apply to TDM. While it is doubtful that these exceptions would apply to TDM, due in part to the application of the Berne Convention three-step test, the potential application of these exceptions is highly fact-dependent. It would not be prudent to attempt to address the potential application of these exceptions to TDM on a general or presumptive basis. That is a matter best addressed by the courts.3. LICENSING MUSIC IS NOT AN INSURMOUNTABLE CHALLENGEThe music business is a licensing business. Any argument that licensing is impractical due to the quantity of data involved must be rejected.Rights holders are experienced in licensing and administering large catalogues of works, including to technology companies. Canadian copyright collective societies like CMRRA and SOCAN process and license billions of lines of music data, or individual performances, each year. Any challenges that might arise are foreseeable and not insurmountable.It also cannot be assumed that all AI models are trained on the same size of datasets. Introducing a TDM exception based on perceived challenges for AI models that train on massive datasets would destroy licensing markets for other AI training methods, such as the use of smaller and more carefully curated datasets.In any event, any licensing challenges that may exist cannot justify the eradication of an exclusive right or the deprivation of a rights holder’s ability to realize value for the use of its works.4. RECORD-KEEPING AND DISCLOSURE IS CRITICALTransparency is critical to protect creators and rights holders and to strike an appropriate balance between fostering innovation in new technologies, on one hand, and protecting the legitimate interests and exclusive rights of rights holders, on the other. AI developers and deployers should be required to keep, and make readily available to rights holders, detailed and accurate records of their training data, the sources of that data, and the existence of any licences authorizing its use. Without those obligations, it will be extremely difficult, if not impossible, for rights holders to detect infringement and pursue enforcement options.Further discussion on this topic can be found in our response to the section of the Consultation addressing infringement and liability.5. THERE SHOULD BE NO COMPULSORY LICENCE OR OPT OUT SYSTEM FOR TDMThe Consultation Paper asks what “level of remuneration would be appropriate for the use of a given work in TDM activities.” The appropriate level of remuneration should be determined in the developing market for the licensing of copyright-protected works for AI training and other uses, not by the Government.To be clear, the Government should not entertain any suggestion that would eliminate a rights holder’s exclusive right of reproduction in favour of either a compulsory licensing system or an “opt-out” system. Since a functional market for the licensing of musical works to technology platforms already exists, and is adapting rapidly to the needs of AI companies, there is no reason for the Government to impose either approach.Compulsory licensing would be an extreme and prejudicial response to a non-existent problem. Among other things, it would (i) deprive rights holders of their right to contract freely in the market, preventing them from assessing and capturing fair value for the use of their works; (ii) prevent rights holders from choosing how their works are used and by whom, forcing them instead to allow the copying of their works for uses they cannot control or anticipate; and (iii) impose significant administrative burdens, including the creation of a needless and complicated infrastructure to administer and enforce the regime. Quashing an exclusive right of reproduction in favour of a right of remuneration would also raise serious concerns under Canada’s international treaty obligations.An opt-out system would also be antithetical to Canadian copyright law and policy and would drastically shift the copyright balance away from rights holders. In Canada, copyright is an opt-in system: prospective users of protected works must obtain advance permission from the copyright owner, who has an exclusive right to authorize—or refuse to authorize—the use. To depart from these fundamental principles would lead to an unwarranted erosion of copyright protection in Canada. It may also be contrary to the Berne Convention, which prohibits conditioning copyright protection on any formality requirement [Berne Convention, art 5(2)].An opt-out system would place a disproportionate burden on creators and rights holders. It would require them to investigate and implement affirmative steps to prevent the infringement of their rights and to monitor compliance on a user-by-user basis. Rights holders who lack the legal or technological sophistication or resources to do so would be treated inequitably as unwitting licensors. In addition, because many rights holders do not control the websites on which their works appear, they would be unable to directly access the website’s code to exercise an opt-out right. The same is true for online piracy sites that rights holders might not be aware of.Finally, an opt-out approach would impose an all-or-nothing assumption on rights holders who may instead be willing to license their works for specific purposes under certain conditions, including fair remuneration.","Consistent with our submissions to the Government’s “Consultation on a Modern Copyright Framework for Artificial Intelligence and the Internet of Things”, MPC submits that Canada’s existing copyright law framework is sufficiently robust and flexible to address issues raised by AI.The Copyright Act is intended to incentivize human creativity and expression. For example, several provisions of the Copyright Act indicate that an author must be a human: sections 6, 7(1), and 9 link the term of copyright to “the life of the author”, while section 14(1) imposes limitations on an author who is the first owner of the copyright based on “the death of the author”. These provisions suggest that some degree of human involvement is necessary for a work to attract copyright protection.Courts have confirmed on several occasions that authorship requires human involvement [see, for example, PS Knight Co Ltd v Canadian Standards Association, 2018 FCA 222 at para 147 <https://canlii.ca/t/hwj3l#par147.; Setana Sport Limited v 2049630 Ontario Inc (Verde Minho Tapas & Lounge), 2007 FC 899 at para 4 <https://canlii.ca/t/1sxmt#par4>]. They have also made clear that originality—the sine qua non for copyright protection—requires an author to exercise skill and judgment that is more than a purely mechanical exercise [see CCH Canadian Ltd v Law Society of Upper Canada, 2004 SCC 13 at paras 16, 25 <https://canlii.ca/t/1glp0#par16>]. That too suggests strongly that a human author must be involved in the creation of a protected work.The determination of copyright authorship and ownership rights related to AI-generated and AI-assisted works is highly fact-dependent. It should be made on a case-by-case basis. In the United States, the courts are now considering several cases that will assist with clarifying the boundaries of copyright law regarding generative AI content.","1. THERE ARE SIGNIFICANT BARRIERS TO DETECTING INFRINGEMENT AND ENFORCING RIGHTSThe Consultation Paper asks, “What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?”As noted in the Consultation Paper, to establish infringement by reproduction, a rights holder must establish that the defendant had access to the original copyrighted work, that the original work was the source of the copy, and that all or a substantial portion of the work was reproduced. A court may infer copying if the defendant had access to a plaintiff’s work and there is substantial similarity between the works [Pyrrha Design Inc v Plum and Posey Inc, 2022 FCA 7, paras 38 & 48 <https://canlii.ca/t/jlqcs#par38>].Without appropriate transparency, large-scale infringement might go undetected by rights holders. Rights holders only have access to the output of an AI system, from which it is nearly impossible to identify what copyrighted works were used in the dataset used to train the AI system. Even if a rights holder suspects infringement, it would be equally difficult, if not impossible, for a rights holder to establish that its work was used to train the AI model. This would create significant barriers to the rights holder’s ability to obtain a remedy—and a right without a remedy is no right at all.Thus, full transparency, including robust record-keeping and disclosure obligations, is necessary for rights holders to protect their intellectual property. Disclosure and record-keeping requirements would enable rights holders to know whether their works have been used. Standard copyright liability principles can then be applied to determine whether there has been an infringement, identify the infringer, and assess the resulting damages.In addition, record-keeping and disclosure of the materials used in AI training and testing activities would accomplish three key objectives:(i) promoting the development of a functional licensing market by incentivizing AI developers to seek authorization before using works and by disincentivizing unauthorized uses;(ii) reinforcing the rights of creators and rights holders to control the use of their copyright-protected works and to obtain fair remuneration for such use; and(iii) ensuring that the remedies in the Copyright Act are not nullified by the practical impossibility of detecting infringement and pursuing enforcement options.Transparency would also serve consumer interests. While consumers, unlike rights holders, may not need to know exactly what data was fed into the AI system they are using, they should not have to guess whether the system was trained on legitimate, authorized copyrighted works rather than infringements or fakes.For these reasons, developers and deployers of generative AI systems should be required to keep and make readily available detailed and accurate records of the data they have used for training, the source of that data, and the existence of any licences authorizing the use of that data. The records should be understandable to a layperson and detailed enough to identify (i) each specific work used in training, retraining, refining, or testing the AI model, or any similar use, (ii) any metadata associated with each work (e.g., title, author, owners), the immediate source of each work, (iii) the purposes for which each work has been used, and (iv) whether a licence has been obtained for each work.Record-keeping and disclosure obligations should apply to every person involved at each stage of the training, retraining, refining, testing, and other development of the AI model, including dataset aggregators.2. WITH RECORD-KEEPING AND DISCLOSURE OBLIGATIONS IN PLACE, THE CURRENT COPYRIGHT ACT WOULD BE SUFFICIENT TO ADDRESS AI-SPECIFIC ISSUESThe Consultation Paper asks, “Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?”Requiring detailed logs of data used by an AI model is a necessary best practice. As an example of transparent disclosure obligations, the European Union’s draft Artificial Intelligence Act would require automatic logging of events while high-risk AI systems are operating. The logging capabilities must address, at a minimum, (i) the recording of the period of each use of the system; (ii) the reference database against which input data has been checked; (iii) the input data for which the search has led to a match; and (iv) the identification of the natural persons involved in the verification of the results” [European Commission, Proposal for a regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts (“EU Proposal”), at art. 12 <https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206>].At the same time, the EU is also contemplating imposing similar record-keeping and transparency obligations on providers of so-called “foundational models”, which are defined as AI system models that are trained on broad data at scale, are designed for generality of output, and can be adapted to a wide range of distinctive tasks. Also under discussion are provisions that would require providers of so-called “general-purpose AI systems” to maintain detailed technical documentation for at least 10 years. That would include “data requirements in terms of datasheets describing the training methodologies and techniques and the training data sets used, including information about the provenance of those data sets, their scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection).” [EU Proposal, at art. 50 and Annex IV <https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206>].Given that record-keeping by AI companies is important for purposes that extend beyond copyright protection, record-keeping obligations could be enacted outside the Copyright Act (for example, in the Artificial Intelligence and Data Act).Importantly, AI developers should not be able to argue that they are shielded from liability for infringement because they do not retain copies of their training material once training is complete or that they did not compile the training data. Authorization from copyright owners is required before assembling and curating datasets that include copyright-protected works, much less before training AI models on those datasets. Whether or for how long the copies are retained is irrelevant.With appropriate proper record-keeping and disclosure obligations in place, the current Copyright Act will be sufficient to address issues specific to AI. Liability could potentially arise for primary or secondary copyright infringement, moral rights infringement, removal of digital rights management information, and circumvention of technological protection measures.","To strike the appropriate copyright balance, it is imperative that Canada approach generative AI in a manner that respects creators and copyright and incentivizes human expression. AI companies, like all technology companies, require permission from copyright owners before using copyright-protected content, whether to curate and assemble datasets or to train AI models on those datasets once assembled. That permission can and should be obtained through negotiated licences, not rendered moot by copyright exceptions, remuneration rights, or an opt-out system. Human creation and expression, and their contributions to Canadian culture, must not be sacrificed at the altar of rapid technological progress.Canada should lead the international community in respecting creators. The development of public policy surrounding AI is in its infancy. That presents the Government with an important opportunity to lead the world in maintaining strong respect for copyright and the rights of creators.Canada should not follow any international approaches to AI and copyright that would exempt or limit the scope of copyright protection in relation to TDM activities. MPC acknowledges and endorses commitments made by the G7, which broadly emphasize “multi-stakeholder” participation in the development of AI standards that prioritizes fairness, transparency, and adherence to existing law; commitment to “human-centric and trustworthy AI”; and continued discussion and analysis of how best to safeguard copyright and other IP rights [European Commission, “Hiroshima AI Guiding Principles and Codes of Conduct” <https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-advanced-ai-systems>; Government of Canada, “G7 Hiroshima Leaders’ Communiqué” <https://www.international.gc.ca/world-monde/international_relations-relations_internationales/g7/documents/2023-05-20-hiroshima-leaders-communique-dirigeants.aspx?lang=eng>]."
Le Regroupement des artistes en arts visuels du Québec (RAAV),Association,"Le Regroupement des artistes en arts visuels du Québec (RAAV) a la même mission depuis 30 ans : la défense des droits sociaux, économiques et moraux des artistes en arts visuels du Québec. Cette mission s'articule autour de 3 grands champs d'action : Représenter, défendre et outiller les artistes en arts visuels québécois.Cette soumission s'appuie sur plus de 220 réponses uniques à un sondage national préparé par CARFAC et le RAAV pour solliciter les commentaires des artistes sur leurs préoccupations concernant les produits d'IA générative, des centaines d'heures passées collectivement à communiquer avec des artistes a travers des comités et rencontres avec des intervenants du secteur culturel au Canada et à l'étranger.Une partie des artistes en art visuel, particulièrement en recherche, utilisent l'IA générative comme outil de création. Nos membres estiment que l'IA générative est et doit demeurer un outil, en ce sens que la créativité humaine doit toujours primer.","Comme l'a noté la Cour suprême du Canada dans l'affaire CCH c. Barreau du Haut-Canada, ""une œuvre originale doit être le produit de l'exercice de la compétence et du jugement de l'auteur. L'exercice de l'habileté et du jugement requis pour produire l'œuvre ne doit pas être si insignifiant qu'il puisse être qualifié d'exercice purement mécanique"". Ces mêmes critères devraient être appliqués lors de l'évaluation de l'octroi de droits d'auteur à des œuvres produites ou assistées par l'IA. La saisie d'une série d'invites textuelles dans un générateur d'images d'IA est assurément un ""exercice purement mécanique"", qui n'exige pas de l'utilisateur qu'il fasse preuve de ""compétence et de discernement"".Il peut toutefois y avoir d'autres situations dans lesquelles les œuvres d'art générées ou assistées par l'IA répondent aux critères actuels d'octroi du droit d'auteur. Par exemple, si un artiste conçoit un modèle d'IA, entraîne ce modèle avec ses propres œuvres d'art afin que le modèle puisse comprendre et interagir avec les données d'entraînement d'une manière unique spécifiée par l'artiste, le contenu généré par l'IA résultant de ce processus peut être mieux placé pour répondre aux critères du droit d'auteur. À cet égard, les lois existantes sur le droit d'auteur sont suffisantes pour traiter la question de la paternité et de la propriété, et aucune modification de la loi sur le droit d'auteur n'est nécessaire.Qu'impliquerait une plus grande clarté de la FTD relativement au droit d'auteur, à la fois pour l'industrie de l'IA et les industries créatives au Canada? Des activités de FTD sont-elles menées au Canada? Pourquoi est-ce le cas ou non?Comprendre comment fonctionne la technologie est essentiel pour permettre l'application du droit d'auteur. Une plus grande clarté permettrait de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les œuvres et autres objets de droit d'auteur sont utilisés. Une clarification permettrait également de déterminer dans quels contextes l'analyse informationnelle est autorisée, ou non, par le régime actuel de droit d'auteur canadien.Des activités de FTD sont actuellement menées au Canada, afin d'entraîner des modèles algorithmiques. Les activités de développement et d'entraînement de systèmes d'IA sont susceptibles d'impliquer la reproduction de contenus protégés par droit d'auteur (œuvres et autres objets de droit d'auteur tels que des prestations), sans que les titulaires de droits y consentent et reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d'y remédier.Les titulaires de droits font-ils face à des défis en ce qui concerne l'octroi de licences de leurs œuvres pour les activités de FTD? Le cas échéant, quelles sont la nature et la portée de ces défis?Oui, les artistes titulaires de droits ne se font pas contacter au sujet de licences pour l'utilisation de leurs œuvres. En outre, il est difficile pour les artistes ou leurs représentants de déterminer quel contenu est utilisé dans le contexte de FTD et quelle est l'ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d'imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d'IA. En utilisant ces mécanismes, les ayants droit pourraient disposer d'informations essentielles à la gestion de leurs droits d'auteur.Quels types de licences de droits d'auteur pour les activités de FTD sont disponibles et ces licences répondent-elles aux besoins des personnes qui mènent des activités de FTD?Diverses licences sont disponibles pour les activités de FTD impliquant l'exercice d'un droit réservé aux titulaires de droit d'auteur. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d'auteur ou être obtenues par le biais d'une société de gestion collective. Ces licences ne semblent toutefois pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner pour les titulaires de droits d'auteur qui peinent à obtenir une juste compensation pour l'utilisation de leurs contenus.Si le gouvernement devait clarifier la portée des activités permises de FTD, quelles devraient en être la portée et les mesures de sauvegarde? Quel serait l'impact d'une telle exception sur votre industrie et vos activités?Nous ne sommes pas favorables à l'adoption d'une exception générale permettant la FTD, laquelle serait prématurée et contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l'ADPIC et l'ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d'auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l'exploitation normale de l'œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur. Ainsi, si jamais le gouvernement décide d'adopter une exception de FTD, il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l'exception soit :Si jamais le gouvernement décide d'adopter une exception de FTD, cette exception ne devrait pas s'appliquer aux droits moraux, mais uniquement aux droits dits « économiques ». Nous réitérons cependant que l'introduction d'une nouvelle exception n'est pas souhaitable, car elle préjudicierait les intérêts des créateurs.Les développeurs de systèmes d'IA devraient-ils être tenus de tenir des registres ou de divulguer les contenus protégés par le droit d'auteur qui ont été utilisés pour la formation des systèmes d'IA?L'environnement actuel ne permet pas aux titulaires de droits de savoir si leurs œuvres ont été utilisées pour former des modèles d'IA générative. Ce modèle de fonctionnement opaque encourage l'utilisation non autorisée d'œuvres d'artistes canadiens par des développeurs d'IA et empêche la négociation de licences.De plus les développeurs et chercheurs du secteur de l'IA générative documentent déjà leurs données d'entraînement, par exemple, par le biais de fiches de données ou « model cards ». Les « model cards » peuvent documenter des informations structurées tels que les noms de domaines où ont été collectés les données d'entraînement. Ces développeurs disposent donc déjà d'outils permettant de documenter les données d'entraînement. L'introduction d'une obligation de transparence ou de tenue de registres ne devrait donc pas entraîner de coûts additionnels pour l'industrie de l'IA.Quel niveau de rémunération serait approprié pour l'utilisation d'une œuvre dans les activités FTD?La rémunération des artistes qui acceptent de céder leurs œuvres à des développeurs d'IA dans le but de former des produits d'IA générative devrait être déterminée par les artistes et les développeurs d'IA impliqués dans ces négociations, et non par le gouvernement.Le gouvernement peut favoriser une solution fondée sur le marché en veillant à ce que les entreprises d'IA opérant au Canada se conforment aux lois canadiennes actuelles sur le droit d'auteur, sans exception, et à ce que les dossiers des œuvres protégées par le droit d'auteur qui ont été utilisées pour former des produits d'IA soient rendus publics.L'IA générative a, et continuera d'avoir, des répercussions négatives sur les possibilités d'emploi dans les industries artistiques et culturelles. Tout en reconnaissant que les nouvelles technologies peuvent avoir de tels impacts, le gouvernement fédéral peut contribuer à stabiliser ces retombées en veillant à ce que les entreprises d'IA générative opérant au Canada respectent les lois sur le droit d'auteur qui soutiendront le développement de modèles d'octroi de licences.","Y a-t-il des préoccupations quant à l'application des critères juridiques existants pour démontrer qu'une œuvre générée par l'IA viole un droit d'auteur (p. ex. des contenus générés par l'IA qui incluent la reproduction complète ou une partie substantielle d'une œuvre utilisée aux fins d'activités de FTD menées sous licence ou d'une autre façon)?Il peut être difficile pour un titulaire de droit d'auteur d'identifier le contenu contrefait ou plagié, ainsi que la ou les personnes responsables de la violation et d'établir que la partie qui a violé le droit d'auteur a eu accès à l'œuvre originale, que l'œuvre originale était la source de la copie et qu'une partie importante de l'œuvre a été reproduite.Les artistes n'ont pas eu la possibilité de négocier l'octroi de licences pour leurs œuvres qui ont déjà été utilisées pour former des modèles d'IA générative. Bien que les modèles de licence ne soient pas utilisés par de nombreuses entreprises d'IA générative grand public, de tels cadres commerciaux existent dans l'industrie de l'IA. Getty Images, par exemple, a publié un générateur d'images d'IA formé exclusivement à partir de son propre contenu. Getty rémunère les créateurs pour l'utilisation de leur travail dans le modèle d'IA.La pluralité des intervenants, l'incertitude juridique, le manque de transparence quant aux systèmes de gestion des données, ainsi que l'opacité des systèmes d'IA sont autant d'obstacles pour que les artiste puisse faire respecter leurs droit. Cette opacité empêche les parties de négocier des conditions de licence et étouffe le développement de marchés de licence émergents. Pourtant, nous comprenons que les développeurs et chercheurs du secteur de l'IA documentent leurs données d'entraînement : une plus grande transparence sur ces données auprès des ayants droit est donc techniquement faisable.La résistance des entreprises d'IA générative à s'engager dans des négociations de licence avec le secteur artistique est un autre défi majeur dans l'établissement d'une approche basée sur le marché pour le consentement et la compensation des œuvres d'art utilisées dans le TDM.Meta, par exemple, a fait valoir que l'imposition d'un régime de licence après coup provoquerait le chaos dans le secteur et n'apporterait que peu d'avantages à chaque artiste, compte tenu de l'insignifiance de leurs œuvres respectives dans le contexte d'ensembles de données plus vastes. Cependant, OpenAI a récemment conclu un accord de licence avec Axel Springer, la société mère de Business Insider et Politico;Il est donc réalisable de mettre en place un régime de licenceLes arguments selon lesquels une seule œuvre protégée par le droit d'auteur est monétairement insignifiante dans le cadre de vastes ensembles de données ne peuvent pas être prouvés car il n'existe pas de cadres obligatoires dans lesquels les négociations de licence peuvent se dérouler. Quoi qu'il en soit, même si la valeur financière d'une œuvre individuelle est jugée faible, cela n'exclut pas le droit de l'artiste de consentir à l'utilisation de cette œuvre et d'être rémunéré pour celle-ci.Lorsque les entreprises d'IA générative ont utilisé, sans autorisation, les œuvres protégées par le droit d'auteur d'artistes de tout le Canada pour former leurs modèles et accroître la valeur commerciale de leurs produits, elles ont commis une violation du droit d'auteur et doivent par conséquent assumer la responsabilité de ces actes.Le fait d'exiger des entreprises d'IA générative qu'elles conservent et publient des registres des œuvres protégées par le droit d'auteur utilisées dans la formation de leurs modèles permettra de remédier à la violation du droit d'auteur à grande échelle qui a déjà eu lieu et fournira aux parties concernées les informations nécessaires pour négocier les conditions d'utilisation de ces œuvres. Cela permettra le développement de marchés de licences et renforcera les économies créatives du Canada, tout en accélérant potentiellement la croissance et la concurrence au sein de l'industrie de l'IA elle-même.La Loi sur le droit d'auteur dispose de mécanismes suffisants pour déterminer la responsabilité en cas de violation de droit d'auteur.Toutefois, afin de permettre une meilleure lecture de la responsabilité, le Canada pourrait imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d'IA.Nous recommandons que les entreprises qui violent la loi sur le droit d'auteur, ou toute autre loi canadienne, ne bénéficient pas d'une exemption au motif que ces actions ont déjà eu lieu.Existe-t-il des approches dans d'autres pays qui pourraient éclairer l'examen de cette question au Canada?Oui. Dans son projet de règlement « EU AI Act », le Parlement européen a introduit une obligation de transparence, de sorte que les entités qui développent des systèmes d'IA devront publier un résumé suffisamment détaillé de leur utilisation de « données d'entraînement protégées par la législation sur le droit d'auteur », ainsi qu'une information appropriée, claire et visible qui distingue le contenu généré de l'original.","Y a-t-il des préoccupations quant à l'application des critères juridiques existants pour démontrer qu'une œuvre générée par l'IA viole un droit d'auteur (p. ex. des contenus générés par l'IA qui incluent la reproduction complète ou une partie substantielle d'une œuvre utilisée aux fins d'activités de FTD menées sous licence ou d'une autre façon)?Il peut être difficile pour un titulaire de droit d'auteurD'identifier le contenu contrefait ou plagié, ainsi que la ou les personnes responsables de la violationD'établir que la partie qui a violé le droit d'auteur a eu accès à l'œuvre originale, que l'œuvre originale était la source de la copie et qu'une partie importante de l'œuvre a été reproduite.Les artistes n'ont pas eu la possibilité de négocier l'octroi de licences pour leurs œuvres qui ont déjà été utilisées pour former des modèles d'IA générative. Bien que les modèles de licence ne soient pas utilisés par de nombreuses entreprises d'IA générative grand public, de tels cadres commerciaux existent dans l'industrie de l'IA. Getty Images, par exemple, a publié un générateur d'images d'IA formé exclusivement à partir de son propre contenu. Getty rémunère les créateurs pour l'utilisation de leur travail dans le modèle d'IA.La pluralité des intervenants, l'incertitude juridique, le manque de transparence quant aux systèmes de gestion des données, ainsi que l'opacité des systèmes d'IA sont autant d'obstacles pour que les artiste puisse faire respecter leurs droit. Cette opacité empêche les parties de négocier des conditions de licence et étouffe le développement de marchés de licence émergents. Pourtant, nous comprenons que les développeurs et chercheurs du secteur de l'IA documentent leurs données d'entraînement : une plus grande transparence sur ces données auprès des ayants droit est donc techniquement faisable.La résistance des entreprises d'IA générative à s'engager dans des négociations de licence avec le secteur artistique est un autre défi majeur dans l'établissement d'une approche basée sur le marché pour le consentement et la compensation des œuvres d'art utilisées dans le TDM.Meta, par exemple, a fait valoir que l'imposition d'un régime de licence après coup provoquerait le chaos dans le secteur et n'apporterait que peu d'avantages à chaque artiste, compte tenu de l'insignifiance de leurs œuvres respectives dans le contexte d'ensembles de données plus vastes. Cependant, OpenAI a récemment conclu un accord de licence avec Axel Springer, la société mère de Business Insider et Politico;Il est donc réalisable de mettre en place un régime de licenceLes arguments selon lesquels une seule œuvre protégée par le droit d'auteur est monétairement insignifiante dans le cadre de vastes ensembles de données ne peuvent pas être prouvés car il n'existe pas de cadres obligatoires dans lesquels les négociations de licence peuvent se dérouler. Quoi qu'il en soit, même si la valeur financière d'une œuvre individuelle est jugée faible, cela n'exclut pas le droit de l'artiste de consentir à l'utilisation de cette œuvre et d'être rémunéré pour celle-ci.Lorsque les entreprises d'IA générative ont utilisé, sans autorisation, les œuvres protégées par le droit d'auteur d'artistes de tout le Canada pour former leurs modèles et accroître la valeur commerciale de leurs produits, elles ont commis une violation du droit d'auteur et doivent par conséquent assumer la responsabilité de ces actes.Le fait d'exiger des entreprises d'IA générative qu'elles conservent et publient des registres des œuvres protégées par le droit d'auteur utilisées dans la formation de leurs modèles permettra de remédier à la violation du droit d'auteur à grande échelle qui a déjà eu lieu et fournira aux parties concernées les informations nécessaires pour négocier les conditions d'utilisation de ces œuvres. Cela permettra le développement de marchés de licences et renforcera les économies créatives du Canada, tout en accélérant potentiellement la croissance et la concurrence au sein de l'industrie de l'IA elle-même.Devrait-on clarifier davantage la responsabilité dans les cas où une œuvre générée par l'IA viole les droits d'une œuvre déjà protégée par le droit d'auteur?La Loi sur le droit d'auteur dispose de mécanismes suffisants pour déterminer la responsabilité en cas de violation de droit d'auteur.Toutefois, afin de permettre une meilleure lecture de la responsabilité, le Canada pourrait imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d'IA.Nous recommandons que les entreprises qui violent la loi sur le droit d'auteur, ou toute autre loi canadienne, ne bénéficient pas d'une exemption au motif que ces actions ont déjà eu lieu.Existe-t-il des approches dans d'autres pays qui pourraient éclairer l'examen de cette question au Canada?Oui. Dans son projet de règlement « EU AI Act », le Parlement européen a introduit une obligation de transparence, de sorte que les entités qui développent des systèmes d'IA devront publier un résumé suffisamment détaillé de leur utilisation de « données d'entraînement protégées par la législation sur le droit d'auteur », ainsi qu'une information appropriée, claire et visible qui distingue le contenu généré de l'original.","Le 12 octobre 2023, le gouvernement du Canada a annoncé cette consultation sur le droit d'auteur à l'ère de l'intelligence artificielle générative, avec des soumissions à remettre avant le 4 décembre 2023, et prolongées jusqu'au 15 janvier 2024. La consultation publique est accueillie favorablement par notre association, qui voit en cet exercice une volonté du gouvernement de clarifier les incidences de l'IA sur le droit d'auteur. Cependant, nous craignons que ce court délai pour préparer des recommandations sur cette question complexe ne risque d'aboutir à des résultats inégaux. Certaines parties prenantes du secteur des arts et de la culture pourraient être injustement désavantagées en ayant à équilibrer des ressources et des capacités limitées tout en préparant une analyse réfléchie et documentée, alors que les industries de l'IA générative peuvent certainement allouer des ressources beaucoup plus importantes au processus. Bien que nous apprécions la prolongation du délai de réponse à cette consultation, les futures consultations bénéficieront de délais plus longs.Notre association ne souhaite pas freiner l'avancement de l'IA, mais désire préserver l'équilibre que la Loi sur le droit d'auteur sous-tend, en veillant à ce que les intérêts des artistes et des titulaires de droits d'auteur soient préservés. En effet, notre association voit le potentiel de l'IA : cette technologie, si elle est adéquatement encadrée, pourrait alimenter la créativité, favoriser la découvrabilité de certains contenus et outiller les créateurs dans le respect de leurs droits.Il est néanmoins essentiel de prendre conscience des impacts négatifs que l'IA peut avoir sur l'ensemble des secteurs, les fondements de notre société, ainsi que sur les droits des auteurs. Afin de freiner ces risques, notre principale recommandation est de veiller au respect de la Loi sur le droit d'auteur en s'assurant que le consentement des créateurs soit obtenu et qu'une rémunération juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de fouille de textes et de données (« FTD »). Nous recommandons également l'imposition d'une obligation de transparence auprès des utilisateurs. Spécifiquement, ce cadre devrait obliger la divulgation de toute œuvre utilisée dans le contexte de l'IA. Un tel mécanisme est une action faisable, qui ne pose pas de difficultés techniques et qui jetterait les premières bases de l'édifice, afin d'assurer une rémunération juste et équitable aux artistes et titulaires de droits d'auteur. Dans tous les cas, nous recommandons que le principe des « 3 C » (consentement, crédit et compensation) guide les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d'auteur qui en découleront."
"SARTEC - Société des Auteur.e.trice.s de Radio, Télévision et Cinéma",Association,"Nous représentons des créateurs, et plus particulièrement des réalisateurs, artistes interprètes, auteurs de la radio, de la télévision et du cinéma, des acteurs et des musiciens. Spécifiquement, la SARTEC est l'association professionnelle des auteurs de langue française œuvrant à la radio, à la télévision, au cinéma et dans l’audiovisuel.Nous soutenons la proposition des sociétés et associations suivantes sélectionnez les entités appropriées:- Artisti,- L’Union des artistes (UDA),- L’Association des réalisateurs et réalisatrices du Québec (ARRQ),- La Guilde des musiciennes et musiciens du QuébecNous soutenons également les principes évoqués pas la Coalition pour la Diversité des Expressions Culturelles dans son mémoire, lesquels visent à préserver la créativité humaine. Ces mêmes principes guident nos réponses à ce questionnaire.Notre association voit le potentiel de l’IA à titre d’outil  : plusieurs de nos membres s’en servent d’ailleurs comme source de recherche ou de point de départ de leurs processus de travail. Il est néanmoins essentiel d’encadrer l’utilisation de la technologie, particulièrement dans le contexte de la fouille de textes et de données (« FTD »), puisque le contenu des créateurs est actuellement utilisé à cette fin à leur insu, sans rétribution.","Une plus grande clarté et transparence permettraient de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les œuvres et autres objets de droit d’auteur sont utilisés, ainsi que les rôles et responsabilités des différentes parties prenantes. Ceci permettrait également de déterminer : (i) dans quel(s) contexte(s) l’analyse informationnelle est autorisée, ou non, par le régime actuel de droit d’auteur canadien et ainsi, (ii) quelles licences et rétributions doivent être versées aux titulaires d’œuvres et d’autres objets de droit d’auteur. Oui, des activités de FTD sont actuellement menées au Canada, afin d’entraîner des modèles algorithmiques. Les activités de développement et d’entraînement de systèmes d’IA peuvent impliquer la reproduction de contenus protégés par droit d’auteur (œuvres et autres objets de droit d’auteur tels que des prestations), sans que les titulaires de droits y consentent et reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d’y remédier. En outre, il est essentiel que le consentement (de type « opt-in » et non « opt-out ») des titulaires de droits soit obtenu préalablement à toute reproduction de leurs contenus protégés, et qu’une rétribution juste et équitable leur soit versée en contrepartie de cette utilisation. L’obtention de ces consentements devra prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, un contentement distinct devra être obtenu auprès des artistes-interprètes si l’autorisation initialement consentie aux producteurs ne couvre pas la FTD. Afin de résoudre ces enjeux, le Canada devrait ratifier le Traité de Beijing, ce qui permettrait aux artistes-interprètes audiovisuels d’exercer un meilleur contrôle sur leurs prestations, notamment lorsque celles-ci sont incorporées dans des œuvre.En outre, il est difficile pour les titulaires de droits d’auteur de déterminer quel contenu est utilisé dans le contexte de la FTD et quelle est l’ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d’imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d’IA.Diverses licences sont disponibles pour les activités de FTD impliquant l’exercice d’un droit réservé aux titulaires de droit d’auteur, à savoir la reproduction. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d’auteur ou être obtenues par le biais d’une société de gestion collective. Ces licences ne semblent toutefois pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner pour les titulaires de droits d’auteur qui peinent à obtenir une juste compensation pour l’utilisation de leurs contenus. Afin de remédier à cette problématique, plusieurs mécanismes peuvent être envisagés, tels que l’introduction d’un droit à une rétribution équitable pour la FTD ou un droit à rétribution via un mécanisme semblable à celui de la copie pour usage privé.Nous ne sommes pas favorables à l’adoption d’une exception générale permettant la FTD, laquelle serait d’ailleurs contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l’ADPIC et l’ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d’auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l’exploitation normale de l’œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur. Ainsi, si jamais le gouvernement décide d’adopter une exception de FTD (ce que nous ne recommandons pas), il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l’exception soit : (i) limitée à des cas spécifiques (par exemple, à des fins de recherche) ; (ii) assujettie à des conditions d’application strictes (par exemple, l’accès à l’œuvre ou objet de droit d’auteur doit être licite) ; et (iii) assortie du versement d’une juste rétribution au bénéfice des titulaires de droits d’auteur, ainsi que d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur. Finalement, cette exception ne devrait pas s’appliquer aux droits moraux, mais uniquement aux droits dits « économiques ». Les développeurs de systèmes d'IA devraient être obligés de tenir des registres et de divulguer les contenues protégés par le droit d'auteur utilisés pour la FTD. Il s'agit, selon nous d'une obligation essentielle qui devrait être intégrée à la Loi sur le droit d'auteur.Une rétribution devrait être versée pour toute utilisation d'une oeuvre dans une activité de FTD : Le niveau de cette rémunération doit être juste et équitable, basé sur les utilisations faites des contenus protégés. Dans tous les cas, la rémunération devrait être arrimée avec les autorisations obtenues et prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestationsComme exposé plus tôt, il n’est pas recommandé d’introduire une exception de FTD au Canada. Au contraire, il est essentiel de veiller au respect de la Loi sur le droit d’auteur en s’assurant que le consentement des créateurs soit obtenu et qu’une rétribution juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de FTD. Nous recommandons également qu’une obligation de transparence ou de tenue de registres soit imposées aux chercheurs et développeurs de systèmes d’IA générative, dans le contexte de la FTD. Si toutefois le Canada souhaite introduire une exception de FTD, il devra veiller à ce que cette exception respecte les balises internationales, soit d’application limitée et assortie d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur. À cette fin, le gouvernement canadien pourrait examiner la situation prévalant au sein de l’Union européenne, la Suisse et le Royaume-Uni.",,,"La consultation publique est accueillie favorablement par nos associations, lesquelles voient en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA sur le droit d’auteur. Nos associations ne souhaitent pas freiner l’avancement de l’IA, mais désirent préserver l’équilibre que la Loi sur le droit d’auteur sous-tend, en veillant à préserver la culture canadienne, la créativité humaine, ainsi que les intérêts des titulaires de droits d’auteur. Pour ce faire, nous recommandons que les principes regroupés sous l’acronyme « A.R.T. » (Autorisation, Rétribution et Transparence) guident les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d’auteur qui en découleront. Par ailleurs, il est important que la consultation publique ne se limite pas aux intérêts des auteurs et autres titulaires de droits d’auteur sur des œuvres, mais qu’elle couvre également les intérêts des titulaires des droits dits « voisins », tels que les artistes-interprètes. L’IA générative bouleverse en effet grandement ces créateurs, notamment dans le contexte de l’hypertrucage (ou « deepfake » en anglais). À ce chapitre, les artistes-interprètes audiovisuels ne disposent pas de droits suffisants pour protéger leurs prestations, incluant dans le contexte de l’IA générative et de l’hypertrucage. Afin de pallier cette situation, il est recommandé d’étendre les droits exclusifs et les droits moraux de ces artistes, par exemple, en ratifiant le Traité de Beijing."
SaskBooks,Association,"1) Our organisation promotes and sells copyright-protected content. We do not use this content in training datasets; we may use its metadata, but not the content itself.2) Our organisation does not use training datasets to develop AI systems.3) As far as I know, there are very few measures taken to mitigate liability risks regarding AI-generated content infringing on existing copyright-protected work, as evidenced by the number of content creators and publishers now searching for their copyright-protected/licensed works in existing datasets.4) Our organisation does not develop AI systems.5) In our area of work, businesses may use AI-generated content for marketing and promotional purposes, or for graphic design. This practice is discouraged, as there is no way to currently license the use of copyright-protected material present in datasets.","1) More clarity around copyright and TDM in Canada would mean the AI industry would be very clear on how and when licensing fees need to be paid to content creators and/or licensors.2) TDM activities are being conducted globally; it's difficult with VPN technology to pinpoint exactly where data is being scrubbed and/ore stored.3) Rightsholders are absolutely facing challenges in licensing their works for TDM activities. To date, we are not aware of any TDM operators paying copyright licensing fees. Therefore, the data being used to train/inform AI includes unlicensed copyrighted material.4) We are not aware of any TDM copyright licenses in existence or being offered.5) The impact of an amendment to the Act to clarify the scope of TDM activities would ensure content creators and licensors of copyrighted material would be able to earn revenue from the use of their copyrighted material. It would mean material already included in datasets would be revenue-generating rather than outright theft.6) AI developers must keep records of and disclose what copyright-protected content is used in training of AI systems. Not to do so is plagiarism.7) A per-use licensing fee for access to datasets, similar to what is done with educational/post-secondary/library licensing would be efficient and effective. Existing copyright collection agencies like Access Copyright would be the perfect agency for these collections and disbursements.8) The work being done in the United Kingdom and the European Union on this topic is interesting and leading-edge.","1) AI-generated material cannot be copyrighted. It is not an unique creation of intellectual property created by a person. It is content generated by algorithm using extant data (therefore, by definition, not unique. Even though those datasets include millions of records; material generated from their use cannot, by definition, be 'unique'). It is content generated by algorithm, not by a person. The person is a user, not a creator. It's doubtful these facts will have any effect on the development and adoption of AI technologies, but Canada should follow the UK's example and rule that AI-created material cannot be copyrighted as it is not the unique creation of a person.2) The Government *must* clarify copyright and authorship in light of AI-generated works. Not to do so will be to undermine the entire purpose of copyright and the ownership of intellectual property. It will undermine content creators' ability to earn a living from their IP.3) Again, the UK and EU is doing good work on this topic.","1) The extant tests for determining whether AI-generated work infringes on copyright are expensive, unreliable, and behind the development of the algorithms that generative AI uses. Considering the extant datasets have already been demonstrated to be using copyright-protected material without permission or license indicates the current tests do not work or are not being applied by the developers of AI.2) Barriers to determining whether an AI system accessed or copied specific copyright-protected content include: cost of the programs; reliability of the programs; enormous datasets; reliability of the data included in the dataset (ie. are the datasets being provided for examination the same ones as were used in the AI system?); the capacity of content creators and licensors in being able to access, understand, and examine those datasets.3) It is unclear whether most businesses truly understand the liability of using AI-generated material that has already been demonstrated to have been using unlicensed copyright-protected material. Businesses that want to commercialise these applications must ensure the datasets they're using are only using licensed works or works in the public domain. Regular audit of their datasets should be part of the business model/workflow.4) There must be greater clarity on where liability lies with AI-generated works infringing on existing copyright-protected works. People using these works may not know they are using plagiarised material.5) UK and EU","Canada must first repair the broken Copyright Act to ensure more clarity is provided around what constitutes ""fair use"". As it stands, businesses, individuals, and, frankly, pirates who want to use unlimited datasets can do so with Canadian material because these definitions are so widely interpretable as to make Canadian copyright almost useless."
Société des auteurs et compositeurs dramatiques – société civile des auteurs multimédia,Association,N/A,"La SACD-SCAM est d'avis qu'aucune modification ne doit être apportée à la LDA afin de permettre les activités de fouille de textes et de données. Premièrement, tout comme nul ne songerait à exproprier les propriétaires d'intrants tangibles afin de satisfaire les besoins d'une industrie naissante requérant ces intrants pour mener à bien ses opérations, le gouvernement doit aussi cesser d'entretenir le réflexe d'exproprier les auteurs de leurs droits afin de répondre aux besoins des entreprises ayant besoin de leurs œuvres pour la conduite de leurs opérations.  Dans la mesure où l'IA a besoin des œuvres des auteurs, nourrir l'IA au détriment des auteurs ne peut qu'ultimement mener à l'appauvrissement de ces derniers, de leur création et ultimement de l'IA elle-même. Deuxièmement, les droits d'auteur visent à permettre aux titulaires de droit d'auteur sur des œuvres d'en autoriser ou interdire l'utilisation et donc de négocier librement les conditions auxquelles ils consentent. Il n'y a pas lieu de créer une exception alors qu'il existe déjà un système via des sociétés comme la SACD-SCAM pour obtenir l'accord des ayants droit. Troisièmement, les traités internationaux en matière de droit d'auteur  auquel le Canada est partie imposent le respect du test en trois étapes. L'adoption d'une exception permettant la FTD serait contraire aux engagements du Canada. La SACD-SCAM est donc d'avis que rien ne justifie la création de nouvelles limitations ou exceptions visant la FTD au Canada, du moins à l'égard des œuvres cinématographiques et dramatiques.",,,"Que la LDA, malgré les changements incontournables dus aux évolutions technologiques, dont l'IA, conserve sa pertinence et soit en mesure de relever les défis soulevés par ces évolutions.La SACD-SCAM rappelle que l'adaptation de la LDA doit d'abord viser à permettre aux auteurs de pouvoir continuer à contrôler l'exploitation de leurs œuvres de façon effective dans le contexte des évolutions technologiques et non de réduire, lors de chaque révision, la portée de leurs droits afin de satisfaire les besoins des protagonistes de ces mêmes évolutions technologiques."
Société professionnelle des auteurs et des compositeurs du Québec,Association,"Plusieurs de nos membres utilisent l’IA générative comme outil de création. Nos membres estiment que l’IA générative est et doit demeurer un outil, en ce sens que la créativité humaine doit toujours primer.","- Une plus grande clarté permettrait de mieux appréhender le fonctionnement de la FTD à titre de processus technologique, incluant la façon dont les œuvres et autres objets de droit d’auteur sont utilisés.- Oui, des activités de FTD sont actuellement menées au Canada, afin d’entraîner des modèles algorithmiques. Les activités de développement et d’entraînement de systèmes d’IA sont susceptibles d’impliquer la reproduction de contenus protégés par droit d’auteur (œuvres et autres objets de droit d’auteur tels que des prestations), sans que les titulaires de droits y consentent et reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d’y remédier, par exemple, via l’imposition d’une obligation de transparence.- Oui. En outre, il est difficile pour les titulaires de droits d’auteur de déterminer quel contenu est utilisé dans le contexte de FTD et quelle est l’ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d’imposer une obligation de transparence auprès des entités développant et entraînant des systèmes d’IA. Cette dernière avenue ne devrait pas entraîner de difficultés particulières, puisque les développeurs et chercheurs du secteur de l’IA générative documentent déjà leurs données d’entraînement, par exemple, par le biais de fiches de données ou « model cards ». Les « model cards » peuvent documenter des informations structurées tels que les noms de domaines où ont été collectés les données d’entraînement. Par exemple, la « model cards » de l’IA GPT-2 d’OpenAI (publiée en 2019) incluait une liste de 1000 des noms de domaine ayant servi de source, ainsi que le nombre de références par nom de domaine. Dans cette liste, on pouvait retrouver des sites illégaux (Pirate Bay), pornographiques (YouPorn) ou d’ayants-droits (Le Monde). En utilisant ces mécanismes, les ayants droit pourraient disposer d’informations essentielles à la gestion de leurs droits d’auteur.- Diverses licences sont disponibles pour les activités de FTD impliquant l’exercice d’un droit réservé aux titulaires de droit d’auteur. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d’auteur ou être obtenues par le biais d’une société de gestion collective. Ces licences ne semblent toutefois pas être obtenues par les personnes menant des activités de FTD, en dépit du cadre législatif actuel pourtant clair et des licences disponibles. Ceci crée évidemment un manque à gagner pour les titulaires de droits d’auteur qui peinent à obtenir une juste compensation pour l’utilisation de leurs contenus.- Nous ne sommes pas favorables à l’adoption d’une exception générale permettant la FTD, laquelle serait prématurée et contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l’ADPIC et l’ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d’auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l’exploitation normale de l’œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur.- Oui, nous le recommandons. Comme exposé ci-dessus, ces développeurs disposent déjà d’outils permettant de documenter les données d’entraînement. L’introduction d’une obligation de transparence ne devrait donc pas entraîner de coûts additionnels pour l’industrie de l’IA.- Le niveau de redevance doit être déterminé par le marché, la Commission du droit d’auteur ou les tribunaux.- Comme exposé plus tôt, il n’est pas recommandé d’introduire une exception de FTD au Canada, car ceci est prématuré en plus de nuire aux intérêts des créateurs.",,,"La Société professionnelle des auteurs et des compositeurs du Québec (« SPACQ ») est une association qui représente les intérêts moraux, économiques et professionnels des auteurs de chansons francophones à travers le Canada et de tous les compositeurs de musique de commande au Québec.La SPACQ accueille favorablement la consultation publique et voit en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA générative sur le droit d’auteur.Nous avons récemment lancé un sondage auprès de nos membres, dans le cadre de cette consultation publique. À la lumière des résultats obtenus, nous constatons que la majorité de nos membres ne souhaitent pas freiner l’avancement de l’IA, mais désirent préserver l’équilibre que la Loi sur le droit d’auteur (la « Loi ») sous-tend, en veillant à ce que les intérêts des auteurs et des titulaires de droits d’auteur soient préservés. En effet, notre association voit le potentiel de l’IA : cette technologie, si elle est adéquatement encadrée, pourrait alimenter la créativité, favoriser la découvrabilité de certains contenus et outiller les créateurs dans le respect de leurs droits.Il est néanmoins essentiel de prendre conscience des impacts négatifs que l’IA peut avoir sur les droits des auteurs. Afin de freiner ces risques, notre principale recommandation est de veiller au respect de la Loi sur le droit d’auteur en évitant l’introduction de toute nouvelle exception à des fins de fouille de textes et de données (« FTD »). Nous recommandons également qu’une obligation de transparence ou de tenue de registre soit imposées aux chercheurs et développeurs de systèmes d’IA générative, dans le contexte de la FTD. Cette obligation ne devrait pas constituer un fardeau particulier, puisque nous comprenons que ces acteurs documentent déjà leurs données d’entraînement.La consultation publique est accueillie favorablement par notre association, qui voit en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA sur le droit d’auteur. Notre association ne souhaite pas freiner l’avancement de l’IA, mais désire préserver l’équilibre que la Loi sur le droit d’auteur sous-tend, en veillant à ce que les intérêts des auteurs et des titulaires de droits d’auteur soient préservés. En effet, notre association voit le potentiel de l’IA : cette technologie, si elle est adéquatement encadrée, pourrait alimenter la créativité, favoriser la découvrabilité de certains contenus et outiller les créateurs dans le respect de leurs droits. Il est néanmoins essentiel de prendre conscience des impacts négatifs que l’IA peut avoir sur l’ensemble des secteurs, les fondements de notre société, ainsi que sur les droits des auteurs. Afin de freiner ces risques, notre principale recommandation est de veiller au respect de la Loi sur le droit d’auteur en évitant l’introduction de toute nouvelle exception à des fins de fouille de textes et de données (« FTD »). Nous recommandons également l’imposition d’une obligation de transparence auprès des utilisateurs. Spécifiquement, ce cadre devrait obliger la divulgation de toute œuvre utilisée dans le contexte de l’IA. Un tel mécanisme est une action faisable, qui ne pose pas de difficultés techniques et qui jetterait les premières bases de l’édifice, afin d’assurer une rémunération juste et équitable aux auteurs et titulaires de droits d’auteur.Nous soutenons, par ailleurs, les commentaires soumis par la Coalition pour la diversité des expressions culturelles (CDEC), la SCGC et la SAC."
"Society of Composers, Authors and Music Publishers of Canada (SOCAN)",Association,"1. Introduction.SOCAN (Society of Composers, Authors and Music Publishers of Canada) is Canada’s largest rights management organization. SOCAN has over 185,000 songwriter, composer, and music publisher members, and licenses tens of thousands of businesses and organizations across Canada. SOCAN issues licences for the performing rights and reproduction rights in musical works. SOCAN collects and distributes royalties to its members and connects more than 4 million creators and publishers worldwide through international rights management organizations with which it has reciprocal agreements. In 2023, SOCAN licensed over 170 billion individual performances of musical works to its licensees.SOCAN believes that, with proper safeguards and an appropriate copyright framework, artificial intelligence (AI) can support and enhance human creativity in the music industry. Indeed, in its response to the 2021 “Consultation on a Modern Copyright Framework for Artificial Intelligence and the Internet of Things”, SOCAN noted that the full potential of AI, as well as its implications, were only starting to be uncovered.Since then, however, there have been monumental developments in the field of AI, most notably the rapid development and adoption of generative AI models. While these developments showcase the possibilities of generative AI, they also lay bare the risks that it poses to songwriters, composers, and other creators if left unchecked. Those risks include (i) the use by AI companies of massive amounts of copyright-protected music to program their models, without permission from or payment to rights holders; (ii) AI-generated works that imitate or reproduce those copyright-protected works or substantial portions of them, which not only threaten the livelihoods of Canadian creators and their ability to continue to pursue careers in music, but also risk destroying a nascent market for the licensing of musical works to AI companies before it has a chance to mature; and (iii) a complete lack of transparency by AI companies, which makes it extremely difficult, if not impossible, for rights holders to know whether AI companies have used their music without permission and, if so, to pursue meaningful enforcement measures.With appropriate transparency, it will be feasible and practical to license the use of music by AI companies, just as SOCAN and other rights holders have done and continue to do for other innovative technologies. The licensing market that is currently developing should be encouraged and promoted. It should not be eliminated either by sanctioning the large-scale unauthorized use of music or by introducing copyright exceptions that would afford preferential treatment to text and data mining activities at the expense of creators.SOCAN is well-positioned to help develop a licensing scheme for AI. It has operated its public performance business for almost 100 years, licensing virtually all musical works under a blanket licence for use in various new technologies, including Internet streaming. Creating a licensing scheme to cover the musical works that may be used by AI developers, for programming or other purposes, is well within SOCAN’s expertise.SOCAN urges the Government of Canada, when considering a copyright policy framework for generative AI, to ensure that creators and copyright are respected, and that human expression is incentivized. The preamble to the Copyright Modernization Act, SC 2012, c 20, emphasizes that the Copyright Act supports creativity, culture, and innovation. To promote those values, it is imperative that creators be able to control, and be paid for, the valuable use of their music by AI companies.2. How does your organization access and collect copyright-protected content, and encode it in training datasets?Based on public reports, SOCAN understands that several major generative AI models have been programmed on vast numbers of copyright-protected works, obtained either from large-scale text and data mining (TDM) activities or from datasets containing unlicensed works.For example, from the Music Publishers Canada (MPC) submission, it has been reported that Google’s T5 model and Meta’s LLaMA model were developed using a dataset containing protected content that was scraped from the Internet, including from scribd.com, a subscription-only digital library, and another website that is notorious for e-book piracy [https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/]. OpenAI, the company behind the leading generative AI model supporting ChatGPT, has acknowledged the use of “large, publicly available datasets that include copyrighted works.” [https://www.uspto.gov/sites/default/files/documents/OpenAI_RFC-84-FR-58141.pdf].That said, SOCAN is also aware of reports from the MPC submission of generative AI models that have been programmed using licensed content. For example, Meta announced that its AI-powered music generator tool, MusicGen, was developed on “20,000 hours of music, including 10,000 ‘high-quality’ licensed music tracks” and instrumental tracks from stock media libraries [https://techcrunch.com/2023/06/12/meta-open-sources-an-ai-powered-music-generator].While licensed uses, to date, appear to have used a smaller scale of data than foundational large language models, they nonetheless demonstrate that a market for the licensing of music to AI companies currently exists, and is feasible and practical. SOCAN is well-positioned to foster the development of that market.3. What measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works?SOCAN is not currently aware of any measures taken, by either AI developers or data providers, to mitigate the risk of liability for infringing existing protected works. In any event, SOCAN believes that it would be a mistake to focus on how to “mitigate” liability. A focus on mitigation tends to frame the issue in a way that fails to respect creators and tacitly accepts AI companies’ non-compliance with established copyright laws and policy. The focus should be on fostering the development of a licensing market and encouraging AI developers to obtain permission before using creators’ works to program their AI models or for other purposes. If that permission is not obtained, then AI developers should be subject to copyright infringement claims like any other user.","1. Licensing is workable, practical, and necessary to follow appropriate copyright principles.As Canada’s largest and most active licensor of musical works, SOCAN firmly believes that the licensing of musical works to AI companies for TDM or other purposes is not only workable and practical, but the best and most appropriate way to build on the foundational purpose of copyright.SOCAN is also confident that a licensing market, which is already developing, will flourish in Canada, if given the opportunity to do so. SOCAN therefore urges the Government not to enact any new or modified exceptions for TDM, which would destroy this market and prevent creators from being compensated for valuable uses of their work.Many of SOCAN’s songwriter and composer members depend entirely on copyright, and their ability to control and be paid for the use of their works, for their livelihoods. Since many members are not also recording or performing artists, they do not have the opportunity to generate income from touring, sponsorships, merchandise, or other such projects.AI developers benefit from the use of high-quality protected works, including musical works, for the programming of their AI models.There is no justification for an AI developer to reap the full benefits of a creator’s labour without permission and without providing any remuneration to the creator. That would be contrary to the objectives of the Copyright Act, which includes securing a just reward for the creator and preventing “someone other than the creator from appropriating whatever benefits may be generated.” [Théberge v Galerie d’Art du Petit Champlain inc, 2002 SCC 34 at para 30 <https://canlii.ca/t/51tn#par30>]. Those objectives are especially important because of the unique risks that generative AI models pose to human creators. After using massive amounts of creators’ works, generative AI models can generate outputs that will compete with the works of those very creators. That creates a serious risk that human songwriters and creators will be displaced and forced to pursue other careers, leading inevitably to an erosion of Canadian culture and the industries that support it.A licensing model for AI will ensure that songwriters, composers, and their music publishers are able to control and be paid for the use of their works by AI companies, in accordance with Canadian copyright law and policy. SOCAN firmly believes that such a licensing model is feasible and practical, regardless of the number of works or the nature of the technology involved. SOCAN has consistently adapted its licensing processes to respond to major technological developments and market disruptions over the years, including the shift to streaming and digital musical consumption. There is no reason for the emergence of generative AI technology to be treated any differently.SOCAN has the experience and tools necessary to license and administer large catalogues of works for a variety of purposes, including AI-related uses. As already noted, SOCAN connects billions of performances in Canada with millions of rightsholders worldwide. SOCAN grants licences to tens of thousands of users across a wide spectrum of industries and activities. That includes licensing millions of musical works under blanket licences for use in new technologies, such as online music streaming. In 2023 alone, SOCAN has licensed more than 170 billion individual performances of musical works to its licensees. There is nothing unique about generative AI that should preclude SOCAN from developing and offering an appropriate licensing scheme for TDM and other AI-related activities.2. There should be no exception for TDM activities.SOCAN urges the Government of Canada not to enact any new or modified copyright exceptions for TDM activities. An exception would wipe out the developing licensing market before it has a chance to mature and flourish. It would also deprive creators of the ability to control and be paid for valuable uses of their works by AI companies. Even if other jurisdictions choose to narrow or limit the scope of copyright protection in relation to TDM activities, Canada should resist the temptation to do the same.SOCAN similarly urges the Government to reject any proposal that would allow an AI developer to use a creator’s works for TDM activities unless the creator “opts out”. Canadian copyright law is inherently an “opt-in” regime: it requires users to seek authorization from creators before using copyright-protected works. Requiring creators and their representatives to take positive steps to opt out of TDM activities by all AI users, in relation to every webpage or platform on which their works are available, and to monitor all AI platforms for compliance, would be an onerous and unfair task to impose on creators. It may also run afoul of international treaties to which Canada is a signatory, including the Berne Convention. The prejudice is exacerbated by the fact that, once an AI model has “learned” from the works of a creator who did not know they could opt out, or was unable to do so, that learning is extremely difficult, if not impossible, to reverse.The fact that some AI companies indiscriminately scrape vast amounts of copyrighted works from the Internet, without permission or transparency, is not a reason to reward them with preferential treatment, either by enacting TDM exceptions or adopting an opt-out approach. To the contrary, robust copyright protection is necessary to ensure that users who wield such significant technological power do so in a responsible and ethical way that respects the creators on whose works they depend.3. Remuneration is best determined in a voluntary licensing marketThe appropriate level of remuneration for creators whose works are used to program AI models, or for other AI-related purposes, is best determined in the developing licensing market. A free market voluntary licensing system is the most likely way to allow creators to control the use of their works while requiring interested parties to agree on the terms, including the price, of that use.Therefore, SOCAN urges the Government to avoid any approach that would limit a creator’s right to control the use of their works by AI companies. For example, the Government should avoid any form of compulsory licensing system, which would deny creators their right to contract freely in the market and, in doing so, to decide whether, how, and by whom their works are used. A compulsory licence would prevent creators from realizing fair value for the use of their works by AI companies. It would also raise concerns under Canada’s international treaty obligations, which require the core reproduction and performing rights in works to be true exclusive rights, not mere rights of remuneration. A free market voluntary licensing system must be protected to ensure that creators and AI companies can negotiate fair terms for the use of copyright-protected works.4. Transparency is paramount.Stakeholders generally agree that transparency, record-keeping, and disclosure obligations are important to ensure that creators understand how and when their works are used by AI developers and whether that use has been licensed or not. These requirements will help foster the developing licensing market by incentivizing AI developers to obtain permission before using copyright-protected works for programming or other purposes. They are also necessary to address AI’s “black box” problem, which makes it extremely difficult, if not impossible, for creators to know when their works have been used by AI models or to pursue legal remedies without proper disclosure from AI developers.For a further discussion of record-keeping and disclosure obligations, please refer to our submission to the Consultation’s question on infringement and liability.","It is not currently necessary to amend the Copyright Act to address authorship or copyright ownership of AI-generated or AI-assisted content. The Copyright Act is based on a philosophy of providing incentives for human creativity, and SOCAN considers the statute—including, for example, the tying of the general term of copyright ownership to the life of a human author—to be clear that the author of a work must be a human [Copyright Act, RSC 1985, c C-42, s 6].The authorship and ownership of works that are created with the assistance of AI tools can be determined on the specific facts of each case. In its current form, the Copyright Act is sufficient to allow courts to develop the law by making those determinations. It would be prudent for the Government to avoid amending the Act unless and until the Government determines that judicial decisions, whether in Canada or elsewhere, expose gaps in the law that need to be addressed.SOCAN’s operations—and, indeed, the music industry more broadly—are premised on the understanding that music creators are individuals, based on the longstanding principle that authors must be human individuals. If this longstanding principle is changed, it could have potentially unintended consequences across an entire music industry which is built on a foundation of human expression.","A critical issue in the field of AI is the “black box” problem, meaning there is a lack of visibility into the works used to program an AI model or how those works, once copied, affect the model’s programming.Due to transparency problems, creators typically have no way to know or detect whether their works have been used to develop an AI model. Even if a creator suspects that their work has been used for programming purposes, it would be extremely difficult, if not impossible, to confirm that use. When large-scale infringements are carried out without the knowledge of creators, it creates a significant windfall for AI developers at the expense of creators.The black box problem also makes it difficult, if not impossible, to prove that an AI-generated work infringes copyright in a creator’s existing work. Even if the two works are substantially similar, a lack of transparency and record-keeping by an AI company will thwart efforts to prove that the AI model used, and therefore had “access” to, the creator’s work, which is a necessary element of the test for copyright infringement.In short, without appropriate transparency, disclosure, and record-keeping, it would be difficult, if not impossible, for a creator to know that its rights have been infringed, much less to pursue and obtain any remedy for that infringement.SOCAN therefore urges the Government to require AI developers, and every person involved in the programming and testing of an AI model, to keep and make readily available detailed and accurate records of the works they have used for that development and how they have used them, including the source of the works and details of any licences authorizing the use of the works and how those works are kept, maintained, or stored by the AI developers. AI developers are best positioned to track that information.SOCAN believes that, with robust transparency, record-keeping, and disclosure obligations, coupled with established copyright principles, the current Copyright Act will be sufficient to address liability issues specific to AI technology.","SOCAN encourages the Government to focus on the perspective of creators when considering AI. Specifically, AI developers must seek consent from creators before using their works, compensate creators for that use, and credit creators as co-authors of AI-generated works where applicable. Any copyright policy that sacrifices the interests of creators for technological advancement erodes the very concept of copyright, and the large-scale infringement by AI companies threatens to eliminate longstanding copyright principles altogether if the perspective of creators is neglected. Together, a free market voluntary licensing system and robust transparency obligations will ensure that Canada carries an appropriate copyright policy, with the interests of all parties adequately represented, into the age of generative AI."
TECHNATION Canada,Association,"How does your organization access and collect copyright-protected content, and encode it in training datasets?Data that is publicly available online is needed to develop safe and performant AI that is unbiased. Much of the data needed for AI development generally is collected from publicly available sources online. It is necessary to train large-scale AI on vast, broad and varied data sets to ensure correctly functioning, safe and unbiased AI. Using the public internet as a source of information is necessary to achieve this scale.How does your organization use training datasets to develop AI systems?N/A for trade associationIn your area of knowledge or organization, what measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works?N/A for trade associationHow do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?AI and AI-generated outputs are used across all areas of industry and society. It will be used in all areas of industry, manufacturing, including material development, health, including drug discovery, etc. Conversational interfaces (chatbots) will be used by people to access many different AI services. Applications will be mostly unrelated to the interests of rightsholders.","What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?More clarity that ensures that TDM is not considered a copyright infringement would enable greater confidence in the development, use and investment in AI development. It would also enable content creators to understand how their works may be used for AI training.Are TDM activities being conducted in Canada? Why or why not?AI development will thrive in jurisdictions that support responsible AI development. Training will occur predominantly in jurisdictions such as the US and Japan where there is more clarity.Legislators and policymakers must not overlook that TDM applies to data analysis more generally; for example, national security techniques may require analysis of large volumes of data, which may include photographs and text documents.We assume that these are conducted in Canada. However, the legality of such methods also risks being put in question if the law is amended to make TDM a copyright infringement. AI use and data analysis techniques that are critical to many use cases would benefit from amendments to the law to clarify that TDM is not a copyright infringement.  Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?Licensing for TDM is not required because TDM is not a copyright infringement. While there is no explicit TDM exception in Canada, other exceptions and limits on copyright exist that permit TDM for commercial purposes. This does not limit the ability of rightsholders to build revenue models around their works that grant access to works that are not publicly available. What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?Licences are not required for TDM – we are not aware of any such licences. If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?Clarity could be improved by an express provision stating that performing TDM is not a copyright infringement. The right to read should be equivalent to the right to mine.Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?NoWhat level of remuneration would be appropriate for the use of a given work in TDM activities?Remuneration is not required. If a person has legal access to a work, they should not be required to pay to read or learn from the work.Are there TDM approaches in other jurisdictions that could inform a Canadian consideration of this issue?Japan","Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?The use of AI as a tool to create new artistic works should not prevent a person from being entitled to own the copyright in a work that they have created. The law permits a person who authors a work, even when using AI, to own the copyright work, and there is no need to amend the law in this regard. Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?No legislation change is needed. Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?No. The UK uniquely has a provision for protecting computer-generated works where there is no human author; this approach is not recommended or needed. A human will be creatively involved in the creation of a new work – it is unlikely that outputs will be solely generated by a computer.","Are there concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright (e.g., AI-generated works including complete reproductions or a substantial part of the works that were used in TDM, licensed or otherwise)?No – the existing law is sufficientWhat are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?No responseWhen commercialising AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?It is not likely that AI will output something that infringes copyright, unless the user uses the model to produce a copy of a work. AI developers and providers should not be liable for such use. However AI developers can take steps in the design of AI systems to mitigate the risk of a user using the model to create a copy. Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?No – the existing law is sufficient Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?No response",N/A
Stratford Intellectual Property - Part of Stratford Group Ltd.,Consulting Firm,N/A,"It is our view that companies and organizations that perform TDM activities log all data used. They should not only take note of the extracted data, but also the jurisdiction in which the data is extracted. Compensation models can then be developed to ensure that copyright owners are properly recognized for their original ideas. It could also be envisioned that copyright holders could also include a notice around terms of use of their content for data training.Given the rise in generative AI platforms from large US-based tech companies such as OpenAI, Microsoft and Google, it is no surprise that Canada has followed suit to embrace the new age of artificial intelligence. For generative AI to operate, it is trained with large amounts of data sets obtained through text and data mining (TDM) activities.Although there are concerns about these TDM activities involving the use of copyrighted material without consent, there have been benefits to doing so as well. For instance, during the height of the COVID-19 pandemic, the BlueDot program, founded by a professor from the University of Toronto, provided useful information for public health authorities to quickly take action. However, this would have not been possible if there were limits to the use of public, commercial and academic data sets to train this program and map the spread of infectious diseases (Fiil-Flynn et al., 2023). Both companies behind generative AI platforms and authors of copyrighted material should find a middle ground to respect copyright ownership without completely shutting down the endless possibilities for innovation through this new technology.During the infancy of generative AI, there were not many clear regulations when it comes to TDM activities in many parts of the world. As such, tech companies behind these platforms have found themselves freely scraping the World Wide Web to obtain data sets for AI training, including original copyrighted material from different artists and authors. At the time, no one could seem to stop these companies from doing so – or so they thought. They later found themselves in hot water as multiple class action lawsuits have piled up against them due to copyright infringement (Lutkevich, 2024).Content creators are also discussing whether to allow their data to be used in TDM.   For example, when Creative Commons polled respondents on whether openly licensed content should be used to train AI models, nearly half the respondents were “it depends” (Vézina, 2021). Because of the public outcry against TDM activities, software developers have come up with ways to control the data fed into AI training models. One example is the platform called Glaze, which aims to prevent AI models from learning a particular artist’s distinctive style. On the other hand, there are some companies, such as Bria, a generative AI startup, that has committed to pay royalties to artists when their works are used to train their AI models (Glover, 2023). Having these examples simply show that it is not impossible to find solutions to meet both the needs of the AI and creative industries.We recommend that companies and organizations that perform TDM activities responsibly log all data used to train their AI models. They should not only take note of the type of extracted data, but also the jurisdiction in which the data is extracted from due to varied copyright considerations. Compensation models can then be developed to ensure that copyright owners are properly recognized for their original ideas. For example, compensation models could be on a pay-per-use basis. References:1) Fiil-Flynn, S. et al. (2022, December 1). Legal reform to enhance global text and data mining research. https://www.science.org/doi/10.1126/science.add6124  2) Lutkevich, B. (2024, January 2). AI lawsuits explained: Who’s getting sued? https://www.techtarget.com/WhatIs/feature/AI-lawsuits-explained-Whos-getting-sued  3) Vézina, B et al. (2021, March 4) Should cc-licensed content be used to train ai? It depends. https://creativecommons.org/2021/03/04/should-cc-licensed-content-be-used-to-train-ai-it-depends/4) Glover, E. (2023, August 23). AI-Generated Content and Copyright Law: What We Know. https://builtin.com/artificial-intelligence/ai-copyright","Briefly, our view is that they should be a harmonized and aligned system for copyright as it applies to ownership and inventorship of AI generated work globally, like other intellectual property right systems.Generally, the authorship of copyright on AI-assisted and AI-generated content should be attributed to the individual (or organization) that originally created the content, not to the person who arranged for the work to be created. Content should be clearly attributed if taken from training data. If the AI-system is modifying the data, then citing the source should be done. Clearly mapping use to creation will also support compensation allocation. If the generative AI-tool is inferring or generating a hallucination, it should be marked as such and would support reducing misinformation.  Authorship of copyrighted works in Canada should be clearly defined in light of AI-assisted and AI-generated works as it has been in the United States. In 2023, the US Copyright Office stated that there should be sufficient human authorship in AI-generated material, but even then, copyright protection will only protect the human-authored aspects of the work. It has also been determined that simply prompting a generative AI platform to produce an output is considered to completely lack human authorship. Furthermore, if applicants will be submitting AI-generated content for copyright registration, they are required to disclose that it has been produced by an AI platform (US Copyright Office, 2023).One of the infamous cases in the US relating to authorship and AI-generated works is that of the case of Dr. Stephen Thaler and his AI machine called DABUS, which stands for Device for Autonomous Bootstrapping of Unified Sentience. Besides being involved in a case of inventorship in patent applications, DABUS has found its way to be listed as an author for a copyright registration application for an AI-generated image titled “A Recent Entrance to Paradise”. Since the US Copyright Office has already established the guidelines surrounding authorship and copyrights at the time, it was clear to a US Federal Judge that AI-generated images cannot be granted copyright protection due to the lack of human authorship (Growcot, 2023). In a similar manner, the graphic novel by Kristina Kashtanova titled “Zarya of the Dawn” was created using the Midjourney platform, was initially granted copyright registration. However, it has since been lost since it has been found that the generative AI platform was significantly lacking human involvement in its conception (Wolfson, 2023).On the other hand, across the border in Canada, we find an interesting case where a fully AI-generated work was granted copyright registration (Stephens, 2023), and is considered to be registered with CIPO to this day. This illustrates that there are still gaps in the Canadian intellectual property system, and we believe that it will be best to emulate a similar approach taken by the US Copyright Office when it comes to their guidelines surrounding AI-assisted and AI-generated works. In addition, we recommend adding due diligence efforts to ensure that there is sufficient human authorship in works already granted copyright registrations in Canada, especially those that have been filed shortly after the launch of generative AI platforms.References:1) US Copyright Office, Library of Congress. (2023, March 16). Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence. https://www.govinfo.gov/content/pkg/FR-2023-03-16/pdf/2023-05321.pdf  2) Growcoot, M. (2023, August 21). Federal Judge Rules AI Images Cannot be Copyrighted, Contrasts it to Photos. https://petapixel.com/2023/08/21/federal-judge-rules-ai-images-cannot-be-copyrighted-contrasts-it-to-photos/3) Wolfson, S. (2023, February 27). Zarya of the Dawn: US Copyright Office Affirms Limits on Copyright of AI Outputs. https://creativecommons.org/2023/02/27/zarya-of-the-dawn-us-copyright-office-affirms-limits-on-copyright-of-ai-outputs/4) Stephens, H. (2023, April 19). Canadian Copyright Registration for my 100 Percent AI-Generated Work. https://hughstephensblog.net/2023/04/19/canadian-copyright-registration-for-my-100-percent-ai-generated-work/","Briefly, our view is that organizations and innovative development will benefit from clear direction on parties responsible for infringement and associated liability. Whether it is the companies behind generative AI tools or the end user – defining where the boundaries exist will benefit the community.  AI systems should be liable for infringement of copyrights if not properly attributed or if modified without consent. The law should be clear that although the use of the copyrighted information has been done by an AI system, the developer (human) of the AI system is liable for the copyright infringement even if the machine has evolved to use other content. In the end the accountability and liability around the use of AI remains with the developers. Interestingly, whereas in the patent system, it is common for the patent owner to go after the system manufacturer for infringement of its component (instead of the component manufacturer). Within AI-generated works, the opposite seems to be mostly happening – where the generative AI-company is being sued rather than its end user. This makes sense from not only a practical perspective, one entity to go after rather than all its users and it is the generative AI company that used the data to train the models.    Given the backlash following the rise in AI-generated works, several tech companies have developed measures to mitigate the risks of liability for infringement – not for themselves, but rather for their users.In September 2023, Microsoft announced that they will provide legal protection for customers who are sued for copyright infringement over content generated by the company’s AI systems – GitHub Copilot and Bing Chat (Criddle, 2023). More recently, OpenAI offered to cover their clients’ legal costs for copyright infringement suits, calling it Copyright Shield. However, there is a caveat as it only applies to users of their business tier, ChatGPT Enterprise, excluding the free version of ChatGPT or ChatGPT+. In addition to OpenAI, companies such as Google, Microsoft and Amazon have also developed similar terms to protect users of infringement with the use of their generative AI platforms (Montgomery, 2023).Numerous active lawsuits have been filed against companies behind generative AI tools because they have the ability to create unauthorized, derivative outputs of copyrighted works – but should these companies really be held liable, or should it be directed towards the user prompting the tool to generate the derivative works? Although a user directly prompts the generative AI platform, the generative AI platform is not completely out of water. For instance, the class action lawsuit against Stable Diffusion and Midjourney claims that companies should be held vicariously liable for copyright infringement. In the United States, there are 2 conditions in which a third party (i.e., the company) can be held liable for copyright infringement: (1) the third party has the ability to supervise and control acts of the person who committed the direct infringement, and (2) the third party has an “obvious and direct” financial benefit from the infringing activity.” Although companies currently may not have the capacity to scan through the use of their tools and limit infringing activities, we believe that they should have the ability to do so. Furthermore, it does not appear that companies have an “obvious and direct” financial benefit from copyright infringement at first glance. However, it has become more common to encounter generative AI platforms that operate based on a subscription, obviously showing that they have a direct financial benefit from the use of their tool, including when it is used to generate works infringing on copyrighted material.Similar to Microsoft’s Copilot Copyright Commitment, indemnification should be clear. In this case, if a user of Microsoft’s Copilot prompts the tool to generate outputs with copyrighted material, then Microsoft promises to defend the user and cover any expenses involved in the copyright litigation process (Smith, 2023). This not only helps manage risk to provide users peace of mind, but also pushes a company to ensure that they have the necessary measures in place to respect the copyrights of original works.References:1) Criddle, C. (2023, September 7). Microsoft pledges legal protection for AI-generated copyright breaches. https://www.ft.com/content/cd7f5391-bba5-4af1-8309-346eb2eafa022) Montgomery, B. (2023, November 6). OpenAI offers to pay for CHATGPT customers' copyright lawsuits. https://www.theguardian.com/technology/2023/nov/06/openai-chatgpt-customers-copyright-lawsuits3) Wolfson, S. (2023, March 24). Style, Copyright, and Generative AI Part 2: Vicarious Liability. https://creativecommons.org/2023/03/24/style-copyright-and-generative-ai-part-2-vicarious-liability/4) Smith, B. (2023, September 7). Microsoft announces new Copilot Copyright Commitment for customers. https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/",N/A
Aula Fellowship,Consulting Firm,"Comments on Datasets:In our own work as a small business:We’ve noticed that most marketing images are coming at us with AI modifications.We have brought about 15% of our graphic work back in-house with AI supportWe have saved this year on legal contracts and marketing reports by using GPT.We have not bought new stock photos this year.As practitioners in AI:In terms of training and datasets being used in responsible ways, there are two datasets that are of concern to us, as we understand they have been used in models that we use, including by OpenAI.The book3 dataset: a dataset of full-length book texts, including copyrighted works, scraped from the internet. Notably includes the works of Margaret Atwood and Stephen King. https://www.cbc.ca/news/canada/canadian-authors-books3-ai-dataset-1.7050243  The LAION-5B dataset: a dataset including links to millions of CSAMs online. https://www.cbc.ca/news/canada/canadian-authors-books3-ai-dataset-1.7050243  It has been useful to us in brainstorming, to consider the comparative reactions to the use of these two datasets: one can be said to be a set of copy-right material, while the other is copy-prohibited material. In that sense, when we consider the use of copy-prohibited material in large language or image generator AI models, it seems clear that copy-prohibitions should also extend to a prohibition to use such material in the model. In which case, the legal status of the data can and does extend to its use in training a model, based on the unacceptability of the model producing new material that contains images with elements of the prohibited material in such a way as to make that prohibited material recognizably inspired by actual victims. In short, if we disallow models to carry prohibited material through the process of dataset-training-output, then why would we allow models to carry through copy-righted material that they haven’t obtained legally?On the technical side, it’s not commonly understood in government and private sector policy conversations that AI can’t be made to forget. If we want something out, our only technical option is to remake the model entirely, and leave out the info. Tech companies have been well aware of this, which indicates that our negotiating options are limited by their defacto release of problematic material. It makes it a question of whether we will make sure artists and writers get compensated, not whether or not they can opt-in.Another concern, still with these two datasets but for any other troubling material, is the openness of models.With the CSAM set, for example:If a model with the set is already out in the wild and open (which they are), then even if we were to remake the model entirely without the set, it would be possible to compare the old and new models and identify the portions of the model that are referring to the set, and in that sense if would make it easier for ill-doers to locate the links to CSAM in the old, unmodified model. In other words: removing it from the new model makes it easier to find the offending material in the old one.We can picture this as a box of parts. We don’t know what the individual parts do, but we send out these boxes of parts. Then we make a new box of parts, taking out the bad ones. We send that new box out. People who have both boxes still don’t know what individual parts do, but they can now identify the parts in the old box that aren’t in the new one. They can therefore identify the bad parts.That has moral and legal implications.It furthermore seems to bestow responsibility on governments to find and enforce the destruction of CSAM-infected models, and perhaps the book3-infected models, too. It seems that our industrial and commercial laws should ensure that people aren’t breaking our criminal laws with governmental oversight.Another concern in datasets and in training is that a lot of the data is labeled, moderated, and monitored overseas in documented oppressive circumstances. There are lawsuits coming out of Africa by groups of employees who are claiming a wide scope of harm. We don’t want to be doing business with people who support the enslavement and/or other harm to our fellow humans.","Comments on infringement:It is possible to build these models without infringing on copyright. The materials are available online and can be purchased. We have a robust network of unions representing authors who can arrange for payment. We were able to organize this for streaming music. Before we were paying for it though: streamers were pirates. Monetizing this, by ensuring fair compensation to artists for their work, will support artistic creation in the way that copyright has always done.Norway has been doing something nicer for authors and AI. They have a national library of public domain and copyrighted works. They have public support to use that in building a national Norwegian-language model of their own. They’re going to be paying the authors of copyrighted material. Authors have agreed. They also have Schibsted on board for the project ( a very large Scandinavian media company). It’s organized by the public library. You could check out the work of Per E Kummervold of the National Library of Norway if you want to know more.","Comments on authorship:Yes, the uncertainty and the moral pressure are making it harder to use AI generated work. It is clear who uses it and who does not, in news outlets and on social media. It has become something of a status symbol to be able to afford original art, because the AI generated art is so very easy to get and modify.You may not be aware that Adobe put out a major update in December to Photoshop. Photoshop is by far the most used photo editing software in the world, and it is decades old. All users received the update and a tutorial on how to instantly modify any element of their images. This was previously available only to AI adepts and is much more powerful than what Midjourney and Dall-E can do, in terms of modifying images.  This concerns us greatly because we are now fully in a media world where we can’t trust what we see.Here is a thought experiment: does the Eiffel Tower exist?I have seen it. If I tell you it is real, and that I have seen it, you can either trust me, or not.If you do not trust me, the only recourse you have is to go to Paris and check for yourself, or else to find another witness you trust.Pictures won’t do the trick, anymore.We therefore think we’re going to need to license journalists or other media persons for trust, like we do Lawyers and Doctors. Will that be pushed forward as a federal program? That would be nice, for trust purposes.","Comments on infringement:I think we need a great deal more clarity. If we use AI work, are we infringing?  That’s a moral question, a marketing question, and a legal question. Will it be defined as infringement in the near future?What’s fair use? It seems that we can get GPT to reproduce full texts of pay-walled New York Times articles by first prompting it with the first few paragraphs of an article. It then puts out the whole of the rest of the article. That doesn’t seem fair. It also seems like big trouble for a few reasons:1- For the NYT and other outlets2- As a user of that text, if I put it into my marketing or my product, there will be no way to prove I didn’t directly plagiarize that original material from the NYT. We don’t see how we can currently use any AI content at all in public-facing marketing or copy.3- I could apparently also infringe inadvertently, with ChatGPT reproducing whole bits from paywalled things without me knowing it. The output being indistinguishable means I can be held libel by the NYT even if I had no knowledge.4- That is certainly the same or worse for more troubling data, like CSAM.Lastly, the OpenAI Terms of Service prohibit people from trying to get GPT to give out copyrighted information. That is not in any way a guardrail or a mechanical/technical protection, but rather a statement that there is potential for that misuse, and user beware. However, how can the user be aware if the output is substantially reproducing copyrighted work? They can’t: but the terms of service would seem to imply that they would be held responsible anyways. The provider seems to be passing the buck here. Can the government hold them to account?","The Aula Fellowship: https://polyaula.com/en/aulafellowship/  We are a Fellowship of scientists and policymakers in the AI space. Our fellowship’s intent is to see to the responsible propagation of AI. Which is to say: the use of AI tools to the benefit of humanity, without adding to harms. We produce research and participate in policy in Canada and abroad. Our Fellowship is formed under the aegis of a tech company, Polyaula, of the Montreal area, which has a small factory producing recycled plastic products, an open-source industrial machinery division, and a consultancy service.My name is Tammy Mackenzie. I am commenting here as an Aula Fellow, which is to say I am wholly empowered to express my own opinion and experiences. I speak for myself and for the mission, not for the other Fellows.My experiences:Professionally, I am the executive director, interim of the Aula Fellowship, CEO of Polyaula (Tech/robotics/industrial consultation), mba, sustainability, small business operations accountant (I started at 14 years old, 33 years ago), controller, and CFO, business and social strategist, ecological and human rights activist. I am also a writer and an artist.I am a postgraduate researcher (MBA- ULaval- Sustainability, Tech, and Small Business Management), studying towards a PhD in Systems and Society.I attend conferences and participate in research and policy discussions in Canada, the United States, and in Europe, usually those with a particular focus on law and rights. As a strategist, I listen in particular for signs that people are missing some key understanding about the technologies or the social systems in place. Things that might limit or distort policy options. I also engage with people on problems of contradictory needs, beyond misunderstanding. I am non-partisan, and promote evidence-based discussion. My comments on this consultation stem from my practice and the work of the teams I supervise at Polyaula and within the Aula Fellowship.I am an alumna of the MILA Summer School on Responsible AI.Last comments:For regulation to work, we will also need new methods of enforcement. The government - either through industrial licensing or otherwise -  needs to be able to say “no” to a given model or application. Not just set rules, but actually be able to shut them down.From the perspective of strategic risk management: mitigation is the most important strategy for potentially grave risks. As such, any regulation will require not just enforcement, but also monitoring.We must as a society be able to hold international companies responsible and to account for not just copy-righted work in their models but certainly for copy-prohibited material. The policies will have to work for both circumstances. Companies will have to account for where they get their source-content, and also how the people who provide it are treated. Failing to do so, ignoring the questionable chain of acquisition of a lot of the data in these systems, is to create and condone injustice. That’s ethically very wrong. It’s also not practical. To create injustice is  to create social unrest. We have enough problems as it is without creating more and building them into our tech.We don’t have enough people at the table. I know that you are aware of this problem. However, it’s blatantly on display in our conferences on AI. It’s not enough to know it’s a problem. People need ressources to get there.The Aula Fellowship and her Fellows are available to consult on these questions, either with links to information in support of the statements in this consultation paper, or to research specific questions either in technical or social-strategic spheres. https://polyaula.com/en/aulafellowship/  Thank you for this opportunity to contribute. I hope that some of these insights from our work on AI science and in policy conferences may be of use to your work on these important regulations.In conclusion to these comments, we invite you to personally imagine AI as a public service. How would you build it, if you could choose?"
ID Quotient Advisory Group,Consulting Firm,"Within my firm we use Generative AI for RFP Creation, code generation, defining new opportunities for robotic process automation as it pertains to compliance and procurement. Leveraging machine learning and neural network is germane to our ability to meet client timelines and reduce OPEX costs to our clients. In particular, we often use AI to assess gap analysis between legacy IT infrastructure assets.Human beings are imperative to development of AI systems but caution must be exercised as it pertains to confirmation and sample bias in particular. Circular logic in algorithms is a major concern, particularly when using AI to create services and processes for the public.Citizen social services offer the greatest area to observe impact of robotic process automation and AI – as we consider the administrative heavy tasks overseen by institutions such as the Canada Revenue Agency, the Ministry of Health, and Service Ontario, amongst others. As we look at metrics of success, savings on taxpayers dollars should be a key metric to expedite implementation of AI","TDM activities are being conducted in Canada, in particular in the finance and insurance industry around use cases where underwriting is considered. Safeguards for TDM should rely heavily on guidance from PIPEDA and GDPR – to ensure that any platforms hosting personally identifiable information are safeguarded against cybersecurity threats.TDM approaches in countries such as Norway and Estonia take a more innovative and future-focused approach",There is uncertainty is understanding how to use GenAI to create outlines and draft research – this is analogous to the perception of using internet sources in research papers and content creation that existed in the early 2000s. Education institutions must ensure that training for natural language processing and also proper use cases for content creation are part of curriculum moving forward. Approaches in Japan to AI and education are a good resource for Canada when considering this issues.,Infringing outputs should go beyond boolean search and leverage contextual insights when trying to determine copyright infringement. Generative AI can in fact be utilized to collate legislative resources for copyright law.,N/A
Hinterland,Games,"We do not use generative AI tools or LLMs in our business, as we are a creator-focused tech company who believes in the primacy of human creativity, and the value of copyright for the protection of IP and creator's rights.We do extensively use AI for our products, but they are video games and therefore we use AI differently than the current crop of AI tools like Midjourney and ChatGPT.","Currently it's unclear whether existing copyright, trademark, or other IP-protective legal frameworks are sufficient to protect our creations from TDM or other scraping techniques employed in the development of LLMs and other generative AI technologies.","Yes, the government should clarify the status of AI-generated outputs as it relates to copyright and trademark protections. There is vast uncertainty within the tech and entertainment industries, and it will be very important for Canada to have clear laws around this. The lack of a clear and safe environment within which to invest in the creation of entertainment IP will have a significantly negative impact on industries like video games, animation, film and television, literature, music, and art, all industries that are culturally significant to Canada and represent a significant amount of economic activity — both in terms of investment, employment, and revenue.",N/A,N/A
"The Ontario Public Service – The Ministry of Public and Business Service Delivery - Privacy, Archives, Digital and Data Division",Government,"The Ontario government is developing a Trustworthy Artificial Intelligence Framework to establish the rules and groundwork for how we leverage the benefits of AI within government with a human-centered approach. The framework consists of six core principles that were developed in consultation with both the public and experts, including the Information and Privacy Commissioner of Ontario and the Ontario Human Rights Commission. These principles include transparent and explainable, safe, good and fair, responsible and accountable, sensible and appropriate, and human centric.These principles also form the basis of the policies, guidance, and tools that Ontario continues to develop and implement to ensure responsible use of AI. In particular, the framework is designed to ensure a human-centered approach throughout the entire lifecycle of an AI system, this includes the discovery, building, deployment, and management of the system. Overall, the framework’s objective is to ensure that AI is used safely and responsibly to mitigate common risks such as biased and discriminatory outputs and to offer better and faster programs and services across Ontario.As Ontario is developing a suite of policy tools to guide the development, deployment, or adoption of AI tools, it is taking a risk-based approach to ensure the thoughtful and appropriate balance of human involvement when AI supports decision-making.","The Ontario Ministry of Public and Business Service Delivery (MPBSD) recommends that ISED provides greater clarity when it comes to text and data mining (TDM) and generative AI systems. MPBSD recognizes the challenge in balancing the need for governance and innovation and the importance of providing the source information used in AI training for greater transparency. Legal frameworks that target exceptions should remain within the scope of academic research, meanwhile other areas such as commercialization and industry-based research should remain out of scope.This should also include clearly defining when secondary infringement occurs and putting legal guardrails in place to deal with cases when users distribute AI generated content that infringes copyright law. Amendments in this area would need to consider the lack of control developers may have over the training data used in some cases. Hence, it will be important to evaluate the different purposes of models that will need to be measured against varying levels of developer control and accountability.Amendments to section 29 and 30 of the Copyright Act could impact right-holders from receiving fair compensation for their work being used in TDM activities and hinder industry innovation. Additionally, stricter requirements could unintentionally create barriers for innovation among Canadian researchers and companies, with start-ups and small businesses being disproportionately impacted. MPBSD recommends ISED to consider conducting targeted engagements with civil society, startups and small businesses, publishers, open-source technology communities to gain a better understanding of the potential impacts an amendment to the Copyright Act could cause.Further, MPBSD recommends that ISED continue to monitor current global trends and standards to ensure Canada’s approach is aligned and to consider best practices. The EU’s AI Act provides a valuable reference point in this area. Article 16 of the EU’s AI Act provides provisions that exempt research activities and AI components offered under open-source licenses. Meanwhile, Article 28b(4)c of the EU’s AI Act requires developers of Large Language Models (LLM) to provide a list of copyrighted materials used in their training datasets. It is important to note that the United States currently does not have an explicit exception for TDM in its copyright legislation, therefore, this can be a leadership opportunity for Canada.We also encourage ISED to explore options to have accountability and transparency measures in place for AI developers to document, evaluate and/or disclose what copyright-protected content or data is used in the training of AI systems. However, differentiating between protected content and unprotected content may present a challenge for lawmakers in determining a reasonable threshold for disclosure. Therefore, policies in this space would promote the ethical use of AI while taking inspiration from the EU’s AI Act in requiring AI developers, particularly big technology companies, to inspect and disclose copyrighted materials used to develop their systems starting from the discovery phase.","MPBSD encourages ISED to provide greater clarity on how the current copyright framework applies to the use of copyright-protected works and other subject matter used in the training of AI systems. While MPBSD recognizes that regulating this space is difficult due to the evolving nature of AI systems, we believe that legislative and policy interventions will be more effective in providing clarity around the authorship of AI generated works.The uncertainty surrounding authorship or ownership of AI-generated works and other subject matter could impact the development and adoption of AI technologies by contributing to a lack of consensus and legal ambiguity. Establishing standards for the attribution of authorship and ownership could address this by providing greater clarity for users who may be unsure if they have copyright protection or not.MPBSD recommends that the federal government propose a clarification or modification of the copyright ownership and authorship regimes considering AI-assisted or AI-generated works. This can be done by evaluating fair dealing policies and updating the definition of fair dealing to bring it within the context of generative AI. Due to the lack of jurisprudence on this issue, MPBSD recommends policies and legislation that support a flexible approach to fair dealing that would allow for a fair balance between innovation and the rights of creators. An example would be an opt-out mechanism for users who do not want their data used for training purposes. This would enable AI training to be deemed as fair, while providing users with a degree of control over their work.When comparing the approaches in other jurisdictions, it's important to note that Canada’s understanding of this concept is much narrower. The United States allows the restricted utilization of copyrighted material, provided that the user introduces a distinctive element to the copyrighted work, resulting in a transformation of the original work.Similar to the UK, MPBSD recommends that a guidance document addressing copyright and authorship concerns is released to encourage best practices. This could serve as an effective intermediate step while the federal government continues to work towards developing generative AI copyright policy and Canadian jurisprudence becomes more defined. The UK’s code of practice on copyright is a valuable reference, as their code aims to make licenses for data mining more available. A Canadian code of practice, complemented with clear policy directions, could encourage authors and creators who use AI tools to keep a log of their contributions in creating a final version of their work. This would help promote important AI principles such as, fairness, transparency, accountability, and privacy.","MPBSD recognizes the lack of evidence and legal precedents related to copyright infringement and liability raised by AI.Canada’s current copyright framework is unclear as to whether the use of copyrighted works in the training of AI systems would result in an infringement. It is important for the government to define a clear threshold for human involvement (such as in the development, sale, or licensing of the AI application) that determines when an individual is considered to have authorized copyright infringement and may be held legally liable. This clarification is essential to prevent confusion among developers.There are also concerns about existing legal tests for demonstrating that an AI-generated work infringes copyright, since establishing these legal tests often rely on the concept of substantial similarity between the original work and the allegedly infringing AI-generated work. Applying these tests to AI-generated content may be complex due to the unpredictable nature of AI models.Additionally, determining whether an AI system accessed or copied specific copyright-protected content when generating an output poses significant transparency and data protection concerns. It also raises questions over how to regulate and monitor the usage of different outputs and what regulatory compliance will look like for end-users, especially in cases where end-users lack the necessary training to understand the implications of different prompts and outputs.MPBSD recognizes the barriers and challenges to determining when an AI system accessed or copied a specific copyright-protected content when generating an infringing output. It is important to note that many AI systems are trained on large and diverse datasets from the internet, with significant amount of user-generated content with various degrees of authorship, hence, making it difficult to pinpoint and establish a link as to the exact sources of information used to generate an output.MPBSD recommends ISED to consider defining criteria that would help identify to what extent developers would be liable for primary or secondary infringement when training AI models and creating AI-generated content. This will be helpful in determining whether an amendment to the Copyright Act should be made to exclude AI-generated content from copyright protection. However, given the complexity of the development and governance of AI models, this would require shared accountability delegated at various levels between the developer, owner and end-user. Any exceptions to criteria in this area should also consider fair use or fair dealing principles to foster innovation and support education purposes.As mentioned earlier, MPBSD recommends ISED to consider approaches in other jurisdictions such as EU’s AI Act and UK’s approach on the governance of generative AI that will help inform best practices for Canada.",MPBSD commends ISED for addressing previous feedback provided to ISED (from Canadian Guardrails for Generative AI – Code of Practice) by narrowing in on an important area of law that will be heavily impacted by the growing development of generative AI systems. We appreciate the opportunity to provide feedback as part of the consultation on the Copyright in the Age of Generative Artificial Intelligence.
Artists' Legal Services Ottawa (ALSO),Law / Legal,"We are responding to this consultation on behalf of Artist’s Legal Services Ottawa (ALSO) which is a non-profit corporation operated by volunteer entertainment, corporate and intellectual property lawyers and law students in Ottawa, Ontario. ALSO aims to provide legal education and informational resources to creators across the National Capitol Region who may not be able to access more expensive alternatives. Since ALSO’s incorporation in 2013, ALSO has facilitated and coordinated educational sessions aimed at informing artists of all disciplines on a wide variety of legal issues that impact their practices and businesses. Additionally, we offer legal networking resources that connect artists to legal counsel that can provide relevant legal information or advice.  Over the past several years, we have seen first-hand the legal challenges that have emerged from AI, both from a creator and user perspective. Since the launch of platforms like ChatGPT and Dall-E, there has been a significant increase in the number of artists with questions about AI. Creators are both excited and nervous about the future of this new and impactful technology, not only on their own creative practices, but also for what it means for them as they continue to form, grow, and scale internationally competitive businesses.In this consultation, the Government is seeking comment on potential copyright policy options to preserve the balance between developing technology and working creators. On one hand, the Government seeks to support innovation and investment in AI and other digital and emerging technologies in all sectors of Canada. On the other, the Government seeks to support Canada’s creative industries and to preserve the incentive of human authors and other creators in all arts disciplines.ALSO welcomes the opportunity to provide our comments on this consultation.Technical Evidence•  How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?AI is currently being used by artists across all disciplines for research, and at various stages of their creative process. AI is becoming an extraordinarily powerful tool to help generate draft text, produce sophisticated images, and even roughs for audio and video. The use of various AI tools throughout an artist’s process can significantly reduce production costs and the time it takes to create new and innovative works. Moreover, integration of these technologies increases an artist’s ability to scale their practice and create works previously not possible.Additionally, artists who sell their own works, for example, visual artists and self-published writers, will make increasing use of AI to track sales, inventory, and to calculate royalties due for their works.","One of the foremost challenges facing artists today is the prolific, unauthorized use of their copyrighted material in the training and development of AI technologies. The success of any AI program depends on the data on which it is developed and trained; the more data a program has to learn from, the more sophisticated and accurate its outputs will be. Therefore, there is great incentive on the part of developers to obtain as much data, in as many forms as possible, to ensure their AI’s outputs are as accurate and, sometimes, as “human” as possible. With the amount of data points often being in the millions, it is inevitable that copyrighted material would be included and used. However, artists’ intellectual property and commercial rights are uniquely threatened by AI because much of the material used in training these models (i.e. text, imagery, audio and visual material) is creative. By extension, much of this material is protected by copyright. To decrease the illegal use of copyrighted works in the generation of AI it is imperative that clear information be provided on the relationship between copyright law and Text and Data Mining (TDM). Despite its title, TDM does not only include literary text; it also can include, among other things, visual art, photography, music, motion pictures, and so on.  Canada should make absolutely clear that scraping copyrighted works for the purpose of TDM in generative AI without authorization of copyright owners and holders is an infringement of copyright law.Content created by artists working in all disciplines, including literary, artistic, dramatic and musical works, choreographic works, works displaying lyrics and musical notation, sound recordings of audio works, and performers’ performances (e.g., dance, songs and spoken words), audiovisual and interactive works derived from these and other works (e.g., motion pictures and video games) are all copyrightable material. Therefore, transparency is desperately needed to ensure authors and copyright holders know exactly what works were included in the data sets on which AI models have been trained or programmed. Creators must also be given a mechanism to monitor compliance if they have authorized certain works to be used in TDM. Developers of AI models should be required to maintain detailed logs of the sources used to train the AI. These logs would allow creators to track the use of their works and be sure that any such use had been authorized. It would be problematic to introduce any new exceptions to the Copyright Act that provide a new exception for TDM or works made by generative AI in reliance on TDM. There is no one-size-fits-all model for how TDM works; each platform developer uses a different programming methodology and sources their data differently. Any exception introduced would have huge negative repercussions on the creative industries, including, but not limited to, production of fake images and texts, sound and audiovisual recordings and other deceptively identified artistic expressions purportedly by name artists (e.g., painters, photographers, poets and film directors). Generative AI platforms are being increasingly used by impersonators to produce works “in the style of” name artists, where works of art are being falsely attributed to persons who did not create them but are gaining notoriety or attention because the work is immediately reminiscent of that artist’s well-known style. Much like with real-life copycats, these AI-generated works are cutting the real artist out of the process completely, and often the financial benefits.An exception for TDM in the Copyright Act would open the floodgates of machine-generated works that will infringe authors’ moral rights, will compete with original copyright works created by human authors and their publishers, producers, and distributed by broadcasters, wholesalers, retailers and other distributors. Permitting TDM to utilize copyrighted material without authorization, attribution or due compensation will reduce incomes for a great many artists in this confusing and overly competitive marketplace, which will likely cause many artists to give up their professions.  Canada’s creative industries have already struggled immensely, especially during the COVID pandemic years. An exception for TDM would make it even more difficult for Canadian artists to be commercially successful both at home and internationally. Response to Bullet #3Our experience communicating with creators is that rightsholders generally do not want their works used for Text and Data Mining and the development of generative-AI models, unless their works would be licensed for clearly specified purposes or uses. Rightsholders generally maintain that this licensing should include compensation for making their works available for those purposes or uses. The flooding of cultural markets by millions of AI-generated works will impair the market for the original works of authors and performers and disincentivize human creators, particularly discouraging and demotivating them when AI-generated works appear to have filled the gap for an original work on a particular subject. Notable examples of this market dislocation include AI-generated content scooping the plots of thinly disguised sequels to a novel or television series.  Fewer works by human creators will be successful in this crowded and confusing marketplace.  AI-generated works that rely on TDM are not original works of human authorship and should, therefore, not be protected by copyright. Under existing law, AI-made works without the intellectual involvement of humans exercising their skill and judgment do not have the “originality” required for copyright, as determined by the Supreme Court of Canada in the 2004 CCH Canada ruling. Given generative AI’s capacity to reproduce works without human involvement, it is our view that the criteria for “original works” should now clearly include a measure of creativity by a human author.Lack of transparency is also currently a challenge because creators cannot engage in a licensing discussion with the AI developer if they do not know that their works are being used for TDM.  To begin with, creators should know that TDM does not only use literary texts, and they should know or be able to find out easily if their literary, dramatic, musical, and artistic works and other subject-matter have been subjected to TDM. They, and ALAC as an organization, have little or no information about the content of the datasets now being used to make publications of text (e.g., print and audiobooks) and images (e.g., prints and photographs), sound recordings (e.g., music and radio programs) and audiovisual presentations (e.g., motion pictures and videogames) that will compete with the copyrighted works of human authors. Creators currently have no ability to monitor uses of their creations by AI developers and platforms, and they have little information about how much of this training of AI models may be making unauthorized use of copyright works (including works of their own) other than from media reports about alleged infringements. At present, even when it is obvious a copyright holder’s rights have been infringed by a clearly substantially similar AI-generated work, it is difficult, and often impossible, to secure evidence of TDM, and thus determine the infringer’s liability. In addition, copyright owners are being deterred from pursuing litigation of this nature because of the formidable costs of investigating and prosecuting such claims. Consequently, it should be the responsibility of AI developers to program safeguards into their models will not reject prompts from users that instruct the AI model to recreate copyrighted works, whether or not those input works were licensed for permissible TDM. Generative AI developers and platforms, as well as falsely-credited authors, performers, publishers or producers, should be liable or share liability for copyright-infringing outputs and for any resulting infringement of the creators’ moral rights of attribution and integrity. Response to Bullet #5There should be no legislated exceptions to copyright for TDM. The phrase “Text and Data Mining” is unfortunately misleading as the “mining” concerned can include, among other things, visual art, photography, music, motion pictures, and so on. Any new exception introduced to the Copyright Act for TDM will negatively affect artists working in every discipline of the arts.   To safeguard against the public being deceived by inaccurate, misleading, manipulative, fraudulent or false information or “deep fakes”, Canadian legislation should prescribe that all displayed, published or made-available AI-generated content should be labelled as “machine-generated” or “generated by artificial intelligence”. Another safeguard should be to require AI developers to develop AI tools that reject prompts of users that could lead to the recreation of copyright works, whether or not those works have been licensed for TDM use.  Generative-AI developers and platforms, as well as persons to whom authorship is falsely attributed, and falsely credited publishers or producers, should be liable or share liability for infringing outputs. Section 30.71 of the Copyright Act permitting temporary reproductions for technological processes should be amended to specifically exclude TDM, if this inclusion has not been ruled out earlier by court decisions. The courts in Canada may decide the current “fair dealing” exception permits some TDM, however, since AI developers all have their own method of training AI models and these methods will likely continue to change as technology develops, the “fair dealing” analysis should be done on a case-by-case basis.","Text and Data Mining Responses ContinuedRegulations for fair dealing specifically for TDM may be needed sometime in future if some generative-AI developers and platforms treat this defence as a loophole and arbitrarily help themselves to the work of creators for unfair advantage. This practice has occurred since 2012 with respect to the then-new fair dealing exception for the purpose of “education” – because of the lack of a definition and the tempting broadness of what might be considered “fair”. Regulations for fair dealing specifically for TDM should provide a clear and narrow definition of any allowable dealing and should be sufficiently flexible to restrain expansion of TDM as generative AI will continue in rapid flux. Unlike an amendment to the Copyright Act, regulations can be changed more easily as circumstances change.If the TDM issue is not resolved sufficiently by regulations on fair dealing under the Copyright Act or, alternatively, by regulations under the Artificial Intelligence and Data Act, which is currently under consideration by a committee of the House of Commons, collective licensing subject to negotiated licenses or a mandatory tariff for specific TDM uses would be appropriate. The proposed Artificial Intelligence and Data Act currently under consideration by Parliament unfortunately does not specifically address the very real probability of significant damage in the copyright landscape arising from generative AI’s potential scale of use, the severity of harm to creators, and the economic imbalance between high-impact AI systems and copyright owners and holders. Although most members or affiliates of collective societies probably want their rights with respect to TDM to be handled by their collective society, a licence from a collective society should not preclude the possibility of direct licensing by an individual creator or other copyright owner or a copyright holder.  •  Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?AI developers should certainly be required to keep and retain records of all works used to produce or “train” their generative-AI models and to release this information promptly to allow inspection and monitoring by authors, other creators, copyright owners/holders and public inspection. This right to inspect/monitor should exist regardless of whether or not there is a perceived or alleged copyright infringement or tort (e.g., libel or slander, appropriation of personality rights or unjust enrichment).Without a requirement to both maintain and disclose training data records, it becomes extremely difficult, often impossible, for a rightsholder to find out whether their works were used to train a particular AI model and whether there has been an infringement of their copyright or a failure to seek a license. Ensuring authors and copyright holders have continued control over their works, and continue to receive economic benefit from them, is of utmost priority. The Copyright Act empowers creators to balance their commercial and moral interests against the public interests; the Act should continue to do so when it comes to AI.•  What level of remuneration would be appropriate for the use of a given work in TDM activities?Fees should be negotiated by the generative-AI developers/platforms and copyright owners/holders, or with their collective societies directly. Arbitration should be required if no license fee is agreed to, or use of copyright material in TDM could be subject to a mandatory tariff determined by the Copyright Board.Criminal penalties for copyright infringement and, if opted for by a copyright owner or holder, the statutory civil damages for plaintiffs that are available need to be increased as the infringers or enablers of infringement are most likely large international technological corporations, and the high costs of individual investigation and prosecution will make enforcement prohibitive otherwise.Authorship & Ownership of Works Generated by AI•  Is the uncertainty surrounding authorship and ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies?The term “author” is not defined in the Copyright Act, but the legislative language and jurisprudence implies that “authors” are humans. Also undefined but implied, performers of performers’ performances must be human. Anyone can call themself an author or a performer regardless of whether or not they have created a copyright work or other copyright subject-matter. We submit, however, that it is not honest or ethical to do so for an AI-generated work.  Not disclosing when an AI tool has been utilized in the creation of a work, or has created a work entirely on its own, crosses a line into commercial deception of the public by trading on the public’s long-standing presumption of human authorship when it comes to creativity.More and more creators will use generative AI for research and many of them will create AI-assisted works, but generative AI without the intellectual involvement of human creators exercising skill and judgment (established as the criteria for original works by the 2004 CCH Canada decision of the Supreme Court of Canada) is not “original”.  In the context of artificial intelligence, we think the criteria for assessing the originality of a work should clearly require creativity by a human author or other human creator.  AI-generated material lacking human originality should not be protected by copyright and should not be permitted to display a copyright notice.We are of the view that AI-assisted works and other subject-matter should be protected by copyright, assuming originality, effective and verifiable human control, and appropriate attribution to their human authors and performers. An AI-assisted work may and would ordinarily display a copyright notice because an artist using an AI tool in their creation of a work is much the same as a painter choosing to use a paintbrush. The use of an AI aid should not stand in the way of a human author’s ability to obtain copyright protection. An AI program creating a work in isolation of human intervention should not receive the same treatment.Another significant concern with granting AI-generated works authorship in conjunction with ownership is that it could encourage bad actors to create works for the sole purpose of eventually bringing claims against human creators for infringement. Given the near endless works that they could generate a day, these AI-created works would flood the market and compete directly with original works created by human authors and their publishers and producers, as well as their broadcasters, wholesalers, retailers and other distributors. This will have the adverse effect of creating confusion in the marketplace, driving down prices, and inhibiting human creators’ incentive to generate new works.It should be an offence for any person or entity, identifying themself as the owner, maker, publisher or author of an AI-generated work or other subject-matter without significant verifiable human intellectual involvement, including a measure of creativity (as we propose above) in addition to skill and judgment, to place a copyright notice on its publication.  A machine-made work or other subject-matter lacking originality should never be protected by copyright. Nor should AI-assisted work or other subject-matter be protected by copyright unless: it contains substantial original material created by humans; its entire content is under effective, verifiable control of humans; and at least one human is identified as its author or publisher.All owners of AI work should be liable for infringements of copyright and for torts (e.g., libel or slander, appropriation of personality rights or unjust enrichment). Producing any AI-generated or AI-assisted work which imitates or mimics the distinctive style of another writer could be viewed as an appropriation of personality rights. It could also be an infringement of a creator’s moral rights, especially their reputation.An AI-assisted author would be liable, not just with respect to their own text, images and other changes (e.g., their edits, adaptations, additions and substitutions), but also because of the possibility that AI-generated material in the content of the work, unbeknownst to them, may infringe copyright or violate the rights of other authors. They may unwittingly incorporate AI-generated material that puts them at risk and should ascertain that the use of all copyright works in datasets for TDM used to train models that they used have been authorized by the copyright owners or holders or are works in the public domain. For example, a scriptwriter who is engaged by a producer to revise a draft script made by generative AI should be cautious.Regulations should include an obligation to name or identify – and publish on every AI-generated publication – a responsible person or entity who will be liable in addition to any named and identifiable author or publisher of the publication.","•  What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?The biggest barrier is the current lack of information on what copyrighted works are being input into a particular AI system. This is mainly because (a) AI developers like OpenAI, Google, Meta and StabilityAI (for example) do not publicly disclose what their data banks contain and how they compile their data sets for a particular program or iteration and (b) because the data banks being used are so phenomenally large. If courts want evidence of TDM to establish unauthorized access by the defendant, despite general availability of a creator’s work in the marketplace or a public forum, as well as substantial similarity between the creator’s work and the allegedly infringing AI-generated material, then the defendant’s must be required to disclose the contents of the data set for the AI program at issue.  Assessing similarity will be subjective, may not be obvious, and will be extremely hard to determine or adjudicate in the absence of information about input. Copying can occur (1) on actual reproduction when a copyrighted work is input into an AI system’s data bank, (2) when a user prompts an AI system to reproduce copyrighted words and images, and (3) when copyrighted material is reproduced by an AI algorithm. Because of the numerous opportunities for copyright infringement by AI there should be an obligation on developers to keep and retain records of all copyright material input into an AI system and to make those records fully available for monitoring by rightsholders and the public. Prior to any legal requirement by legislation or regulation, the Government should ask AI developers to do this on a voluntary basis. Knowledge or awareness of infringement or use of TDM without rightsholder consent should be presumed in law if AI developers or users of their AI tools fail to keep records and comply with other regulations.•  Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?There absolutely should be greater clarity on where liability lies when it comes to AI-generated works that infringe existing copyright-protected works. To ensure certainty and predictability in the law, AI developers, platform developers and those claiming authorship or identifying as publishers of an AI-generated work should be liable or share liability for infringing copyrighted works just as they would be in a non-AI context. Producers of AI-generated content must be clear on what liability awaits them if they use copyrighted material without authorization. Equally, creators deserve to know their rights when it comes to enforcing copyright in an AI context. The","Artist’s Legal Services Ottawa (ALSO) is a non-profit corporation which, among other activities, facilitates and coordinates legal education and networking opportunities for artists working in all disciplines of the arts, and to arts organizations offering services to artists and other creators. ALSO observes and submits as follows:As AI continues to develop at an amazing speed, it is our view that it is too early for Parliament to pass any copyright legislation with respect to generative AI systems unless it becomes necessary to curb abuses of Text and Data Mining immediately.  Appropriate amendments to the Artificial Intelligence and Data Act, currently under consideration by a House of Commons Committee, may allow regulation of AI-generated works to curb abuses of Text and Data Mining. These regulations could be established well prior to any amendments to the Copyright Act, which would likely be quickly outdated by further AI developments in Canada and elsewhere. No legislation is needed right now to clarify that authorization from rightsholders is required prior to Text and Data Mining. It may be that some use of TDM and resulting AI-generated output will be accepted by courts, perhaps as “fair dealing” and this may suffice for the time being to deal with AI until it becomes necessary to set parameters on fair dealing, preferably by regulation in order to remain flexible.  Section 30.71 of the Copyright Act permitting temporary reproductions for technological processes should eventually be amended to specifically exclude TDM if not ruled out earlier by court decisions.Authors and other creators of copyrighted works or other subject-matter or, if authorized, their publishers, producers, or collective societies, may choose to license the use of their work to AI developers for TDM-specific purposes and uses, subject to negotiated limitations on use, fees, record-keeping, and other conditions negotiated with the generative-AI developers and platforms directly.There should be no exceptions to the Copyright Act to accommodate developers of generative-AI platforms. Exceptions would encourage more use of entirely AI-generated works that would substitute for, compete with, and impair the market for original copyrightable works created by the skill and judgment of human authors as well as, in our opinion, their creativity, including original AI-assisted works. What is desperately needed right now – prior to any eventual amendments to the Copyright Act – is much more information and transparency about any AI systems being used to generate published materials, including the sources of the data relied on for producing that content. This information should be easily available to rightsholders and the public, not just in case of alleged copyright infringement but in any case. Creators and users of AI systems should know what has been included in the datasets on which AI models have been “trained” and to be able to monitor compliance if they have authorized TDM. Furthermore, AI developers should develop generative-AI tools that will reject prompts by users of their systems that could recreate copyright works or that deliberately attempt to imitate the style of specifically named human authors.AI developers, as well as generative AI platforms, credited publishers and producers of AI work, and individuals to whom authorship of such AI work is attributed should clearly label all such work as machine-generated; as such, these parties should be liable or share liability for infringing outputs. It should be an offence for any person or entity, identifying itself as the maker, publisher or author of an AI-generated work without significant verifiable human intellectual involvement and a measure of creativity, to place a copyright notice on its publication. Penalties for copyright infringement and statutory damages available to plaintiffs should be increased as the infringers or enablers of infringement are most likely to be large international technological corporations.To recognize copyright in AI-generated works without originality due to human creativity and control would disrespect authors, performers and other artists working in all disciplines of the arts, demean their professions, reduce incomes earned by already struggling artists and force some to look for other careers. Moreover, incentivizing the proliferation of AI-generated works over human-created works would further reduce the number of jobs in Canada’s cultural sectors more broadly. This would be a devastating loss to Canadian culture, our economy, and society at large.Parliament should not jump prematurely to enact copyright legislation on AI in this extraordinarily disruptive time before Canadian society gets accustomed to generative AI and the inevitable huge change to Canadian culture. There should be certainty that any changes to the Copyright Act will be compatible, to the extent reasonably possible, with the copyright laws of Canada’s main trading partners, particularly the United States, Europe, the United Kingdom, as well as the broader Commonwealth and Francophonie.  The technological progress of artificial intelligence is laudable, and we recognize that AI-generated material can have great value if used responsibly in appropriate contexts. But it should not encroach on human authorship and our broader societal values.  Paragraph 2 of Article 27 of the Universal Declaration of Human Rights reminds us that “Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author.” It should not be forgotten that our Copyright Act is based on human authorship including the sole rights vested in authors set out in Section 3. Any exception from copyright with respect to AI must pass the 3-step test in Article 9(2) of the Berne Convention for the Protection of Literary and Artistic Works, which is echoed in the WIPO Copyright Treaty, the WIPO Performances and Phonograms Treaty and in the Canada-US-Mexico Agreement, providing that exceptions must not “unreasonably prejudice the legitimate interests of the author.”Moreover, ensuring Canada’s copyright regime continues to advance and protect the rights of creators is paramount given that artists are fundamental to the creation and preservation of culture. The artistic contributions of minority groups, especially Canada’s Indigenous peoples, are specifically important to the creation and preservation of Canada’s diverse cultural fabric. Article 11 of the United Nations Declaration on the Rights of Indigenous Peoples, to which Canada is a signatory, specifically enshrines that indigenous peoples have a right to control their cultures, and in particular, their “visual and performing arts and literature”. Protecting artistic from AI-based copyright infringement will fulfill this obligation and ensure Canada’s indigenous communities maintain control over their vitally important artistic and cultural practices.As AI continues to rapidly change the way we live, create, and do business all across the world, it is imperative that Parliament be thoughtful about its approach to copyright and AI, especially when it comes to fulfilling our international and treaty obligations. Canada’s copyright regime must remain consistent across the myriad emerging and advancing technologies, not only to uphold technological neutrality, but to ensure Canadian creators and businesses have clarity on their rights and obligations as they navigate, and thrive, in competitive global economies.Thank you for considering our perspective on this important issue."
Soproq,Law / Legal,"La Soproq est une société de gestion collective des droits des producteurs d'enregistrements sonores et de vidéoclips. Nous percevons et distribuons les redevances découlant des droits d’exécution publique, de ceux liés à la reproduction et au régime de copie privée pour les enregistrements sonores et les vidéoclips faisant partie de notre répertoire. Nous négocions également avec les services de musique et émettons des licences générales pour l’utilisation des titres contenus dans notre répertoire. Le répertoire de la Soproq inclut près de 2,5 millions de titres (enregistrements sonores et vidéoclips) appartenant à près de 7000 ayants droit provenant du Québec, du Canada et d’autres pays : entreprises de production, artistes auto-producteurs, distributeurs, associations, sociétés de gestion étrangères, etc.La Soproq est heureuse de répondre à l’appel lancé par le gouvernement du Canada dans le cadre de la « Consultation sur le droit d'auteur à l'ère de l'intelligence artificielle générative ».Plusieurs de nos sociétaires utilisent l’IA générative comme outil d’aide à la production et création d’enregistrements sonores et de vidéoclips. Ces derniers considèrent l’IA comme un outil facilitant certains procédés plus techniques mais estiment que l’exercice du talent et du jugement humain demeure toutefois à la base des principes du droit d’auteur. Afin de recevoir leurs redevances, en contrepartie de l’utilisation de leurs contenus protégés par les utilisateurs de musique, les ayants droit doivent déclarer à la Soproq les métadonnées relatives à ces contenus. La réception de ces métadonnées est accompagnée d’une déclaration de la personne qui soumet les données, attestant qu’elle détient les droits applicables sur le contenu soumis.Actuellement, les métadonnées recueillies des ayants droit ne permettent pas à la Soproq d’identifier les enregistrements sonores ou vidéoclips qui auraient été produits, en partie ou en entièreté, par intelligence artificielle générative. Il serait néanmoins possible de mettre en place rapidement la cueillette de telles informations. La Soproq n’utilise pas les données recueillies à des fins d’entrainement de système d’IA générative.","La popularisation de la Fouille de Textes et de Données (FTD) comme moyen principal pour fins d’apprentissage-machine marque une étape significative dans l’avancement de l'intelligence artificielle.  Selon OpenAI, compagnie derrière l’intelligence artificielle générative ChatGPT, leur système utilise une combinaison de trois sources de données pour entrainer l’algorithme : « (1) Information publiquement disponible sur internet, (2) Information acquise sous licences de tiers, et (3) Information fournie par nos utilisateurs ou formateurs humains » (https://help.openai.com/en/articles/7842364-how-chatgpt-and-our-language-models-are-developed ) [notre traduction]. De ces trois sources d’information, seule la deuxième semble respecter le principe du droit d’auteur puisque l’information est acquise sous licence.D’abord, une distinction importante doit être faite entre « information publiquement disponible » et information libre de droits. Par exemple, un quotidien publiant les articles de ses journalistes sur son site web rend ceux-ci accessibles publiquement, mais ne libère pas nécessairement les droits et privilèges que leur accorde la Loi sur le droit d’auteur. En ce sens, bien que le contenu utilisé pour entraîner les systèmes génératifs soit disponible publiquement sur le web et puisse être moissonné en grande quantité à l’aide de programmes de type web-crawlers, l’utilisation de contenus protégés viole les droits des créateurs lorsque ces contenus ne sont pas adéquatement libérés. De plus, les contenus saisis par les utilisateurs ou les formateurs humains, soit la troisième source de données mentionnée par OpenAI, peuvent eux aussi contenir du contenu protégé, et donc, doivent aussi être dûment libérés et compensés. L’ampleur de l'essor de l'IA rappelle la démocratisation du web au début des années 1990, impactant tous les pans de la société. Au même titre, nous constatons déjà qu’il y a un avant et un après ChatGPT. Cependant, le développement de l’IA générative présente une différence importante avec l’explosion du web d’il y a 30 ans. Contrairement aux fondements non lucratifs du développement web, la trajectoire des modèles d'IA générative est en grande partie définie par des acteurs multinationaux en quête de gains financiers. Cette distinction soulève des interrogations significatives quant à l'équité et à la juste distribution des avantages issus de ces percées technologiques.La protection des contenus protégés par le droit d’auteur est la pierre d’assise de la culture des démocraties modernes. La raison d'être du droit d'auteur est de sauvegarder et de reconnaître la valeur de l'expression humaine. Toute proposition qui sape ou va à l'encontre de cet objectif doit être rejetée. Nul avancement technologique, aussi important soit-il, ne peut se soustraire aux principes fondamentaux du droit d’auteur sous prétexte que la libération des droits du matériel utilisé nuirait aux développements technologiques. Ainsi, l'accès aux contenus protégés par le droit d'auteur par ces systèmes génératifs, et la reproduction des contenus que ces systèmes font, constitue un point sensible pour le milieu culturel et ses représentants. La Loi stipule que « Le droit d’auteur sur l’œuvre comporte le droit exclusif de produire ou reproduire la totalité ou une partie importante de l’œuvre, sous une forme matérielle quelconque » (art 3). La reproduction inhérente à la FTD ne peut être considérée comme une activité accessoire. Au contraire, elle se présente comme la matière première essentielle pour les systèmes d'IA générative. Dans cette optique, l'application d'une exception relative aux reproductions temporaires (art 30.71) ne semble pas appropriée, étant donné la centralité de la reproduction dans le processus technologique. Au contraire, la Loi accorde aux ayants droit un droit de paternité, un droit moral, et un droit exclusif quant à la reproduction de leurs contenus protégés et il est de la responsabilité des acteurs technologiques souhaitant reproduire ces contenus de les respecter.En ce sens, l’introduction d’une exception à la Loi viendrait non seulement affaiblir les droits actuels des ayants droit, mais viendrait également couper des opportunités financières aux détenteurs de droits en limitant leurs possibilités de monétiser leurs contenus dans un marché libre. De plus, l’ajout d’exceptions à la Loi pour les activités de FTD constituerait un financement détourné des compagnies technologiques de la poche même des créateurs culturels. Rappelons que les entreprises mettant en marché les outils d’IA générative les plus populaires le font en partenariat avec certaines des compagnies les plus lucratives au monde, et qu’ils le font dans un but commercial, et non de façon altruiste.L’industrie technologique argumentera certainement que de libérer les droits pour tout le contenu utilisé lors de l’apprentissage machine serait irréaliste, et qu’une telle restriction nuirait au développement technologique de leurs services. En ce sens, ils argumenteront sans doute qu’une distinction doit être faite entre le matériel protégé par le droit d’auteur et les données utilisées pour entraîner les algorithmes. Même le gouvernement canadien, dans les documents liés à cette consultation, fait le même raccourci en parlant de « grandes quantités de données, y compris celles extraites de contenus protégés par le droit d'auteur », comme si le contenu protégé perdait son identité aux mains de l’apprentissage-machine et était réduit à de simples données anonymes. Or, les contenus protégés sont la matière première des systèmes d’IA générative, au même titre que les enregistrements sonores sont la matière première des stations de radio. Si ces derniers doivent libérer les droits des contenus protégés qu’ils utilisent, il en va de même pour les compagnies derrière les systèmes d’IA générative. Ainsi, nous recommandons que les plateformes d'IA générative soient tenues de respecter des normes de transparence qui engloberaient la publication de registres renfermant des informations sur les contenus protégés utilisés à des fins d’apprentissage-machine.Rappelons également que l’argument souvent entendu selon lequel la libération des droits sur le contenu utilisé comporterait un fardeau administratif trop grand est fallacieux. La gestion collective des droits permet aux utilisateurs de contenus protégés de libérer de façon simple et efficace les droits sur des contenus appartenant à un grand nombre d’ayants droit distincts. La gestion collective est déjà largement répandue au Canada et l’efficacité de ce type d’administration de droits n’est plus à démontrer. Dans cette perspective, il est fondamental de reconnaître le rôle crucial de l'autorégulation du marché, favorisant un équilibre entre la libération des droits et la facilité administrative.Pour l’information publiquement disponible moissonnée sur le web, la Soproq dispose de différents modèles de licences permettant aux utilisateurs de faire la reproduction des contenus protégés faisant partie de son répertoire. Ces modèles peuvent s’adapter à tout développement technologique, y compris l’IA générative. Quant à la reproduction de contenus protégés lorsque de l’information est fournie par les utilisateurs ou formateurs humains, ce sont en plus les principes du régime de copie privée qui devraient s'appliquer.Au sujet de la question du niveau de rémunération appropriée, il doit être évidemment juste et équitable en regard de l’importance de cette reproduction dans les activités de l’entreprise, étant entendu que ces reproductions sont au cœur des systèmes d’IA générative. Sans contenu pour entrainer les algorithmes, ces systèmes n’existent pas. Dans tous les cas, cette valeur doit être déterminée par le libre marché, en prenant en considération les principes déjà établis par la Commission du droit d’auteur.",,,"Dans la dynamique évolutive de l'intelligence artificielle générative, l'équilibre entre la préservation du droit d'auteur et la promotion de l'innovation émerge comme une nécessité impérative. Nous espérons que ces considérations contribueront à guider le gouvernement dans l'élaboration de politiques qui favorisent le progrès technologique, tout en préservant les intérêts des créateurs au sein du Canada.Nous soutenons que le cadre législatif actuel est suffisamment robuste pour s’assurer de cet équilibre, à condition qu’il soit appliqué tel quel, sans nouvelles exceptions. La montée en puissance de l'IA n’est que le plus récent d’une longue série de cataclysmes technologiques débutant il y une trentaine d’années avec la démocratisation du web, l’iPod, le téléphone intelligent et l’écoute en continu. Au cours de ces trois décennies, multiples exceptions et exemptions ont été introduites à la Loi sur le droit d’auteur, privant les ayants droit d’une rémunération juste et équitable. Nous saluons l’initiative du gouvernement canadien quant à la consultation actuelle menée au sujet du cadre du droit d'auteur et des technologies d'IA. Bien que la conversation sur l'IA soit essentielle, nous ne pouvons pas perdre de vue les amendements nécessaires à la Loi sur le droit d'auteur qui peuvent être promulgués immédiatement, qui sont basés sur le marché et ne nécessitent aucun financement supplémentaire du gouvernement. Ces amendements permettront non seulement de maintenir la neutralité technologique de la Loi, mais favoriseront également l'équité pour des milliers de créateurs de partout au pays. Ainsi, nous réitérons les trois demandes du milieu musical canadien, soit (1) de modifier la définition d’enregistrement sonore de manière à ce que les artistes-interprètes, les producteurs et les maisons de disques puissent toucher une rémunération équitable lorsque leurs enregistrements sonores sont utilisés dans un film, à la télévision ou à même un autre contenu audiovisuel ; (2) d’éliminer l’exemption introduite en 1997 permettant aux radios commerciales de ne pas verser de redevances pour l’exécution publique d’enregistrements sonores sur leurs ondes pour les premiers 1,25M$ de revenus publicitaires ; et (3) d’actualiser le régime de copie privée pour maintenir sa neutralité technologique et ainsi percevoir une redevance à la vente de tous produits pouvant stocker des copies de musique.En plus du travail de réflexion sur l’IA, la Soproq demande ardemment au gouvernement canadien de corriger ces aberrations dans la Loi. Les revendications de la Soproq s’alignent avec celles des autres intervenants du secteur des droits voisins au Canada.Finalement, nous tenons également à souligner que la Soproq est membre de la Coalition pour la diversité des expressions culturelles (CDEC). À ce titre, nous avons contribué à l’élaboration des recommandations fournies par la Coalition et nous endossons, en plus des réponses fournies ici, les réponses fournies par la CDEC."
Vandana Taxali,Law / Legal,"As a lawyer specializing in intellectual property, technology, and the arts/entertainment sectors, my work primarily revolves around representing and collaborating with individuals and organizations within the arts and creative industries. I am also the founder of Artcryption, an art+tech platform for artists and creators.  I had the opportunity to engage with artists and gather insights during the week-long digiArt Art + Tech conference which I helped organize and was held on November 24, 2023 until Nov 30th. The valuable feedback and perspectives shared by these artists have significantly informed my views on the matter.During the conference, a comprehensive poll revealed that a minority of artists acknowledged the integration of AI into their artistic practices, while the majority did not incorporate AI technologies into their creative processes. It became evident that artists who did engage with AI often used it for generating or assisting in the creation of their artworks. Notably, a common sentiment among these artists was a lack of awareness or clarity regarding the training datasets employed in AI models, raising concerns about the source and usage of these datasets.Nevertheless, it is essential to highlight that a substantial portion of the artistic community expressed a strong desire for more explicit and well-defined copyright protection of their art and copyright protected works in AI models. These artists voiced their opposition to the incorporation of AI in AI models, emphasizing the need for clearer rules to safeguard their creative works in the evolving landscape of AI-generated art. These insights underscore the importance of addressing copyright concerns and providing guidance to artists as they navigate the intersection of AI and the arts.","Transparency and clarity concerning the use of copyright-protected works are crucial in the evolving landscape of AI and creative industries. There is a growing consensus for increased transparency and well-defined guidelines for attribution and compensation.  AI developers should indeed maintain records and disclose their utilization of copyright-protected works in accordance with the provisions set forth in the Copyright Act.However, it's worth noting that during our survey of artists, many respondents expressed a lack of awareness regarding how to grant permission or monetize the use of their works in AI models. Interestingly, a significant portion of artists did not express a strong desire to do so. Therefore, it is imperative that mechanisms are in place to simplify the process for artists who wish to provide licenses for their work, ensuring accessibility and ease of use.  There is a growing consensus for increased transparency and well-defined guidelines for attribution and compensation. Within the legal realm, the discourse surrounding the choice between opt-in and opt-out consent models transcends mere privacy considerations and delves into the core of artists' autonomy over their creative works. Opt-in models not only uphold ethical principles but also empower artists by enabling them to make conscious and informed choices regarding how their creations are utilized as per the Copyright Act. Furthermore, the notion of collective societies emerges as a potential avenue for compensation rights holders for the use of their work in AI models.  However, a better approach would be to provide the artists/creator with complete autonomy and control over the amount of fee, and conditions for usage of their work.  A variation of the Creative Commons licenses for the use of artists works in AI may provide artists a greater efficiency in providing permissions and licenses.  However, it is imperative that an artist/creator/copyright owner in the creative industry have complete control over which option they preferThere is a need for support  including legal defense and advocacy for the creative industry, in navigating the complex terrain of copyright in the AI era. Many corporations controlling AI have legal defence funds making it difficult for an artist or creator to protect their rights.  A collective approach not only ensures that artists' rights are safeguarded but also facilitates a unified voice in negotiating fair compensation and protection.The US Copyright Office has previously ruled out copyright registered to an AI as the author instead of a human  in 2022 noting it “lacks the human authorship necessary to support a copyright claim”.","Under the Copyright Act, copyright owners possess the inherent right to attribution, credit, and the exclusive permission for the use of their intellectual creations. This fundamental principle should extend seamlessly to the realm of AI-assisted and AI-generated works. Copyright owners must retain the unequivocal ability to grant authorization for the utilization of their works within AI systems, while also delineating the specific conditions and parameters governing such usage.It is imperative for the government to play a role in ensuring clarity and transparency when AI models incorporate copyright-protected works with the appropriate permissions. This entails clearly indicating whether a work is being licensed within an AI model and enforcing the obligation to provide due credit and attribution, contingent upon the permissions granted by the artist or creator.I concur with the approach adopted by the United Kingdom, which involves the creation of a code of practice for the use of AI systems. Such a framework enhances clarity for both copyright owners and users, fostering a balanced environment where authorship and ownership of AI models are well-defined and respected. This approach aligns with the evolving landscape of AI technology and copyright in the modern era, where clear guidelines are essential to address the intricacies of authorship and ownership in AI models.There are a also number of legal risks in the use of AI for the creative industries and include the following:Copyright Infringement:The use of AI in creative industries may involve the incorporation of copyrighted materials without proper authorization, potentially leading to copyright infringement.Lack of Transparency:The opacity of AI-generated creative processes can create challenges in identifying the origin of content, raising issues of transparency and attribution.Privacy Violations:AI systems may collect and process personal data, risking privacy breaches and violations of data protection laws if not managed appropriately.Ownership and Authorship Ambiguity:Description: Determining ownership and authorship of AI-generated artworks or content can be complex, leading to disputes over intellectual property rights.Ethical Concerns:The use of AI in creative works may raise ethical questions, such as the potential for bias in AI-generated content or the use of AI to replicate an artist's style without consent.Data Security:The handling and storage of large datasets for AI training can pose security risks if not adequately protected, leading to data breaches and legal repercussions.Regulatory Compliance:Description: Compliance with evolving regulations related to AI, copyright, data privacy, and consumer protection is essential, with non-compliance carrying legal penalties.Algorithmic Accountability:Lack of accountability in AI algorithms can result in unintended consequences, discrimination, or bias, leading to legal challenges and liabilities.Licensing and Permissions:The use of third-party datasets or copyrighted materials in AI applications requires proper licensing and permissions, with failure to do so risking legal action.Liability for AI-generated Content:Determining liability for AI-generated content, especially in cases of harm or misinformation, poses legal challenges that need resolution.These legal risks underscore the complexity of integrating AI into the creative industries, necessitating clear legal frameworks and responsible practices to mitigate potential legal issues.","The existing legal criteria for determining copyright infringement may prove inadequate in cases where the authorship of AI-generated works is ambiguous, particularly when multiple pre-existing works are utilized or amalgamated. To address this issue and enhance transparency, it is essential that when users create an output using AI, they are provided with information about which copyright-protected works contributed to the output.It's worth noting that many artists are reluctant to embrace AI due to concerns about the use of copyrighted works without permission. This hesitancy reflects a broader sentiment within the artistic community, emphasizing the need for greater clarity in defining liability when AI-generated works potentially infringe upon copyright.  Anti-AI theft technologies such as Nightshade and Glaze are emerging as protective measures and should be explored provided their use is lawful and ethical. Nightshade employs data poisoning to introduce errors into AI training datasets, and Glaze masks artwork to prevent scraping.The Copyright Board in the US has provided guidance on whether AI assisted-works can get a copyright registration.  Further, current developing cases of various class actions in the creative industries also holds significant promise in offering guidance.It is crucial to strike a balance where the rights of copyright owners are preserved and not diminished in any way under the Copyright Act. A comprehensive and evolving legal framework will help navigate the intricate terrain of copyright in the age of AI, ensuring that authorship, ownership, and protection remain robust and equitable.The US Copyright Office Guidance: Work Containing Material Generated by Artificial Intelligence,  March 16, 2023 is extremely helpful and should serve as guidance for the Canadian government.- The US copyright reviewed a graphic novel in February 2023 comprised of human authored text combined with images generated by the AI service Midjourney constituted a copyrightable work, but that the individual images themselves could not be protected by copyright.- “In the Office’s view, it is well established that copyright can protect only material that is the product of human creativity. Most fundamentally, the term “author,” which is used in both the Constitution and the Copyright Act, excludes non-humans”.- “a human may select or arrange AI-generated material in a sufficiently creative way “that the resulting work as a whole constitutes an original work of authorship”.- In previous case law, a monkey cannot register a copyright in photos it captures with a camera because the Copyright Act refers to an author’s “children,” “widow,” “grandchildren,” and “widower,”— terms that “all imply humanity and necessarily exclude animals.”- Artist can modify AI generated works as long as such modifications meet the standard for copyright protection- In the case of works containing AI-generated material, the Office will consider whether the AI contributions are the result of “mechanical reproduction” or instead of an author’s “own original mental conception, to which [the author] gave visible form.” 24 The answer will depend on the circumstances, particularly how the AI tool operates and how it was used to create the final work.25 This is necessarily a case-by case inquiry.- Prompts are not considered copyright protectible as prompts as the “traditional elements of authorship” are determined and executed by the technology – not the human user.  Users do not exercise ultimate creative control over how such systems interpret prompts and generate material. Instead, these prompts function more like instructions to a commissioned artist— they identify what the prompter wishes to have depicted, but the machine determines how those instructions are implemented in its output.","UNESCO, Recommendations, 2021 are also insightful and can provide guidance to the government. The General Conference of the United Nations Educational, Scientific and Cultural OrganizationRecommendations:“that globally accepted ethical standards for AI technologies, in full respect of international law, in particular human rights law, can play a key role in developing AI-related norms across the globe.”“considers ethics as a dynamic basis for the normative evaluation and guidance of AI technologies, referring to human dignity, well-being and the prevention of harm as a compass and as rooted in the ethics of science and technology.”“approaches AI systems as systems which have the capacity to process data and information in a way that resembles intelligent behaviour, and typically includes aspects of reasoning, learning, perception, prediction, planning or control.”“provides ethical guidance to all AI actors, including the public and private sectors, by providing a basis for an ethical impact assessment of AI systems throughout their life cycle.”Principles:Proportionality and Do No HarmSafety and securityFairness and non-discriminationSustainabilityRight to Privacy, and Data ProtectionHuman oversight and determinationTransparency and explainabilityResponsibility and accountabilityAwareness and literacyMulti-stakeholder and adaptive governance"
Le Devoir,Media / Communication Organization,N/A,N/A,N/A,N/A,"Title: Ensuring respect for intellectual property and media continuity in the age of generative artificial intelligence1. SummaryLess than a year ago, Le Devoir, a daily newspaper of reference in the Quebec market, deployed tools to block the extraction, indexing and harvesting robots that patrol its digital platforms to capture data. Like publishers around the world, we are seeing the emergence of generative artificial intelligence (GAI) tools, which have fed off our content to fuel cutting-edge technologies based on large language models (LLMs). These technologies are also based on data indexing, extraction and harvesting tools. We are witnessing an unprecedented and unauthorized transfer of intellectual property that threatens the ability of the media and all creators to enforce and profit from their copyright. Neither Bill C-27, which regulates artificial intelligence, nor the anticipated reform of the Copyright Act, currently allows copyright protection to evolve in the age of artificial intelligence. This significant legal vacuum comes at a time when Canadian media outlets, which are pillars of democracy, are seeking new business models to ensure their sustainability. The Canadian government has a real and urgent interest in establishing a legal framework around generative artificial intelligence and the tools associated with it, and in extending the protections provided by the Copyright Act to these new technologies. The legislative framework must explicitly permit content creators, and by extension the media, to obtain compensation for use of their content by tools based on generative artificial intelligence and large language models.2. About Le DevoirFounded in 1910 by politician and intellectual Henri Bourassa, Le Devoir is a multi-platform daily newspaper read by 1.66 million readers every week [NOTE 1]. Its principal shareholder is Fiducie Le Devoir, a non-profit organization that ensures its independence and inalienability. Le Devoir's business model is based on subscriptions to print and digital editions. Subscription revenues and donations provide more than two-thirds of its income, contributing to its sustainability. Since October 1, 2023, Le Devoir has been considered a Registered Journalism Organization (RJO), a status that allows it to issue tax receipts to donors and solicit major foundations. As a result of prudent management, optimal use of Quebec and Canadian tax credit programs, and a strategy of revenue diversification, Le Devoir enjoyed six consecutive years of profitability from 2017 to 2022. A growing media company, Le Devoir has gone from 102 employees to 183 employees in the past four years. Since 2016, its director has been Brian Myles.3. Background to the legislative debateOn June 16, 2022, the Government of Canada tabled Bill C-27 (which includes the Artificial Intelligence and Data Act (AIDA)). The reform aims to strike a balance between supporting artificial intelligence (AI) research and innovation, and proactively identifying and mitigating risks to prevent harm and discrimination.The ambitious legislative framework aims to ""ensur[e] that Canadians can trust the digital technologies that they use every day. The design, development, and use of AI systems must be safe, and must respect the values of Canadians.""[NOTE 2]. While we fully agree with these principles, we deplore the fact that this framework completely ignores issues relating to respect for intellectual property and copyright. This legal vacuum is worrying for the media and the public's right to information.Among the values that Canadians hold dear is the presence of a healthy and diversified news ecosystem, capable of playing its role as an independent watchdog of democratic institutions. This objective was deemed important enough for the Government of Canada to adopt a policy of support for Canadian journalism, in the 2019 Budget Statement. These support measures recognize that ""A strong and independent Canadian news industry is crucial to a well-functioning democracy"" [NOTE 3].If Bill C-27 is not the appropriate vehicle for addressing intellectual property and copyright issues, then we submit that this important public policy issue must be addressed through reform of the Copyright Act. However, consultations on this subject ended immediately prior to the public launch of the first generative artificial intelligence (GAI) tool, ChatGPT.The media, an essential cog in a healthy democracy, thus finds itself in a total vacuum. GAI and tools based on large language models present them with unprecedented challenges in terms of protecting and enhancing intellectual property and copyright, at a time when media outlets are already exposed to profound challenges to their business models.The media is only just recovering from the upheaval that the emergence of social networks has wrought on news consumption habits. News outlets are facing new changes that are coming at it at a speed that is unprecedented in human history.At the recent C2 conference, held in Montreal in May 2023, anthropologist Yuval Noah Harari, author of the bestseller Sapiens, described this dizzying evolution in graphic terms. It is as if we had witnessed the evolution from amoeba to tyrannosaurus over the course of a few years, instead of millions of years. The figures speak for themselves. It took Netflix ten years to reach the 100-million-user mark worldwide, around four-and-a-half years for Facebook and two-and-a-half years for Instagram. ChatGPT reached this milestone in... two months.According to estimates by Canada's Ministry of Innovation, Science and Economic Development [NOTE 4], global AI revenues will exceed $680 billion in 2023, and possibly $1.2 trillion in 2026. Canada's market share could reach $2 trillion by 2030.Canadian media are facing the challenges of AI under an outdated and inadequate legislative framework. They will not be equipped to benefit from these potential spin-offs. Copyright is one of a media company's main assets (along with subscription, donation and advertising revenues). Protecting and enhancing copyright is a major challenge if we are to have sufficient resources to withstand the difficulties facing the entire information sector. We are therefore in need of unwavering support from the government to achieve these goals.Canada must seize the opportunity to legislate copyright protection in the age of artificial intelligence. GAI holds great promise for empowerment and innovation but will quickly be devoid of substance if it is not subject to human regulation. The Government of Canada has a fundamental role to play in protecting the democratic values embodied by the media, ensuring the sustainability and diversity of the news ecosystem, and protecting Canadians from the risks associated with misinformation.4. The challenges of AI in the media sectorAs soon as ChatGPT was launched in November 2022, Le Devoir realized it would be confronted with unprecedented intellectual property issues. Generative artificial intelligence is based on large language models (LLMs). This technology can be likened to an artificial neural network that generates original content from existing data. LLM tools need to be fed large quantities of information in order to learn. They are able to find this information in abundance on media platforms that are renowned for the rigour and quality of their content. ChatGPT is just one among many and will be neither the first nor the last player in the unprecedented transformation of our relationship with the dissemination of knowledge.In concrete terms, a very large number of companies are using our content without paying royalties. Every day, hundreds of companies come to our sites to plunder our content and generate revenue from this data. We think it is only fair that the raw material used to feed platforms or provide services should be remunerated.We know this because, for less than a year now, we have been deploying technological tools that enable us to track the activity of the robots that are capturing mass data and block them. These solutions, which are relatively simple to apply, nevertheless entail additional costs and effort on the part of our IT and copyright teams.To illustrate, on a day chosen at random, November 6, 2023, we recorded the presence of:Of the three scenarios described above, only the third is accepted by Le Devoir, as it enables our advertising customers (agencies and direct clients) to measure the success of their campaigns. In the case of extraction, indexing, and harvesting robots—originating from several countries—they generate an average of over 200,000 sessions per day and over 500,000 page views for unauthorized purposes. Despite the very high volume, this traffic has no impact on our audience and advertising revenues. This is because the technology used by these companies is not captured by measurement tools such as Google Analytics.In addition to blocking the bots that visit our site, we have also modified the terms of use on our digital platforms [NOTE 5] to prevent such unauthorized use. Given the number of bots we block every day, we can conclude that these licensing conditions are being roundly ignored.If there is any doubt about the extent of the unauthorized transfer of intellectual property that has taken place with the emergence of GAI, we refer you to the official statements made by Sam Altman, founder of OpenAI (the company behind ChatGPT) and Brad Smith, President of Microsoft. Appearing before the US Senate Committee on Privacy, Technology and the Law in September 2023, Altman conceded that ""creators deserve control over how their creations are used […], and figure out new ways with this new technology that creators can win."" [NOTE 6]. Mr. Smith said that journalists and publishers ""should be able to decide whether or not they want their content to be available to drive [GAI’s tools]"" [NOTE 7]. He even referred to their collective bargaining rights.That said, OpenAI and Microsoft are blowing hot and cold. In other forums, both companies have expressed their deep reservations about the regulation of GAI by democratic states, preferring a model based on self-regulation from which they would be the main beneficiaries, due to their dominant position in the emerging GAI market.5. Possible reforms to the Copyright ActThe Canadian government has already indicated that it will not be addressing the intellectual property issues raised by AI as part of its study of Bill C-27. As explained above, this legal vacuum is not likely to ensure the sustainability and diversity of the news ecosystem. Le Devoir believes that the overhaul of the Copyright Act should close this loophole and correct certain shortcomings that have existed since the 2012 reform.Many countries around the world are juggling with this new reality. The European Union (EU) is about to adopt the most ambitious law on artificial intelligence [NOTE 8]. The plan calls for the creation of an ""AI czar"" with the power to discontinue products or services that cause harm to society. Companies involved in AI will be required to submit a list of the data sources they use. This measure is designed to deter the use of creative content for unauthorized purposes. Creators will easily be able to determine whether their content has been plagiarized and thus claim compensation.International media outlets, such as The New York Times, The Washington Post, NewsCorp and others, are considering suing major AI companies for infringement of their intellectual property [NOTE 9]. The GAI companies have exploited the fair use doctrine to the full extent, to the detriment of original content creators in the media and cultural sectors.In September 2023, 26 organizations from around the world published a framework declaration on AI [NOTE 10]. News Media Canada, the organization representing Canadian publishers, was one of the signatories. The declaration insists on the recognition of copyright in the AI era, its protection, and the ability of copyright holders to reap its full benefits. In Quebec, Copibec, the collective management society for reproduction rights, has also come out in favour of a revision of the Copyright Act [NOTE 11]. There is a worldwide consensus on the risks posed by GAI to the creative industries, the obsolescence of the protections offered by the various copyright laws, and the need for governments to act.When it comes to copyright compliance, the Associated Press (AP) is an exception. Believing that the chances of a successful lawsuit were limited, and that the legal costs would be astronomical, the news agency chose to negotiate and conclude a commercial agreement with OpenAI [NOTE 12]. In short, OpenAI's GAI tools will be ""trained"" from AP content, in exchange for a fair fee.This innovative agreement could serve as a model were it not for two major irritants. On the one hand, the imbalance of power between the global AI giants and Canadian media makes fair negotiations between the parties uncertain, if not unlikely. On the other hand, AI tools are based almost exclusively on English-language content.This is an attack on the protection of cultural and linguistic diversity, as conversational robots will be deprived of the richness and nuance provided by nations and media evolving in languages other than English.For Canada, a bilingual country that aspires to protect the French language, this issue is particularly important, hence the following two recommendations:Recommendation 1The reform of the Copyright Act should include specific provisions on the use of generative artificial intelligence. The legislative framework should explicitly allow content creators, and by extension the media, to obtain compensation for the use of their content in tools based on generative artificial intelligence and large language models (or LLMs).Recommendation 2The framework for generative artificial intelligence must include provisions to ensure the influence and vitality of French-speaking institutions and creators.6. Restricting the exception for educational purposesThe most recent reform of the Copyright Act, dating from 2012, introduced overly generous exceptions allowing content to be reproduced for educational purposes.Article 29 provides that ""Fair dealing for the purpose of research, private study, education, parody or satire does not infringe copyright.""Article 29.4 (1) states that ""It is not an infringement of copyright for an educational institution or a person acting under its authority for the purposes of education or training on its premises to reproduce a work, or do any other necessary act, in order to display it.""These uses are numerous in the education and research sector, and can also be carried out using GAI, indexing, and harvesting tools. These exceptions, tailor-made for the educational sector, have had harmful consequences for the media, which have been deprived of substantial sums. At Le Devoir, copyright revenues stagnated in the years that followed the 2012 Copyright Act reform.High schools, colleges and universities are major users of journalistic content. It is used to enrich students' thinking and academic careers. Since the reform, many research centres simply no longer wish to pay royalties. And yet, the analyses produced using our content are used for professional purposes and feed important thinking without our being paid. Research and teaching practices have greatly evolved since 2012. The market for big data is booming in the age of social networks. Educational institutions are resorting to in-depth analysis and making extensive use of our content to fuel scientific research.We understand that the financial resources of universities and the education sector are limited. Nevertheless, we feel it is unfair to place the burden of supporting a portion of research or education on the media, whose financial health is precarious. This is the responsibility of society as a whole. We believe that the media should have the possibility to negotiate financial compensation for these uses from public institutions, hence the following recommendation:Recommendation 3Articles 29 and 29.4 (1) of the Copyright Act should be amended to specify that the exception for research and educational purposes does not apply in secondary schools, colleges, universities and research centres.7. Protecting titles, subtitles and other essential elements of the newsA recognized principle in journalism is the importance of the headline, sub headline, and lead (first paragraph) as essential elements of a story. They provide the essential information, while attracting the reader's interest.In a civil case, the Superior Court recognized the importance of granting protection to an article as a whole (headlines, sub-headlines, lead, etc.). In this case, a service provider (La Dose) was producing press reviews and media monitoring for its clients from the content of the plaintiff media (La Presse, Le Devoir, Le Soleil) without paying royalties to these publishers or their business partner, Cedrom-SNI.The interlocutory injunction issued in favour of the media on July 24, 2017, is unequivocal. Mr. Justice François P. Duprat confirmed that the making of a title and a lead are the result of creative work and constitute an important part of the work protected by the Copyright Act:In light of all these factors, the Court cannot conclude that the defendants' use of the titles and primers is fair. Accepting the defendants' position that they can freely use the titles and/or primers and generate income for themselves, without creating income for the plaintiffs, is not, in the Court's view, fair. The defendants' real motive is to use a business model where they can obtain the work free of charge and reproduce it to generate a profit. From the point of view that the Court must maintain a balance between the public interest and the rights of publishers, the present dispute favours the plaintiffs [NOTE 13].We therefore make this recommendation:Recommendation 4The Copyright Act should include specific provisions, recognizing the essential attributes of a news item, in order to facilitate commercial negotiations between the media and providers of press review services.8. Regulating mass collection in the age of AIHundreds of companies come to our website daily to use our content. They capture the content we produce to display only the link to the title, or to analyze it on behalf of their clients. Many of them consider that they are not subject to copyright law, as was the case with La Dose. These companies take advantage of the vagueness of the law to use our content without remuneration. To date, we have rarely received any revenue for these unauthorized uses. The only way to enforce our copyright is through the courts and injunctions—a long and costly process with an uncertain outcome.For the sake of efficiency and consistency, we'd like to draw your attention to a segment that's easier to target: the media monitoring market. In the past, companies providing paper-based press review services paid royalties to the media. Their customers did the same. The transition to digital has changed all that. Despite the emphasis we may place on the terms of use of our sites (only personal use is permitted), these are rarely respected, with limited potential for enforcing our copyright.The media intelligence market is enjoying a meteoric rise in North America, according to data from Fortune Business Insights [NOTE 14]. From US$1.36 billion in 2020, it is projected to grow to around US$6 billion by 2029. The growth prospects are very attractive, and can generate a great deal of interest, hence the following recommendations:Recommendation 5The Copyright Act should explicitly prohibit all forms of big data collection without the express consent of the targeted media.Recommendation 6The Copyright Act should prohibit any form of commercialization of media content by a third party without the explicit consent of the media.Recommendation 7In cases where media content is used for mass data collection or commercial purposes by a third party, without prior agreement or payment of financial compensation, the Copyright Act should include dissuasive penalties to encourage licensing agreements between the parties concerned.We submit that these recommendations respect the spirit of the Copyright Act with regard to the provisions on fair dealing (section 29, subject to Recommendation 3), user-generated non-commercial use (section 29.21) and reproduction for private purposes (section 29.22). Our proposals are in line with article 29.3 (1), which specifies that the acts included in the fair dealing category must not be performed with the intention of making a profit (emphasis added). Our proposals essentially aim to modernize this section, so that it can apply to usages, business practices and technologies that simply did not exist when the Copyright Act was last recast in 2012.Generative artificial intelligence tools pose unprecedented challenges for the media in protecting and enhancing their intellectual property. As explained in Section 5, nations and media outlets around the world are seeking to regulate AI without stifling innovation. Media and content creators (actors, musicians, photographers, etc.) see a risk that their intellectual property will be completely devalued.The ""Web 2.0"" era, which marked the emergence of social media and the domination of the GAFAM companies in the digital advertising market, has already disrupted the value chain for creative companies and the media. For two reasons, they are no longer able to realize the full potential of their creations. On the one hand, creative companies and media outlets have to use distribution networks (social media, online and streaming platforms, etc.), over which they have no control, to reach their customers. On the other hand, they face geographical, technological, and financial limitations that will never allow them to compete with the giants of digital commerce in the advertising market.In the best-case scenarios (and this is the case for Le Devoir), it is possible to establish a complementary relationship with digital platforms and take advantage of their reach to connect with tomorrow's audience. The fact remains, however, that this relationship is asymmetrical. Without the contribution of subscription revenues (print and digital) and donations, Le Devoir would be unable to maintain its market position. The business model based on free content and media financing through digital advertising is doomed to failure in this global context.The media are barely adapting to this new reality, and generative AI will render the ""Web 2.0"" paradigm obsolete. Once again, this will be to the disadvantage of creative companies and the media, who will see a new disruption in the value creation chain. They will find it even more difficult to realize the full commercial potential of their respective creations.The speed and efficiency of AI tools based on large language models (LLMs) have a lot to do with this. Robots patrol the digital universe, capturing metadata, which is then used to enrich the vocabulary and reasoning capabilities of conversational robots, such as ChatGPT and Bard. There is no doubt that these bots have been taking content from news organizations with impunity. Media that have deployed monitoring tools to prevent data extraction, indexing, and harvesting can observe companies such as OpenAI attempting to capture their content in real time.In the US, the News Media Alliance (NMA), an organization representing 2,200 media companies, has just published a report showing that conversational robots draw extensively from news texts to generate responses, in violation of the licensing and copyright conditions of the media in question [NOTE 15]. The study shows that the data extracted by conversational robots from original news content was 5 to 100 times more numerous than the data extracted from generic content. In some cases, the news content was reproduced verbatim by the conversational robots.""GAI systems, while holding promise for consumers, businesses and society at large, are commercial products that have been designed – and are operating – on the backs of content creators,"" the NMA aptly observes.The NMA makes the right diagnosis. What the giants of generative AI describe as ""training"" robots on metadata is, in fact, an inappropriate and illegal use of journalistic material protected by copyright law [NOTE 16]. This is not fair use, because the automated responses generated by the robots are, for all practical purposes, similar to the original content, or inspired by the original content to such an extent that no new work is created.Part of the problem stems from the speed with which generative AI entered our daily lives, with the deployment of ChatGPT in November 2022. The media didn't realize what was going on behind data mining, indexing, and harvesting practices until they saw ChatGPT's tremendous advances first-hand. Many media outlets are still unaware that they can and must protect their digital platforms from future mass data collection activities. This will come soon enough.The most worrying issue is the complete inadequacy of the Copyright Act to regulate these new uses. While it is possible to identify and block the conversational bots that patrol our platforms, it was impossible to know the extent of metadata capture prior to the launch of ChatGPT and other generative AI tools. In a similar vein, for any initial instruction or query (prompt), it is impossible to determine how much of the content may have served as the basis for the large-scale language models that underpin generative AI, and from which information source it originated.A Copyright Act adapted to the reality of AI should be based on principles of transparency and fairness, so that creative businesses and the media can enforce and benefit from their intellectual property.In conclusion, we make the following recommendations:Recommendation 8Generative artificial intelligence systems should be subject to transparency rules for the media. They should have the right and opportunity to know which systems or companies have captured their content, and for what purposes.Recommendation 9Copyright law should provide for a flexible mechanism to facilitate negotiations and commercial agreements between the media and companies operating AI systems.Recommendation 10Content generated by generative artificial intelligence (GAI) should be identified as such by the media and by digital distribution intermediaries.9. ConclusionThe first phases of the digital transformation were marked by the paradigm of free content and net neutrality. In the 90s, Net pioneers encouraged governments to stay out of this emerging market, to avoid stifling the innovative potential of these new, unifying and emancipating technologies. We know what happened next. With the advent of social media and e-commerce in the early 2010s, ""Web 2.0"" turned into a gigantic project to exploit personal data for advertising purposes. Two companies, Google and Meta, now control almost 80% of the digital advertising market.Generative artificial intelligence has only just emerged and is already dominated by the giants. This time, Microsoft (through its association with OpenAI to market ChatGPT) and Google (through Bard) are the dominant figures in a landscape that is changing before our eyes.The concept of ""net neutrality"" has been stretched to the limit for the benefit of the digital giants. The advantages are undeniable in terms of innovation and the democratization of communication tools. The drawbacks are just as great. Misinformation, polarization, the erosion of media advertising revenues and the difficulty for content creators to obtain fair compensation for their work, whether in music, TV, or film, are some of the undesirable effects in these universes that have been deregulated for too long.The Canadian government and other countries around the world are now mobilizing to reverse this trend. The Online Streaming Act, the Online News Act, and bills to regulate artificial intelligence and hate speech all fall into the category of public policy initiatives aimed at restoring a balance between innovation and the democratization of technological tools, and respect for human dignity, privacy, principles, and institutions that are part of the democratic landscape.These concerns must now be transposed into the framing of generative artificial intelligence, in line with the Organisation for Economic Co-operation and Development's (OECD) statements of principle: inclusive growth, sustainable development and well-being; human-centred values and fairness; transparency and explicability; robustness, security and safety; accountability [NOTE 17].Yet generative AI falls into a legal vacuum that will deprive the creative industries, including the media, of the ability to protect their intellectual property and reap the full benefits. To ensure the diversity, vitality, and sustainability of these ecosystems, we need to modernize the Copyright Act to ensure the deployment of generative AI will be guided by human aspirations.NOTE 1 : Vividata, Quebec, autumn 2021.NOTE 2 : Innovation, Science and Economic Development Canada, The Artificial Intelligence and Data Act (AIDA) – Companion document, March 2023.NOTE 3 : Canada Revenue Agency, Supporting Canadian journalism, March 2019.NOTE 4 : Innovation, Science and Economic Development Canada (ibid).NOTE 5 : The terms and conditions of use of Le Devoir ask the user ""not to use any automatic, robotic or manual device for the purpose of cataloguing, summarizing, monitoring or copying this site and its contents, for any purpose whatsoever, without the prior written consent of the Publisher"".NOTE 6 : US Senate Committee on the Judiciary, Oversight of AI: rules for artificial intelligence, testimony of Samuel Altman, May 16, 2023.NOTE 7 : Ibid, testimony of Brad Smith, September 12, 2023.NOTE 8 : The Guardian, EU in «touching distance» of world’s first laws regulating artificial intelligence, October 24 2023.NOTE 9 : Marketing Brew, Publisher’s group warns that generative AI content could violate copyright law, June 5, 2023.NOTE 10 : News Media Alliance, Global Principles on Artificial Intelligence (AI), September 6, 2023.NOTE 11 : Copibec,  Revising copyright to bring artificial intelligence and culture closer together, September 29, 2023.NOTE 12 : Open AI has also donated US$5 million to a philanthropic organization, The American Journalism Project, to facilitate the use of AI in local newsrooms. However, this kind of agreement is no substitute for proper negotiation based on copyright recognition and remuneration.NOTE 13 : Superior Court of Quebec, the Honourable François P. Duprat presiding, July 24, 2017, Cedrom-SNI inc. c. Dose Pro inc., 2017 QCCS 3383.NOTE 14 : Fortune Business Insights, Media monitoring tools market size, share & COVID019 impact analysis, July 2023.NOTE 15 : News Media Alliance, White paper : How the pervasive copying of expressive works to train and fuel generative artificial intelligence systems is copyright infringement and not a fair use, November 2024.NOTE 16 : For present purposes, we recognize that there are distinctions between Canada's Copyright Act and its American counterpart. However, the principles underlying intellectual property and copyright are similar in both countries.NOTE 17 : OECD, Recommendation of the Council on Artificial Intelligence, 2022."
"Telecommunications Service Providers - Rogers, Cogeco, Québecor, Bell",Media / Communication Organization,N/A,N/A,"Should the Government propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works? If so, how?Existing Canadian copyright law principles offer protection to works that are the product of skill and judgment by a natural person and achieve a threshold level of originality.In the context of generative AI, attribution would likely correspond to the natural person who provides instructions to the generative AI system (but not the creator of the AI system itself), for example in the form of a text or visual prompt, and/or who modifies, edits, arranges, or compiles the AI-generated work. However, it should be noted that with the advent of sophisticated generative AI technologies such as ChatGPT and Dall-E, there are, and will continue to be, instances where humans may not contribute sufficient skill and judgment to meet the necessary threshold for authorship/protection. An example of such an occurrence would be where an AI generates work based solely on a single prompt without any further human input, either before or after the work is AI-generated.Maintaining the existing framework adheres to the fundamental principle of technological neutrality, which provides that the Copyright Act should not be interpreted or applied to favour or discriminate against any particular form of technology.The government should proceed with care when considering modifications to the existing framework as the practical consequences, and potential unintended consequences, of changing the law with respect to authorship and ownership are not yet well understood.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?The above noted approach of attributing copyright authorship to the person who makes arrangements for the creation of the work is in line with what has already been adopted in other jurisdictions, for example the United Kingdom or Australia.","Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?Given the prevalent role that intermediaries such as telecommunications service providers (“TSPs”) in providing the passive infrastructure that certain AI technology operates on, we feel it is important that the existing, safe harbour protection for Internet intermediaries remain in full effect.Under the Copyright Act, safe harbour provisions shield intermediaries from obligations or liability in connection with alleged or proven copyright infringement where the intermediaries only provide the technical means by which others infringe. Where TSPs are acting as mere conduits or passive carriers in this way, they must not be required to monitor or be otherwise engaged with the activities of generative AI users or providers to support the protection or enforcement of private rights. The Supreme Court of Canada has already held that Internet Service Providers do not authorize infringement by merely providing connectivity to their users. This stance makes sense because TSPs provide the technical means for communicating and storing content, but their role does not change based on the nature of an end-user’s activity online, even if said activity is infringing or AI-related.Enforcement obligations on TSPs that would impose monitoring, notification or enforcement obligations on TSPs for AI-related activities would run contrary to the existing structure of Canada’s copyright regime and the direction of the Supreme Court’s previous decisions, which carefully balance protections for rightsholders against the burdens on third party stakeholders. To make such changes would put the vibrant online marketplace and digital services sector in Canada at risk.The adoption of a framework  that excludes TSPs from the existing copyright safe harbour provisions or imposes obligations on TSPs would increase the cost of the provision of internet services to Canadians, raise concerns about the neutrality of the Internet in Canada, and introduce a disincentive to the massive infrastructure investments necessary to bring the benefits of 5G networks (and future 6G networks) to Canadians and Canada’s economy.  Furthermore, given that AI outputs may well engender innumerable, highly contentious claims of copyright infringement, anything less than an absolute safe harbour for TSPs would threaten an untenable amount of cost and intervention, both of which would have serious negative impacts on Canadians who use digital networks.",N/A
Artists and Lawyers for the Advancement of Creativity,Non-profit / Think Tank,"How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?We, Artists and Lawyers for the Advancement of Creativity (ALAC), as a non-profit association facilitating a pro bono legal clinic and providing other legal resources for artists – i.e., creators working in all disciplines of the arts – know that artificial intelligence (AI) is currently in use by artists for research.AI is an extraordinarily powerful tool that artists from many disciplines can harness for AI-assisted works. AI can be used to help generate draft text, images and even roughs for audio and video. It is used in the ideation phase, for inspiration boards and also for final content creation. AI can reduce costs and time to create content and allow artists to scale and create works previously not possible.Artists will use AI to calculate royalties due for their works and those who are in business to sell their own works, for example, visual artists and self-published writers, will make increasing use of AI for tracking their own sales and inventory.Additionally, we know that some artists have used AI as a medium for their work, where the expression and presentation of AI output amounts to social commentary. In other words, the use of AI is a form of expression, and often a comment about AI, for example, as a reflection of bias in society.---------2. Text and Data Mining:If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?There should be no legislated exceptions to copyright for Text and Data Mining, which is unfortunately a misleading term, as the “mining” can include, among other things, visual art, photography, music, motion pictures, and so on. Any new exception introduced to the Copyright Act for TDM will negatively affect artists working in every discipline of the arts and likely have unintended consequences. As a safeguard against the likelihood of persons in the public being deceived by inaccurate, misleading, manipulative, fraudulent or false information and by deep fakes, legislation should require all displayed, published or made-available AI-generated content to be marked or labeled as “machine-generated” or “generated by artificial intelligence”.Another safeguard should be to require AI developers to develop AI tools that do not provide prompts to users of their systems that could recreate copyright works used as input, whether or not those works have been licensed for TDM use. Generative-AI developers and platforms as well as persons falsely claiming credit as author or other creator, entities falsely claiming to be the publisher or producer, and distributers that are aware of such fraud should be liable or share liability for copyright-infringing output, including the infringement of the author’s or the performer’s moral rights of attribution very likely to accompany infringement of their economic rights.Section 30.71 of the Copyright Act permitting temporary reproductions for technological processes should be amended to specifically exclude TDM, if not ruled out first by court decisions. Before any legislative change, the courts in Canada may decide that the current “fair dealing” exception to copyright permits some TDM with respect to copyright works. Since AI developers all have their own method of training AI models and these methods will likely continue to change as technology develops, the “fair dealing” analysis must be done on a case-by-case basis.Regulations for fair dealing specifically for TDM may seem premature right now, but will be needed sometime in future if some generative-AI developers and platforms treat this defence as a loophole and arbitrarily help themselves to the work of creators. Legislative amendment in 2012 that introduced the fair dealing exception for the purpose of “education” had an unforeseen severe impact on creators’ incomes as a result of the lack of a definition and the tempting broadness of what might be considered “fair”. Regulations for fair dealing specifically for TDM should provide a clear and narrow definition of any allowable dealing and should be sufficiently flexible to restrain expansion of TDM, as generative AI will continue in rapid flux.Unlike an amendment to the Copyright Act, regulations can be changed more easily as circumstances change. If the TDM issue is not resolved expeditiously and sufficiently by regulations on fair dealing under the Copyright Act or, alternatively, by regulations under the Artificial Intelligence and Data Act, which is currently under consideration by a committee of the House of Commons, collective licensing subject to negotiated licenses or a mandatory tariff for specific TDM uses would be appropriate.Collective licensing of TDM should be permissible in any case. Any exception for TDM is likely to lead to an increased number of infringements of copyright, and members or affiliates of collective societies may want their rights with respect to TDM to be handled by their collective society. However, a licence from a collective society should not preclude the possibility of direct licensing of TDM or litigation by an individual creator or other copyright owner or holder.  The proposed Artificial Intelligence and Data Act currently under consideration by Parliament unfortunately does not specifically address the very real probability of significant damage in the copyright landscape arising from generative AI’s potential scale of use, the severity of harm to creators, and the economic imbalance between high-impact AI systems and copyright owners and holders. Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?AI developers should certainly be required to keep and retain records of all works used to produce or “train” generative-AI models and to release this information promptly to allow public inspection as well as inspection and monitoring by authors, other creators and copyright owners or holders, whether or not in the context of a perceived or an alleged copyright infringement or tort (e.g., libel or slander, appropriation of personality rights or unjust enrichment).Without a requirement to both maintain and disclose records, it becomes extremely difficult or impossible for a rightsholder (as well as too expensive, probably even for a collective society representing many rightsholders) to find out whether their works were used to train the AI model and whether there has been an infringement of the copyright or a failure to seek a licence.What level of remuneration would be appropriate for the use of a given work in TDM activities?Fees should be negotiated by the generative-AI developers and platforms with copyright owners or holders, or with their collective societies, subject to arbitration if no licence is agreed or subject to a mandatory tariff determined by the Copyright Board.Criminal penalties for copyright infringement and, if opted for by a copyright owner or holder, the statutory civil damages for plaintiffs that are available need to be increased as the infringers or enablers of infringement are most likely large international technological corporations. Otherwise, the high costs of individual investigation and prosecution will make enforcement prohibitive.","What would more clarity around copyright and TDM in Canada mean for the AI industry and the creative industry?Clear information could decrease the amount of illegal reproduction of copyright works used for Text and Data Mining (TDM), which despite its label does not only include literary text but can also include, among other things, visual art, photography, music, motion pictures, and so on. The question of to what extent, and in what circumstances, dealing with pre-existing works is “fair dealing"", and therefore not infringing, is a live question in Canada.  So-called TDM activities not only leverage the works of the creative community to train AI, exploiting human ingenuity and originality and advantaging machine learning, but also compete with and threaten to displace the role of artists in society. Given the challenges to visual artists, literary authors and other creators making a living wage in the creative economy, there should be a reward that goes back to the creative community that reflects the economic value extracted from such use of works. To the extent that copyright protects works that are used to train AI, creators should be entitled to a just reward for use of their works. From this perspective, it should be absolutely clear that scraping copyright works for the purpose of TDM without authorization from copyright owners and holders whose works are used in generative AI is an infringement of copyright content created by artists working in all disciplines, including literary, artistic, dramatic and musical works, choreographic works, works displaying lyrics and musical notation, sound recordings of audio works, and performers’ performances (e.g., dance, songs and spoken words), and audiovisual works (e.g., motion pictures including animation) and interactive works  (ie.g., video games) that are derived from these and other works. Output from AI models that infringes the economic rights of a creator’s copyright is also likely to infringe their moral rights.Clarity on any fair dealing extending to TDM activity will be needed.  Ambiguity in the law tends to favour economic interests that can afford to test the waters.  In the face of ambiguity over whether fair dealing may extend to TDM activities, most members of Canada’s creative community would not have the resources, nor would they be prepared to risk the expense and time required to litigate the matter, knowing the result would be uncertain. Creators also hesitate to use AI-generated content as it exposes them to potential claims of infringing copyright material that they could not identify.Transparency is also desperately needed so creators will know what works were included in the datasets on which AI models have been “trained” (a common usage ironically implying human intelligence!) or programmed, and so creators will be able to monitor compliance if they have authorized TDM. Developers of AI models should be required to maintain detailed logs of the sources used to train the AI. These logs would allow creators to track the use of their works and ascertain that such use had been properly authorized. Another way to provide transparency would be to require AI output to include a list of the works that have been used in the making of that output, again allowing creators to monitor the use of their work and also to provide comfort when using AI-generated work themselves.Additionally, transparency is needed with respect to the use that AI technology will make of output as well as any content or instructions provided by creators. Creators need to know if any of their instructions regarding use will in turn be integrated into future datasets and output to be used by others. It would be problematic to introduce any new exceptions into the Copyright Act to deal with TDM or works made by generative AI in reliance on TDM. There is no one-size-fits-all model for how TDM works. Any exception introduced could have significant negative or unintended repercussions on the creative industries, some caused by the works of artists being falsely attributed to persons who did not create them including fake images and texts, sound and audiovisual recordings and other deceptively identified artistic expression purportedly by name artists (e.g., painters, photographers, poets and film directors) and some by works euphemistically in the “style of” name artists.Any exception for TDM is likely to lead to floods of machine-generated works, including some infringing works, that will compete with original copyright works created by human authors and their publishers and producers and distributed by broadcasters, wholesalers, retailers and other distributors. Resulting lower incomes for a great many artists in this confusing and overly competitive marketplace will cause many to give up professions which may already be marginal for them – now less viable for some as a result of the lockdowns of the COVID pandemic years. Are rightsholders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?Our experience communicating with artists working in all disciplines of the arts is that creator rightsholders generally don’t want to have their works used for Text and Data Mining and the development of generative-AI models, unless they could license their works for clearly specified purposes or uses, subject to compensation for making their works available for those purposes or uses. While there are a few examples of voluntary licensing initiatives having been introduced by AI developers, we have not seen instances where creators have accessed or used these systems. The flooding of cultural markets by millions of AI-generated works will impair the market for the original works of authors and performers and disincentivize human creators. It seems inevitable that most if not all creators would be discouraged and demotivated when AI-generated works appear to have filled the gap for a work on a particular subject, or if the plots of thinly disguised sequels to a novel or television series have been scooped for AI-generated content.  Fewer works by human creators will be successful in a crowded and confusing marketplace. AI-generated works that rely on TDM are not original works of human authorship and therefore should not be protected by copyright, which is indicative of ownership of original works.We observe that, in any case under existing law, AI-made works without the intellectual involvement of humans exercising their skill and judgment do not have the “originality” required for copyright as determined by the Supreme Court of Canada in a 2004 case. We note that, because of generative AI, it is our view that these criteria for original works should now additionally include a measure of creativity by a human author.Lack of transparency is also currently a challenge because if creators don’t know their works are being used for TDM, how can they engage in a licensing discussion with the AI developer.  To begin with, creators should know that TDM does not only use literary texts, and they should know or be able to find out easily if their literary, dramatic, musical, visual and other artistic works and other subject-matter have been subjected to TDM. They or copyright holders of their works, and ALAC as an organization, have little or no information about the content of the datasets now being used to make publications of text (e.g., print and audio books and software code) and images (e.g., prints and photographs), sound recordings (e.g., music and radio programs) and audiovisual recordings (e.g., motion pictures including animation) that will compete with the copyright works of human authors. They have no ability to monitor uses by AI developers and platforms, have little information about how much of this training of AI models may be making unauthorized use of copyright works (including works of their own) – other than from media reports about alleged infringements – or, if the use of copyright works is authorized, do not know whether the training includes their instructions for their content when developers instruct the AI to produce the output.Right now, even when the economic rights of copyright owners and holders are obviously infringed by AI-generated works that are derivative works substantially similar to the original work, the difficulty or near-impossibility of getting evidence of TDM and anyone’s liability remains a hurdle. In addition, copyright owners and holders are deterred by the formidable costs of endeavouring to investigate and prosecute such claims. It should consequently be the responsibility of AI developers to develop AI tools that will not provide prompts to users of their systems that could recreate copyright works used as input, whether or not those input works were licensed for permissible TDM. We also note that there is some discussion in the creative community around whether rights management information may be used in relation to TDM activities. It is premature to know what technical or other solutions may be appropriate, and further investigation into options is desirable prior to eventual amendment of copyright legislation. At this time, what is clear is that if an artist uses digital rights management information (“DRMI”) to indicate that a work may not be used for TDM activities, the DRMI notice must be respected, failing which copyright should be deemed infringed. However, creators of works must not be required to use DRMI in order to preclude or “opt-out” from use of their works in TDM activities or to safeguard their works from use in TDM without their permission.","Is the uncertainty surrounding authorship and ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies?The term “author” is not defined in the Copyright Act, but the legislative language and jurisprudence imply that “authors” are humans. Also undefined but implied, performers of performers’ performances must be human. Anyone can call themself an author or a performer regardless of whether or not they have created a copyright work or other copyright subject-matter. We submit, however, that it is not honest or ethical to do so for an AI-generated work.  This crosses a line into commercial deception of the public by trading on the public’s long-standing presumption of human authorship and the valuable goodwill associated with human authorship.More and more creators will use generative AI for research and many of them will create AI-assisted works, but generative-AI content without the intellectual involvement of human creators exercising skill and judgment (established as the criteria for original works by the 2004 decision of the Supreme Court of Canada) is not “original”.  As a result, there is no copyright protection for such AI-generated works, and this should not change. In the context of artificial intelligence, the criteria for assessing the originality of a work should clearly require creativity by a human author or other human creator.  AI-generated material lacking originality should not be protected by copyright and should not be permitted to display a copyright notice.We are of the view that AI-assisted works and other subject-matter should be protected by copyright, assuming originality, effective and verifiable human control, and appropriate attribution to their human authors and performers. An AI-assisted work may and would ordinarily display a copyright notice. There should, however, be a disclosure requirement that AI was used in generating the work.A significant concern with granting authorship of AI-generated works to owners of those works is that it could encourage bad actors to generate works for the sole purpose of eventually bringing claims against human creators for infringement. Given the near-endless works that such malicious persons could generate, these AI-created works could flood the market and compete directly with original works created by human authors and their publishers and producers as well with the broadcasters, wholesalers, retailers and other distributors of their works. This will have the adverse effect of creating confusion in the marketplace, driving down prices, and inhibiting human creators’ incentive to generate new works.It should be an offence for any person or entity, identifying themself as the owner, maker, publisher or author of an AI-generated work or other subject-matter without significant human intellectual involvement, including a measure of creativity (as we propose above) in addition to skill and judgment, to place a copyright notice on its publication.  A machine-made work or other subject-matter lacking originality should never be protected by copyright. Nor should AI-assisted work or other subject-matter be protected by copyright unless it contains substantial original material created by humans and unless its entire content is under effective and verifiable control of humans and at least one human is identified as its author or publisher.All owners of AI-generated and AI-assisted works should be liable for infringements of copyright and for torts (e.g., libel or slander, appropriation of personality rights or unjust enrichment), as should the developers involved in creating and training the AI model. Producing any AI-generated or AI-assisted work which imitates or mimicks the distinctive style of another writer could be viewed as an appropriation of personality rights.It is noteworthy that if an AI model is trained only on licensed works, and the licence addresses clearance for outputs that include similarities, the risks associated AI-generated and AI-assisted works would be materially reduced. Also, without transparency requirements, knowing whether an output is likely to have reproduced a substantial part of a prior work will be challenging. Infringements of the economic rights of copyright are also likely to be an infringement of a creator’s moral rights of attribution.An AI-assisted author should be liable or share liability, not just with respect to their own text, images and other changes (e.g., their edits, adaptations, additions and substitutions), but also because of the possibility that AI-generated material in the content of the work, unbeknownst to them, may infringe copyright or otherwise violate the rights of other authors. They may unwittingly incorporate AI-generated material that puts them at risk and they should ascertain that the use of all copyright works in datasets for TDM used to train models that they used have been authorized by the copyright owners or holders or are works in the public domain. For example, a scriptwriter who is engaged by a producer to revise a draft script made by generative AI should be cautious.Regulations should include an obligation to name or identify – and publish or display on every AI-generated publication or production – a responsible person or entity who will be liable in addition to any named and identifiable author or publisher of the publication or production.","What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?The biggest barrier will be the lack of information on the input of copyright works into an AI system if courts want evidence of TDM to establish access by the defendant despite general availability of a creator’s work in the marketplace or a public forum, as well as substantial similarity between it and allegedly infringing AI-generated material. This assessment of similarity will be subjective, may not be immediately obvious and will be hard to determine or adjudicate, particularly in the absence of information about input. Copying may occur on actual reproduction on input into an AI system or may result from ordering of output words and images by an algorithm.There should be an obligation to keep and retain records of all copyright material input into an AI system and to make them fully available for monitoring by rightsholders and their collective societies.  Prior to any legal requirement by legislation or regulation, Government should ask AI developers to do this on a voluntary basis. Knowledge or awareness of infringement or use of TDM without rightsholder consent should be presumed in law if AI developers or users of their AI tools fail to keep records and comply with other regulations.Should there be greater clarity on where liability lies when AI-generated works infringe existing copyright-protected works?AI developers and platforms and those claiming authorship and identifying as publishers and producers of an AI-generated work in publications and productions as well as distributors that are aware of such fraudulent claims and identification should be liable or share liability for infringing copyright works. The apportionment of liability should be determined by the courts on a case-by-case basis.","Artists and Lawyers for the Advancement of Creativity (ALAC), a non-profit corporation operated by volunteer entertainment and intellectual property lawyers, creators and law students, that among other activities, facilitates and co-ordinates a pro bono legal clinic for artists. This legal clinic, founded in 1986 and long known as ALAS (Artists’ Legal Advice Services), provides summary legal advice to artists working in all disciplines of the arts and to arts organizations offering services to artists and other creators, mostly unable to access more expensive alternatives.Since its incorporation in 1991, ALAC has facilitated and coordinated the ALAS legal clinic, where volunteer lawyers have provided summary legal advice at the ALAS legal clinic to artists and other creators in all arts disciplines and to arts organizations offering services to artists since it first began in 1986 – over 37 years ago. In addition to continuing the ALAS legal clinic, ALAC provides educational sessions focused on different areas of law and art, in which industry and legal experts provide artists with information and guidance. Additionally, we offer legal resources that provide summary information on legal topics that are relevant to creators, currently available at the website (alasontario.ca).  Over the past several years, we have seen first-hand the legal challenges that have emerged from AI, both from a creator and user perspective. Ever since the launch of Chat GPT and Dall-E, for example, there has been a significant increase in the number of artists attending the ALAS legal clinic with questions about AI. Furthermore, our educational sessions devoted to AI have been the most popular sessions we have ever had. Creators are both excited and nervous about the future of AI.We understand the need for Government policy to preserve the balance between supporting innovation and investment in AI as it positively and negatively affects the creative sector and preserving the incentive for human authors and other human creators in all arts disciplines to create. ALAC welcomes the opportunity provided by this Consultation to make our comments and suggestions: As AI continues to develop at an amazing speed, it is our view that it is premature right now for Parliament to pass any copyright legislation with respect to generative-AI systems unless it becomes necessary to curb abuses of Text and Data Mining (TDM) immediately. Perhaps with slight amendments to the Artificial Intelligence and Data Act, currently under consideration by a House of Commons Committee, regulation of AI-generated works to curb abuses of TDM could be accomplished well prior to any amendments to the Copyright Act, which would likely be quickly outdated by further AI developments in Canada and elsewhere. It may be that some use of TDM and resulting AI-generated output will be accepted by courts, perhaps as “fair dealing”, and this may suffice for the time being to deal with AI until it becomes necessary to set parameters on fair dealing, preferably by regulation in order to remain flexible. Section 30.71 of the Copyright Act permitting temporary reproductions for technological processes should eventually be amended to specifically exclude TDM.Authors and other creators of copyright works or other subject-matter or, if authorized, their publishers, producers or collective societies, should be able to choose to license AI developers for TDM for specific purposes and uses, subject to negotiated limitations on use, fees, record-keeping and other conditions negotiated with generative-AI developers and platforms.There should be no exceptions to the Copyright Act to accommodate developers of generative-AI and platforms. Exceptions would encourage more use of entirely AI-generated works that would substitute for, compete with, and impair the market for original copyright works created by the skill and judgment of human authors as well as, in our opinion, their creativity, including original AI-assisted works. What is desperately needed right now – prior to any eventual amendments to the Copyright Act – is much more information and transparency about any AI systems being used to generate published materials including the sources of the data relied on for content. This information should be easily available to rightsholders and the public, not just in case of alleged copyright infringement but in any case. Creators and users of AI systems should be entitled to know what has been included in the datasets on which AI models have been “trained” and to be able to monitor compliance if they have authorized TDM. Furthermore, AI developers should develop generative-AI tools that will not provide prompts to users of their systems that could recreate copyright works used as input or deliberately imitate the style of specifically named human authors.AI developers as well as generative-AI platforms and credited publishers and producers of AI works as well as individuals to whom authorship of such AI work is attributed should clearly label all generative-AI work as machine-generated and should be liable or share liability for infringing output. It should be an offence for any person or entity, identifying itself as the maker, publisher or author of an AI-generated work without significant human intellectual involvement including a measure of creativity, to place a copyright notice on its publication or production. Penalties for copyright infringement and statutory damages available to plaintiffs should be increased as the infringers or enablers of infringement are most likely to be large international technological corporations.To recognize copyright in AI-generated works without originality due to human skill, judgment and creativity and without effective and verifiable human control would disrespect authors, performers and other artists working in all disciplines of the arts, demean their professions, reduce incomes and force some to look for other careers, as well as reduce the number of jobs generally in the cultural sector of the Canadian economy.  This would be a devastating loss to Canadian culture, economy, and society.Parliament should not jump prematurely to enact copyright legislation on AI in this extraordinarily disruptive time before Canadian society gets accustomed to generative AI and the inevitable huge change to Canadian culture. There should be certainty that any changes to the Copyright Act will be compatible, to the extent reasonably possible, with the copyright laws of Canada’s main trading partners, particularly the United States, the United Kingdom and the European Union, as well as former colonies of countries with compatible laws.  Technological progress of artificial intelligence is applaudable, and we marvel at the text, images and sound that can be produced by generative AI and recognize that AI-generated material can have great value if used responsibly in appropriate contexts, but it should not encroach on human authorship and societal values.  Paragraph 2 of Article 27 of the Universal Declaration of Human Rights reminds us that “Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author.” It should not be forgotten that our Copyright Act is based on human authorship including the sole rights vested in authors set out in Section 3 and that any exception from copyright with respect to AI must pass the 3-step test in Article 9(2) of the Berne Convention for the Protection of Literary and Artistic Works, echoed in the WIPO Copyright Treaty, the WIPO Performances and Phonograms Treaty and in the Canada-US-Mexico Agreement, providing that copyright exceptions must not “unreasonably prejudice the legitimate interests of the author.”"
Canadian Copyright Institute (CCI),Non-profit / Think Tank,"Technical EvidenceAI is currently in use by authors and publishers in the book and periodical industry for research and review and for routine tasks such as checking spelling and grammar in a manuscript for publication or tracking inventory and sales. AI is used by some authors for generating scenarios or drafts, and by some non-author users to generate full texts. It is used by some publishers for generating marketing copy, or for drafting alternative text descriptions of images for use in accessible ebook publishing.","Text and Data MiningClarification is needed for both understanding and compliance. TDM without authorization from copyright owners and holders whose works are used is a misappropriation of copyright content created by authors. An exception in the Copyright Act for TDM or for works made by AI in reliance on TDM will lead to a flooding of the market for books, magazines and images of works of art by a massive number of machine-generated works that will compete with original works created by human authors and their publishers, reduce their incomes, put some of them out of business and cause others to leave their profession.As an organization, CCI has no direct or specific knowledge of the pirated content of the datasets being used in the process of making publications that will compete with the original works of human authors, but we do know that many rightsholders do not want to license their works for this purpose or to be complicit in encouraging AI developers and platforms that may simply want rightsholder licences as an insurance policy to reduce the risks of making models that spew out machine-made works in reliance on the published copyright works of human authors. Such works without the intellectual involvement of humans exercising their skill and judgment do not have the “originality” required for copyright protection (as delineated by the Supreme Court of Canada) and will impair the market for original works. If the rights of copyright owners and holders and author’s moral rights are apparently infringed by such AI-generated works, there will likely be little they can do to establish anyone’s liability, quite apart from being deterred by formidable costs of endeavouring to do so. It should be the responsibility of AI developers to develop AI tools that will not allow prompts by users of their systems that could recreate copyright works used as input, whether or not those input works have been licensed for use in TDM.There should not be a legislated exception to copyright specifically for TDM. Regulations for setting limits on TDM as fair dealing would be premature, but at some point they may be needed.TDM for AI development should be permitted only if specifically licensed by rightsholders under direct or collective licences. In the absence of negotiated licences, rightsholders should have the option to apply through the Copyright Board for mandatory tariffs that are subject to arbitration by the Board. AI developers should be required to develop AI tools prohibiting prompts by users of their models that might recreate copyright material used as input for their AI systems, and AI developers as well as AI platforms, any credited publisher and any persons to whom authorship is attributed should be liable or share liability for infringing output. Although many members and affiliates of collective societies will likely prefer their rights with respect to TDM to be handled by a collective society, a licence from a collective society should not preclude the possibility of direct licensing by an individual copyright owner or holder. As a safeguard against inaccurate, misleading, manipulative or false information and deep fakes, all published AI-generated content should be labelled as “machine-generated” or “generated by artificial intelligence”. Section 30.71 of the Copyright Act permitting temporary reproductions for technological processes should be amended to specifically exclude TDM if not ruled out earlier by court decisions.AI developers should be required to keep records of all works used to produce or “train” generative-AI models and to release this information promptly to allow public inspection in addition to monitoring by copyright owners or holders, whether or not alleging infringement.Lack of transparency around what works are used to train generative-AI models also increases the likelihood of infringing authors’ moral right of attribution.Fees should be negotiated by the AI platforms and copyright owners or holders or by collective societies which they have voluntarily joined or with which they have voluntarily affiliated. In the absence of negotiated licences, rightsholders should have the option to apply to the Copyright Board for mandatory tariffs that are subject to arbitration by the Board.Criminal penalties for copyright infringement and the statutory damages for plaintiffs that are available if opted for by a copyright owner or holder, need to be increased as the infringers or enablers of infringement are most likely to be very large international technological corporations.","Authorship and Ownership of Works Generated by AINeither the user of a generative-AI model nor its AI owner should be treated as an author protected by copyright because a machine-made work lacks the originality without which there is no copyright work.An AI-generated work should not be protected by copyright. Nor should an AI-assisted work be protected by copyright unless under effective and verifiable human control by a named author and publisher. An AI-assisted work may have a copyright notice, but if published anonymously, pseudonymously or under a pen name, it should be published under an identifiable publisher’s imprint or under the name of an identifiable individual or entity prepared to accept liability if there is an infringement of copyright or if another issue arises, such as libel, invasion of privacy, breach of personality rights or unjust enrichment. Imitating or mimicking the distinctive style of another writer could be viewed as an appropriation of personality rights. Regulations should include an obligation to name or identify – and publish on every AI-generated publication – a responsible person or entity if liability should fall to anyone other than or in addition to a named author and publisher of the publication.","Infringement and Liability regarding AILack of information on the input of copyright works into an AI system is a huge barrier to establishing the access considered necessary by courts to prove the infringement of a work in addition to necessarily subjective assessment of observable substantial similarity between it and infringing AI-generated material – whether there was an actual reproduction of the copyright work or whether the order of words or images in the AI-generated work was predicted by an algorithm. There should be an obligation to keep records of input into an AI system and to make them available promptly for public inspection and for monitoring by rightsholders. These obligations could be required by regulations, which should ideally also state that knowledge or intent to cause harm may be presumed if AI developers or users of their AI tools fail to comply with the regulations.AI developers and platforms and those claiming to be authors and publishers of an AI-generated work should be liable and bear liability for infringing copyright works.","Comments and SuggestionsThe Canadian Copyright Institute (“CCI”), founded in 1965, a non-profit association of organizations and individuals comprising creators, publishers and distributors of copyright works with an interest in copyright law, observes and submits as follows:Technology related to artificial intelligence worldwide will likely continue to develop at an astonishing speed. Consequently it is the view of CCI that it is premature to pass any new copyright legislation with respect to AI systems. No legislation or regulation is needed to clarify that authorization from rightsholders is required prior to any scanning of works into an AI system, except that it may become necessary to put regulatory parameters on “fair dealing” for TDM. Instead of copyright law continuing, as it has historically since the enactment of the Statute of Anne in 1709, in the British Parliament, to reward human authors for their work and provide an incentive for them to create more works, recognition of copyright in AI-generated works without effective and verifiable human control would disrespect human authors and their publishers and demean their professions as well as reduce incomes in the book and periodical sector of the Canadian economy and put some workers out of work. To legislate change to this basic assumption of human authorship of copyright works would bring a huge cultural shift. AI output of text and images that do not result from authors exercising human skill and judgment should never be protected by copyright.What is needed right now – prior to eventual amendments to the Copyright Act – is much more information and transparency about any AI systems being used to generate materials including the sources of the data relied on for content. This information must be easily available, not just in case of alleged copyright infringement but in any case. There should be no exceptions now to copyright to accommodate developers of AI and generative-AI platforms. Any legislated exception would encourage more use of entirely AI-generated works that would substitute for, compete with and impair the market for original copyright works created by the skill and judgment of human authors, as well as their creativity and labour, including AI-assisted works.Parliament should not jump prematurely to enact copyright legislation on AI, before there is certainty that it will be compatible, to the extent reasonably possible, with the copyright laws of Canada’s main trading partners, particularly the United States, Europe, the United Kingdom, as well as former colonies of countries with compatible laws.Regulations – and any eventual copyright legislation – should require users of AI systems to state on their publications that all or part of the content has been generated by AI and that authorization has been obtained from rightsholders for input material obtained by TDM. In case an author who has made some use of AI wants to be in a good position to defend, as fair dealing, a potential claim of copyright infringement, they may be well-advised to include on their published work any relevant source and, if in the source, the name of the author.In this continuing extraordinarily disruptive period as Canadian society gets accustomed to generative AI, and as the book and periodical industry accustoms itself to modified practices within the book and periodical sector, it should be remembered that the Copyright Act is based on human authorship including the sole rights vested in authors set out in Section 3.Article 9(1) of the Berne Convention for the Protection of Literary and Artistic Works states that authors “shall have the exclusive right of authorizing reproduction of their works in any manner or form.” Any exception must pass the 3-step test in Article 9(2) for exceptions and, certainly, any exception allowing use of generated-AI material derived from authors’ works without authorization will “unreasonably prejudice the legitimate interests of the author” and violate that test for exceptions. The 3-step test is also included in the WIPO Copyright Treaty and in the Canada-US-Mexico Agreement.We should not lose sight of the potentially devastating impact of generative AI on the creative community comprising authors, their publishers and other workers in the book and periodical industry and of how authors’ works benefit those who enjoy, learn from or rely on those works in any way – nor lose sight of how the consumers of some AI-generated materials may be misinformed, misled, deceived, manipulated or otherwise adversely affected. While we marvel at the text and images that can be produced by generative AI and recognize that AI-generated material can have great value if used responsibly in appropriate contexts, let’s not allow use of AI to encroach on respect for human authorship – as expressed in paragraph 2 of Article 27 of the Universal Declaration of Human Rights: “Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author.”"
Council of Canadian Innovators,Non-profit / Think Tank,The Council of Canadian Innovators does not work directly to develop AI products and services or use them such that we actively use training datasets.,"The use of large amounts of training data is essential to producing viable artificial intelligence and machine-learning (AI/ML)-based products and services. In some but not all cases, data are drawn from publicly available sources, including on the open internet.At the technical level, how text- and data-mining (TDM) activities provide algorithmic models with training data is widely misunderstood to involve the storage and repeated reading and ‘copying’ of data by algorithms from a database of materials used in training. Most such activities do not work in this way and could plausibly be said to fall under the scope of fair dealing. It is also important to note that some proposals, including that AI training be restricted to data in the public domain, would only increase the likelihood of biased outputs due to the significant age of many such materials, as well as make AI-powered products and services less useful to end users.Clarity and guidance in establishing which text- and data-mining activities and practices fall within the scope of fair dealing, temporary reproductions or similar clauses could increase certainty for investors. With that said, AI is a broad family of technologies and care should be taken to ensure that regulation, clarification or other interventions into the marketplace treat the technology and the copyright regime holistically and especially do not serve to bring Canada’s existing AI governance regime out of overall alignment and compatibility with jurisdictions like the United States and the European Union.With regard to obligatory recording and disclosure of the use of copyrighted materials in TDM work, this would create a very high burden on smaller, innovative companies and restrict access to AI training at scale to large, established and mostly multinational players. This would seriously hamper the potential of Canadian companies to scale significantly, particularly if such requirements brought Canada as a jurisdiction out of regulatory alignment with peer countries.Given the emergence of opt-outs from inclusion in training data sets and other mechanisms in this market to respond to the concerns of copyright owners, as well as ongoing efforts to more broadly regulate AI technologies in Canada and abroad, Canada’s innovators feel that it would be premature for government to do more than offer guidance regarding copyright at this stage and to let the market mature, and then allow more specialized regulatory bodies like the proposed AI and Data Commissioner to re-examine the issue in more detail at a future date.","The policy space governing works created using AI tools and authorship is still in its infancy, and Canada’s innovators wish to indicate that comments here are of a prefatory nature and could evolve as the space matures.Given that AI tools are not persons, the assigning of authorship for copyright purposes to works created using AI to the AI tool itself is (given the current state of technology) nonsensical. AI tools should be considered for the purpose of authorship and copyright as equivalent to other software tools used in creative endeavours, such as Adobe’s Photoshop. These tools enable the creation of creative output, and many incorporate AI/ML tools within their suite of options for users, but still rely on human creativity and talent.Similarly, ‘prompt engineering’ for generative AI tools could be considered comparable to human inputs in other design and creative software for the purposes of determining authorship. The difference in using a natural-language interface in the form of text prompts with an algorithmic tool to edit or create an image or text and using a stylus, mouse or keyboard to do the same is fundamentally not a difference that should matter unduly to a technology-neutral framework like the Copyright Act.This is an area that would benefit primarily from clarification as case law evolves rather than active attempts to change legislation. From the point of view of Canada’s innovators, given that digital software in the use of creative industries, including the use of AI/ML tools and products, is not fundamentally new, the current law is adequate to meeting the challenge of governing generative AI tools and services.","As discussed above, Canada’s innovators believe that AI tools in a copyright context are best considered in comparison to other software tools used in creative endeavours, such as text, video or photo editing software. As also discussed above, itemizing training data would be prohibitive for all but the biggest companies, and in any case would not actually serve to enhance copyright protection since AI models’ interaction with training data is best understood as fair dealing or as a temporary reproduction. If users are using software tools to facilitate the infringement of copyright, the responsibility for infringement rests with users rather than the developer of the tool.",N/A
Goodbot Society,Non-profit / Think Tank,N/A,"Clarity on regulatory requirements on copyright and TDM in Canada can allow the AI and creative industries to develop and implement practices that account for the interests of the public and end users. TDM activities are conducted widely in Canada in the public and private sectors. Applications are broad and can impact end users in many critical ways.In the public sector, law enforcement, health organizations, research institutions and nonprofits engage in data mining and analysis using TDM to generate insights and inform decision making on a range of issues. See Palantir's contract with Defense http://tinyurl.com/mtstbp42; the OPP's use of Palantir http://tinyurl.com/5h22wren; the Canadian military's data mining of social media http://tinyurl.com/5xyzyyza; PHAC's mining of social media http://tinyurl.com/2vdnfu9c; data mining by universities and nonprofits including Population Data BC http://tinyurl.com/4hzee8a4, Cybera https://tinyurl.com/3uenysvb, University of Toronto http://tinyurl.com/bpn62ks3 and University of Waterloo http://tinyurl.com/4f7cwmzd.In the private sector, companies collect and use data about customers to generate insights into consumer behaviour, while data brokers collect and use data to generate insights that are sold to other companies. See Loblaws http://tinyurl.com/4t7vxhsh and Canadian Internet Policy and Public Interest Clinic's draft report on Canada's data brokerage industry http://tinyurl.com/23uarcup.Unfortunately, resources that support TDM activities and their products are often not freely available to the public. Archives of academic research, legal information, financial information and news are typically paywalled and available only through a few major publishers, with little competition. Market dominance allows publishers to bargain for licensing and assignment rights that perpetuate monopolies over information. Sarah Lamden's book Data Cartels (Stanford University Press, 2022) describes the monopolization of information by US companies such as RELX and Thomson Reuters, while Tim Ribaric notes similar trends in Canada http://tinyurl.com/2razce4u. Major publishers often use this data to perform TDM to generate insights which are sold to other companies (see Data Cartels, and LexisNexis' Canadian websites, such as Intelligize http://tinyurl.com/4t649y78).In addition, the largest data mining companies typically serve only large clients such as corporations, universities, law enforcement, and governments (see websites of the largest data mining companies http://tinyurl.com/yc8d3fva for primary customers.) Copyright Act supports copyright over code and data compilations that meet the test of originality (see synopsis of the Federal Court of Appeal's decision in 2017 FCA 236, on database copyright http://tinyurl.com/3rjwpff2) and is likely to be used by companies to protect products in ways that severely limit end users' access.Even for organizations that can afford TDM services, licenses are expensive, sometimes costing millions for a single archive (Data Cartels). Even then, licences do not necessarily provide end users with desired access to conduct TDM (e.g. formatted data, data analysis outside TDM vendor environments).TDM services are typically fee-based licenses that provide to access to (See Peter McCracken and Emma Raub http://tinyurl.com/mwrmpk4s)1. copyrighted data made available by a vendor in formats amenable to TDM activities2. data that a vendor has copyright in and that can be downloaded for use in TDM activities in any environment, but which is not necessarily formatted for TDM3. third-party copyrighted data aggregated by a vendor, where end users can perform TDM activities using copyrighted data that must be performed within a vendor's environment due to restrictions from third-party copyright holders, and4. proprietary data formatted by the TDM vendor where data can only be accessed and TDM activity can only be performed within a vendor environment.The latter two licenses are predominantly described in literature and by virtue of creating closed TDM ecosystems, they limit the scope of TDM activities that can be performed.To protect the end user's interests, Canada should amend Copyright Act to clarify the scope of permissible TDM activities and the safeguards that should be in place. In doing so, Canada should consider how to address following concerns:- AI systems should be transparent. AI developers should be obligated to both keep records of and disclose what copyright-protected content is used in training AI systems. Moreover, end users should be able to access and review sources relied on by generative AI models such as chatbots.- Products intended for TDM activities involving personal information or products created by performing TDM on data including personal information, should be strictly regulated in terms of the copyright protections extended to creators. Serious consideration should be made on whether it is consistent with public interest to profit off products using personal information (PI) at all, even if PI is deidentified or anonymized.- Copyright laws that specifically regulate databases are required. At present, the Copyright Act protects databases independently created by the author and that display a threshold minimum degree of skill, judgment and labour in its overall selection or arrangement. However, this threshold minimum is unclear. Given databases are crucial for performing TDM activities and require intensive resources to maintain, economic incentives, such as those provided by copyright, to maintain databases may be required; however, economic incentives must be balanced with the need for information to remain a public resource. Copyright Act should be amended to provide guidance on when a database will be subject to protection to ensure copyright cannot be used to limit end users' access to databases that are not truly entitled to copyright protection.- Copyright Act does not enshrine access to copyrighted materials for public purpose as a policy goal but Canada has an obligation to ensure copyright does not stymie flows of information in the public interest. For example, while fair dealing currently places the burden of proof on end users to prove they did not infringe copyright, Copyright Act should grant explicit end-user rights to use copyrighted material for permitted purposes (e.g. research, policy-making).- Copyright law should preserve and protect information as a public resource. This should encompass an explicit set of end-user purposes which include research, teaching and disseminating current affairs. It should also include the ability to understand and challenge automated/AI-enabled decisions made by organizations that can substantially impact lived experiences of end users, such as access or denial to resources and services. As such, all academic research, legal, financial information and news should be made readily available to end users, without requiring prohibitive cost or effort.- Even if Canada does not agree that Copyright Act should explicitly protect information as a public resource, end users should have a right to access, without cost, copyrighted materials used in TDM acivities and AI-enabed decision tools that impact end users, including to remedy harms. A right to access is distinct from a fair dealing exception which does not guarantee access to copyrighted materials and instead places the burden on end users to prove they accessed copyrighted materials for a purpose protected by fair dealing. When it comes to understanding and challenging AI-facilitated decision-making processes about themselves, an end user should not have to worry about, first, how they can access the copyrighted materials used in that decision-making, and second, whether they are complying with copyright laws when it comes to accessing those materials. (See article on federal government guidelines on use of AI by employees on critical concerns: http://tinyurl.com/3dhnw7sd)- Different classes of creators have differing interests, levels of bargaining power, and different classes of works, but copyright laws do not distinguish between these creator classes or and works. Consideration should be given as to whether current assignment and licensing regimes adequately balance and protects all classes of creators (e.g. authors vs a publishing conglomerate) and adequately balances public interest in free flow of information (e.g. should assignment and licensing terms be solely determined by negotiations between the copyright owner and the assignee/licensee or should there be mandated considerations in those negotiations, such as sufficient public access), and whether the same copyright protections should extend to all classes of works (e.g. should research papers be subject to the same length of copyright as a novel).- Copyright law should work in tandem with other areas of law such as patent, privacy, competition and contract law to protect and preserve information as a public resource.As Canada considers copyright and TDM policy, discussions in the US and EU are instructive.1. The EU Database Protection Directive is instructive in terms of how not to balance economic incentives for database creation and maintenance with public access, having led to overprotection of databases (see Pamela Andanda http://tinyurl.com/a84vy9sv and David Freedman http://tinyurl.com/rcrj729n).2. Both the US and EU have created exceptions to copyright law for TDM performed for the purpose of scholarly research and teaching and for scientific research, respectively. Exceptions are listed in the US under the Digital Millenium Copyright Act (DMCA) and in the EU's Directive on Copyright in the Digital Single Market (see Authors' Alliance petition to Library of Congress on renewing DCMA exemptions http://tinyurl.com/2xvyrwaw and Thomas Margoni and Martin Kretschmer work on the EU's Directive http://tinyurl.com/23nakewm).","GoodBot submits that the Canadian copyright ownership and authorship regimes in respect of AI-assisted or AI-generated works lack clarity. This lack of clarity results in uncertainty and risk for an end user who is consuming and using such works.Clarification is required at both the legislative level in the Copyright Act and in Copyright Office procedure. Both copyright authorship and ownership should be restricted to natural persons, and artificial intelligence (AI) is characterised as a tool that supports the creative process of such a natural person.The copyright regime is designed to protect copyright owners while promoting creativity and the orderly exchange of ideas (http://tinyurl.com/ypcyb8z5). This is an incentive structure suited for human behaviour and should be limited to natural persons. Since AI, as a tool embodied in a machine or software, cannot be incentivized in the same manner as a human, it is therefore not reasonable to allow AI to be copyright authors or owners.To give context to the discussion below, it is important to distinguish between copyright authorship and ownership. Subject to the exceptions provided within the Copyright Act, the author of a work is generally the first owner of the copyright, although copyright ownership is assignable (Copyright Act, s. 13). While the Copyright Act does not define ""author"" specifically, the term generally refers to the person who created the work, or the person who first put it in a fixed form (Gould Estate v Stoddart Publishing Co Ltd (1998), 39 OR 555 (Ont CA)). The Copyright Act already alludes to the concept of authorship being tied to a natural person, given that the Act ties the term of copyright protection to the life and death of an author (Copyright Act, s. 23), and Canadian courts have interpreted this as meaning that an author must be a natural person or human being (See for example P.S. Knight Co Ltd v Canadian Standards Association, 2018 FCA 222, at para 147; Setanta Sport Limited v 2049630 Ontario Inc (Verde Minho Tapas & Lounge), 2007 FC 899, at para 4). Under the Copyright Act, copyright protects ""original"" expression (Copyright Act, s. 5). To be an original expression or original work, the work must be an exercise of an author's skill and judgment in expression of their ideas (CCH Canadian Ltd v Law Society of Upper Canada, 2004 SCC 13).To restrict copyright authorship to a natural person, the definition of ""original"" work in section 5 of the Copyright Act should be amended to define the nature and extent of human input or contribution required for a work to be ""original"" – namely, that an ""author"" must be a natural person or human being – thus reinforcing the notion at case law that the skill and judgment required in creating the work must be exercised by a natural person.By restricting copyright authorship to a natural person, a question that must be addressed is what nature or quality of human contribution is required for copyright authorship. For example, do the human contributions of the creator of an AI tool contribute to authorship? Does the human user of AI perform authorship in creating a work?GoodBot is of the view that characterising AI as a tool can provide a helpful starting point for determining the quality of human contribution required for copyright authorship (for example, the US District Court (for the District of Columbia) has referred to the use of AI by artists ""in their toolbox"", see Stephen Thaler v. Shira Perlmutter and The United States Copyright Office (1:22-cv-01564) http://tinyurl.com/2496aatk). By characterising AI as a tool, the human creator of the AI tool is not a part of the creative process of creating an original work, and thus is not an author of the original work. Copyright authorship in an AI-assisted work would thus fall with the AI user who creates the original work.Copyright authorship not being available to the creator of an AI tool provides a clear benefit to the end-user – these works being free from copyright allows for them to be freely used and reused by anyone. This is in contrast to an unfair monopoly that would result from the creator of an AI tool having ownership in every piece of work produced using that AI tool. The copyright lies with the user, namely, the author who used the AI to create the work.In the US, the District Court held that the US Copyright Act requires human authorship and therefore only protects works of ""human creation"" (Stephen Thaler v. Shira Perlmutter and The United States Copyright Office (1:22-cv-01564) http://tinyurl.com/2496aatk).In Europe, a work can be copyrighted if the work is the ""author's own intellectual creation"" (Copyright Directive (2001/29/EC), as interpreted by a number of Court of Justice of the European Union (CJEU) cases starting with Infopaq in 2009 http://tinyurl.com/yeyb2nkp). While not harmonized under the current EU copyright framework (EU copyright law nowhere expressly states that copyright requires a human creator), it is generally understood by commentators that some level of human contribution is required for copyright authorship (See, for example, Hugenholtz, P.B., Quintais, J.P. Copyright and Artificial Creation: Does EU Copyright Law Protect AI-Assisted Output?. IIC 52, 1190–1216 (2021). http://tinyurl.com/ymn8nskz).With respect to the quantity of human contribution that is required for copyright authorship, the extent of human input that is necessary to rise to the level of authorship needs to be clearly defined, allowing for a distinction to be made between work that is ""AI-assisted"", containing both human and AI-generated contributions, and ""AI-generated"" work that is wholly created by an AI tool.In the US, the US Copyright Office has issued guidance indicating that for those seeking registration of their copyrighted works, any more than a ""de minimis"" amount of AI-generated content in the work must be disclosed and disclaimed, and thus, excluded from copyright registration (Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence http://tinyurl.com/3ru54v65). At the time of writing, however, it is not clear how much human contribution or authorship is required for copyright registration in the US, nor has a clear standard been defined for a ""de minimis"" amount of AI-generated content.The US Copyright Office has held that entering a series of prompts into an AI system does not make someone an author (Letter from the Copyright Review Board to Tamara Pester, Esq., (5 Sep 2023) ""Second Request for Reconsideration for Refusal to Register Théâtre D'opéra Spatial SR #1-11743923581 http://tinyurl.com/e75bsdte).By contrast, in China, a recent Beijing Internet Court decision indicates that prompt engineering, parameter setting and output selection of a generative AI system require originality of the author, and therefore the work resulting from such intellectual input is subject to copyright protection (China's First Case on Copyrightability of AI-Generated Picture, Seagull Song http://tinyurl.com/4sfrvnw7).In Canada, while a copyrightable work is protected by copyright laws the moment it is created and fixed in a material form, copyright may be formally registered at the Canadian Copyright Office.The copyright registration process by the Canadian Copyright Office requires more oversight, and more substantive review, at least of authorship. Oversight of copyright authorship could be facilitated by a duty on the applicant to disclose to the Office the presence of any AI-generated content in the work, in a similar manner to the requirement in the US Copyright Office where applicants have a duty to disclose the inclusion of AI-generated content in a work submitted for registration and to provide a brief explanation of the human author's contributions to the work (Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence http://tinyurl.com/3ru54v65).The Canadian Copyright Office has granted copyright registration for a work in which a natural person and AI system were listed as co-authors (Canadian Copyright Registration No. 1188619, ""SURYAST"" http://tinyurl.com/33hxuf4j). Since the registration is not substantively reviewed, this result creates confusion in the standard for authorship. In the long term, a lack of substantive review of copyright registration can lead to inconsistency as between the Copyright Office and case law that may need to be resolved in the courts, and ultimately a lack of public confidence in the copyright regime. Canada's copyright policy – including Copyright Office directives – should be consistent and explicit in allowing exclusively natural persons to be listed as authors which achieves a nonexplicit intent of disallowing AI tools to be authors.","Under the existing legal test for copyright infringement, Canadian courts analyze whether the alleged work is similar to at least the substantial part of the copyrighted work (Techno-Pieux Inc v Techno Piles Inc, 2023 FC 581). The court will analyze the copyrighted work as a whole and in particular if the author's skills and judgement resulted in original work. The court also states that ""original work"" has a lower standard than novelty and uniqueness but still needs skills and judgement. Canadian Intellectual Property Office has approved certain copyright applications when AI is a co-author and the human author has exercised skills and judgement in creating a work, however, the substantiveness of the copyright claim has not been examined (See, for example ""SURYAST"" by Ankit Sahni, Canadian Copyright Database, 1188619, 1 Dec 2021, http://tinyurl.com/33hxuf4j).While Canada has not released its opinion regarding the copyright infringement of AI generated works, other jurisdictions may provide some guidance regarding the Canadian approach.ChinaChina recently passed an official regulation relating to AI and intellectual property right infringements (Cyberspace Administration of China, Measures for the Management of Generative Artificial Intelligence Services, Jul 13, 2023, http://tinyurl.com/3cywpsve [in Chinese] English translation for draft version http://tinyurl.com/y92xsa54). The Measures include liability on the AI content provider, requiring them to respect lawful rights of other persons and have a duty to prevent IP infringement under Article 4.5. Furthermore, AI content providers are required under Article 13 to stop or suspend the generation of right-infringing content if they receive complaints or realize that the content may be violating intellectual property rights. Article 15 also requires the AI content provider to optimize the training models to prevent the recurrence of right-infringing content within 90 days of discovering the infringement or receiving a complaint.The Chinese approach likely is based on the rationale that AI developers have direct knowledge of the datasets used to produce the AI-generated results. In contrast, AI platform users generally do not have access to the raw AI model training data. Interestingly, this approach does not waive or indemnify users for creating and using the AI because users can be jointly liable along with AI developers for copyright infringement under the Chinese law.JapanThe Japanese Government takes a position to separate the infringement issues into two parts: (1) infringement occurred during training and development of the AI, and (2) infringement occurred during the generation and output of AI using trained or untrained data.For the first type of infringement, according to Fukuoka, Japanese copyright law provides a high degree of flexibility when companies use copyrighted materials for model training under the data analysis exception as long as the purpose is ""not to enjoy the ideas or sentiment expressed in the work"" (See Shinnosuke Fukuoka et al., ""Legal Issues in Generative AI under Japanese Law – Copyright"", Jul 11 2023, page 3, http://tinyurl.com/4urycmdx). Consent is generally not needed if the exception applies. However, consent may still be necessary when copyright holders' interests are unreasonably impaired. However, the Japanese law does not provide a clear definition regarding unreasonably impaired for training and other AI uses.At the generation stage, infringement can occur when the generated content ends up similar to a copyrighted work, especially when the training relies on AI models trained by the copyrighted work. Fukuoka suggests companies may not rely on data analysis to escape their legal liabilities.SingaporeSimilar to Japan, Singapore's Intellectual Property Office (SIPO) prohibits AI companies from using copyrighted work without permission for purposes not covered by data analysis exceptions (See Intellectual Property Office of Singapore, ""COPYRIGHT FACTSHEET ON COPYRIGHT ACT 2021"", Nov 24, 2022, http://tinyurl.com/2tfn67tm). Unlike Japan that is silent on whether companies can use copyright materials illegally obtained, SIPO emphasizes lawful access, meaning that companies cannot circumvent paywalls and must demonstrate due diligence in verifying the source used for obtaining copyrighted works.USARegarding the AI model training stage, as the US does not have a specific data analysis exception, AI companies rely on the fair use regime to conduct these activities. The US jurisprudence such as Authors Guild v. Google, 721 F.3d 132 (2nd Cir. 2015), seems to open a floodgate that wide scope of activities may qualify as fair use in which Google organized and published the digital snippets of copyrighted books that were considered fair use. AI model training may be comparable to what Google has done as the use was transformative and public disclosure of copyright materials are usually limited. As such, companies may conduct AI model trainings without having the right holder's consent.The United States Copyright Office (USCO) issued an official policy document that clarifies its position on copyright for AI generated works (USCO, Mar 16 2023, ""Rule Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence"", http://tinyurl.com/3urwhzh4). The policy affirms that the office only grants copyright to AI works with human authorship and rejects applications that are based on works autonomously generated by AI. Applicants also need to disclaim AI-generated content if it exceeds the de minimis standard. This means that the office has the authority to reject applications if the AI-generated elements could be eligible for copyright protection had they been created by a human, even though the specific standard is not clearly defined. USCO has rejected several applications, and at least one US court supports USCO's perspective (Thaler v. Perlmutter and USCO (1:22-cv-01564), D.D.C, Jun 2 2022).In Andersen v. Stability AI Ltd, 23-cv-00201-WHO, N.D. Cal. Oct. 30, 2023, the court allowed the plaintiff to pursue infringement claim against Stability AI when the plaintiff used a third party report as evidence to show her copyrighted work has been used by Stability AI for AI training.EUThe draft EU Artificial Intelligence Act, Article 28 adds an obligation that AI content providers are required to record and publish a ""sufficiently detailed summary"" of the training data protected by copyright laws (European Parliament, ""Texts adopted – Artificial Intelligence Act"",14 Jun 2023, https://tinyurl.com/yc6ywv4z). According to Matt Hervey, a UK Gowling WLG lawyer, the Recital 58a also mentions that AI deployers must also conduct risk mitigations, including protecting third-party copyrights and other IP rights (Matt Hervey, Jun 26 2023, ""The EU AI Act and IP"", https://tinyurl.com/4mus2cd4).Canada's Desired ApproachCanada should balance the public interest with the rights of copyright holders in its approach to AI. AI development can severely impact the day-to-day life of copyright holders and the general public. It is unreasonable and infeasible to put any responsibility on public users, who generally lack a technical understanding of generative models. However, AI service providers and deployers have the money and resources to implement safeguards and other measures to increase transparency and take ownership of the system.Therefore, GoodBot recommends that- Canada adopt the EU approach requiring AI developers to disclose any and all copyrighted work used to train AI models. This requirement addresses a key barrier to determining if an AI system has accessed or copied a copyrighted work, and provides more concrete grounds to the general public in establishing infringement claims.- Canada should make AI developers liable for using illegally obtained data to train AI models. Both the Japanese and US Fair Use approaches are poorly defined and lack explicit disclosure obligations that risk prioritizing the rights of AI developers over end users. AI developers should hold responsibility for protecting and disclosing existing copyrights, and thus, Singapore and EU approaches are more reasonable. Importantly, Canada's fair dealing is different from the US's fair use in that it explicitly provides a fixed category of written exceptions under Canadian copyright law; such exceptions may be tabled accordingly to address the issue of generative AI. AI developers will also be in infringement while using trained models to generate an output that infringes an existing copyrighted work. Thus, Canada should move towards the Chinese, Singapore, and EU approaches such that AI developers should demonstrate that data has been obtained legally and also be responsible for third-party copyright infringement and for removing infringing output.- To better protect the public interest and put more burden on the AI developers, Canada should make AI developers responsible for clarifying copyrights, including a mandatory disclosures of copyright work used in training models.- Canada should invoke a rebuttable presumption in the amendment to state that general users are sheltered from copyright liabilities for using AI to produce work if they do not knowingly order the AI to generate infringing content. To balance AI developer's interests, they may invoke due diligence defence by warning users about potential copyright infringement, i.e., ""a user must not input explicit prompts that are directed to generate copyright infringing content"". This amendment can also incentivize AI developers. For instance, they may establish a well-defined exception that places the responsibility on AI developers and content providers to use copyrighted data responsibly when training AI models for specific non-commercial research purposes that ultimately benefit the general public.","While GoodBot's submission is mindful of how generative AI impacts workers and creators, i.e. future of work, we assume that = entities representing these interests will submit industry specific recommendations. Our submissions therefore focuses on the impact of policies on end users, (i.e. everyday Canadians) who we assume will be under-represented in other submissions on Copyright policy.AI developments have significant implications for Canadians that need to be addressed through various forms of intellectual property beyond copyright, such as patents and trademarks.At this time, the advent of Generative AI, coupled with a historical lack of intentional focus on the rights of end users and effective enforcement mechanisms has resulted in a lack of policy coherence which contributes to confusion, uncertainty and harm to end users and the public interest. Policy exists more in theory than in reality for many Canadians impacted by technology-enabled harms.The Government of Canada must address gaps and inconsistencies in policy while prioritizing the establishment of effective enforcement mechanisms capable of rebalancing towards end-user rights who are at an asymmetrical disadvantage to technology companies and espeically Big Tech.The Government of Canada should revise policy and operational processes that prioritize the rapidly evolving needs of end users, including through substantive rights-based policies that consider and account for harms and impacts on end-users. Rebalancing rights also requires that policy frameworks provide improved access to legal remedies and enforcement mechanisms that monitor legal obligations and ensure that rights can be realized.Increasingly conversations also prioritize the need to align the development of technology with public interest. Yet while technology industries, governments, and civil society (including academia, nonprofits) all engage in different ways on how technology impacts people, families, communities, societies and democracies, there is limited shared common understanding of the issues and the solutions to address them.These differences are in part a product of different language, approaches, priorities and incentives facing different stakeholder groups which often contribute to growing power asymmetries and to adversarial relationships between rights focused actors prioritizing public interest and industry-aligned actors prioritizing minimal obligations. This conflict is not productive and not aligned with public interest which is the domain of government.The result is a thin common layer of understanding of what is in the public interest (which often comes down 'what is legal?' and/ or 'what can I get away with?') A consequence of this permissive approach is that even riskier applications once considered unthinkable are later pursued once market dominance is established (see OpenAI's recent decision to revoke military bans on the use of Generative AI products.)Developing and thickening a robust public interest layer is in everyone's interest especially for end-users, content creators, workers, policymakers, entrepreneurs sectors and markets, if perhaps not monopolies whose dominance is itself an issue.A robust layer of public interest means that:- companies are actively disincentivized from employing harmful practices or business models that pit user and societal well-being against company profits- healthy technology markets can emerge that are no longer dominated by a handful of ungovernable monopolies and where emerging responsible companies can compete on trust- companies own the primary burden of demonstrating that models are safe and fair, and that they have been developed with lawfully obtained data- transparency requirements can enable robust oversight and accountability when companies fail to adhere to legal obligations or when they cause harm- end users are aware of on rights and have accessible mechanisms available where corrective measures can be realizedMoving policy frameworks to rebalance toward public interest requires substantive obligations for generative AI companies. It is – for example – in the public's interest to understand how AI models are developed, trained and normalized in order to address and provide resource when harms arise from models. Such obligations should include but are not limited to the disclosure of data used to train AI models, demonstrations of legal provenance, and accessible remedial procedures such as the expedient removal of copyright-protected content from models as well as compensation (where appropriate) to creators whose works were infringed.Such obligations can and should be scaled according to size (e.g. level of profit, investment), risk, including the risk posed by copyright content data sets and the risks posed by the development of AI models, as well as the extent of potential breach causing harm to end-users. GoodBot recommends modelling EU approaches to risk, which require risk-based audits and human rights impact assessments based on assessed risks of AI models.The Text and Data Mining submission specifically raises the questions as to whether it is consistent with public interest for creators to profit off products created using personal information at all, even if that personal information is de-identified or anonymized in the final product. This is especially true if reasonable efforts have not been made to address known risks such as bias that could impact on automated decision systems.It is also important to the role of technology lobbies, backed by industry groups, that attempt to disincentivize countries and regions from robustly legislating on AI. These groups are often mandated with weakening policy obligations and legislations by pitting countries against one another, dangling the promise of AI investment dollars (See conflict between the UK, France and Germany in the final days of the AI Act http://tinyurl.com/47ps3ksc). As industry bodies invest in lobby groups, there is no equivalent lobby for end-users.Robust and coherent multilateral public policy is therefore also critical as an antidote to companies attempting to undermine policy. Canada should advance substantive rights-based global policy efforts to regulate AI that balance end-users rights and that include civil society delegations that can represent thes interests.Generative AI is likely to cause disruptive societal challenges in the years to come. On Jan 14, 2024, International Monetary Fund (IMF) chief Kristalina Georgieva raised concerns that nearly 40% of jobs around the world could be affected by the rise of AI, a trend which is likely to deepen inequality. The IMF is calling on governments to establish social safety nets and offer retraining programs to counter the impact of AI http://tinyurl.com/mv3rmwnx. This post was published on the same day that Oxfam released a report demonstrating that the five of wealthiest men in the world – including tech bosses Elon Musk, Jeff Bezos and Larry Ellison – have doubled their fortunes since the pandemic and now make nearly twice as much wealth as the rest of the world put together over the past two years. http://tinyurl.com/9srbw9xzGoodBot welcomes Canada's efforts to amend the Copyright Act for regulating the use of generative AI and recommends prioritizing and safeguarding rights of end users (i.e. everyday Canadians) over industry interest. Embracing this regulatory end, we emphasize that this submission is not anti-technology but rather underscore a commitment to foster responsible use of technology. Through the proposed recommendations we encourage the Canadian government to establish a framework that balances innovation with ethical considerations, ensuring a public interest-oriented integration of generative AI within legal boundaries. Canada should ensure that policy frameworks to address public interest requirements and that limit the ability of copyright policy to be used as a tool to stymie access to information that is the public interest.GoodBot believes effective public policy can enable a wave of technology developments that prioritize and align with public interest and that it is in the long interests of even technology companies to be effectively regulated to avoid races to the bottom that are harmful to society. The longer it takes to regulate, the more painful it will be for companies to adhere to new obligations.This moment also provides an opportunity to address the vast and growing asymmetry of power of Big Tech which is positioned to further consolidate its dominance in ways that are making companies ungovernable."
Internet Archive Canada,Non-profit / Think Tank,"Internet Archive Canada is a not-for-profit digital library based at 330 West Pender in Vancouver, B.C.For the past nineteen years, Internet Archive Canada has been building a Canadian digital library. We have partnered with organizations across the country–including the University of Toronto, the University of Ottawa, and Library and Archives Canada–to work towards this goal. This has included digitizing more than 650,000 books, government publications, and other works, a great many of which are focused on Canadian cultural heritage.In recent years, Internet Archive Canada has substantially expanded its footprint and operations, reflecting our pride and confidence in the Canadian library system, our belief in the promise of Canadian innovation, and the opportunity for serving the public good inherent in Canada's balanced and user-focused copyright system. This has included expanding, alongside other organizations, into new physical facilities in Canada (including our home in Vancouver), growing our Canadian workforce, and building new partnerships right here at home.Internet Archive Canada is committed to using the promise of new technologies to further access to information and benefit the public interest. For example, when we help digitize a book, custom machine learning models automatically suggest page boundaries of scanned materials–making our library processes more efficient and our collections more useful for our patrons. Sometimes, we use these experiences to aid the policymaking process–such as through this submission and our earlier one to the 2021 Consultation. And we try to make sure we are sharing our resources to help the broader community–for example, from November 15-17, 2023, we hosted in partnership with Simon Fraser University and others the 2023 Artificial Intelligence for Libraries, Archives, and Museums Annual Conference at our headquarters in Vancouver.Internet Archive Canada submits this response to the Government's Consultation on Copyright in the Age of Artificial Intelligence because we care deeply about the future of access to knowledge in Canada and the Canadian library system–and, by extension, copyright law. Our comments are guided by two core principles. First, copyright rules and technological developments should advance the public's right and ability to access knowledge and culture. Second, libraries and other publicly-oriented institutions should be empowered to utilize new technologies to expand access to knowledge.","1. Centering the Public's Interest in Access to Knowledge and Culture""Copyright law has public interest goals.""[1] As the Supreme Court of Canada has explained, ""increasing public access to and dissemination of artistic and intellectual works, which enrich society and often provide users with the tools and inspiration to generate works of their own, is a primary goal of copyright.""[2] So we were pleased to see the Consultation Paper acknowledge that copyright is at root ""a balance between promoting public interest in the encouragement and dissemination of works of the arts and intellect and obtaining a just reward for the creator.""[3]Unfortunately, the Consultation Paper also states that, ""[i]n considering possible copyright policy options relating to AI, the Government will aim to balance two main objectives:"" to support innovation, and to support Canada's creative industries. While these are certainly important considerations, this balancing framework obscures the public's interest in access to knowledge and culture that is copyright's true objective. The ""copyright bargain"" is not one to be negotiated between the technology and creative industries; it is ""a balance between promoting the public interest in the encouragement and dissemination of works of the arts and intellect and obtaining a just reward for the creator.""[4] The relevant copyright balance is not between two competing economic or ministerial interests, but between the public and authors.We therefore urge the Government, when considering new copyright rules for artificial intelligence or otherwise, to keep the public's interest in access to knowledge and culture at the center of copyright policy. Proposals to amend the Copyright Act to address AI should be evaluated by the impact such new regulations would have on the public's access to information, knowledge, and culture. In cases where proposals would have the effect of reducing public access, they should be rejected or balanced out with appropriate exceptions and limitations. Copyright law should enable, not restrict, the promise of new technology to expand the public's access to knowledge and culture.---[1] York University v. Canadian Copyright Licensing Agency, 2021 SCC 32 at para. 91.[2] Id. at para. 92.[3] See Théberge v. Galerie d'Art du Petit Champlain inc., [2002] 2 S.C.R. 336 at para. 30[4] See CIPPIC, Copyright Law, https://cippic.ca/en/FAQ/copyright_law#faq_copyright-bargain",N/A,"2. Preserving a Flexible Legal FrameworkIn our view, a flexible legal framework is the best way to ensure copyright keeps the public's interest at its core while responding to new technological developments like artificial intelligence.As is often the case with new technologies, artificial intelligence is a rapidly evolving, unpredictable field.[5] And while the consultation paper asks many of the right questions about artificial intelligence today, the answers to those questions—and the relevant questions themselves—may well change tomorrow. Indeed, research and progress in artificial intelligence is moving extremely rapidly.[6] In the circumstances, while legal certainty is no doubt important, the appropriate copyright framework for artificial intelligence must be flexible in order to ensure technological change does not disrupt the copyright balance to the detriment of the public's interest.Fortunately, Canada is already a global leader in copyright due to its user-centered approach to fair dealing and the doctrine of technological neutrality. The consultation paper rightly recognizes the role fair dealing can play in enabling artificial intelligence work in Canada today. But as the paper also recognizes, the legal situation in Canada is more uncertain than it could be. In particular, increased clarity could be brought on the question of whether training artificial intelligence and machine learning models on copyrighted works gives rise to liability. This could be achieved in two ways.First, the Government could reaffirm and strengthen fair dealing to provide for an open, fair-use-style approach. Many have called for adopting an explicit ""such as"" approach to fair dealing in the Copyright Act, making the fair dealing purposes in the Act illustrative.[7] Indeed, the Report of the Standing Committee on Industry, Science and Technology recommended just that in its June 2019 Statutory Review of the Copyright Act.[8] This approach doubles down on the flexibility of fair dealing and, in practice, can provide the certainty needed for technical innovation to thrive.[9]Second, the Government could take steps directly targeted towards the question whether training artificial intelligence and machine learning models gives rise to copyright liability. To this end, a targeted AI exception could be added to the fair dealing framework.[10] That said, the requisite certainty might also be achieved with a flexible framework without a new targeted exception.Any reforms must take account of actual marketplace conditions if they are to be efficacious. As it stands, many electronic resources offered to libraries and others are double-locked against text-and-data mining and other similar uses: first, by contractual license terms that purport to override the limitations and exceptions in the Copyright Act, and second, by technological enforcement of those terms through the use to technical protection measures. Thus, for any reform to respond to the actual conditions ""on the ground,"" it should make clear that no exception to copyright can be overridden by contract, and that TPMs can be circumvented for such non-infringing uses.---[5] See, e.g., Canada's AI Research Ecosystem, available at https://radical.vc/2021-primer-canadas-ai-research-ecosystem.[6] E.g., Mike Drolen & Megan Robinson, Global News, Artificial Intelligence: Canada's future of everything, available at https://globalnews.ca/news/10110598/artificial-intelligence-canada-future/.[7] See Geist, Michael, ""Fixing Fair Dealing for the Digital Age,"" available at https://www.michaelgeist.ca/2019/06/fixing-fair-dealing/[8] Dan Ruimy et al, ""Statutory Review of the Copyright Act""available at https://www.ourcommons.ca/Content/Committee/421/INDU/Reports/RP10537003/indurp16/indurp16-e.pdf[9] See Corynne McSherry, Fair Use Economics: How Fair Use Makes Innovation Possible and Profitable, available at https://www.eff.org/deeplinks/2016/01/fair-use-economics-how-fair-use-makes-innovation-possible-and-profitable[10] See, e.g., Canadian Federation of Library Associations and Canadian Association of Research Libraries, Brief to the Government of Canada: Consultation on a Modern Framework for Artificial Intelligence and the Internet of Things, available at https://www.carl-abrc.ca/wp-content/uploads/2021/09/CFLA-CARL-Brief-Artificial-Intelligence-and-the-Internet-of-Things.pdf.","3. The Need for Human ReviewWhile a detailed examination of machine learning and artificial intelligence techniques is beyond the scope of this submission, it is important to note that it is sometimes necessary to manually review portions of datasets both before and after ingestion.[11] There is increasing understanding that bad datasets lead to bad results.[12] Recent research from Europe confirms that ""[t]he fitness of a modern copyright system"" vis-a-vis artificial intelligence must therefore be measured, in part, by whether it provides an ability to mitigate potential bad and discriminatory results by permitting ""access to the original training data... to scrutinise [it] for mistakes, omissions or bias....""[13]Humans utilizing large datasets—whether in connection with the machine learning and artificial intelligence technologies available today, or with the as-yet-undeveloped technologies of the future—must therefore be able to review the underlying materials as a part of their work. In our view, one way to do this that both provides the necessary flexibility, and is fully compliant with the Copyright Act today, is through a technique known as controlled digital lending.[14] Controlled digital lending is the digital equivalent of traditional library lending; it permits libraries to digitize books they own and lend them out to their patrons one at a time (just as they would with the physical book, and in place of it). It is a practice that has the support of many libraries, librarians, and others around the world in order to make materials available ethically and within a recognized legal framework.[15] And its potential application here underscores the necessity of flexible copyright exceptions to respond to technological change.3. ConclusionInternet Archive Canada greatly appreciates the government's careful consideration and open process with this consultation. Please do not hesitate to contact us if we can be of any further assistance.---[11] See, e.g., Margoni, Thomas, & Kretschmer, Martin. (2021). A deeper look into the EU Text and Data Mining exceptions: Harmonisation, data ownership, and the future of technology at 8-9. Zenodo. https://doi.org/10.5281/zenodo.5082012[12] See, e.g., https://cdt.org/ai-machine-learning/[13] See Margoni et al., supra.[14] See Christina De Castell et al., Controlled Digital Lending of Library Books in Canada, available at https://doi.org/10.21083/partnership.v17i2.7100[15] https://www.ifla.org/publications/ifla-statement-on-controlled-digital-lending/"
Internet Society – Canada Chapter,Non-profit / Think Tank,"CANADIAN COPYRIGHT LAW MUST BE CLARIFIED TO PROMOTE COMPETITION, INNOVATION, AND INVESTMENTS IN CANADIAN COMPUTATIONAL POWERThe organizations that fund, build and operate large-scale computing facilities are closely examining what the next generation of computing will be, and are sensibly examining the regulatory environment to evaluate long-term investments in computing capacity.Canadians benefit from having computing and networking infrastructure built domestically. It creates jobs, boosts skill sets across the entire economy and creates greater capacity to access information.Right now, AI is a significant driver for increasing computing capacity. AI requires specialized chips and new technologies that are built-for-purpose. Before making decisions about where to deploy expensive computing capacity, companies will look to where and whether they and their customers can use it in the location of deployment. Any changes to the law that will increase the legal or regulatory risk associated with the use of infrastructure will disincentivize investment in computing capacity in Canada, to the detriment of the socio-economic benefits for Canadians.Simply put, Investment in computing capacity will be influenced by the degree of clarity provided by copyright law for potential investors. Canada has an opportunity to glean valuable insights from the experiences of its international partners—for example, where clarity arising from text and data-mining (TDM) exceptions have succeeded in other jurisdictions.In Canada, a clear exception for TDM is crucial to encourage competition and innovation from smaller, Canadian players. If copyright law requires licensing of the internet—or the corners of it originating in Canada—before an LLM can be trained, then only the biggest players with the deepest pockets and hoards of proprietary data may be able to innovate. This would be a massive barrier to entry for an upstart company and would prohibit Canadian companies with Canada's best interest at heart from competing and innovating.","COPYRIGHT AND THE CREATION OF LARGE LANGUAGE MODELSAny discussion about copyright and large language models (LLMs) needs to start with a common understanding of how LLMs work. The discussion should also distinguish between the ""inputs"" of an LLM and the ""outputs"".To create an LLM, a large data set is ingested, and the words—or portions of words—are analyzed in terms of probabilistic distribution. Software examines the data set and encodes what words are in the data set and what words follow other words. It evaluates the context in which particular words appear. It evaluates the context in which particular words appear. The result is a massive table of numerical tokens that represent words, their frequency, and their tendency to appear together. Other patterns in the appearance of words may be mapped. This creates a word prediction model, not a data set of the works examined or the training data itself. Thus, any ""copying"" of the training data is incidental, ephemeral, and temporary. The creation of an LLM should not trigger any of the exclusive rights of a holder of copyright under s.3(1) of the Copyright Act.The output of an LLM depends on the model itself and the prompts given to the system by the user. One cannot enter a citation of an article or any other work and ask for a copy of it. The database would not contain the work. ISCC believes that, at present, the Copyright Act can effectively address the outputs and requires no amendment in this regard.In the event that a clearly constructed prompt results in an output that appears to be a word-for-word copy of an existing text, it is due to the probability that words exist in this particular sequence—not because the original text is stored in the LLM. For example, if you entered the following prompt into an LLM, ""finish the sentence: it was the best of times, it was …"" the result would probably be ""it was the best of times, it was the worst of times,"" because of the number of times this phrase has been repeated on the internet, not because the LLM contained a copy of ""A Tale of Two Cities.""Understanding the difference between inputs and outputs are imperative, as any radical changes to the Copyright Act because an LLM appears to be copying an artistic work would be misplaced. The use of a copyrighted work is not prima facie infringing. Canadian copyright law has never countenanced restricted or prohibited learning from a copyrighted work or describing a copyrighted work. Creating a new author's right out of thin air is not consistent with the existing statute or the case law with respect to fair dealing.To the extent clarity is desirable, Canada should follow the leads of Japan, South Korea and Israel, all of whom have clarified that the input, the training of LLMs, is not a violation of their copyright laws. The following clarification to the Act is recommended:29.23.1 It is not an infringement of copyright for a person to use a work or multiple works for the purpose of information analysis, including the comparison, classification or other analysis of information pertaining to language, sound, images or other elements constituting information extracted from a work, including the creation of systems and databases to support an artificial intelligence system.","The output of an LLM depends on the model itself and the prompts given to the system by the user. One cannot enter a citation of an article or any other work and ask for a copy of it. The database would not contain the work. ISCC believes that, at present, the Copyright Act can effectively address the outputs and requires no amendment in this regard.In the event that a clearly constructed prompt results in an output that appears to be a word-for-word copy of an existing text, it is due to the probability that words exist in this particular sequence—not because the original text is stored in the LLM. For example, if you entered the following prompt into an LLM, ""finish the sentence: it was the best of times, it was …"" the result would probably be ""it was the best of times, it was the worst of times,"" because of the number of times this phrase has been repeated on the internet, not because the LLM contained a copy of ""A Tale of Two Cities.""Understanding the difference between inputs and outputs are imperative, as any radical changes to the Copyright Act because an LLM appears to be copying an artistic work would be misplaced. The use of a copyrighted work is not prima facie infringing. Canadian copyright law has never countenanced restricted or prohibited learning from a copyrighted work or describing a copyrighted work. Creating a new author's right out of thin air is not consistent with the existing statute or the case law with respect to fair dealing.PROTECTING CANADIAN CULTURE, LANGUAGE AND VALUES THROUGH CANADIAN INPUTS TO LLMSWhile we are at the beginning of the AI revolution and just starting to see the technology's utility, it is clear that AI is an important way that people seek answers to questions. Thirty years ago, people went to a library. Currently, we use internet search engines. Those search engines are becoming enhanced by AI to understand our questions and match them to appropriate search results. The next step will the use of AI to match a particular question to an appropriate answer.In effect, AI will shape our understanding of world. It's of utmost importance that Canadian data, language, values and culture are reflected in the information-seeking and world-shaping activities powered by LLMs and other generative AI technologies.If barriers are created that effectively discourage or prohibit the use of Canadian works to build LLMs, the result is that Canadian data will be excluded. These LLMs, therefore, would not be able to provide answers or results that fully reflect Canada. They may produce answers ""about Canada,"" but only from data originating outside of Canada—about us, not by us. LLMs used in Canada, by Canadians, should include data that is relevant and appropriate for Canadians. To do so otherwise would be actively harmful.Canadian cultural policy generally rests on the concern that Canadian culture and its cultural products may be overwhelmed by those from the United States; moreover, that Canada's bilingual and multicultural legacy may be diluted. Any scenario in which there is mandatory licensing or other restrictions on the use of Canadian content in the creation of LLMs will obscure results about Canada to Canadians and the rest of the world. This would be a bad outcome.",See submissions related to TDM.,"Submission to Innovation, Science and Economic Development Canada re: Copyright in the Age of Generative Artificial IntelligenceBy Internet Society Canada ChapterJanuary 15th, 2024EXECUTIVE SUMMARYThe Internet Society Canada Chapter (ISCC) welcomes the opportunity to provide insight on how to leverage amendments to the Copyright Act to ensure Canadians can harness the full benefits of generative artificial intelligence (AI) and other AI technologies.ISCC agrees with the objectives of the Copyright Act and believes that it must facilitate the creation of a positive environment for investment in AI development in Canada. Our laws should ensure that Canadian works are reflected—not excluded—from global AI systems and that Canadian creators have the means to protect their works from copyright infringement due to AI-generated outputs in appropriate cases. As AI further influences how information is gathered online, and therefore the knowledge that shapes worldviews, Canadian data, language, values and culture must be included.More specifically, the ISCC submits that:Recognition of the difference between the ""inputs"" and ""outputs"" of Large Language Models (LLMs) is imperative;A modern copyright framework for generative AI must ensure that Canadian data, language and values are reflected in the inputs to LLMs to protect Canadian culture and reflect it in world-shaping AI technologies;Canadian copyright law must be clarified to promote competition, innovation, and investments in Canadian computational power.ABOUT THE INTERNET SOCIETY CANADA CHAPTERThe Internet Society Canada Chapter (ISCC) is a member-based not-for-profit that advocates for affordable, fair and secure internet access for all Canadians. ISCC engages on legal and policy issues to promote an open internet. Our focus is to bridge the digital divide along all axes to ensure that Canadians reap the socio-economic benefits the internet provides.We provide Canadians with a proactive voice on all internet issues through various committees, roundtable discussions, conferences and membership meetups, where leaders and experts from governments, the private sector, civil society, academia, the technical community and end-users can discuss key issues, identify common solutions and share resources.INTRODUCTIONAs stated in the consultation paper, ""the [Copyright] Act to promote the creation and distribution of content, to foster investment and job creation, promote just rewards for creators, and to create a thriving marketplace that offers consumers choice ad access to diverse content."" These are all objectives that ISCC agrees with.While Canada is a global leader in AI fundamental R&D, it continues to be a laggard with regards to commercialization and adoption. This is an issue central to Canada's ability to compete in the global digital economy. It is also critically important that Canadians have the skills needed to commercialize and scale adoption of AI-driven technology. If Canada and Canadians are to reap the economic, innovation and cultural benefits of rapidly evolving AI technologies, our copyright law must facilitate the creation of a positive environment for domestic AI investment, development and commercialization.Our laws should ensure that Canadian works are not excluded from global AI systems such that they become inaccessible and irretrievable as an unintended consequence of overly restrictive Canadian copyright law.Canadian copyright law should ensure that Canadian creators have the means to protect their works from copyright infringement due to AI generated outputs in appropriate cases.ISCC is concerned that amendments to the Copyright Act could effectively place a toll or limit on the ability to use Canadian content to develop and train large language models (LLMs), ultimately harming Canadian consumers and Canadian creators. Copyright law reflects a careful balance between the rights of creators and the rights of users of creative content. Any recalibration of this balance needs to be very carefully considered to avoid unforeseen or unintended consequences.Canada has generally only made changes to its copyright laws in harmony with our main trading partners. A change to our copyright laws that is out-of-step with the international community will inevitably create barriers and disadvantage Canadians. A mandatory licensing scheme will result in Canadian content being excluded from learning models, and thus not available for Canadians to use."
Oxford Disinformation & Extremism Lab,Non-profit / Think Tank,"At the Oxford Disinformation & Extremism Lab, we do not collect copyright-protected data but we remain concerned about the potential for violent extremists, malicious actors, and state influence operations to use copy-right protected materials (including news media, video games, music, and images) to create deepfakes, memes, and propaganda using popular media.","Copy-right protected content must be protected when Generative AI is both trained and used. However we also need to consider more serious use cases involving criminal and terrorism offences with this content. Users exploiting and editing copyright-protected content in GenAI platforms have used the tools to produce powerful propaganda that picks up on existing memes, trends, and movements. Further regulation (similar to the the EU Digital Services Act) can help limit this potential by requiring better classifiers in consumer LLMs.",Further regulation (similar to the the EU Digital Services Act) can help limit the potential for copy-right abuse by requiring better classifiers and hash-sharing to be included in consumer LLMs.,Hash-sharing and image classifiers are not perfect at identifying content and companies should invest in developing more robust tools to identify copy-right protected content.,N/A
Re:Sound,Non-profit / Think Tank,"Re:Sound recognizes the value of AI and is reviewing options to utilize AI in the future to assist with the process of matching sound recordings, enhancing data quality and conducting data analysis, in order to create efficiencies and better serve rights holders.","Re:Sound is the Canadian not-for-profit music licensing company dedicated to obtaining fair compensation for artists and record companies for their performance rights. We advocate for music creators, educate music users, license businesses and distribute royalties to creators — all to help build a thriving and sustainable music industry in Canada.Re:Sound administers the right of equitable remuneration under section 19 of the Copyright Act on behalf of performers and makers for the communication by telecommunication and public performance of their sound recordings. As this right is not a right of copyright under section 3 of the Act and does not involve the reproduction right, it would not appear to be directly engaged by text and data mining (“TDM”). In support of creators, Re:Sound submits that the use of their sound recordings in TDM must be both authorized and compensated.The use of sound recordings of musical works in TDM has obvious value, providing an essential input to the creation of AI. Creators should be fairly compensated for the use of their works and have the right to authorize such uses. This can be done without impeding innovation. Digital streaming services license entire catalogues of sound recordings, AI developers can do the same. Copyright owners as well as collective societies such as Re:Sound routinely process data for millions of sound recordings. The volume of data required by AI developers is not an impediment to a fair licensing system that tracks the ingested works and fairly compensates their creators.No new exceptions should be created under the Copyright Act for TDM. The creation of a sound recording requires considerable time, effort, resources, and talent. AI developers relying on TDM exceptions could use those original sound recordings and generate output that competes with the very creative work that made it possible in the first place. That runs entirely counter to the incentives to create that the Copyright Act aims to achieve.AI developers should be required to keep records of the copyright-protected content used to train their AI systems in order to ensure that the creators of that content are fairly compensated for the use of their content.","While the right of equitable remuneration administered by Re:Sound is not a right of copyright and not directly engaged by this issue, in support of creators, Re:Sound submits that the current Copyright Act is sufficiently clear that only a human creator is entitled to copyright protection. No modification of the Act is required at this time, however this issue could be revisited in the future based on developments in jurisprudence.","The right of equitable remuneration administered by Re:Sound does not include the remedy of infringement. In support of creators, Re:Sound submits that the existing provisions of the Copyright Act are sufficient at this time to address infringing AI-generated works. However, additional legislative measures are needed to address the following:","Re:Sound thanks the Ministries of Heritage and ISED for this opportunity to provide comments on such an important issue. Re:Sound encourages policymakers to take into account the principles of the Human Artistry Campaign (humanartistrycampaign.com):(i) technology has long empowered human expression, and AI will be no different;(ii) human created works will continue to play an essential role in our lives;(iii) use of copyrighted works and the use of voices and likenesses of professional performers requires authorization and free-market licensing from all rightsholders;(iv) governments should not create new copyright or other IP exemptions that allow AI developers to exploit creations without permission or compensation;(v) copyright should only protect the unique value of human intellectual creativity;(vi) trustworthiness and transparency are essential to the success of AI and protection of creators; and(vii) creators’ interests must be represented in policy making."
"The Samuelson-Glushko Canadian Internet Policy & Public Interest Clinic (CIPPIC), Centre for Law, Technology and Society, University of Ottawa",Non-profit / Think Tank,"Questions 1-3 are inapplicable to CIPPIC.Q4) The development of AI is human reliant. While self-programming AI systems have been theoretically formulated by many scholars, to date there has been no successful system of this kind due to current computational constraints. There has been success developing self-modifying AI systems using code-generating language models, meaning that the system is able to manipulate its own hyperparameters to improve its operation. Still, such a model does not involve actual AI self-programming but requires a human to develop and implement the model itself. Similarly, programs such as Codex (Open AI) are able to generate code from natural language inputs. Like all current, publicly available generative AI systems, however, this system was built and made available by a human developer, and further requires prompting by a human user to produce the desired output. As a result, humans are still integral to the development of current AI systems.Q5) CIPPIC is a public interest technology law clinic, meaning that our area of work primarily involves monitoring and intervening in policy issues and discussions arising at the intersection of law and advancing technologies. In the Canadian legal landscape, AI-assisted and AI-generated content can assist lawyers in reviewing contract formalities, generating memos and factums, as well as with research on specific legal topics as prompted by the user. Legal clients may also use generative AI-systems to ask for suggestions on how to approach a legal issue they are facing, though this should not be considered legal advice.","Q1) Further clarity around copyright and TDM could shed light on: A) The nature of the copyrighted content being scraped for TDM purposes and whether the type of content has implications for TDM-based infringement; B) How broadening authors’ rights to capture TDM may shift copyright’s balance and in so doing create risk and uncertainty for innovative activity (shifting to protection of ideas rather than expressions; violations of tech neutrality; unforeseen effects on non-technological applications of learning techniques); and C) How authors who would like to prevent their copyrightable digital works from being scraped for TDM purposes may do so effectively. Such clarity would ensure that innovators are aware of any copyright-imposed limitations on TDM activities. The creative industry benefits from clarification on author rights and limitations when it comes to preventing their work from being subject to TDM and use in AI-training datasets.Q2) TDM activities are conducted in Canada across a variety of sectors including research, health record analysis, business intelligence, and AI development. Generally, TDM activities play a significant role in assessing the Canadian population and consumer patterns, making it a key component to informed decision-making, even when separated from generative AI applications. Importantly, TDM describes a practice, not a technology. TDM can occur in analog form and is ultimately a human practice. TDM in the Gen-AI context is just one application of a wider practice that has been a staple of innovative research for some time. Accordingly, any policy proposal to address TDM must consider the implications of the change outside of the AI industry, and for practices involving or similar to TDM such as structuring and indexing information and innovating with technological processing systems (ex. search engines and plagiarism detection). It is worth considering whether we are in the midst of a panic with the emergence of a powerful new technology. Any move to subject the development of AI to the controls and risks inherent to the copyright regime must proceed on the basis of an accurate understanding of how and when AI models interact with works. Equally, addressing the challenges of AI will involve an appreciation of the balancing purposes of copyright law and the nature of author’s rights. Any proposed legislative amendment should proceed only with a clear-eyed appreciation of its consequences for copyright’s virtuous balance.Q3) Canadian copyright holders often face challenges in licensing their works for TDM activities, in addition to facing challenges in preventing their copyright protected work from being used in TDM. The lack of clarity in Canadian law regarding how TDM may infringe copyrights, namely through unauthorized reproduction of the work, leaves rights holders with uncertainty as to their entitlement to licenses, the specific nature of licensing rights, as well as the proper content of licensing agreements. The further lack of direction on the applicability of fair dealing to TDM also introduces uncertainty as to when infringement occurs. More so, the diverse nature of TDM activities and works sought for TDM has led to a lack of standardization in licensing agreements, as well as undue complexity in licensing terms. This poses challenges for rights holders assessing fair compensation and defining the scope of licenses for use of works.Q4) In Canada, there are various approaches to licenses for TDM activities. The most common form for publicly accessible data is terms of use agreements, which lay out the scope of permissible data use and any specific conditions for use of TDM results. For example, the terms of use may indicate that TDM is only permitted for non-commercial purposes. Permissible use of the data may be dependent on the payment of a subscription or one-time fee to access the copyrighted material. For many of these sources, the individual seeking to conduct TDM agrees to the terms of use by performing the TDM activity itself, rather than agreeing to a negotiated license with the copyright holder.Since Canadian copyright law fails to address TDM, those seeking to perform TDM must investigate the terms of use for each specific data source to ensure they have the necessary permissions. Similarly, they must ensure that their proposed use of the data aligns with what is actually allowed under the agreement. As a result, the current scheme poses several challenges since there is no clear, consistent approach to licenses for use, which leaves T&D miners unaware of potential risks regarding copyright infringement and any legal obligations under licenses. Those conducting TDM on a smaller scale face a resource and knowledge gap when compared to big data corporations, leaving them at a greater risk of violating license terms or being priced-out from purchasing licenses. Additionally, those seeking to complete TDM activities often face unduly limitations on data access, which hinders research and innovation pertaining to AI development (ex. the license may limit the TDM results to specific word-limited extractions, rather than the whole of the results). The inconsistencies among licenses further limits accessibility, as the differences in terms of use may prevent comprehensive TDM-driven research where several sources are used.Q5) TDM activities should be permissible and not cause infringement as long as the training data is not reproduced in any resulting generative output, meaning that the tech sector should be able to use copyrightable works in training datasets for AI in a manner that avoids infringement by reproduction. Canadian copyright protects original expressions of an idea as demonstrated through the exercise of an author’s skill and judgement, but not the idea itself (CINAR v Robinson, 2013 SCC 73 at para 24; Copyright Act, s. 5). Infringement by reproduction occurs where a substantial portion of the original work was copied, which is a question of quality and requires a holistic comparison of the works as a whole (CINAR at para 26). Applying this to TDM, copyright-protects works would likely not be infringed through use in AI training data. Rather than resulting in a durable reproduction, TDM provides the AI with data from which the model can extract knowledge from. The model is essentially deriving meta data to advance its capability to mimic human intelligence. Any technical, temporary reproductions arising from this process benefits from a number of user rights designed to facilitate innovation and its ensuing scientific, economic, and creative benefits. Fair dealing and the exception for temporary reproductions for technological processes both address these benefits. In other words, TDM activities alone do not give rise to an infringing reproduction, publication, or performance of the work. Extending owner’s rights to TDM would unduly extend protection to ideas, information, and data rather than the expression of the work.Q6) Considering the normative purpose of the Copyright Act, maintaining a balance between the public interest in the encouragement and dissemination of works of art and intellect and obtaining a just reward for the creator, AI developers should disclose the use of copyright-protected content when used in the training of an AI system. Disclosure of the use of copyrighted content provides due acknowledgement to the original creator of the work even when the content itself is not being reproduced in any way, thereby upholding their moral rights to be associated with the work. At the same time, the public receives the benefit of AI systems with stronger and more accurate technological capacity, and AI developers are able to advance the technology through TDM activities without fear of unmerited legal claims. A way to address this normative position would be to specifically include TDM among those qualifying purposes of fair dealing that oblige the user to mention the sources and, if given, the author.Q7) If Parliament concludes that TDM results in copyright infringement, owner and author remuneration should be addressed through thoughtful application of the current licensing framework. AI Firms are entering into licenses with copyright owners to gain access to their content for TDM activities. These licenses reflect both risk mitigation (avoiding expensive litigation) and the value of content towards enriching training datasets rather than acknowledging existing liability. Structured or edited data, for example, may have greater value than unstructured data for some purposes. If Canada were to adopt this approach, which minimizes the harm to innovation and ensures that markets remain competitive and open to new entrants, Canada should adopt a remuneration model, not an exclusive rights model, for compensating authors. This system could also address authorship – as opposed to ownership – entitlements to ensure that authors obtain discrete benefits from use of their works (rather than exclusively publishers).Q8) The US has yet to adopt any legislative frameworks specific to TDM. Rather, US courts have applied the doctrine of fair use to permit for TDM, justified by the “transformative use” factor of the test (USC Title 17 – Copyrights, s. 107). Japan has updated its Copyright Act to permit for use of copyrighted works for machine learning, which includes TDM activities. Importantly, Japan only imposes compensation for use where there has been enjoyment of a copyrighted work. Since no one is enjoying the work during TDM, there is no infringement (Article 30-4, Japan Copyright Act). Europe has implemented Articles 3 and 4 to Directive 2019/790 to allow TDM under an opt-out system, such that authors can prevent having their works mined. Since 2014, the UK has provided a copyright exception for TDM under s. 29A of the Copyright, Designs and Patents Act.","Q1: The current copyright framework does not explicitly address AI-generated works, leading to ambiguities in cases where works are created with significant mixed human and AI involvement. The Copyright Act should be updated to explicitly state that authorship is the exclusive domain of humans. The primary benefit of such an amendment is to head off needless litigation and administrative burdens imposed by actors attempting to assert copyright authorship for algorithms, which, among other things, lack legal personhood to hold such rights.Copyright theory, legal doctrines, and its underlying rationales, require a human author. The Copyright Act already assumes authors are human; otherwise, s. 6 of the Act, tying the term of copyright to the lifespan of the author, would be meaningless when considering AI. For copyright to vest, a work requires the exercise of skill and judgment, and the work must not be so trivial that it could be characterized a purely mechanical exercise (CCH v Law Society of Upper Canada, 2004 SCC 13 at para 16 [CCH]).As long as human input is required, AI should be viewed as a tool instead of an author. The originality and creativity elements will need to be judged on a case-by-case basis by examining the input (i.e., prompt) as well as the work itself. A generic input like “a picture of a cat” arguably lacks the originality criteria for copyright protection. The more specific and creative the input, the stronger the case for copyright protection of the resulting work. Outputs that lack original human input are unauthored and fall into the public domain.Q2: The human providing specific inputs to an AI should hold the copyright in a generated work, especially when inputs are not generic, which aligns with the principles of existing copyright law. However, it would be beneficial for the Canadian Government to clarify these aspects to address the evolving landscape of AI-generated works. This approach maintains technology neutrality while ensuring that copyright continues to protect human creativity and expression.Q3: There are 3 broad national approaches addressing authorship of AI-generated works in copyright law (WIPO Conversation on Intellectual Property and Artificial Intelligence). First, the United States, Australia, and most continental European countries requires human creativity in copyright law and does not extend copyright protection to AI-generated works (see Thaler v. Perlmutter, case No. 1:22-cv-01564, (D.D.C. 8/18/23), at p. 2).Secondly, the United Kingdom, New Zealand, South Africa, and India award authorship through legislation to the human that arranged the work, and broadly permits fully autonomous or sentient AI to author works (see s. 9(3), Copyright, Designs, and Patents Act of 1988 (CDPA) – UK). The United Kingdom allows a copyright to subsist in AI-generated works by attributing authorship of the works to the human, corporate, or AI machine author that simply arranged the final copyrighted work. Thus, the United Kingdom relies on skill of labour or sweat of brow to determine who arranged the work (CPDA s. 9(3)).Finally, China and Japan use the judicial system to incrementally expand upon existing legislation by attributing copyright authorship to human programmers and companies that create code dictating AI’s creative decisions and by declining to extend authorship to AI. For example, in Shenzhen Tencent v. Shanghai Yingxun (2019), the Chinese judiciary extended copyright protection to AI-generated works and attributed authorship in the final work to the human author or organization that created the AI. In Gao Yang et al. v. Golden Vision (2020), high-altitude photographs taken automatically by AI merited copyright protection because although humans did not click the shutter-release button to take the photograph (the AI made this decision), humans were solely responsible for making creative decisions that influenced the high-altitude photographs, such as the shooting angle, video recording mode, and video display format.Our suggestion is that Canada follows the Chinese approach to authorship by attributing copyright authorship to the humans or corporations that create the code or prompt dictating the AI’s output. This approach allows copyright to extend to AI-generated works by focusing on the creativity and originality of the input, rather than judging the amount of creativity and originality in the creation of the output. It also avoids creating sui generis rights or legal fictions to accommodate AI-generated creations. This approach is more open to considering AI’s role as a tool in the creative process.","Q1: As previously described, whether a substantial portion of the work has been infringed is a question of quality rather than quantity and requires a holistic comparison of the works as a whole (CINAR at para 26). In other words, infringement can be found for both literal and non-literal copying where the substantial quality of the work is reproduced (CINAR at para 27). As the Supreme Court has ruled, an assessment of substantial copying focuses on whether copied features constitute a substantial part of the original work of the author; thus, the alteration of copied features or its integration into a notably different work may not preclude an infringement claim if a substantial quality of the work has been copied (CINAR at para 39).As a result, generative AI systems may face infringement claims if their outputted works copy a substantial portion of the quality of the original work that the system was trained on (i.e., substantial reproduction of the copyright protected training data). This will be extremely difficult to monitor considering the expansiveness of most AI training data sets, as elements from a multitude of different works may be combined to produce a generative output. Infringement may be clearer when the prompter asks the AI system to generate an output addressing the specific expression of an author, artist, musician, or other copyright-protected creator. The law currently accommodates this issue by holistically assessing each alleged infringement on a case-by-case basis; copyright infringement is a matter of degree, nuance, and context, and whether a substantial part of a work has been copied is a flexible and fact-specific notion (CINAR at paras 26 & 40).Due to the nuanced nature of this test, concerns are likely to focus on where an AI-generated work, trained by TDM activities, including copyright-protected expression, is being commercialized. In this situation, creators may raise issues related both to their moral and economic rights. For moral rights, authors may raise concerns related to how the integrity of their work has been manipulated by the AI system, as well as the loss of association with a substantially copied derivate of their original work. Considering that economic rights include the right to authorize reproductions, copyright owners may also raise concerns when another party exercises any of the exclusive rights associated with their work without consent (Copyright Act, s. 3; Théberge v Galerie d'Art du Petit Champlain Inc, 2002 SCC 34 at para 12).Q2: The vast majority of modern-day AI uses deep learning. Deep learning is a subset of AI and uses artificial neural networks to mimic the human brain’s learning process. The one pitfall of deep learning is that generated outputs are developed using black-box algorithms, meaning that users are unable to see how the deep learning system actually makes its decisions. While we understand the training data inputted to the AI model and can observe the outputs created, we have no way of knowing how the AI actually came to that output. The only indicator we would likely have is the user-generated code used as the original scaffolding for the AI’s learning patterns.In other words, considering both the black-box algorithm issue and the expansive breadth of datasets, there is no way for us to assess whether or not the AI accessed a specific copyright-protected work. Our knowledge is limited to the inclusion or exclusion of the copyright-protected work in the original dataset.However, the core principle of how generative AI models function does not implicate copyright infringement: AI researchers do not design AI systems to reproduce training data; they design them to abstractly “learn” from training data. Training data influences the algorithm, but the algorithm does not reproduce the training data.In rare cases, generative AI models reproduce copyright-protected expression. A precise understanding of how, why, and when this occurs should predicate any policy conclusions the Canadian government draws from this phenomenon. CIPPIC’s understanding of this phenomenon suggests that it arises from specific technological phenomena combined with user-specific prompts. AI researchers are better able to describe the scope and limits of this phenomenon.Larger concerns arise from copyright protection for the reproduction of abstract concepts of expression, such as fictional characters (ex. the CINAR case). Caselaw will, over time, provide greater clarity over the limits of expression of abstract ideas that reproduce expression subject to copyright protection. Developers of AI systems will need to consider mechanisms for identifying where such occurrences are likely to emerge.Q3: How the Canadian Copyright Act applies to AI-generated outputs is unclear, leaving businesses and other organizations unsure of liability for copyright infringement through AI-applications. As a result, Canadian enterprises are adopting a patchwork of risk-mitigation strategies. Examples include: restricting training data for AI software such that all data used is either licensed or public-domain; corporate indemnification clauses to protect end users from infringement claims where their use of AI was within the scope of the software’s terms and conditions; and author-applied tags to label their works as being non-TDM friendly.Some enterprises have combined these approaches to create a robust framework protecting AI application users from infringement liability. For example, Adobe Firefly, which uses generative AI to alter an image based on user-inputted text prompts, has co-founded and implemented the Coalition for Content Provenance and Authenticity (C2PA) and the Content Authenticity Initiative (CAI). The C2PA and CAI work together to permit publishers, creators, and consumers to trace the origin of different types of media using an open technical standard. These tools allow users to add Content Credentials that allow the creator to indicate that generative AI was used in the production of the work. Information about the specific AI models used can be traced by the user, thereby helping to increase transparency and prevent the spread of misinformation regarding the use of generative AI in creative works.Adobe has also made efforts to ensure that Firefly’s commercial character does not lead to infringement claims by training the AI model on licensed (Adobe Stock) and public domain content, while not training the AI using any subscribers’ personal content. Adobe Stock contributors whose works have been used to train Adobe Firefly are eligible for a “Firefly bonus compensation plan.” This plan represents a license agreement whereby contributors are paid for the use of their work as training data in the Firefly AI software. The purpose of Adobe’s approach was to eliminate the potential for copyright infringement claims, with Adobe going insofar as to offer intellectual property indemnification for any legal issues arising from its use. This indemnification clause provides that as long as the user has used the Firefly product in accordance with the terms and conditions, Adobe will compensate the individual for any IP-related legal claims that may arise. As a result, any generated work incorporating Firefly AI within the scope of its authorized terms will not be subject to personal copyright infringement liability. Q4: Yes. Further clarity is required in several areas related to AI systems generally, but specifically for generative AI systems and the works they produce. First, we need greater clarity on what constitutes a “substantial part” of a work is necessary for determining the liability of AI-generated works for infringement. There must be further clarification on the protection of artistic styles and whether that is considered as an unprotected idea or a protected expression of skill and judgement. Secondly, greater clarity is required regarding who would be liable for copyright infringement in these circumstances. Considering that copyright authorship requires an original expression through an exercise of skill and judgement, the legislature must provide clarity on whether or not an AIsystem can truly fulfil these criteria. At its core, AI is a mathematical and statistical computer science tool that analyzes training data for correlations and patterns, and then it uses those patterns to generate a predictive output. Essentially, the AI is regurgitating and recombining data to create a novel output. The issue of whether this constitutes an exercise of skill and judgement, such that the AI system is an author of an original, expressive work, must be resolved by the legislature. If it does, the AI itself would be liable, which would require a novel remedy of some kind. If it does not, is the human prompter who generated the specific output liable? Or does liability fall onto the corporation or individual who coded the AI system itself? Such clarity need not originate with legislative initiatives. In any event, special legislative amendments that depart from the usual copyright rules of liability for specific industries or technologies would violate the law’s neutrality. Experience has shown that such solutions are short-lived as the pace of the market and innovation inevitably leaves them behind.Industry standards, consensus best practices documents, and litigation can all contribute to providing greater certainty around AI innovations. The government can play a role in facilitating multi-stakeholder initiatives that can lend themselves to this end.Q5) Please see prior response to Authorship Section, Q3.","Two additional issues merit attention: A) vicarious liability; and B) liability for treatment of rights management information.A) Vicarious LiabilityAs with any neutral technology that interacts with works, users can accidentally or deliberately produce AI outputs that infringe copyright. This raises the question of whether proprietors of AI systems used in this way may be vicariously liable for the infringements of its users.In Canada, vicarious liability for copyright infringement arises primarily through (a) the authorization of an infringing act or (b) the provision of a service primarily for the purpose of enabling acts of copyright infringement (Copyright Act, s. 3(1) & s. 27(2.3). Whether a party “authorized” infringement is a question of fact, looking to whether the alleged authorize infringer sanctioned, approved, or countenanced the infringement (CCH at para 38). Authorization can also be inferred from the facts, meaning that both positive acts and sufficient indifference or passivity to known infringement can be grounds for a secondary infringement claim (CCH at para 38). Notably, liability for authorizing infringement does not occur where a person authorizes the mere use of technology that could be used to infringe copyright (CCH at para 38). Courts look to the knowledge the authorizer possessed of the infringing acts, and the degree of control the alleged authorizer exercised over the primary infringer.Authorizing infringement is relevant to the discussion of copyright, TDM activities, and generative AI outputs because it opens the door to liability for programmers, providers, and users of AI systems who prompt the generation of an infringing work. Regardless of the identity of the author of the infringing AI-generated work, an expansive approach to authorization could extend liability throughout the chain of people responsible for building the AI, training it, and prompting the work’s creation. For example, if TDM is used on copyright-protected material to create training data for an AI, the sale or distribution of that training data to other parties could give rise to a secondary infringement claim. The programmers who train generative AI on such data sets and build the AI system such that it can reproduce a substantial, infringing portion of copyright-protected work could also face liability (see Liability Section, Q1).The notion that infringement is not authorized where only equipment that could result in infringement is provided further complicates vicarious liability, as this rule indicates that only prompters should be liable for requesting the generation of an infringing work by the model. It must be clarified whether the issue is A) the potential for the AI model to reproduce a substantially similar output to its copyright protected training data or B) the ability for users to prompt such an output.The manner in which courts have construed the authorization right should prove satisfactory in addressing such risks. AI services do no exercise control over any primary infringer producing outputs that infringe copyright. AI is neutral technology, and only in exceptional circumstances would the ordinary use case implicate a copyright infringement. Similarly, authorization does not require intervention to stop infringements on the part of an otherwise neutral by-stander, including the purveyor of technology used by another to infringe copyright. Copyright does not violate the liberty principle that underlies much of Canadian law: the law does not require Canadians to police the actions of our neighbours.Expansive interpretation of the authorization provisions of the Act could result in the potential for broad vicarious infringement claims against all parties involved in the development of an AI system. For example, in Voltage Holdings, LLC v. Doe #1, 2023 FCA 194, the plaintiff has sought liability against internet subscribers on the basis of deemed knowledge of infringing acts, alleged control over the point of internet access, and an alleged failure to stop the infringements. Should courts abandon the traditional control test (that looks to the legal and personal relationship between allegedly infringing actors) in favour of assumed technological control, authorization liability could become a significant risk for AI actors. Similarly, if the courts were to overturn long-standing precedent and import into authorization a duty to police or intervene in copyright wrongs, this too would raise red flags.  It is worth commenting that radical policy shifts in the scope and reach of authorization would affect far more than just purveyors of AI services and should provoke a legislative reaction.The Act’s prohibition on the provision of infringement enablement services should prove adequately focused on bad actors to avoid its inadvertent deployment against content-neutral, general application AI services.B) Rights Management InformationThe Copyright Act’s prohibition in s. 41.22(1) on altering or removing electronic rights management information (“RMI”) associated with an electronic copy of a work ought not to prove a concern for AI entrepreneurs. This is so for both TDM activities and with respect to outputs. RMI liability requires a that a claimant meet a “triple knowledge“ criteria: to be liable, a defendant must (1) “knowingly remove or alter” RMI, (2) without the consent of the copyright owner, and (3) in circumstances where the defendant “knows or should have known” that the removal or alteration “will facilitate or conceal any infringement of the owner’s copyright.” The particularity of these knowledge requirements, and their inapplicability to cases involved fair dealing or other exceptions to infringement – greatly limit the potential of RMI tampering claims to frustrate AI research and commercial applications."
The Schwartz Reisman Institute for Technology & Society (SRI) at the University of Toronto (U of T),Non-profit / Think Tank,N/A,"IntroductionThe Schwartz Reisman Institute for Technology & Society (SRI) is a research institute at the University of Toronto (U of T). Its mission is to be the world’s leading institute for innovative research and practical solutions to help ensure that artificial intelligence (AI) and other advanced technologies benefit all of humanity. Central to this mission is SRI’s belief that mitigating potential harms and unlocking the many benefits of AI will require new approaches in law and regulation. What follows is SRI’s response to the Government of Canada’s Consultation on Copyright in the Age of Generative Artificial Intelligence, issued by Innovation, Science, and Economic Development Canada (ISED).Text and Data Mining (TDM)If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards?If the government were to amend the Copyright Act to clarify the scope of permissible TDM activities, it should do so in a way that makes it clear that copyrighted data can be used to train AI systems. Copyrighted works in TDM should not require additional authorization from rights-holders. The purpose of copyright law is to motivate the production of new creative works by offering some monopoly protection for a limited period of time to people who invest in producing new ideas. It does not protect ideas themselves—in fact, it encourages the free flow and exchange of them. Barring AI systems from training on these existing ideas runs counter to the principles of copyright law.The boundaries around what copyright does and does not protect can be explored through the example of a painting. If I see your painting—at a gallery, museum, or posted online—there is nothing to prevent me from reproducing some aspect of it. I can decide to adopt your distinctive style of painting, take your idea to paint a cat exploring outer space, or even reproduce the same image you’ve created in my own style. The only thing copyright protects against is exact copying. The bounds of these protections are purposefully narrow, so as to encourage creativity and innovation. We want creators to draw inspiration from other creative works, to expand upon them, and to bring new creations to life. The line for copyright has always existed to protect creators just enough that they are motivated to continue creating, without stifling the ability of other creators to draw inspiration and make similar but iterative works.It may be tempting to look at an AI system being trained on copyrighted material and suggest that the use of such materials should not be permitted, or that copyright holders should be compensated for this use. Yet copyright is not based on labour theory—we are not protecting creative works simply because someone put their labour into making those works. We are protecting them for economic reasons. Simply put, creators need some level of protection in order to receive the economic benefits of producing new creative works. Without these benefits, there would be little motivation to produce new works, and we would lose the innovation and continued creation required to stimulate the economy.Existing copyright does not prevent new artists from studying the works and styles of artists who came before them. Rather, we want to motivate this free flow of ideas between creators as a way of prompting continued creativity and innovation. Barring AI systems from being trained on copyrighted material would therefore distort copyright law and its purposes.    Technological Protection MeasuresHaving established that barring TDM goes against the core purpose of copyright law, let us quickly address technological protection measures, or TPMs. Access to copyrighted works can be prevented by using TPMs such as digital locks or digital rights management. As such, another question that may be worth exploring is whether, and to what extent, TPMs interfere with the data scraping activities discussed above.Although the portion of copyrighted materials currently protected by TPMs is relatively small, this may increase to an overwhelming majority if rights holders remain unhappy with TDM, and turn to TPM as a way of pushing back against their materials being scraped from the web. As such, although allowing TDM is the right approach in keeping with copyright law, it is worth noting the existence of TPMs and other existing mechanisms that may allow rights holders to ‘rebel’ against this choice. The compensation scheme suggested in the section below would help in addressing these types of concerns.    Individual licensingThe Consultation Paper notes that various stakeholders have been resistant to the idea of licensing, arguing that this will stifle innovation. This is a valid argument—individual licensing is costly, both in terms of actual monetary cost and the amount of time required to track down and bargain with every individual license holder. Further, most generative models are trained on a scrape of the web. Any kind of individual licensing system would make this type of training impossible, introducing serious barriers into the process of creating new generative models. This would run counter to the general purpose of copyright law, by demotivating the production of new works and ideas.","Ownership of AI-Generated WorksThe consultation paper presents the following three approaches for analysis:1. Clarify that copyright protection apply only to works created by humans2. Attribute authorship on AI-generated works to the person who arranged for the work to be created3. Create a new and unique set of rights for AI-generated worksWe believe that something akin to approach 3, creating a new and unique set of rights for AI-generated works, is the best approach. However, we will first quickly address options 1 and 2.The approach that copyright protection only applies to works created by humans likely does not have very much staying power. As AI capabilities increase, determining what has been created by humans will become more difficult to distinguish. The consultation paper suggests that an AI-generated output could be copyrighted when a human author uses AI to generate the output, but in the process uses skill and judgement. Deciding, however, the appropriate level of skill and judgment for AI becomes murkier as the technology advances and new capabilities emerge. Strictly applying copyright to human-made works may cause future issues and calls for a more nuanced approach. Moreover, as noted above, the goal of copyright law is not to protect human labour per se but rather to encourage creativity and innovation. If machines become capable of creativity and innovation, it would seem appropriate to encourage that by providing the economic protection that copyright offers human creators.The next proposed approach is to attribute authorship of AI-generated works to the person who “arranged for the work to be created.” This would presumably operate similarly to a business model, in which works created by the employees of a company in their capacity as an employee are owned by the business (or organization, academic institution, etc) that employs them. This is a viable approach, and having the existing example of works created by employees and owned by companies would help serve as a model for resolving problems that may arise.However, the most viable approach seems to be introducing a new type of compensation scheme to motivate creators. Copyright provides us with a useful mechanism for incentivizing and compensating creators. However, in the age of generative AI, this mechanism begins to break down. Traditional copyright was not created to account for the speed at which AI systems can learn and process vast amounts of new information, nor the abilities of these systems to generate new works in a matter of seconds. It is not actually consistent with copyright to suggest that these systems cannot have access to ideas and images that exist—albeit with certain protections—in the public sphere. Yet, this suggestion is often posed in the context of generative AI, seemingly motivated by the feeling that it doesn’t seem fair that a company can scrape the whole internet for free, and then take control of vast amounts of wealth and market share.We should not twist copyright into something it’s not on the basis of feelings about what is and is not fair. However, we should pay attention to the fact that copyright is an economic tool for motivating creativity and the continued production of new ideas and works; if we think this motivation will be hindered by allowing generative AI companies to capture too much of the market share, then we will need some kind of solution.What we are faced with in the age of generative AI is a fairly momentous transformation of the nature of our production relationship. As a result, what we likely need is a method for sharing the surplus: the wealth that is generated from these systems. Canada could get in front of these coming complications by creating a new type of compensation scheme for creators. Such a compensation scheme could avoid the concerns that generative AI companies operating on a free scrape of existing ideas would capture too much of the surplus, dominating markets and demotivating the creation of new ideas and works by smaller creators.This compensation scheme could take various forms, but should share the core economic motivations of copyright law. The government could decide to impose a tax on generative systems and divert the proceeds towards funding various projects that incentivize new ideas and works, such as education or stipends for creators. Or, it could be decided that what is needed is an intermediary organization that receives a share of the profits generated by an AI system that’s producing new works, and distributes those profits to the creators in its network (similar to the American Society of Composers, Authors and Publishers). Whatever form the compensation scheme takes, it should tackle our economic concerns (stifling the production of new ideas and works due to a lack of motivation for individual creators), rather than our moral ones (it doesn’t seem fair that this generative system can create images at a fraction of the speed and cost that humans can).","Infringement and LiabilityThe question of liability in the context of generative AI systems largely boils down to this: who should be liable for a generated work that violates existing copyright laws? The AI developer, who trained the model on copyrighted works, or the user who prompted the model to produce a work that duplicates or too closely resembles an original piece?Generally speaking, liability should lie with the user who prompts the model. If a user wants to make a system reproduce Van Gogh’s Starry Night, and gives it directions to do that, then fault will lie with that user. This is likely to be the case in the majority of copyright infringements. However, should there be instances where a user is unfamiliar with Starry Night, and the generative system just decides to output an exact replica of this work because it remembers Starry Night from its training data, then liability will lie with the system developer. Determining who caused the copyright violation should be relatively straightforward in the majority of cases, simply requiring a retracing of the steps that caused the infringing output to be generated.",N/A
Vector Institute for Artificial Intelligence,Non-profit / Think Tank,"How does your organization access and collect copyright-protected content, and encode it in training datasets?Vector Institute (“Vector”) has worked with its legal counsel to develop a decision tool consisting of a grid showing alignment of  common licenses and their terms. This tool enables the review of licenses associated with data that Vector AI practitioners would like to use for training AI models, and also enables the coordination of terms to license products that may contain other copyright-protected content.This tool ensures that Vector meets the terms of the original license(s), and flows those terms forward in the new license by clearly demonstrating which initial datasets can be used in the final product based on the original license terms.Vector works with staff to ensure only original data with license terms that align with the usage and final product license are used.As an example of how Vector builds a training dataset, Vector’s AI Engineering workstream has created an AI and machine learning (ML) training dataset composed of a number of open-source datasets. For this training dataset, Vector used a Creative Commons License and only included open-source datasets with existing licenses that fit within the Creative Commons License that was chosen for the finished product. In doing so, Vector avoided contaminating the resulting training dataset with the terms and conditions of a more restrictive open-source license.Vector also ensures that original input datasets are acknowledged. This is done by Vector staff when the final product is published, by entering the acknowledgement information in the Creative Commons License.Vector collects and processes diverse datasets from various sources, including closed-source and publicly available texts, under strict adherence to legal and ethical standards, to train and continually improve AI models. These standards can be specific to each dataset.In collecting data, Vector staff navigates relevant copyright laws and regulations, among other considerations for appropriate access to the data, which are specific to each dataset.This often involves using content that is publicly available, licensed for use, or that falls under fair use exemptions, so as to avoid complications and administrative burden associated with more restricted datasets since the economic and resource obligations of doing so do not make sense from an ROI perspective.Vector also considers the ethics and potential impact of its data collection and utilization practices on data creators and rights holders, in addition to its legal obligations, as a reputational risk.For closed-source data, Vector employs a rigorous approach to ensure compliance with data provider and/or legal requirements, and ethical integrity (e.g., Research Ethics Board [REB] approvals).This approach includes obtaining explicit permissions or licenses from data owners, and ensuring that the use of the data aligns with the specific terms and conditions set forth by the providers.In handling closed-source data, Vector staff is especially cautious about privacy, intellectual property rights, and any contractual obligations associated with use of the data for AI inquiry since there is no standard model of terms and conditions associated with such datasets, and the risks associated with holding them are far greater than using open-source datasets.How does your organization use training datasets to develop AI systems?The process of acquiring and utilizing training datasets for AI systems is multi-faceted and rigorous:- Vector staff begins with the ethical and legal acquisition of data; this includes REB reviews where appropriate, and obtaining necessary licenses- Data are then processed to prepare for AI applications; this includes cleaning, curating, and categorizing the data (NB: de-identification and verification of the same is a necessary condition for transfer of data into Vector data and analytics environments)- Processed data are then used to train AI models through an iterative learning process, where the models progressively improve in recognizing patterns and analyzing data- The models are evaluated and refined for enhanced accuracy and functionality using an iterative process, and once they achieve satisfactory performance, they are deployed for practical applications (NB: the models themselves are deployed, but the corresponding training data are not released if they are under any restriction)- Regular updates with new data or model improvements are also part of maintaining the effectiveness and relevance of AI systemsSome of Vector’s work is done in collaboration with data providers; for these projects, Vector implements Data Transfer Agreements that include specific terms and dictate how each party’s contributions are recognizedIn your area of knowledge or organization, what measures are taken to mitigate liability risks regarding AI-generated content infringing existing copyright-protected works?Dataset Curation and Compliance: As above, Vector’s approach includes careful curation of training datasets, and ensuring alignment with copyright laws; where private data are used for model training, Vector implements agreements providing explicit approval and/or appropriate licenses for its use, favouring the Creative Commons License or open-source datasets with similarly equivalent permissive terms and conditions.Regular Model Updates and Training: Vector updates and re-trains its AI models to enhance their quality, and ensures adherence to copyright regulations in that process - particularly for generative models - carefully monitoring to ensure that there is no copyright violation.Guidelines for Users: Vector provides guidelines for the responsible and lawful use of AI-generated products; users are required to acknowledge these terms through a data user agreement for training data and through Vector’s Code of Conduct, which includes trust and safety principles, and adhere to these guidelines when utilizing Vector’s AI tools.Consultation with Legal and Ethics Experts: Vector engages with legal and ethics experts to remain compliant with the evolving landscape of copyright laws and ethical standards in AI, both as a matter of due diligence and as part of its mission to work together with its AI partners in other parts of Canada to ensure that they have the people, skills, and resources to be best in class at the use of AI.In your area of knowledge or organization, what is the involvement of humans in the development of AI systems?Vector leverages algorithmic techniques and AI models guided by human expertise in research, data curation, ethical oversight, and quality control.Vector AI practitioners are conducting leading-edge research on mitigating bias in data and models to ensure high quality, trustworthy, and safe outputs.Data generated from individuals (Personal Information, Personal Health Information) may be used for projects. Therefore, to mitigate associated risks of doing so, Vector requires that such data be de-identified before being transferred into Vector’s data and analytics environments, and confirms this with the data provider prior to transfer.How do businesses and consumers use AI systems and AI-assisted and AI-generated content in your area of knowledge, work, or organization?Vector’s AI solutions are applied by its industry sponsors, institutional partners, and small- and medium-sized enterprises across domains such as health, financial services, and manufacturing, to support functions such as customer support, analytics and insights, personalized training, and research and development.While automation and generative AI tools can offer efficiency and scalability, Vector emphasizes human-centred, carefully controlled processes to maintain high standards of accuracy, innovation, and ethical compliance.","What would more clarity around copyright and text and data mining (TDM) in Canada mean for the AI industry and the creative industry?More clarity, and specifically definitions and limitations on liability related to the use of training data for generative AI, could foster a more collaborative, innovative, and legally secure environment for both the AI and creative industries. Such definitions and limitations must be at least as permissive and clear as Canada’s closest major competing AI jurisdictions: the US. There will be a public policy push to balance the interests of technology advancement with the protection of intellectual property, carving out appropriate exceptions where overly burdensome requirements for protecting IP will stifle innovation and discovery. However, if the result of that exercise results in a regime that is not competitive with the US, Canada’s closest competitor that has greater funding, greater market access, and greater VP capacity, it will result in a weakening of Canada’s international standing in AI.Are TDM activities being conducted in Canada? Why or why not?TDM activities are being conducted in Canada, with their application spanning numerous sectors including academic research, market analysis, and biomedical research, as well as in the development of AI/ML models. While TDM is a routine practice in domains like social media and natural language processing (NLP), its use in the health sector is comparatively less frequent, particularly when dealing with patient data.Are rights holders facing challenges in licensing their works for TDM activities? If so, what is the nature and extent of those challenges?Designing fair and clear licensing agreements for TDM  is complex, as these must address factors like scope of use, duration, content type, intellectual property, and compensation, which are concepts that - in their current forms - do not always map neatly onto AI/ML use cases. The mismatch originates from the idea that traditional processes require that a hypothesis be matched to a dataset in order to receive approval: the researcher has a signal that they are looking for or a problem they are trying to solve. These processes are less effective when mining data using ML techniques since the researcher may not know the pattern they are looking for or the problem that they are trying to solve at the starting point.The evolving legal framework for TDM adds uncertainty, especially with varying laws across jurisdictions, leading to concerns among rights holders about the legal implications of licensing their works; companies may be inclined to move to a jurisdiction with clearer limits on definitions and liability, even if the jurisdiction is less competitive in terms of AI talent generation needed to expand the company.There is also apprehension regarding potential misinterpretation, misuse, or reputational damage from how the extracted data might be used, but this reputational damage occurs after-the-fact in the case where an unclear definition of liability may have caused an entity to take on a risk that was unclear or, in reverse, make a risk-managed decision that is subsequently found to be problematic after-the-fact because of unclear definitions.What kind of copyright licenses for TDM activities are available, and do these licenses meet the needs of those conducting TDM activities?- Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0): This license allows free use, sharing, and modification of the work, provided that: the original creator is credited; it is not used for commercial purposes without permission; and any adaptations are distributed under the same license.Creative Commons Attribution 4.0 International (CC BY 4.0): This license permits the distribution, remixing, adaptation, and building upon existing work, even commercially, as long as the original creator is properly attributed. Users are free to use, share, and modify the work with credit to the author.- Creative Commons Attribution-ShareAlike 3.0 License: Users are free to use, share, and adapt the licensed work, with the condition of attributing the original creator and distributing any modifications under the same license.- Creative Commons Zero (CC0): This tool allows creators to place their works into the public domain, removing copyright restrictions. It enables unrestricted use, modification, and distribution of the work without requiring attribution or imposing any conditions.- GNU General Public License (GPL): This free software license allows users to use, modify, and distribute software, while protecting software freedom and the rights of users. Version 3.0 (GPLv3) is the most recent version of this license.- Creative Commons Zero 1.0 Universal Public Domain Dedication (CC0 1.0): This public domain dedication tool allows creators to waive their copyrights, dedicating their works to the global public domain for unrestricted use, modification, and distribution without needing attribution.If the Government were to amend the Act to clarify the scope of permissible TDM activities, what should be its scope and safeguards? What would be the expected impact of such an exception on your industry and activities?Amendments should focus on defining the types of data (e.g., health, social media, etc.) that can be mined, appropriate purposes for TDM, and should ensure robust safeguards for privacy and intellectual property that balance the big data needs for training high quality, accurate models, with the protection of individual and corporate rights. This may require new business models for how content creators license their outputs and data.Should there be any obligations on AI developers to keep records of or disclose what copyright-protected content was used in the training of AI systems?Yes, AI developers should keep and disclose records of copyright-protected content used in training AI systems to ensure transparency and adherence to copyright laws, support ethical practices, build trust, facilitate accountability, and contribute to research and development in the field; however, this requirement needs to be balanced with protecting trade secrets and privacy. It is worth noting that while records may be generated automatically, the scale of datasets used to train LLMs and other large models is such that those records are likely much larger than could ever be recorded or reviewed by a human.What level of remuneration would be appropriate for the use of a given work in TDM activities?The following factors should be considered for the use of a given work in TDM activities:- The type and significance of the work being used (academic or research-oriented works might have different valuation compared to commercial or proprietary content);- Whether the outputs of the activity will be used commercially (e.g., commercial uses typically necessitate higher remuneration than non-commercial, educational, or research purposes) - the prevailing market rates in competing jurisdictions for similar types of content and TDM activities should be applied, ensuring fairness and competitiveness; and- Pre-existing agreements or standard industry practices around licensing content for TDM.","Is the uncertainty surrounding authorship or ownership of AI-assisted and AI-generated works and other subject matter impacting the development and adoption of AI technologies? If so, how?Businesses and content creators are hesitant because of the uncertainty surrounding ownership rights and the potential for monetization of AI-generated content, especially in the legal and intellectual property domains. Clarity is necessary for AI development, and there are ethical questions about giving credit to AI vs human creators, which can hinder collaboration and data sharing. Users may be reluctant to interact with AI-generated content whose legal status is unclear, which has an adverse effect on consumer trust and market dynamics.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?If this exercise results in a regime that is not competitive with the US, Canada’s closest competitor that has greater funding, greater market access, and greater VP capacity, it will result in a weakening of Canada’s international standing in AI.","What are the barriers to determining whether an AI system accessed or copied a specific copyright-protected content when generating an infringing output?The details of training commercial models are typically restricted, and the trend is toward even more closed systems. The market environment is competitive, and model providers will resist releasing details on training data composition. Moreover, the move towards custom models (fine-tuning or retrieval augmented generation) means that there are many more models proliferating that are created by small teams without oversight.When commercializing AI applications, what measures are businesses taking to mitigate risks of liability for infringing AI-generated works?More businesses are turning towards local or self-hosted models, some of which are trained on base models with transparent training processes.Are there approaches in other jurisdictions that could inform a Canadian consideration of this issue?The most recent development of international interest was a commitment from OpenAI on November 9, 2023 that it will cover the legal costs of users who are sued for copyright and now has a regime in place to provide such guarantees. To the extent that the US legal regime and the company’s position allows it to make this guarantee, one could speculate that any company/jurisdiction not able to provide a competitive/equivalent statement will lose ground to companies and jurisdictions that are not able to do so.",N/A
The Canadian Chamber of Commerce,Non-profit / Think Tank,N/A,N/A,N/A,N/A,"The Canadian Chamber of Commerce is pleased to make this submission to Innovation, Science and Economic Development (""ISED"") Consultation paper: Consultation on Copyright in the Age of Generative Artificial Intelligence (AI).The Canadian Chamber of Commerce is the country's largest business association with an active network of nearly 400 chambers of commerce and boards of trade representing nearly 200,000 businesses of all sizes, in all sectors and regions of our country. As such, we consulted with members from a variety of sectors, including telecommunications, finance, manufacturing and the creative industries, represented on the Canadian Chamber's Digital Economy Committee, Privacy and Digital Trade Council, Cyber.Right.Now. Council and Future of AI Council.Members of the Canadian Chamber's newly formed Future of AI Council are particularly focused on proactively supporting federal AI policy, and advocating for policies that will establish AI as a positive economic force through the responsible development, deployment, and use of AI in business.Our members across sectors, Councils and Committees acknowledge that leveraging the significant power of AI in our economy and society is a complex challenge. Since AI can present both opportunities and risks, there is curiosity and contention about what the future development and deployment will look like. The Canadian Chamber of Commerce, made up of an inclusive cross-section of organizations operating in Canada, serves as a network and forum for businesses to collaborate and address this challenge together. We are committed to working with government to encourage Canadian-led innovation and to integrate AI into business in a responsible manner that profoundly increases economic productivity and growth, thus benefiting the lives of Canadians across the country.AI will significantly impact all industry sectors, with reports estimating that generative AI could add more than $4 trillion in value to the global economy (McKinsey Digital Report, The economic potential of generative AI: The next productivity frontier, June 14, 2023). Given that generative AI will significantly impact the global economy and financial markets, the Chamber supports the government's action to review the Canadian Copyright Act (the ""Act"") (RSC, 1985, c C-42) and how it applies to AI systems, and how text and data mining (""TDM"") activity and the training of AI using copyright-protected works can legally function in Canada.While our organization represents a variety of sectors and different sizes of companies from all of Canada, our intent with this letter is to underscore key principles ISED should prioritize as part of its review. Setting the right AI regulatory environment in Canada is essential to support Canada's advancements in its ambition to be a global AI leader and to promote responsible use of TDM.As ISED reviews the Act, our members encourage the department to recognize:An AI-fueled economy could drive innovation and bolster productivity gains across sectors by making advanced solutions widely available for Canadian businesses, which fosters economic growth and international competitiveness.The Canadian Chamber of Commerce supports the government's goals of protecting rightsholders while at the same time promoting innovation, Canada's international competitiveness, and fostering further AI research, adoption, and investment. The right policy environment will make Canada an attractive destination for AI growth and business investment.Thank you for the opportunity to submit our recommendations. We gladly make ourselves available at your convenience to meet and discuss our recommendations further.Ulrike Bahr-GedaliaSenior Director, Digital Economy, Technology & InnovationCanadian Chamber of CommerceC: 613.410.6629E: ubahr-gedalia@chamber.ca"
Copibec,Rights Organization,"Copibec est la société québécoise de gestion collective des droits de reproduction, une entreprise d’économie sociale à but non-lucratif spécialisée en gestion des droits d’auteur. Elle représente plus de 30 000 autrices et auteurs, et 1 300 maisons d’édition. Elle offre aux utilisatrices et aux utilisateurs de matériel protégé par le droit d’auteur des solutions simples et adaptées à leurs besoins. À l’échelle internationale, la société de gestion collective a conclu des ententes avec plus de 33 sociétés étrangères afin d’inclure les livres, journaux et revues de ces pays à son répertoire. Elle compte parmi ses membres l’UNEQ, l’ANEL, le RAAV, l’AJIQ, la FPQJ, la SODEP, les Quotidiens du Québec et les Hebdos du Québec.  La consultation portant sur le droit d’auteur à l’ère de l’intelligence artificielle générative lancée en octobre dernier alors qu’une consultation sur un cadre moderne du droit d’auteur pour l’intelligence artificielle et l’Internet des objets avait été initiée en 2021 exprime en soi l’évolution rapide de l’IA.Cette évolution rapide et les questions que suscite l’intelligence artificielle générative en lien avec le droit d’auteur pourraient nous contraindre à agir avec une trop grande célérité en ne mesurant pas l’ampleur des changements à venir. Il faut, bien sûr, prendre acte des défis que pose l’avènement de l’IA et des questionnements qu’elle suscite. Il ne faut pourtant pas éluder le fait que l’on oppose l’intelligence artificielle à l’intelligence qui, elle, émane d’êtres humains. Certes, les questions sont vertigineuses, mais elles nous ramènent aussi à notre essence. De ce point de vue, la Loi sur le droit d’auteur, modelée sur ce qui nous est propre, nous renvoie à ce qui nous singularise et nous distingue.Si la dénomination de l’IA ne suffit pas à la cerner, il demeure que les mots permettent de définir ce que nous nommons. Que nous ayons ainsi pensé important d’apposer l’adjectif « artificielle » au substantif « intelligence » dénote bien le fait qu’il faut distinguer l’IA de ce qu’est l’intelligence qui, sans autre qualification est associé à l’intelligence humaine. L’IA force en quelque sorte l’intelligence qui nous est propre à se définir par opposition à ce qui serait un autre ensemble référentiel. L’utilisation de l’expression « machine learning » met déjà plus à distance ce que nous tentons de cerner et peut aussi nous aider à répondre aux questions qui nous sont posées. Un possible amalgame entre “intelligence artificielle” et “intelligence humaine” porte déjà en son sein un glissement qui pourrait s’avérer tendancieux.Il nous semblait important de nous attarder aux termes utilisés et qui désignent ce que nous devons circonscrire quant à la demande qui nous est faite par cette consultation sur le droit d’auteur à l’ère de l’intelligence artificielle générative. Il faut d’ailleurs noter que le terme « générative » s’est ajouté dans cette nouvelle consultation, alors qu’en 2021 nous n’en étions encore qu’à l’intelligence artificielle.Il pourrait être facile de s’abandonner à la technicité, de sacrifier les questions éthiques au nom de la science. Ce n’est pas la voie que nous emprunterons ici.Que la Loi sur le droit d’auteur soit à nouveau interpellée par de nouvelles technologies, qu’elle soit poussée dans ses derniers retranchements, qu’on la questionne et l’interroge face à des objets éloignés de son centre nous oblige en fait à définir ce que nous désirons protéger. Disons d’emblée que la technologie n’est pas neutre et que nous constatons dès à présent les enjeux que sont notamment le manque de diversité, la présence de biais cognitifs et la possibilité, en nous projetant, d’entrevoir une uniformisation en ce qui a trait aux extrants générés par l’IA. Ainsi, prendre un recul critique face au développement de l’IA permet de mieux la situer. Il semble que ChatGPT fut le déclencheur d’une prise de conscience planétaire des capacités de l’IA, comme si un seuil avait été franchi, et ce n’est pas qu’au Canada que l’on tente de la juguler, de l’endiguer, de la paramétrer. Nous sommes donc devant un effort à l’échelle mondiale pour trouver des réponses satisfaisantes en ce qui concerne l’IA générative et force est de constater que la culture est l’un des vecteurs qu’impacte l’IA à l’ambition totalisante. La prise en compte de l’ensemble de ces vecteurs démontre les aspects problématiques que suscitent l’avènement de l’IA. Il nous est à ce jour difficile d’envisager l’avenir même à très court terme.Le document de consultation parle à certains moments de « contenus créatifs» en se référant à ce que peuvent générer les systèmes d’intelligence artificielle. Nous avons entendu « artefact», «contenu généré», et il nous semble important encore ici de nous distancier du terme «œuvre» utilisé dans la Loi sur le droit d’auteur.Ce qui pourraient n’être que des considérations lexicales sont au contraire des éléments qui nous disent d’emblée que la façon d’appréhender l’IA générative, sans nous interroger en amont sur cette nouvelle « réalité », procède d’une analyse qui ferait l’économie de son objet. C’est ce que nous désirons indiquer par des remarques que l’on pourrait qualifier de liminaires, mais qui ne sont pas, de notre point de vue, accessoires.De plus, les questions identifiées dans le document de consultation produit, tout en nous indiquant la possibilité de commenter de façon plus large, produisent néanmoins un effet d’ancrage chez le répondant qui aura tendance à se modeler à ce qui est proposé et à ne pas questionner les prémisses de base. Nous avons discuté de l’emploi du terme « intelligence artificielle », de la dénomination des extrants générés par l’IA. Ce qu’est un « auteur », une « œuvre» sont autant d’éléments fondateurs dans la Loi sur le droit d’auteur. Qui plus est, la version anglaise de la Loi pose déjà des défis. Son titre lui-même ayant fait l’objet d’analyses et le terme «work», équivalent du terme «œuvre», en langue anglaise ne sont que des exemples de l’importance et de la difficulté que pose le champ lexical en droit d’auteur.Les questions que pose l’IA vont au-delà de l’objet de cette consultation et la Loi sur le droit d’auteur est le substrat d’éléments partagés et sur lesquels nous avions une compréhension commune. Que la Loi ne définisse pas, par exemple, ce qu’est un auteur et que l’on ait une approche dans laquelle l'historicité de la Loi est évacuée nous semble bancal. Que l’on constate le caractère évolutif des textes est une chose, qu’on le dénature en est un autre.L’originalité est certes le critère qui définit le mieux ce qui sera protégé de ce qui ne le sera pas – il s’agit d’un élément fondateur et nous y reviendrons lorsque nous parlerons de titularité.","Nous sommes fermement en défaveur de l’établissement d’une exception qui permettrait de procéder à toute activité de fouille de textes et de données. Nous n’avons pas, en notre qualité de société de gestion collective des droits de reproduction, reçu de demande concernant la FTD. Par ailleurs, des licences existent déjà afin d’autoriser cette activité et nous croyons qu’un marché peut se développer. Il correspondrait à la logique interne du droit d’auteur selon laquelle les autorisations se transigent en égard aux droits exclusifs des auteurs et qu’une valeur monétaire est offerte en contrepartie d’une utilisation déterminée. Le Copyright Clearance Center (CCC) aux États-Unis offre de telles licences pour la FTD en ce qui a trait aux œuvres artistiques et littéraires. Nous soumettons que la LDA répond avec efficacité aux besoins exprimés par l’industrie et nous reprenons les termes du document de consultation : « La présente consultation a pour objectif de poursuivre l’important travail de recherche des faits déjà entamé, plus particulièrement en vue d’éclairer la politique sur le droit d’auteur à une époque où le contenu, même s’il peut sembler créatif et original, peut être facilement généré par un système d’IA. » (p. 3)La recherche des faits qu'évoque le document de consultation est ardue pour nous puisque nous n’avons en aucun cas été sollicité en lien avec la fouille de textes et de données. Nous ne nions pas l’existence de la FTD, mais elle n’apparaît sur aucun de nos écrans radar.L’entraînement des systèmes d’intelligence artificielle a nécessité l’utilisation d’œuvres protégées par le droit d’auteur sans qu’aucun consentement n’ait été accordé et qu’aucune forme de rémunération n’ait été établie. Nous plaidons pour une exigence de transparence.",,,"En tout état de cause, on aura compris que l’IA générative a des conséquences qui vont au-delà de la Loi sur le droit d’auteur mais touchent aussi ce que la Loi protège. Les créateurs, tout comme l’ensemble de la société civile, voient déferler des avancées technologiques que l’on pensait voir survenir dans un futur beaucoup plus éloigné. Le premier réflexe ne doit pas être de voir la Loi comme étant un frein à l’innovation. Elle porte plutôt en son sein son fruit et les sociétés de gestion collective font partie de la solution."
International Trademark Association,Rights Organization,N/A,N/A,"In June 2023, the AI and 3D sub-committee of the INTA Copyright Committee released a survey report on ""Copyright and Neighbouring Rights in Outputs Made by or Made by Means of AI Systems"". The report summarized the results of a limited study conducted by INTA in 2022, relating to the protections (if any) afforded to AI outputs in different jurisdictions. 48 countries were surveyed. 71 respondents provided their input and responded to a short questionnaire.The INTA Survey considered whether (and on what terms) such outputs were (or might be) protected under traditional copyright which has a human authorship component; as a ""neighbouring right"" (e.g., protections afforded to performer's performances, and makers of sound recordings or broadcasts) which rights arise agnostic to the copyright status of the underlying content; or as a sui generis right. It also considered whether protection afforded to AI outputs give rise to moral rights in the output (such rights arise in tandem with copyright in many jurisdictions, including Canada).Of note, the INTA Survey distinguished between protections for outputs that are AI-generated versus AI-assisted. The first category — ""Generated"" outputs — are those for which no human author exists (the only human contribution being ""pressing the button""). This category includes outputs produced by autonomous artificial intelligence systems (commonly known as ""generative AI"" systems). An example of such ""generative AI"" systems includes ChatGPT.The second category — ""Assisted"" outputs — are those generated by one or more humans using one or more AI systems as tools. While the INTA Survey results did indicate jurisdictions might protect such works in theory, protection in these instances would be tied to questions surrounding the requisite quantum of originality and human authorship required for copyright, and whether such conditions were satisfied with respect to the output in question. The INTA Survey did not explore in-depth the question of the level of human participation involved in creating AI-assisted outputs and how different levels of human involvement may affect the copyright analysis.Survey Results: The INTA Survey found that in jurisdictions without a sui generis right or other specific legislative language, whether the AI output in question is capable of attracting protection under copyright appears to be assessed with respect to the threshold question of ""originality"". The approach to assessing ""originality"" of a work for the purposes of copyright is neither internationally settled nor uniform. It varies between jurisdictions. For example, Canada's standard considers the ""skill and judgement"" of the author in producing the work. This will necessarily involve intellectual effort. As explained by the Supreme Court of Canada, ""skill"" means the use of an author's own ""knowledge, developed aptitude or practiced ability in producing the work"". ""Judgment"" means use of the author's ""capacity for discernment or ability to form an opinion and evaluation by comparing different possible options in producing the work"". Moreover, ""the exercise of skill and judgment must not be so trivial that it could be characterized as a purely mechanical exercise"" (such as changing a font to produce ""another"" work): CCH Canadian Ltd. v. Law Society of Upper Canada, 2004 SCC 13 at para 16. Originality is also relevant to copyright protection for compilations. A compilation takes existing material and casts it in different form. The Supreme Court has explained that the Copyright Act does not require originality in both the selection and arrangement; rather, originality in one will suffice to attract protection (i.e., originality in selection or originality in arrangement: Robertson v. Thomson Corp. 2006 SCC 43 at para 35, 37. Canada's approach differs from the approach taken in other jurisdictions. For example, the United States looks to whether there is ""a modicum of creativity"" (Feist Publications Inc. v. Rural Telephone Service Co., 499 U.S. 340 (1991) at p. 346 (USSC)), while the EU test for originality requires non-copying and the ""intellectual creation"" of the author"".The INTA Survey indicated that it remains unsettled how the originality test may apply to computer generated works. While human involvement and human originality will likely remain relevant, variabilities in the ""originality"" standard across jurisdictions may well lead to different results.AI-Generated Outputs: At the time the Survey was conducted, INTA found that only four countries have specific protections for ""computer generated works"".Of those four, only one (1) country — Ukraine — offered a sui generis right outside of copyright. This sui generis right protects non-original subject matter created by software (including AI) — i.e., outputs that differ from other works of a similar type and are created without the participation of humans. Rights arise at the moment of the output's creation There is no requirement that the output meet the ""originality"" requirement. Rights last for 25 years. They accrue to the owner or licensed user of the software that generated the output. Rights granted include the right to use, and to authorize (or prohibit) third-party use of the output. No moral rights arise in relation to protected outputs.The other three (3) jurisdictions found explicitly protected ""computer generated works"" — the UK, Ireland, and South Africa —do so under their respective copyright laws. In these jurisdictions, there is a definitional distinction between the AI-generated output (which is specifically deemed to be a protected ""work"" or ""creation"" under the legislation) and the ""author"" of that work, who is a human. The legislation approach here is to identify the ""author"" of the computer-generated work as the ""person by whom the arrangements necessary for the creation is undertaken."" The term of protection is not tied to the life of the author, but rather to an event — for example, the date the work is first lawfully made available to the public (Ireland), or from the date the work is made (UK), or some combination (South Africa). The remaining jurisdictions surveyed had either not yet dealt with the issue of copyright protection for AI output, or required an actual human creator.The INTA Survey Results Report identifies ways in which a ""neighbouring rights"" regime may be an appropriate avenue through which to protect AI-generated outputs. However, no jurisdictions were identified that currently took this approach.AI-Assisted Outputs: Conceptually, where AI is used to assist authorship (e.g., as a tool, resource, mechanism or means for human creation and to facilitate human expression) copyright is more likely to be available for the resulting work. By contrast, where work is the result of AI operating with no or limited contribution by a human, the work may not be protectable. In either case, the threshold question of ""originality"" would need to be assessed.Possible Application of Canada's Originality Test: As noted above, variabilities in the ""originality"" standard across jurisdictions may well lead to different resulting protections. As canvassed in the INTA Survey Results Report, the US Copyright Office's decision involving ""Zarya of the Dawn"" in February 2023, led to the refusal of copyright in the visual elements of a comic book created with the assistance of a generative-AI program (Midjourney AI), on the basis that the AI at issue did not render predictable results, and thus the human instructing the AI could not be deemed the ""master-mind"" behind the resulting images. However, protection was granted to those portions of the comic book entirely attributable to the human author (in that case, the text, and the selection, coordination, and arrangement of the work's written and visual elements). Based on the INTA Survey, and considering the different originality standards, the analysis in Canada would be different, and may well lead to a different result. Applying the Canadian test for originality, it is unsettled whether there could be sufficient ""skill and judgment"" exercised by the human author in generating the visual works that were compiled into the publication, and what level of involvement might be sufficient to shift the output from ""unoriginal"" (and thus not protected) to ""original"" (and thus protected). For example, whether the human author's exercise of ""skill and judgment"" to design the prompt(s) that produce the desired images (output), could be of a sufficient nature so as to render the resulting images (output) as ""original"" (and thus protected), or if an author's exercise of ""skill and judgement"" is limited to the prompt design, and does not flow through to the AI output produced by execution of that prompt.It is likely, however, that in a case like ""Zarya of the Dawn"", the human author's compilation of text and AI-generated images would satisfy the Canadian test for originality, and lead to as similar result with respect to protection of the work as a compilation, as occurred before the USCO. To illustrate how the Canadian jurisprudence has examined copyright protection for compilations, generally it has been held that while the arranger of a compilation does not have copyright in the individual components, the arranger may have copyright in the form represented by the compilation: ""It is not the several components that are the subject of the copyright, bbut the over-all arrangement of them which the plaintiff through his industry has produced"": Robertson v. Thompson Corp. 2006 SCC 43 at para 36, citing Slumber-Magic Adjustable Bed Co. v. Sleep-King Adjustable Bed Co. (1984), 3 C.P.R. (3d) 81 (B.C.S.C.), at p. 84; see also Ladbroke (Football) Ltd. v. William Hill (Football) Ltd., [1964] 1 All E.R. 465 (H.L.), at p. 469.",N/A,INTA is available to discuss our comments in more detail. Thank you in advance for considering the views of INTA.
Artisti (La société de gestion collective de l'Union des artistes inc.),Rights Organization,"Cette soumission constitue une position commune des associations et société suivantes :Artisti, une société de gestion collective canadienne représentant divers artistes-interprètes pour la gestion collective de leur droit à la rémunération équitable et leur droit à la rémunération découlant de la copie privée ainsi que tout ou partie de leurs droits exclusifs ;L’Union des artistes (UDA), un syndicat professionnel représentant les artistes de plusieurs disciplines œuvrant en français ou dans toute autre langue à l’exception de la production faite et exécutée en anglais ;La Guilde des musiciens et musiciennes du Québec (GMMQ), une association d’artistes légalement reconnue au Québec pour représenter les musiciens professionnels, notamment lors de la négociation d’ententes collectives visant leurs conditions de travail et de rémunération.Celles-ci voient le potentiel de l’IA à titre d’outil de création : plusieurs de leurs membres s’en servent d’ailleurs comme d’instruments leur permettant de livrer une prestation. Il est néanmoins essentiel d’encadrer l’utilisation de la technologie, particulièrement dans le contexte de la fouille de textes et de données (« FTD »), puisque les prestations des artistes interprètes sont actuellement utilisées à cette fin à leur insu, sans rétribution.","Une plus grande clarté et transparence permettraient de mieux appréhender le fonctionnement de la FTD, incluant la façon dont les prestations d’artistes interprètes sont utilisées, ainsi que les rôles et responsabilités des différentes parties prenantes. Ceci permettrait également de déterminer : (i) dans quel(s) contexte(s) l’analyse informationnelle est autorisée, ou non, par le régime actuel de droit d’auteur canadien et ainsi, (ii) quelles licences et rétributions doivent être versées aux titulaires des prestations d’artistes interprètes. Des activités de FTD sont actuellement menées au Canada, afin d’entraîner des modèles algorithmiques. Les activités de développement et d’entraînement de systèmes d’IA peuvent impliquer la reproduction de contenus protégés par droit d’auteur dont des prestations d’artistes interprètes ou leur voix et leur image hors prestation, et ce, sans qu’ils y consentent ou reçoivent une juste rétribution. Ceci est évidemment problématique et il importe d’y remédier. En outre, il est essentiel que l’autorisation (de type « opt-in » et non « opt-out ») des artistes interprètes soit obtenue préalablement à toute reproduction de leurs prestations, leur voix ou leur image, et qu’une rétribution juste et équitable leur soit versée en contrepartie de cette utilisation. L’obtention de ces consentements devra prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, un contentement distinct devra être obtenu auprès des artistes-interprètes si l’autorisation initialement consentie aux producteurs ne couvre pas la FTD, ce qui est le cas pour l’instant.À cet égard, il est également important de rappeler que les artistes interprètes qui ont consenti à ce que leurs prestations soient intégrées à une œuvre cinématographique ne peuvent présentement pas exercer leurs droits de l’article 15 (1) compte tenu de l’article 17(1) de la Loi sur le droit d’auteur et qu’ils ne peuvent pas non plus bénéficier de droits moraux à l’égard de ces prestations audiovisuelles. Afin de résoudre ces enjeux, le Canada devrait ratifier le Traité de Beijing, ce qui permettrait aux artistes-interprètes audiovisuels d’exercer un meilleur contrôle sur leurs prestations incorporées dans des œuvres cinématographiques.Les titulaires de droits face à des défis en lien avec en ce qui concerne l’octroi de licences pour les activités de FTD. En outre, il est difficile pour les artistes interprètes de déterminer quel contenu est utilisé dans le contexte de la FTD et quelle est l’ampleur de cette utilisation. Afin de pallier cette lacune, il pourrait être envisagé d’imposer une obligation de transparence ou de tenue de registres auprès des entités développant et entraînant des systèmes d’IA.Diverses licences sont disponibles pour les activités de FTD impliquant l’exercice d’un droit réservé aux titulaires de droit d’auteur, à savoir la reproduction. Ces licences peuvent être négociées de gré à gré avec les titulaires de droits d’auteurs incluant les artistes interprètes ou être obtenues par le biais d’une société de gestion collective. En effet, en ce qui a trait aux artistes interprètes, la possibilité de faire des reproductions de leurs prestations aux fins de la FTD n’est généralement pas incluse dans les autorisations qu’ils ont données aux producteurs d’enregistrements sonores ou d’œuvres cinématographiques, ces autorisations visant essentiellement l’exploitation commerciale des enregistrements sonores et des œuvres cinématographiques. Il faudrait donc que des autorisations aux fins de FTD soient obtenues auprès des artistes interprètes ou de leur société de gestion collective. Les artistes interprètes ou leur société de gestion collective seraient tout à fait à même de les émettre.Pour rappel :  ces licences ne semblent présentement pas être obtenues par les personnes menant des activités de FTD. Ceci crée évidemment un manque à gagner notamment pour les artistes interprètes qui peinent à obtenir une juste compensation pour l’utilisation de leurs contenus. Comme les prestations reproduites aux fins de FTD sont des prestations fixées sur des enregistrements sonores ou audiovisuels et qu’il s’agit de prestations d’œuvres, plusieurs mécanismes peuvent être envisagés pour compenser les ayants droits visés pour cette utilisation qui est faite de leurs prestations : l’introduction d’un droit à une rémunération équitable pour la FTD ou un droit à rémunération via un mécanisme semblable à celui de la copie pour usage privé font partie de ces mécanismes.La reproduction des prestations d’artistes interprète aux fins de la FTD ne pas couvertes par les dispositions contractuelles qui encadraient la fixation de ces prestations. C’est donc dire qu’aux fins de cette activité, l’autorisation de l’artiste interprète devrait donc systématiquement être obtenue. En effet, il ne faut pas oublier que la reproduction d’une prestation aux fins de la FTD impliquera souvent la reproduction de la voix et de l’image d’un artiste interprète (des données biométriques), qui sont des attributs de sa personnalité protégés par les droits de la personnalité, le droit à la vie privée et les législations en matière de protection de données personnelles. Compte tenu de ces différentes protections législatives, il semble donc impossible d’envisager une exception pour permettre l’utilisation de ces prestations impliquant la voix ou l’image d’un artiste aux fins de la FTD puisqu’un ensemble d’autres dispositions législatives contrecarraient et contrediraient l’introduction d’une telle exception.Nous ne sommes donc pas favorables à l’adoption d’une exception générale permettant la FTD, laquelle serait, par ailleurs, également contraire aux engagements du Canada en vertu de divers traités internationaux, tels que la Convention de Berne, l’ADPIC et l’ACEUM lesquels précisent que toute limitation ou exception à laquelle le Canada entend assujettir un droit d’auteur doit être restreinte à certains cas spéciaux où il n'est pas porté atteinte à l’exploitation normale de l’œuvre, ni causé de préjudice injustifié aux intérêts légitimes de l'auteur. Ainsi, si jamais le gouvernement décidait d’adopter malgré tout une exception de FTD (ce que nous ne recommandons pas), il devra veiller au respect de ses engagements internationaux, par exemple, en veillant à ce que l’exception soit : (i) limitée à des cas spécifiques (par exemple, à des fins de recherche) ; (ii) assujettie à des conditions d’application strictes (par exemple, l’accès à l’œuvre ou objet de droit d’auteur doit être licite) ; et (iii) assortie du versement d’une juste rétribution au bénéfice des titulaires de droits d’auteur, ainsi que d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur.Finalement, cette exception ne devrait pas s’appliquer aux droits moraux, mais uniquement aux droits dits « économiques ».Nous recommandons fortement la tenue de registre ou la divulgation des contenus protégés par le droit d’auteur qui ont été utilisés pour la formation des systèmes d’IA. Il s’agit d’une obligation essentielle qui devrait être intégrée dans la Loi sur le droit d’auteur. La transparence est l’un des principes fondamentaux qui devraient guider en tout temps les développeurs de systèmes d’IA.Le niveau de rémunération approprié pour l'utilisation d'une œuvre ou d'un objet du droit d'auteur dans les activités FTD doit être juste et équitable, basé sur les utilisations faites des contenus protégés. Dans tous les cas, la rémunération devrait être arrimée avec les autorisations obtenues et prendre en compte les particularités de chaque contenu reproduit. Par exemple, dans le cas des prestations fixées, une rémunération distincte devra être versée aux artistes-interprètes si l’autorisation initialement consentie aux producteurs des contenus reproduits ne couvrait pas la FTD.Comme exposé plus tôt, il n’est pas recommandé d’introduire une exception de FTD au Canada. Au contraire, il est essentiel de veiller au respect de la Loi sur le droit d’auteur et des autres dispositions législatives trouvant présentement application (tels que les droits de la personnalité et ceux liés à la protection des renseignements personnels qui sont en jeux lors de la reproduction des prestations d’artistes interprètes à d’autres fins que celles initialement consenties ou la reproduction de leur voix et leur image hors-prestations) en s’assurant que l’autorisation des artistes interprètes soit obtenue et qu’une rémunération juste et équitable leur soit versée lorsque leur contenu est utilisé à des fins de FTD.Nous recommandons également qu’une obligation de transparence ou de tenue de registres soit imposée aux chercheurs et développeurs de systèmes d’IA générative, dans le contexte de la FTD. Si toutefois le Canada souhaitait, en dépit de nos recommandations et en contravention des droits de la personnalité, droit à la vie privée et droits liés à la protection des renseignements personnels qui protègent la voix et l’image des artistes interprètes, introduire une exception de FTD, il devra veiller à ce que cette exception respecte les balises internationales, soit d’application limitée et assortie d’un mécanisme de retrait (« opt-out ») pour les titulaires de droits d’auteur. À cette fin, le gouvernement canadien pourrait examiner la situation prévalant au sein de l’Union européenne, la Suisse et le Royaume-Uni.",,,"La consultation publique est accueillie favorablement par nos organisations, lesquelles voient en cet exercice une volonté du gouvernement de clarifier les incidences de l’IA sur le droit d’auteur. Nos organisations ne souhaitent pas freiner l’avancement de l’IA, mais désirent préserver l’équilibre que la Loi sur le droit d’auteur sous-tend, en veillant à préserver la culture canadienne, la créativité humaine, ainsi que les intérêts des titulaires de droits d’auteur. Pour ce faire, nous recommandons que les principes regroupés sous l’acronyme « A.R.T. » (Autorisation, Rétribution et Transparence) guident les actions du gouvernement, dans le contexte de cette consultation publique et des possibles amendements à la Loi sur le droit d’auteur qui en découleront. Par ailleurs, il est important que la consultation publique ne se limite pas aux intérêts des auteurs et autres titulaires de droits d’auteur sur des œuvres, mais qu’elle couvre également les intérêts des artistes-interprètes sur leurs prestations ainsi que sur leur voix, leur image et leur ressemblance. L’IA générative bouleverse en effet grandement ces créateurs, notamment dans le contexte de l’hypertrucage (ou « deepfake » en anglais). À ce chapitre, les artistes-interprètes audiovisuels ne disposent pas de droits suffisants pour protéger leurs prestations, y compris dans le contexte de l’IA générative et de l’hypertrucage. Afin de pallier cette situation, il est recommandé d’étendre les droits exclusifs et les droits moraux de ces artistes, par exemple, en ratifiant le Traité de Beijing."
Intellectual Property Institute of Canada,Rights Organization,"The Intellectual Property Institute of Canada (IPIC) is the professional association of patent agents, trademark agents and lawyers practicing in all areas of intellectual property law. Our membership totals over 1,850 individuals, consisting of practitioners in law firms and agencies of all sizes, sole practitioners, in-house corporate intellectual property professionals, Government personnel, and academics. Our members' clients include virtually all Canadian businesses, universities and other institutions that have an interest in intellectual property (e.g., patents, trademarks, copyright, and industrial designs) in Canada or elsewhere, as well as foreign companies who hold intellectual property rights in Canada.IPIC is pleased to provide these comments in response to the consultation initiated on October 12, 2023, on Copyright in the Age of Generative Artificial Intelligence (AI), and the accompanying consultation paper issued by the Government of Canada.As a preliminary comment, IPIC remains of the view that the Government of Canada should navigate the interplay between copyright and AI with moderation and restraint. To the extent that stakeholders respond to the Consultation with evidence to suggest that the current copyright regime may not strike the right balance between copyright holders and users, IPIC encourages the Government to first report the evidentiary findings and to invite comment on possible policy implications and whether legislative change is needed based on the evidence. In IPIC's view, the current copyright regime is sufficiently flexible to allow for fair text and data mining activities, to recognize copyright protection in certain works created with the assistance of AI tools, and to appropriately allocate liability in cases of infringement involving AI. Legislative change appears premature; IPIC does not believe there is sufficient evidence to indicate that the current regime requires amendment at this time. Reflexive approaches that do not take into account the speed with which AI is evolving and the diversity of AI technologies have the potential to calcify rapidly stale-dated statutory schemes and to either create unreasonably broad copyright exemptions or to hamper innovation. Such approaches therefore miss the opportunity for courts addressing specific situations to find the appropriate middle ground, and risk disrupting emerging licensing markets benefitting both AI developers and copyright owners. It is also important to highlight that this conversation is not taking place in an isolated Canadian environment. These are questions that are being discussed globally, and Canada should proceed with caution to ensure that any actions we take are consistent with the evolving global standards and principles. Should any amendment be undertaken, it remains important that Canada respects its international treaty obligations, including with respect to the Berne Convention and other international agreements to which Canada is a party, while still making policy decisions that permit Canada to remain competitive internationally, and to remain generally aligned with our trading partners, particularly when it comes to AI.","The provisions contained in the current Copyright Act are likely sufficient to accommodate ""fair"" TDM activities in connection with copyright-protected works. Introducing specific provisions for TDM now would be prematureCanadian copyright law has long accommodated and embraced new technologies, including via the doctrines of fair dealing and technological neutrality. These doctrines are designed to balance the rights of owners and users in a predictable and fair manner. Accordingly, IPIC does not believe amendments to the Copyright Act (the ""Act"") pertaining to generative AI are necessary or appropriate at this time, including the introduction of any exceptions or limitations, such as an exception for TDM from the Act's requirements, just because AI is involved.IPIC supports preserving the existing legal framework for protection of copyright and related rights, including the doctrine of fair dealing applied in an appropriate manner to determine whether a statutory exception to copyright infringement applies (i.e. the dealing is for an enumerated purpose). In such cases, courts can then determine whether the dealing is ""fair"" in fact-specific circumstances based on the application of six non-exhaustive jurisprudential factors. While other countries have adopted more specific exception-based systems (e.g. Japan and Singapore), IPIC believes that Canada's existing fair dealing and technological neutrality frameworks are adequately robust and flexible to address novel AI uses predictably and fairly. IPIC predicts it would be difficult to draft a TDM exception into the legislation that properly calibrates various interests, whereas courts are best placed to conduct such analyses based on fact-specific circumstances. IPIC is of the view that there is no demonstrable need at this time for Canadian copyright law to adopt special fair dealing exceptions for AI, including any TDM exception. However, if Parliament is inclined to introduce a TDM exception it must be appropriately and carefully calibrated so that any use does not conflict with a normal exploitation of the work; does not unreasonably prejudice the legitimate interests of copyright owners or undermine the policy objectives of the Act; and does not conflict with Canada's obligations in relation to technological protection measures and rights management information under the WIPO Copyright Treaty, the WIPO Performances and Phonograms Treaty or the Canada-United States-Mexico Agreement.Another reason to refrain from introducing new exceptions is to prevent bad actors from relying on overbroad TDM exceptions as a pretext for both infringement and the downstream use of infringing works for unauthorized purposes. Further, as discussed below, copyright owners' licensing markets for training AI models have been developing, and amendments to the Act that would broadly exempt certain unauthorized uses could interfere with those emerging, mutually beneficial markets. Further, building conditions into a TDM exception to safeguard emerging models may invite complication.While AI will continue to raise many interesting and important copyright issues, at present IPIC is not aware of evidence to suggest that the Act and case law interpreting it are ill-suited to address these issues. As new issues arise, Canadian courts are well placed to approach these questions in a thoughtful and careful manner, using the existing flexible framework guided by the doctrines of fair dealing and technological neutrality. Accordingly, IPIC submits that any changes to legislation, if necessary, should support and bolster creators' control over their datasets and/or works, including the marketplace that enables a healthy open AI ecosystem and AI development.In time, there may be justification for the introduction of exceptions and/or limitations to address very specific fact situations.Affirmative Consent (Opt-Ins) to the Use of a Copyright Owner's Works for Training MaterialsAs a basic principle, if fair dealing or another copyright exception does not apply to the use of works for AI training, such use is infringing, and it is the user's obligation to affirmatively obtain consent from the owners to use the owners' works (i.e. opt-in processes). While some AI developers have taken a step in the direction of opt-out processes, proposals for opt-out processes present challenges for the proper implementation of consent systems and for enforcement of copyright.If it is decided that an opt-out process is workable then careful consideration should be given to the respective onuses of rightsholders and users (e.g. developers).Copyright Policy Should Support Voluntary Direct LicensingAs a matter of policy, the Act should strive to promote voluntary licensing transactions between copyright owners and prospective users. At this time, there are several emergent examples of copyright owners and companies engaged in training generative AI models and systems entering into voluntary licensing agreements, and therefore government intervention appears unnecessary. In fact, as it relates to certain industries, the emergence of direct voluntary licenses has already occurred, because some copyright owners have already entered into licensing agreements with AI companies. For example, the AI company Bria has a license with Getty Images that gives it rights to the photographs it uses for training. OpenAI has entered into license agreements with Shutterstock to pay for specialized content and with Associated Press to access the news agency's archive of stories.These types of agreements and policies show that market-based solutions, which both respect copyright owners' rights (and provide creators with market-based compensation), and facilitate the training of generative AI models are continuing to develop. Therefore, voluntary direct licensing is both feasible and desirable for different industries and for a variety of rights and uses. Copyright policy should support, not undermine, voluntary direct licensing schemes as they develop in the market. As such, there appears to be no reason to turn to compulsory licensing or extended collective licensing at this time.Transparency and Record Keeping on Materials Used to Train AI ModelsIPIC sees the benefits in obliging those who provide AI services or systems to the public to maintain appropriate records identifying the materials used to train their models. These records could allow rightsholders to track and license uses of their intellectual property while allowing the public and courts to meaningfully assess the lawfulness, as well as the reliability, of the developers' activities. Maintenance of such records may also be required because of anticipated litigation.Without such obligations, it may prove difficult for rightsholders to discern whether their works and other protected content were used in the development and training of models in such circumstances as when faced with system outputs suggestive of possible infringement or text and data mining activities of a character suggestive of unfair dealing with copyright-protected works or circumvention of technological protection measures. IPIC believes this deserves specific further study, including to help inform transparency requirements from a rightsholder's perspective to ensure their rights are properly balanced against the interests of those dealing in copyright-protected -works for fair text and data mining activities. In order to ensure the safety of these systems and to have functioning copyright and privacy frameworks, AI systems must be accountable for the works they ingest and are trained on. Accordingly, AI developers and creators of training datasets should ideally be required to collect, retain, and when requested by rightsholders, disclose records identifying the material used to train their models.While there was no consensus on whether amendments to the Act were the better means to achieve these objectives, it was suggested by some that Bill C-27, The Artificial Intelligence and Data Act (AIDA), which is intended to establish requirements for the design, development and use of AI systems, might provide a regulatory vehicle for such obligations. IPIC believes the Government of Canada should be thoughtful about the context and nuances of any recordkeeping requirements to ensure that policies are narrowly targeted to achieve the desired goal. It is also important that any suggested transparency and disclosure requirements not be overbroad in scope. Any record keeping requirements should respect confidentiality when all parties to the transaction (i.e. the owners of the training materials and the AI trainers) agree to maintain confidentiality.","IPIC does not believe amendments to the Act pertaining to generative AI are necessary or appropriate at this time, including to address questions of authorship and ownership of AI-generated works or AI-assisted works.Technologies utilizing some form of machine or computational intelligence have existed, and contributed to the creation of original expression for decades. Recent developments have advanced at a significant pace, but that does not necessarily mean that AI developments will require copyright law to evolve in a dramatically different manner. Developments in AI, like preceding technological advancements, have a great potential to enhance—not replace—human creativity. IPIC believes these developments can, and should, co-exist with a copyright system that incentivizes the creation of original expression and protects the rights of copyright owners.Humans are and will remain at the heart of the creative process, and as such, IPIC believes that consistent with the Act, fully machine generated works should not be copyrightable. At the same time, IPIC believes that AI, including potential uses of generative AI as it continues to develop, can be a powerful tool in the hands of authors. IPIC supports a robust copyright system that facilitates and provides incentives to create copyright protectable works, including by protecting certain works that creators make with the assistance of generative AI – in the same way that such principles apply to uses of other technologies that assist creators in realizing their vision.Generative AI broadly covers many variations of AI technologies, many of which have been in use for many years and should not raise the copyrightability and authorship issues presented by popular prompt-based tools.While AI will continue to raise many interesting and important copyright issues, based on its current knowledge of AI technology, including ""Generative AI"" IPIC believes the Act and case law interpreting it are well-suited to address these issues, and courts should apply existing copyright principles when addressing legal issues arising out of the use of AI technologies. For example, for copyright to subsist in a work, the work must be 'original'. Canadian courts have held that for a work to be 'original' it must result from the exercise of skill and judgment, which necessarily involves intellectual effort. The Supreme Court of Canada has held that the requisite ""skill"" will involve the use of an author's own ""knowledge, developed aptitude or practiced ability in producing the work"". The requisite ""judgment"" will involve the author's ""capacity for discernment or ability to form an opinion and evaluation by comparing different possible options in producing the work"". The author's exercise of skill and judgment must not be so trivial so as to be characterized as a purely mechanical exercise. The copyright regime also affords protection to compilations, which are works that result from the selection or arrangement of data, or of literary, dramatic, musical or artistic works or parts thereof. For a compilation to be original, the author must have exercised skill and judgment in either the exercise of selecting or arranging materials into the compilation. The Canadian standard for originality differs from that in other jurisdictions. We have yet to have a Canadian court apply the originality standard to AI generated or assisted works. The Canadian standard for originality will result in copyright protection for a work created where an author's skill and judgment is exercised, including if AI is used to assist the expressive activity. Separately, copyright protection would also arise where an author exercises skill and judgment in compiling works or data that have been generated using AI.IPIC believes that copyright should protect works that result from and reflect human expression, including where AI is a tool or assists in the authorship of original works. Conversely, copyright should not protect subject matter where there is no expressive contribution from a human author. The current Canadian originally standard appears to strike an appropriate balance. The authorship determination should continue to focus broadly on the question of originality, and in particular on the human author's exercise of skill and judgment, and the intellectual effort applied to the author's process and decisions to produce the work (for example, with respect to compilations, how the author selects, arranges, and/or positions elements of the ultimate work). Focusing on these human choices ensures that copyright subsists in original works that are derived from the author's ""skill and judgment."" The same reasoning can apply to human uses of generative AI. Input material provided to the AI tool (like a drawing or photo), refinements and direction all involve intellectual and creative contributions inseparable from the ultimate work. Creators can employ generative AI systems as tools to enhance the expressive process, just as they have availed themselves of software that render computer enhanced imagery, such as Adobe Photoshop, and received copyright protection for their works. The fact that creators produced some parts of a work with the assistance of AI should not render those portions uncopyrightable, provided the author exercised sufficient skill and judgment in the creation of the work to result in the work being original.While IPIC appreciates that some commentators call for additional clarity regarding the authorship and ownership of works generated by AI to create more certainty in the marketplace, IPIC cautions against introducing any exception to the longstanding principles of copyrightability when humans employ AI as a tool in their creative processes. Doing so at this time would be premature, and considering the rapid pace of development of AI technology and associated global standards and principles, appears likely to have unintended consequences. An approach that attempts to isolate the use of AI and treat it differently than other technologies used to support human-driven expression threatens to impair rather than stimulate and support creativity. The Government of Canada should therefore resist trying to draw definitive conclusions based on limited experience and information.","The Existing Liability Provisions Are Sufficient to Address Copyright InfringementAI technologies present new opportunities for third parties to make unauthorized use of works and infringing use of works that are substantially similar to those works.At least two potential scenarios implicate traditional principles of copyright law. First, if a pre-existing copyrighted work is copied to train an AI model, and then the AI system outputs a substantially similar copy, that scenario would present a clear case of infringement of the reproduction right. Second, users' prompts to AI systems may result in AI-generated outputs being unauthorized reproductions or adaptations of copyright works.With that context in mind, IPIC believes the existing liability provisions in the Act establish a general, well-accepted framework for analyzing claims of direct and secondary copyright infringement in the context of new technologies. While a precise determination of which parties are directly or secondarily liable will depend on the facts, courts should be able to apply traditional copyright principles to new technologies, given the robust case law in Canada regarding the principles of fair dealing and technological neutrality. As a result, IPIC does not believe amendments to the existing liability provisions in the Act to specifically address generative AI is necessary or appropriate at this time.",N/A
Motion Picture Association - Canada,Rights Organization,Please see MPA-Canada's responses to the other sections of the Consultation Paper.,"1) Exceptions/Limitations to Address Generative AI, including an Exception for Text and Data Mining (TDM), Should Not be IntroducedCanadian copyright law has long accommodated/embraced new technologies, including via the doctrines of fair dealing and technological neutrality. These doctrines are designed to balance the rights of owners and users in a predictable and fair manner. MPA-Canada does not believe amendments to the Copyright Act pertaining to generative AI are necessary/appropriate at this time, including the introduction of any exceptions/limitations, such as an exception for TDM from the Copyright Act’s requirements, just because AI is involved.Commercial uses in the context of training AI models should not be treated differently than other commercial uses. The Government should navigate the interplay between copyright and AI with moderation, restraint, and respect for copyright. Reflexive approaches that do not take into account the speed with which AI is evolving and the diversity of AI technologies have the potential either to create unreasonably broad copyright exemptions or to hamper innovation. Such approaches miss the opportunity to find the appropriate middle ground and risk disrupting emerging licensing markets benefitting AI developers and copyright owners.MPA-Canada supports the existing international legal framework for protection of copyright and related rights. That framework provides a principled consistency based on global norms while still allowing for differences in national approaches, e.g., Canada relies on “fair dealing” to determine whether a statutory exception to copyright infringement applies (i.e., the dealing is for an enumerated purpose). If a statutory exception applies, the court will then determine whether the dealing is fair in fact-specific circumstances based on the application of six non-exhaustive factors, an approach that is similar to that applied by courts in the U.S. in respect of the “fair use” defence. While other countries have adopted more specific exception-based systems, MPA-Canada believes that in its current state, the existing “fair dealing” and “technological neutrality” frameworks are sufficiently robust to address novel AI uses predictably and fairly. At this time, there is no need for Canadian copyright law to adopt special exceptions to copyright for AI, including a TDM exception.In contrast to the approach under Canadian law, which applies doctrines designed to balance the rights of owners and users in a predictable and fair manner, other jurisdictions have hastily introduced broad/inflexible TDM exceptions in the name of promoting innovation, e.g., Japan has enacted a “non-enjoyment” exception for TDM, which generally exempts TDM from the requirements of Japanese copyright law, provided: (1) it is “not a person’s purpose to personally enjoy or cause another person to enjoy the thoughts or sentiments expressed in [the copyrighted] work”; and (2) the use does not “unreasonably prejudice the interests of the copyright owner in light of the nature or purpose of the work or the circumstances of its exploitation.” Singapore’s TDM exception is equally broad and does not provide any ability for rightsholders to opt out. Aiming to address creators’ concerns and to minimize risks of copyright infringement by AI developers and users, the Japanese government is consulting on the relationship between AI and copyright around the scope of the TDM exception, particularly the lack of a lawful access requirement and an opt out for rightsholders.MPA-Canada submits these types of exemptions are bad policy, and they likely fail to comply with the Berne Convention’s “three-step” test, e.g., bad actors may use overbroad TDM exceptions as a pretext for both infringement and the downstream use of infringing works for any purpose. As discussed below, copyright owners’ licensing markets for training AI models have been developing and amendments to the Copyright Act that would broadly exempt certain unauthorized uses would interfere with those emerging, mutually beneficial markets. MPA-Canada believes the Copyright Act should not be amended to adopt broad exceptions that Japan, Singapore, and other jurisdictions have enacted, and should instead adhere to the fair dealing and technological neutrality frameworks for analyzing particular use cases.  While AI will continue to raise many interesting/important copyright issues, the Copyright Act and case law interpreting it are well-suited to address these issues. As new issues arise, Canadian courts are well placed to approach these questions in a thoughtful/careful manner using the already flexible framework provided under domestic copyright law. Accordingly, the Government should resist trying to draw definitive conclusions for nascent technologies based on limited experience and information. To the extent developers wish for certainty in their use of copyrighted works to train AI systems, they can always seek licenses from the copyright holders. Such licensing will also help avoid other concerns about AI use, because the training inputs are likely to be of higher quality, tailored to the specific AI system’s needs, and supported by the requisite consents, minimizing risks of error, bias, and violations of privacy.2) Affirmative Consent (Opt-Ins) to the Use of a Copyright Owner’s Works for Training MaterialsAs a basic principle, if “fair dealing” or another copyright exception does not apply to the use of works for AI training, such use is infringing and it is the user’s obligation to affirmatively obtain consent from the owners to use the owners’ works, i.e., opt-in.While some AI developers have taken a step in the direction of an opt-out process, proposals for opt-out processes present significant challenges for the proper implementation of consent systems and for enforcement of copyright. In addition, proposals for opt-out may also prove to be unworkable.At present, there are two main types of opt-out: (1) opting out with the AI developer directly, which some AI developers require to be done for each individual piece of content; and (2) tagging the content with metadata so parties know the owner does not consent to training. Because MPA Members’ libraries include thousands of works and promotional/other material, the sheer scale/volume means these proposed opt-out regimes will likely be insufficient/overly burdensome for the copyright owner. Moreover, such solutions likely will not address the problem of infringing content used as training material.In general, the AI developer, and not copyright owners, should bear the burden of establishing a high-functioning, accessible, and reliable process for copyright owners to opt-out. This is because using others’ works to train AI models benefits the developer of the model. If opt-out is required, it must at a minimum: (1) allow copyright owners to exercise an opt-out covering all of the works they own without the need to specify every work/location where an owned work might be found on the internet; and (2) require the AI developer to ensure the opt-out is honoured, and not require copyright owners to police the model for individual works/excerpts.3) Copyright Policy Should Support Voluntary Direct LicensingCopyright legislation should always promote voluntary licensing transactions between copyright owners and prospective users. Any variations from traditional direct individual licenses should be initiated/tailored to the needs of the particular copyright owner industry.At this time, there is no reason to believe that copyright owners and companies engaged in training generative AI models and systems cannot enter into voluntary licensing agreements, such that government intervention might be necessary. As it relates to certain industries, the emergence of direct voluntary licenses has already occurred because some copyright owners have already entered into licensing agreements with AI companies, e.g., the AI company Bria has a license with Getty Images that gives it rights to the photographs it uses for training. OpenAI has also entered into license agreements with Shutterstock to pay for specialized content and with Associated Press to access the news agency’s archive of stories. These types of agreements/policies show that market-based solutions, which both respect copyright owners’ rights (and provide creators with market-based compensation) and facilitate the training of generative AI models, are continuing to develop. Voluntary direct licensing is feasible/desirable for different industries and for a variety of rights/uses. Copyright policy should support, not undermine, voluntary direct licensing schemes as they develop in the market. There is no reason to turn to compulsory licensing or extended collective licensing at this time.4) Transparency and Record Keeping on Materials Used to Train AI ModelsMPA-Canada sees the benefits in having those who provide AI services/systems to the public maintain and make available appropriate records regarding the materials used to train their models. These records would allow the public/courts to meaningfully assess the lawfulness/reliability of the developers’ activities. Maintenance of such records may also be required because of anticipated litigation.MPA’s Members believe the Government should be thoughtful about the context/nuances of any recordkeeping requirements to ensure that policies are narrowly targeted to achieve the desired goal. MPA’s Members appreciate that the questions raised in the consultation are meant to apply only to AI developers rather than copyright owners’ potential use of their own copyrighted works. However, it is important that any suggested transparency/disclosure requirements not be overbroad and not apply to copyright owners’ potential uses of their own copyrighted works, or content routinely generated with their own works with the assistance of AI.","1) Amendments to the Copyright Act Are Not Needed to Address Questions of Authorship and Ownership of Works Generated by AIMPA-Canada does not believe amendments to the Copyright Act pertaining to generative AI are necessary or appropriate at this time, including to address questions of authorship and ownership of AI-generated works or AI-assisted works.Technologies utilizing some form of machine or computational intelligence have existed, and contributed to, the creation of original expression for decades. Recent developments have advanced at a significant pace, but that does not necessarily mean that AI developments will require copyright law to evolve in a dramatically different manner. Moreover, AI-specific changes to copyright law would violate principles of technology neutrality.Developments in AI, like preceding technological advancements, have a great potential to enhance – not replace – human creativity. MPA’s Members further believe these developments can, and should, co-exist with a copyright system that incentivizes the creation of original expression and protects the rights of copyright owners. Humans are and will remain at the heart of the creative process, and as such, MPA-Canada believes that, consistent with the Copyright Act, fully machine generated works should not be copyrightable. At the same time, MPA’s Members believe that AI, including potential uses of generative AI as it continues to develop, can be a powerful tool in the hands of human artists and those involved in creating motion pictures to enhance and serve the filmmaking process. MPA-Canada supports a robust copyright system that facilitates and provides incentives to create movies, television programs, and other art forms, including by protecting certain works that human creators make with the assistance of generative AI – in the same way that such principles apply to uses of other technologies that assist creators in realizing their vision.AI is a tool that can, and does, assist creators in the creative process. Given that reality, creators who use AI as a tool to assist them with their creation of original expression do produce human-authored copyrightable works. Generative AI broadly covers many variations of AI technologies, many of which have been in use for many years and should not raise the copyrightability and authorship issues presented by popular prompt-based tools. MPA’s Members may use AI as a production and post-production tool in the hands of human creators to enhance expressive material.For example, animators and visual effects artists for decades have used a process called “rotoscoping”, which involves manually altering individual frames within a single shot to align live-action and computer-generated images and is incredibly detail oriented and time consuming. Contemporary visual-effects artists now have sophisticated tools, some of which incorporate AI technology, to assist with this type of work, which frees artists to focus their energies on the creative aspects of the visual effects.  AI also helps creators realize their vision and enhance the audience experience by making visual effects more dramatic, realistic, and memorable. Creators can use AI for everything from colour correction, detail sharpening, and de-blurring; to removing unwanted objects from a scene; to more involved work like aging and de-aging an actor; or to adjusting the placement of computer-generated images to make sure everything in a scene flows smoothly and aligns properly.  Artists have expressed enthusiasm for AI tools that enhance their work, and for continued technological development of these and similar tools.  In short, the use of AI technology presents developing opportunities for creators and their audiences. MPA’s Members are optimistic about that future.While AI will continue to raise many interesting and important copyright issues, based on their current knowledge of AI technology, including “Generative AI”, MPA Members believe the Copyright Act and case law interpreting it are well-suited to address these issues and courts should generally apply existing copyright principles when addressing legal issues arising out of the use of AI technologies. In particular, MPA-Canada believes the authorship determination should focus broadly on the human author’s creative process and decisions, e.g., how to arrange, select, and position elements of the ultimate work.  Focusing on these creative choices ensures that copyright subsists in original works that are derived from the author’s “skill and judgment.” The same reasoning can apply to human uses of generative AI: material they provide to the AI tool (i.e., inputs, like a drawing or photo), refinements, direction, and then use of the output can all involve intellectual and creative contributions inseparable from the ultimate work. Creators can employ generative AI systems as tools to enhance the creative process, just as they have availed themselves of cameras and Adobe Photoshop and received copyright protection for their works.This point is particularly important for MPA’s Members’ works. Perhaps different from the creation process for literary, visual, or even musical works, the motion picture creation process is exceedingly complex in the number and type of creative contributions, across sometimes thousands of individuals. A large motion picture may include dozens of individuals working in writing and story, the art department, camera and electrical, stunts, sound and music, special effects and visual effects, makeup, animation, costume and wardrobe, production, editing, and more. Many of these individuals contribute creative elements to the ultimate motion picture. They may use AI technologies, including using those that potentially qualify as generative AI, as a tool to enhance materials humans create.  These elements are then interwoven into a single motion picture work.The fact that creators produced some parts of the film with the assistance of AI should not render those portions uncopyrightable. The practical result would be untenable. Take a hypothetical example of a superhero motion picture. The movie might be copyrighted, but would a scene involving AI-assisted visual effects depicting a battle in space receive the same protection? Can a studio protect its rights if the underlying characters and scene script are protectable, but the visual output that involves the AI-assisted effects is not?While MPA-Canada appreciates that there are calls for additional clarity regarding the authorship and ownership of works generated by AI to create more certainty in the marketplace, there also should not be an exception to the longstanding principles of copyrightability when humans employ AI as a tool in their creative processes. An approach that attempts to isolate the use of AI and treat it differently than other technologies used to support human-driven creativity threatens to impair rather than stimulate and support creativity. The Government of Canada should therefore approach these questions in a thoughtful and careful manner and should resist trying to draw definitive conclusions based on limited experience and information.","1) The Existing Liability Provisions Are Sufficient to Address Copyright InfringementMPA’s Members have an obvious interest in robust copyright protection and enforcement and are acutely aware that AI technologies present new opportunities for third parties to make unauthorized use of MPA Members’ works.The importance of meaningful copyright protection and enforcement cannot be overstated. MPA’s Members make enormous investments in the creation of their copyrighted works. Copyright rights, including the right to license their exclusive rights to others, provide MPA’s Members the opportunity to recoup those investments and to create new content.  Unauthorized (and uncompensated) use of MPA Members’ works undermines this entire process.MPA Members’ copyrighted works likely have been, or will be, the subject of unauthorized reproductions in the context of training AI models.  Likewise, users of AI tools have used, and will continue to use, that technology to create unauthorized copies of MPA Members’ works and infringing works that are substantially similar to MPA Members’ intellectual property. It is imperative that the unauthorized exercise of the rights of MPA’s Members, whether through the use of AI or any other technology, remain subject to meaningful enforcement and remedies.There are at least two potential scenarios that implicate traditional principles of copyright law: (1) if a pre-existing copyrighted work is copied to train an AI model, and then the AI system outputs a substantially similar copy, that scenario would present a clear case of infringement of the reproduction right; and (2) if AI-generated outputs are then distributed or otherwise made available to third parties, those outputs could then infringe not only the reproduction right, but also other exclusive rights under copyright law, including communication to the public, making available, adaptation, and the authorization rights.  Additionally, if copyrighted works are used as inputs to an AI system, it is possible that such use infringes the reproduction right, regardless of the ultimate output.With that context in mind, and provided exceptions and limitations are not introduced, MPA-Canada is of the view that the existing liability provisions in the Copyright Act establish a general, well-accepted framework for analyzing claims of direct and secondary copyright infringement in the context of new technologies. While a precise determination of which parties are directly and/or secondarily liable will depend on the facts, courts should be able to apply traditional copyright principles to new technologies, given the robust case law in Canada regarding the principles of fair dealing and technological neutrality. As a result, MPA-Canada does not believe that amendments to the existing liability provisions in the Copyright Act to specifically address generative AI are necessary or appropriate at this time.","MPA members’ use of technology exists against the backdrop of a stable legal regime governing the rights and responsibilities of copyright owners and consumers alike.  The Canadian copyright system functions well and has successfully accommodated technological change since its inception.  Based on their current knowledge of AI technology, including “Generative AI”, MPA’s members believe courts should generally apply existing copyright principles when addressing legal issues arising out of the use of AI technologies and that there should be no blanket exemption from the Copyright Act’s requirements just because AI is involved.  In ensuring a careful and considered approach to AI and copyright, and avoiding disruption of emerging markets, there are no grounds to deviate from fundamental copyright principles."
"Access Copyright, The Canadian Copyright Licensing Agency",Rights Organization,"Access Copyright is a not-for-profit reproduction rights organization (RRO) that licenses the reproduction of works whose copyright is owned by creators and publishers with whom it has affiliation agreements.Access Copyright, along with the Canadian creative sector, supports innovation in artificial intelligence (AI) technology, provided that policy measures taken in respect of generative AI are mindful, ensure that existing copyright law is respected and generative AI is used responsibly and ethically, and incorporate matters of importance to creators and rights holders, in order to ensure a level playing field between the creative industries and the technological sector.","The Copyright Act is fit for purpose. Text and data mining (TDM) and the training of generative AI platforms engages the exclusive rights of the copyright holder in respect of their works, and TDM activity does not fall under existing fair dealing exceptions. It is Access Copyright’s submission that no exceptions for TDM activities should be introduced or required under the legislation.TDM activity in CanadaThere is no question that TDM activity is occurring in Canada. Generative AI models take in data via TDM activity, scraped from webpages or fed directly to large language models (LLMs); this activity occurs without borders, including in Canada. As the Canadian AI industry grows, the amount of TDM activity occurring in Canada is likely to increase further. For example, Cohere is a Canadian multinational tech company focused on artificial intelligence and LLMs, that recently announced new financing to accelerate their pace of development (https://txt.cohere.com/announcement/).When generative AI platforms engage in TDM activities, the platform’s consumption of copyrighted works constitutes complete or at least substantial reproductions of such works. TDM activities, like other substantial reproductions, fall under the exclusive rights of rights holders, and require a license before the work is used for such purpose.  It appears that most, if not all, of the LLM models are currently profiting from unauthorized use and reproduction of copyright protected works, infringing both the economic rights of rights holders and the moral rights of creators.There are already many exceptions to copyright law in Canada, which have created an imbalance that has prevented rights holders from receiving fair compensation for their work and has discouraged creators from making and sharing new material. For instance, the addition of ""education"" as a fair dealing purpose in 2012 has led to over a decade of litigation and a loss of $200 million in royalties for Access Copyright's affiliates. Many publishers and creators have since stopped publishing for the education sector, thus depriving Canadian classrooms and students of new Canadian content. Introducing any new exceptions for TDM would further disrupt the balance the Copyright Act aims to achieve.While clarity around copyright and TDM in Canada is a laudable goal, it is unlikely to be fully achievable, given the fast pace at which technology and the market are evolving. Importantly, the rights market for AI and TDM is still developing. There are serious risks in hastily assuming any new technology automatically requires new copyright exceptions before its full impacts are clear and the rights market has adapted to the new uses. Reflexive reactions cannot adequately consider the speed at which generative AI is advancing and how quickly it may transform creative industries. The introduction of exceptions for TDM activities would encroach on and undermine present and future rights markets, resulting in an unknown quantum of harm to the creative sector.Licensing of TDM activitiesIn jurisdictions around the world, including Canada, many types of licenses and models are emerging to address the TDM needs of different use cases.  Many publishers directly license their works for TDM purposes, as do some copyright collectives. For example, the Copyright Clearance Center, a copyright collective based in the United States, provides a RightFind XML for Mining license (https://www.copyright.com/businesses/xmlformining/).  Other industry players such as Elsevier, a journal publisher, have also successfully engaged in TDM licensing (https://www.elsevier.com/about/policies/text-and-data-mining). Newspapers license their articles for TDM for media monitoring and news aggregation purposes (https://www.canada.ca/en/canadian-heritage/campaigns/fair-revenue-sharing/stakeholder-engagement.html). The non-fiction book summary service get Abstract works with publishers and obtains copyrights to all books they summarize to add to their library (https://support.getabstract.com/en/knowledge/summaries-copyright). In short, many businesses are willing to pay for TDM licenses because they recognize the value of the works licensed.It is essential that both direct licensing and collective licensing by rights holders for TDM activities are allowed to flourish, permitting the development of a vibrant Canadian rights marketplace, where generative AI developments exist alongside the protection of the rights of copyright holders and fair compensation when their works are used by AI platforms. Creators must have the ability to control when their protected works are used for TDM purposes. When a creator chooses to allow such use via license, they should have the opportunity to participate in the value generated by AI systems that they have contributed to by virtue of the platform using their protected works.As an example of a foreign government recognizing the need to maintain and grow a vibrant rights market for the benefit of the creative sector, the UK’s current version of its Artificial Intelligence (Regulation) Bill has abandoned an expanded TDM exception in order to maintain a rights marketplace where rights holders are fairly compensated for use of their works, while still allowing the AI sector to grow (https://www.allenovery.com/en-gb/global/blogs/data-hub/uk-re-considers-proposed-exception-for-text-and-data-mining).As the market for TDM evolves, various entities are and will continue to offer access to data, protected works, and licenses, including collective licenses, for generative AI training purposes. The costs of such licenses will properly continue to vary by supplier and the content covered by the license. In a robust and balanced licensing market, the appropriate cost of licensing for TDM will adjust organically with that evolving market, as negotiated by parties on equal footing. The government should not insert itself in these negotiations, as doing so would impede the development of market-based solutions for TDM.Should TDM activities be determined by a court to be subject to an existing fair dealing exception under the Copyright Act or should a new exception specifically for TDM activity be created, the Canadian rights market would be dramatically hindered or subverted entirely, unfairly impacting creators and allowing large generative AI systems to be the sole beneficiaries deriving value from the creative works ingested by their platforms. As such, policy measures taken in respect of generative AI technologies must always ensure that rights holders of copyrighted works can effectively license and enforce their rights in respect of their protected works.Transparency obligations of AI developersRights holders face difficulties licensing works for TDM due to a lack of transparency into how AI systems use their content. This lack of transparency enables some platforms to take a bullish attitude that no authorization is needed under copyright law or that their systems are non-infringing, offering indemnification despite protests over fair use from executives like the one who resigned from Stability AI (https://www.bbc.com/news/technology-67446000). Binding transparency obligations on generative AI systems, like those proposed in Europe, would help address this issue by illuminating how rights holders' works are used and correcting the information imbalance that allows licensing challenges to persist.Both consumers and rights holders must know how protected works are being used by the platform in question. Further, record keeping and disclosure obligations by generative AI platforms are necessary for such rights holders to know when their works are being used by AI systems.Currently, there is no transparency in respect of TDM activities. TDM activity is taking place within a “black box,” where rights holders know it is happening, but due to the information asymmetry between themselves and AI platforms, they cannot determine who is conducting the activity, with whose works, and have no mechanism to stop it from happening.Without robust transparency requirements, rights holders have an impossible evidentiary burden to demonstrate that AI platforms have infringed their copyright in the consumption of their protected works via the TDM process. To rectify this imbalance, generative AI systems must be required to disclose the source records of all protected works used to train their platforms, allowing a rights holder to determine when and how their protected work has been used.Serious harm to the creative and cultural sectorThe substantial reproduction of works undertaken in the process of TDM must only be permitted on a licensed basis, where creators must be able to choose whether to license the use of their works to train LLMs.While there is currently an emerging market for the licensing of TDM activities in Canada, lack of transparency requirements undermines the ability of rights holders to fully engage in ensuring, in the appropriate circumstances, that the use of their works is properly licensed. The creation of a TDM exception would severely reduce, if not destroy, this emerging and growing rights market. Importantly, rights holders must be able to prohibit outright the use of their works for AI training purposes where such use might potentially substitute the market for the original work.The creative industry in Canada can only thrive where rights holders can give or withhold permission for AI platforms to use their works, and where such permission is given, those rights holders are fairly compensated for the use of those works.","It is a fundamental principle of copyright that copyright protection is available exclusively for human creators. A key threshold under the Copyright Act is that a work must be original, meaning it cannot simply be a replication of another work, and must result from a process involving an exercise of the author’s skill and judgment (CCH Canadian Ltd v Law Society of Upper Canada, [2004] 1 SCR 339, 2004 SCC 13).  The necessary skill and judgment to meet the standard of originality simply cannot be exercised by a machine. Consequently, AI-assisted works may only receive copyright protection if humans have significantly contributed to and imparted the necessary exercise of skill and judgment. In contrast, outputs entirely generated by AI are not eligible for copyright protection, as they lack human input and insight.Moreover, we recommend that when an output is fully AI generated, without human contribution, it must be clearly labelled to indicate that it has been generated solely by an AI tool. This labelling requirement ensures that consumers are informed that what they are viewing or reading is the product of generative AI, preventing any potential misleading of the public regarding the nature of the content.Human creativity and expression in the creation of copyrightable works must be prioritized, in order to maintain our cultural expression, diversity and discourse in Canada. Canada’s cultural expression through books, magazines, visual art, music, movies, and other works is a demonstration of how we share our values and beliefs, build Canadian culture, and maintain a sovereign cultural identity.Canada’s cultural industry is a significant and valuable economic driver, as well. Currently, the arts, cultural and heritage sector represents more than $57 billion in the Canadian economy, and contributes 673,000 jobs to the Canadian marketplace (https://www.canada.ca/en/canadian-heritage.html).We strongly encourage the Government of Canada to make decisive, sensible, and prudent decisions to ensure the responsible deployment of generative AI. Careful consideration and creation of policy measures are necessary to prevent the overshadowing or silencing of the human voices, that are so integral to Canada’s rich tapestry of cultural expression, by AI generated content.The unchecked expansion of generative AI, in the absence of adequate policy measures, poses a risk of further consolidating power within major technology platforms, predominantly non-Canadian entities, which already dominate the spheres of content discovery and distribution. The advent of automated content creation and production by AI tools could enable these platforms to exert control over the entire spectrum of the Canadian cultural value chain, from creation to distribution. This scenario underscores the need for strategic policy interventions to maintain a diverse and balanced cultural ecosystem.","TDM and the training of generative AI with copyright protected works certainly infringes the exclusive rights of rightsholders; however, such clarity of position is insufficient to allow rightsholders to make infringement claims against those platforms that would ingest their protected works without permission.Without AI developers and platforms being required to offer full transparency regarding the works used to train generative AI models, rightsholders face an insurmountable challenge in proving infringement of their protected work. Establishing that infringement has occurred requires that a rightsholder prove: (1) a defendant copied or made available all or a substantial part of its protected work, (2) the defendant had access to the original work, and (3) that the original work was the source of the copy. It is nearly impossible for a rightsholder to provide evidence to these ends without AI developers being subject to obligations of robust transparency about the works used to train their AI platforms.To rectify the information imbalance between rightsholders and generative AI systems, all AI platforms must be required to publicly disclose and keep accessible traceable records of the works used to train their systems. This level of transparency is essential to enabling rightsholder to ascertain if their work has been used by the AI system for training purposes, constituting an infringement if done without the rightsholder’s consent. Provided such record-keeping and disclosure obligations are put in place, the Copyright Act would be sufficient to address issues of infringement specific to generative AI.The EU’s new AI Act has dedicated rules for generative AI systems to ensure transparency along the value chain. We recommend that the government adopt legally binding transparency obligations to generative AI systems, at least as stringent as those recommended by the European Parliament.Requiring generative AI systems to publish records of ingested copyrighted content is necessary so copyright owners can protect and monetize their intellectual property.  With transparency obligations in place, the current Copyright Act's infringement provisions will be sufficient to address generative AI issues, while transparency will promote a more efficient licensing market by reducing information asymmetry.",N/A
"American Society of Composers, Authors and Publishers (ASCAP)",Rights Organization,N/A,N/A,N/A,N/A,"ASCAP is one of the world’s leading music performing rights organizations (“PRO”), currently representing over 950,000 songwriter, composer and publisher members and a repertory of over 19 million copyrighted musical works.ASCAP receives from its members a global, non-exclusive grant of right to license public performance rights in the copyrighted works known as “musical compositions” on all platforms and services. It does not today license any rights other than those associated with public performances of musical compositions, such as mechanical rights and synchronization rights, and it does not license the copyright in the sound recording (a separate copyright from musical compositions).ASCAP collectively licenses the non-dramatic public performance rights of its members’ musical compositions on a non-exclusive basis to music users (i.e., licensees) that publicly perform music in virtually every communications media, including internet-delivered audio-only and audiovisual video streaming (both interactive and non-interactive), terrestrial radio, broadcast television, cable and satellite, in-person performances at bars or concerts, as well as background music in stores, fitness centers and dance schools, and many more. ASCAP’s primary business is offering music users “blanket licenses,” meaning that in exchange for a fee, the licensee may use any amount of music in the ASCAP repertoire. The “blanket license” has long been known as the most efficient and cost-effective form of licensing at scale and could be a reasonable form of licensing for AI.  Society of Composers, Authors and Music Publishers of Canada (or “SOCAN”) operates as a similar collective licensing organization in Canada.ASCAP represents not only U.S. writers and publishers, but also hundreds of thousands of non-U.S. writers and publishers through binding agreements that are often reciprocal in nature with approximately 100 foreign Collective Management Organizations (“CMOs”) that cover nearly every country in the world, including an agreement with SOCAN with regard to Canada. Through these agreements, ASCAP is permitted to license in the U.S. the public performing rights in hundreds of thousands of musical works controlled by non-U.S songwriters and composers. When the agreements are reciprocal, ASCAP likewise receives royalties from those foreign CMOs for performances of ASCAP musical works occurring overseas, including for performances in Canada.ASCAP is the only PRO in the U.S. that operates on a not-for-profit basis. In accordance with ASCAP’s Articles of Association, all dollars collected less expenses (and a broad-approved reserve) are distributed to ASCAP members based on performances of their copyrighted works by licensees—about 90 cents of every dollar collected goes back to ASCAP’s members as royalties, meaning that ASCAP’s current overhead is 10%. All of ASCAP’s competitors in the U.S. operate on a for-profit basis and are owned by U.S. broadcasters, private equity and other investors.In addition to licensing its members’ work on their behalf, ASCAP enforces its members’ rights when their copyrighted works are performed publicly without authorization. To that end, ASCAP brings copyright infringement lawsuits in U.S. Courts throughout the country regularly on behalf of its members to enforce their rights to be paid.ASCAP is thus well-positioned to comment on behalf of the nearly one million songwriter, composer, and music publisher members whose rights and livelihoods it protects. Because most ASCAP members are not sound recording artists and accordingly do not have opportunities to be paid for concert tours, merchandise, and related projects, the public performance royalties paid to these members are often their only source of income. In the event that AI platforms usurp this revenue stream, untold numbers of creators stand to lose their ability to make a living.While generative AI has the potential to enhance human creative efforts, the unchecked use of this technology threatens to undermine the very purpose of the copyright laws by supplanting, rather than supporting, human creative work. Accordingly, the AI industry must be held responsible under all applicable laws—including existing copyright laws and state and federal legal frameworks—to ensure that it does not unfairly and illegally exploit the work of human artists, writers, and other creators. In June 2023, the ASCAP Board of Directors unanimously approved and publicly announced that the following principles should govern the development and use of generative AI.In accordance with these principles, ASCAP believes voluntary collective licensing is the best way to harness the power of generative AI while preserving the livelihoods of creators. Collective licensing has long been a staple in the music industry and has adapted to major technological developments such as an industry-wide shift to digital music consumption at the turn of the millennium. AI will be no exception.As demonstrated by the hundreds of thousands of businesses that currently license public performance rights from ASCAP, voluntary collective licensing is practically feasible and mutually beneficial for both creators and businesses that derive value from the use of copyrighted musical works. Similarly, the AI industry can and should obtain consent and pay fair market value for copyrighted musical works before using them in the development of AI models. In fact, OpenAI reached a licensing deal with the Associated Press in July this year for the use of the latter’s news archive in the development of generative AI models. Such licensing efforts need to be widely adopted across creative industries.The main obstacle to voluntary collective licensing is the lack of willingness on the part of AI providers to come to the negotiation table with the creators. AI providers have been operating under the presumption, albeit a false one, that their use of unlicensed copyrighted works for training AI models is legal and somehow a “fair use”. The lack of transparency from AI providers concerning their use of copyrighted works in AI training also makes it extremely onerous for creators to enforce their rights and thus deprives them of meaningful bargaining power.Therefore, the following measures are necessary to create the relevant incentives that can bring about meaningful voluntary licensing negotiations:On the issue of the copyrightability of AI-generated works, this should be determined on a case-by-case basis, taking into account the nature and degree of human involvement. When a human significantly edits, manipulates, or alters the output generated by an AI tool, the resulting material should be subject to copyright protections to the extent the work reflects human creativity. We point you to the recent guidelines established by the U.S. Copyright Office as a foundational basis.In closing, we wish to emphasize that international consistency is crucial for the licensing of musical works. As PROs across the world—like ASCAP in the U.S. and SOCAN in Canada —cross license their repertories and require uniformity in certain copyright administration rules and systems, it is important to ensure that countries adopt consistent regulations concerning AI. Otherwise, loopholes can develop that can disrupt music use and enforcement of laws in other countries."
Canadian Artists' Representation / Le Front des artistes canadiens (CARFAC),Rights Organization,"Canadian Artists’ Representation / Le Front des artistes canadiens (CARFAC) is the national association for visual and media artists in Canada. We represent 4,000 artist members across Canada, and we work to affirm the economic and legal rights of all visual and media artists. The non-consensual use of intellectual property by generative AI companies profoundly impacts artists. This submission results from over 220 unique responses from artists to a national survey regarding their concerns about generative AI products; community dialogues at virtual panel events organized by CARFAC in Ontario and Saskatchewan; and hundreds of hours connecting with artists and stakeholders across the cultural sector in Canada and abroad.We are concerned about how generative AI companies interpret the laws that apply to their business models. For example, Midjourney recently updated its terms of service to clarify that users may not use the product to violate others' intellectual property rights, and that doing so may result in the company taking legal action against the user. Yet, the company has itself been accused of copyright infringement on multiple occasions. The terms of service goes on to state that the company does not guarantee that the service does not infringe on copyright.Additionally, Open AI recently launched a program called Copyright Shield which promises to pay legal costs for its developer customers who face lawsuits over IP claims. Assertions that these business practices are in compliance with the Copyright Act are inconsistent with these protective measures, and also raise the question why some AI companies are ratifying licensing deals with major publishing and media providers, but argue against the use of licensing models for all content being used as training data. We discuss this issue further in this submission.Regarding how businesses and consumers use AI-assisted and AI-generated content, Canadian artists face growing labor disruptions. This trend is unsurprising as organizations that once licensed the use of original works can now use generative AI to meet their needs without paying creators.","Using artwork obtained through TDM to train Generative AI products without allowing artists to provide consent, negotiate compensation, or determine if/how they will be credited violates those artists’ rights under the Copyright Act. This consultation is an opportunity for the Government to educate generative AI companies to ensure they comply with the law.Questions about moral rights are notably absent from this survey; however, the violation of artists' moral rights is inevitable based on the current business models used by most generative AI companies. It is common for generative AI models to distort original works which may harm the reputation of artists, and artists do not commonly have the choice to be credited or remain anonymous. Generative AI also enables an environment in which artists are unable to protect their works from association with causes, products, services, or institutions to which they are personally opposed.Eighty-two percent of artists responding to our survey indicated they were very concerned that their artwork is used without consent to train generative AI products. This concern is so deep and widespread that independent countermeasures are required. For example, the University of Chicago has developed Glaze, a tool that artists can use to protect their works online from becoming AI training data. While these efforts are appreciated, protecting the IP rights of artists against non-consensual use by some of the world’s largest corporations should be done through copyright law and federal regulation. It should not rely solely on these independent initiatives.Terms such as “training data” are used frequently, and this language can devalue a creator’s intellectual property. For artists, this is not “training data”; this is their life’s work.The plurality of stakeholders, the legal uncertainty, the need for more transparency in data management systems, and the opacity of AI systems are insurmountable obstacles for artists to defend their copyrights without support. The critical challenge currently faced by Canadian rights holders in licensing their works is the inability to determine what copyright-protected works have trained generative AI products; this opacity prevents parties from negotiating licensing terms and stifles the development of emerging licensing markets. It is also challenging to establish that the infringing party had access to the original work, that the original work was the source of the copy, and that the work was significant in informing the creation of the new content produced. However, we understand that AI developers and researchers in the sector document their training data. Therefore, greater transparency of this data with rights holders is therefore technically feasible.Most artists have yet to have opportunities to negotiate licenses for their works already used to train generative AI models. Though many mainstream generative AI companies do not employ licensing models, such business frameworks exist within the AI industry. Getty Images, for example, has released an AI Image Generator trained exclusively on its content. Getty compensates creators for the use of their work in their AI model.Resistance from generative AI companies to engage in licensing negotiations with the arts sector is another critical challenge in establishing a market-based approach to consent and compensation for artwork used in TDM. Meta, for example, has argued that imposing a licensing regime after the fact would cause chaos for the industry and result in little benefit for artists, given the insignificance of their respective works within larger datasets. Already, however, we are seeing contradictions in these arguments. OpenAI recently entered a licensing deal with Axel Springer SE, the parent company of Business Insider and Politico; such an agreement could become the norm. Companies that regularly violate the Copyright Act should not benefit from an exemption on the grounds that those actions have already occurred. Even when the financial value of an individual work is small, this does not preclude the rights of artists to provide consent and receive payment for using that work.The Canadian Government should avoid entertaining arguments that complying with the Copyright Act and obtaining prior consent from artists would slow the development process of generative AI products. While AI technology may be complex, basic principles of fairness, justice, and asking permission before taking things are straightforward and baked into Canadian laws and social values.Generative AI companies are rightfully excited about the products they produce and understandably feel a sense of urgency to accelerate the development of those products. Artists are no different; we must regard their needs with the same level of importance, innovation, and urgency. Neither group can be permitted to operate outside of the law or develop their products in ways that harm individuals or society at large. The Copyright Act is sufficient and applicable to protect the rights of creators in the context of generative AI. There is no reason to believe that current copyright laws do not, or should not, apply. Situations in which private companies use, without permission, the copyrighted works of Canadian artists to develop and grow the value of their commercial products is precisely the kind of scenario that the Copyright Act should prevent. The Federal Government should refrain from implementing new exceptions for TDM. Doing so would devastate the economic environment for Canadian artists – many of whom live at or under the poverty line. A TDM exception would result in long-term negative social and cultural externalities, including compromising the global competitiveness of Canadian arts and culture and harming small creative businesses.The current environment must enable rights holders to determine if their works have been used to train generative AI models. An opaque operating model both encourages the unauthorized use of Canadian artists’ works by AI developers and prevents licensing negotiations from taking place. We, therefore, recommend that generative AI companies be required to publish records of copyright-protected works that have trained AI models.Developers and researchers in the generative AI sector are already documenting their training data, for example, using model cards. Model cards can record structured information, such as the names of domains where training data is collected. Therefore, introducing a record-keeping obligation should not entail additional costs for the AI industry and would provide much-needed transparency.Artists and generative AI companies should negotiate remuneration for licenses without government intervention. The Government can enable a market-based solution by ensuring that the generative AI companies operating within Canada comply with current Canadian copyright law without exception, and that records of copyright-protected works that trained AI products are made public. Generative AI has negatively impacted labour opportunities in our industry. The Federal Government can contribute to stabilizing this fallout by ensuring that generative AI companies operating in Canada adopt appropriate licensing models.","Existing copyright laws are sufficient to address authorship and ownership, and no legal amendments are required. As the Supreme Court of Canada noted in CCH v. The Law Society of Upper Canada, “An original work must be the product of an author’s exercise of skill and judgment. The exercise of skill and judgment required to produce the work must not be so trivial that it could be characterized as a purely mechanical exercise”. These same criteria should apply when evaluating the granting of copyright to AI-produced or AI-assisted works. Entering a series of text prompts into an AI Image Generator is decidedly a “purely mechanical exercise,” that does not require the user to exercise “skill and judgment.”There may be, however, other situations where AI-generated or AI-assisted artwork meets the criteria for copyright protection. For example, suppose an artist designs an AI model and trains that model with their artwork so that the model can understand and interact with the training data in unique ways specified by the artist. In that case, the content resulting from this process may meet the copyright criteria.The question of authorship of AI-generated works is essential but difficult to consider in a landscape where private companies use Canadian artists' intellectual property without consent, credit, or compensation to develop their products and increase the value of those products. Suggestions that generative AI companies could be able to continue developing their products using unauthorized Canadian artists’ works while simultaneously considering if the resulting content generated by those products should receive copyright protection are concerning.The devastating impact this would have on the creative economy in Canada is profound and difficult to predict, though it is essential to highlight the specific effects on Indigenous artists. As the theft of original Indigenous cultural expressions is already widespread, its unauthorized use by generative AI companies is unconscionable and contrary to notions of Truth and Reconciliation. Moreover, including counterfeit Indigenous artwork in training datasets accelerates the spread of counterfeit imagery, and the generation of AI content based on authentic or fake Indigenous artwork cannot be permitted. This issue deserves a separate analysis and consultation process.","When generative AI companies use Canadian art to train their models and build the commercial value of their products without consent, they commit copyright infringement and must assume liability for those actions.Requiring generative AI companies to keep and publish records of copyright-protected works used to train their models will address the large-scale copyright infringement that has already happened and provide parties involved with the information needed to negotiate terms for using those works. This will enable the development of licensing markets and strengthen Canada’s creative economy while potentially accelerating growth and competition within the AI industry itself.","On October 12th, 2023, the Government of Canada announced this Consultation on Copyright in the Age of Generative Artificial Intelligence, with submissions due by December 4th, 2023, and extended to January 15, 2024. We are concerned that this short timeline to prepare recommendations on this complex issue has the danger of capturing uneven results. Some arts and culture sector stakeholders could be unfairly disadvantaged by having to balance limited resources and capacity while preparing thoughtful and researched analysis, while generative AI industries can allocate much deeper resources to the process. While we appreciate the extension to respond to this consultation, future consultations will benefit from longer timelines. And while we are thankful for the opportunity to respond to this survey, we are disappointed that we were not invited to consult on, or contribute to, its design.CARFAC does not wish to hinder the advancement of AI, but we need to preserve the balance that the Copyright Act underpins, and we must uphold the interests of copyright holders. Indeed, we see the potential of AI: if adequately regulated, it could fuel creativity, promote content discoverability, and equip creators to defend their rights.Nevertheless, it is essential to be aware of the negative impacts that AI can have on all sectors, on the foundations of our society, and the rights of artists. As generative AI profoundly impacts the cultural industries, creators must be centrally involved in developing the governance and policy frameworks affecting our sector.In summary, our primary concern is to ensure compliance with the Copyright Act. The ""3 Cs"" principle (consent, credit, and compensation) must guide the Government's actions in this public consultation and any potential amendments to the Copyright Act. Our request is consistent with those called for by artists in other countries at the present time. Creators' consent must be obtained and the Government must not undercut their options to be paid when their content is used for text and data mining (""TDM"") purposes. We also recommend that a transparency obligation be imposed on users. Specifically, this framework should require disclosure of any works used in the context of generative AI. Such a mechanism is feasible and poses no technical difficulties for generative AI companies. Rather, it would lay the foundations of the edifice, in order to ensure fair and equitable remuneration for artists and copyright holders."
OCAD University,University,"Background: At OCAD University, Canada’s oldest and largest art and design university, a key strategic goal is to increase access to emerging technologies, and enable students to use, create and innovate with these technologies skillfully and responsibly. As such, Artificial Intelligence (AI) and Generative Artificial Intelligence (GAI) are topics the institution is grappling with through a faculty advisory, a working group with external experts organized by the University’s Cultural Policy Hub, and input from students, faculty, and staff. AI and GAI represent an incredible opportunity for artists. Many OCAD U students, faculty, and staff members from across the university’s community use AI, GAI, and multimodal models (such as ChatGPT, Midjourney, Dall-E, Stable Diffusion, Bard, GrammarlyGo, among others) as part of their work. For example, the university’s administrators may use ChatGPT for general purpose copy drafting, while faculty and students experiment with image and music GAI tools and explore how they can be used to enhance their creativity. But these tools also have the potential to disrupt the standards and regulations that are in place to protect artists and the work they create. The university also has researchers who have formed a group exploring the ethical dimensions of the recent and rapid rise of GAI; they are working to establish guidelines and recommendations on how their peers can use GAI responsibly, both in pedagogical and creative contexts. Overall, the institution has recognized that GAI technologies have significant and immediate implications for conceptions of creativity, authorship, as well as approaches to pedagogy, and has responded with a focus on developing critical AI and GAI literacy by:Defining the technology and its applications for students and faculty; Establishing the affordances and limitations of this technology; Situating the work around AI and GAI within the university’s broader anti-racist and decolonial framework and acknowledging how these technologies provide potential opportunities and drawbacks for marginalized students, faculty, and staff; andStriving for equitable access to GAI tools, particularly for Indigenous, Black, people of color, neurodivergent, and marginalized faculty, staff and students.Some of the university’s students and faculty are wary of GAI’s potential and how it could impact their creative practice. Members from a few departments have serious concerns about the potential of GAI tools to replace entirely the need for human intervention or participation in certain creative processes, and the accompanying threat to their livelihood. As a result of these different viewpoints, the university’s approach seeks to balance the following priorities: Promote innovation and experimentation in the development of new and powerful creative tools;Train students and faculty to understand and implement these tools so they can incorporate them into their practice and remain proficient in using them; Anticipate industry and sector trends in adopting these tools to ensure that students are future-proofed and ready for their transition into the professional realm;Establish guidelines and guardrails and provide recommendations to government that will protect students and faculty’s creative work from exploitation; and Advocate when necessary for artists and creatives retaining control over how their work is used now and in the future.This background informs the responses to the questions posed by ISED in the consultation. The university’s approach to AI and GAI is iterative and in progress. As such, the recommendations posed should be considered in this context. This consultation raises more questions than answers, and our primary recommendation to the government is that more time is needed for discussion and public consultation on the issues raised, as well as those not raised.OCAD U encourages the government to reopen the consultation process with an additional lens to the following issues, which this most recent survey does not address:Bias in datasets used to train AI and the perceived threat of increased bias if AI developers are restricted to using materials from the public domain for TDM and machine-learningThe recognition of Indigenous sovereignty in the development, training, and application of AI and changes to copyright and intellectual property lawThe existing and future impacts on human rights in AI development and implementationThe implications for education around ethical approaches to pedagogy in the age of GAI","Recommendations: Develop regulations to ensure transparency around datasets. With these regulations should come oversight and compliance.Put safeguards in place that track, record, and disclose how an artist's work is being used in text and data mining (TDM) activities.Put the onus of developing those mechanisms and obtaining permissions or licensing for the use of content in TDM activities on AI tool and model developers, not content creators.Datasets are largely comprised of customer data that we originally understood to be used for internal purposes but were then used for social media and targeted advertising and are now being used by AI to create products that are being sold back to us. The components of the datasets were technically acquired legally, but complied to laws that didn’t envision this use case. Any laws regarding AI need to be generated in such a way that they reflect this new use of information and data previously, currently, and prospectively–these laws should benefit and protect users rather than the creators of the tools.The issue of dataset transparency was recently addressed by the European Parliament proposed regulatory framework on AI. Their recommendations specifically addressed the issue of dataset transparency by establishing the following requirements:Disclosing that the content was generated by AIDesigning the model to prevent it from generating illegal contentPublishing summaries of copyrighted data used for trainingThe European Parliament also noted that “high-impact general purpose AI models” might pose systemic risk and should be subjected to thorough evaluations. They continued that citizens would have the right to report “serious incidents” involving this technology to the European Commission. More information is required on how the EU intends to ensure compliance with these requirements and be proactive in ensuring that citizens’ and creatives’ rights are not being infringed.Many artists and creatives, especially emerging ones, are the direct copyright owners of their work, and do not have the support of agents, producers, and/or legal experts to ensure that their work is not being exploited or used in ways that circumvent or contravene the copyright act. Even if their work is found to be used inappropriately or illegally, the authors of those works in most cases do not have the capacity or resources to expend enforcing how their work is used and getting the compensation they are owed for its use.Given these material realities, it is critical that the Canadian government, too, put safeguards in place that automatically protect an artist's work from being used in text and data mining activities. There need to be mechanisms for oversight and compliance in place that track, record, and disclose how content is being used in TDM activities. Finally, the Canadian government should put the onus of obtaining permissions or licensing for such work on those compiling content to develop and use training datasets, not on the content creators themselves.OCAD U’s initial recommendations on best practices and potential ways forward are as follows:Develop regulations to ensure transparency around datasets. Oversight and compliance must be considered as part of these regulations.As a rule, artists should have the option to opt their work into being used openly in TDM activities. They should not be expected to opt their work out of being used in TDM activities.Licensing and subsequent compensation will likely need to be achieved through collective models and could be serviced in part through existing collective management organizations (or Collective Societies) such as SOCAN, CAARC, SODRAC, ACTRA, and others. It would be reasonable for artists to opt into or register with a Collective Society to be eligible for remuneration from TDM activities.If effective regulation and transparency around datasets is not in place, mechanisms must be developed to track how an artist’s work is being used in TDM activities. Search engines like “Have I Been Trained?” already exist to help artists determine if their work has been used in TDM activities. This type of program would need to be expanded with cooperation from those developing training datasets for TDM and machine-learning activities. Still, this remains a defensive response that places the onus on creators and does not represent a meaningful or sustainable solution to the larger issue of a lack of transparency in datasets.As for the levels of remuneration for the use of a given work in TDM activities, the government could adopt a recommended fee structure to be developed by a consortium made up of: experts on artistic remuneration (e.g. CARFAC, RAAV, IMAA, etc.); representatives from the tech industry and others developing GAI tools and engaging in TDM activities; legal experts on copyright and remuneration; and representatives from arts service organizations across disciplines. There are a number of obstacles that arise when considering how the above recommendation could be implemented:How to develop a or multiple mechanisms to track, record, and disclose content being used in TDM activities? (Examples already exist, such as Hugging Face’s BigCode project: https://huggingface.co/datasets/bigcode/governance-card#2-data-and-model-governance).How to regulate this process of tracking and recording?How to establish realistic licensing regulations and parameters to not stifle innovation?How to educate artists and creatives about their rights as well as any changes to existing copyright legislation?Ultimately, the goal should be to ensure fair remuneration for artists that will reflect how their work is being used in TDM activities. The government could also consider whether artists and creatives should be retroactively compensated for the use of their work in TDM and ML activities that have led to the creation of significant and highly popular GAI systems like ChatGPT, DALL-E, Midjourney, etc.","Recommendations:The definition of an author or creator may need to be redefined to account for how GAI is involved in the creative process.The revision of these definitions should be led by authors and creators working alongside policy makers, and not by those developing GAI technologies.Continue consultation on this topic, alongside the Department of Canadian Heritage and creatives.The uncertainty around authorship of GAI- and AI-assisted creative works could have significant impacts for the creative community. Current definitions of authorship as being attributable to a “natural person” fail to account for instances where GAI is involved in the input or output of creative materials. The existing definitions in copyright law may not be sufficient for protecting the creative work of artists and designers and also enabling them to fully leverage new tools.Our existing understandings of authorship may now be resting on premises and assumptions that are insufficient. There needs to be greater consideration of where the work of creativity is located in existing processes that are changing with the rise of new technologies, as well as in new modes of creation that are becoming possible as those technologies become more accessible. The experts on these questions of how authorship and creativity has changed are authors and creators themselves; if policymakers intend to revise how they define these terms, creatives need to be directly involved in developing these new definitions and understandings.This questions around authorship and ownership requires more consultation and discussion, which ISED should lead alongside the Department of Canadian Heritage and must involve creatives.","Recommendation:The government needs to be proactive in putting regulations in place rather than encouraging innovation and then leaving it up to the courts to make legal determinations of liability in instances of infringement (or suspected infringement).OCAD U has begun to develop frameworks to help students and faculty develop an awareness of how GAI applications might currently store or use their ideas and/or intellectual property without their explicit consent. Its current guidelines remind students and faculty to always attribute when and how they are using GAI tools in their work, alongside best practices for doing so. The guidelines also put the onus on the person using a GAI tool to “ensure [they] are familiar with the privacy policy of each application before [they] use it [and] never enter someone else’s work into a GAI app without their permission and consent” and encourage faculty members to remind students of this in their course outlines and assignment instructions.While these measures may help students and faculty protect themselves in the short term, there is much more clarity required from government on how the content used to train these AI tools should be tracked and regulated, how the content creators whose work is used should be compensated, how authorship is determined when these tools are involved, and where liability lies if copyright is infringed on by GAI tools.Consultation with many experts suggests that businesses that build commercial AI applications can be expected to advocate for as little oversight as possible in tracking and recording what content they use to train their models. They are expected by and large to advocate for the deregulation of content and for free and open access to as much content as possible. This model would not only enable them to potentially build more powerful tools; it would allow them to do so at a significantly lower cost.Unfortunately, the ensuing benefits to innovation would come at the cost of opportunities for artists and creative professionals to be compensated for the use of their work. As an institution that prepares students for careers in the creative sector, OCAD U’s recommendations need to situate artists and creatives—and their opportunities to be successful in their work and practices—first.The main barrier that the university anticipates in determining whether an AI system has accessed or copied copyright-protected content when generating an infringing output is the lack of implementation of sector-wide tools and standards to track, record, and disclose what content is being used in TDM and machine-learning activities. Furthermore, research on code LLMs has suggested that the lack of transparency can also hinder innovation by allowing only a small number of well-funded labs to participate in shaping the technology (see the Hugging Face report linked above). Implementing the earlier recommendation on tracking and disclosing this information would provide a record of what types of data were included in a machine’s training set and what it could be borrowing or stealing from in generating new work that could be infringing on copyright-protected material.There must be greater clarity on where liability lies when AI-generated works infringe on copyright, and there needs to be greater efforts to educate artists and users of GAI tools on how to ensure that their practice is responsible and in compliance with any legislations or regulations that are adopted on this issue. Infringement as it relates to AI-generated works is both an opportunity for protection and a liability for artists, businesses, and developers alike. If the government relies on the courts to eventually set precedents and make determinations on the potential harms and unlawful outcomes of this technology’s proliferation, the harm will be most acutely experienced by marginalized individuals and communities. As such, the government needs to be proactive in putting regulations in place, regulations which should address or clarify:Definitions around authorship when GAI tools are involved.Protections from liability for coders, programmers, and other workers involved in developing AI tools and models on behalf of private companies.The establishment of updated corporate liability models for potential infringing activities.Processes for registering AI tools and models, as well as standards and guidelines for disclosing human involvement in AI-generated works.","OCAD University is Canada’s oldest and largest art and design university with a key strategic goal to increase access to emerging technologies, and enable students to use, create and innovate with these technologies skillfully and responsibly. Artificial Intelligence (AI) and Generative Artificial Intelligence (GAI) are topics the institution is grappling with through an advisory council, a working group with external experts organized by the University’s Cultural Policy Hub, and input from students, faculty, and staff. Overall, OCAD University encourages the government to reopen the consultation process with an additional lens to the following issues, which this most recent survey does not address:Bias in datasets used to train AI and the perceived threat of increased bias if AI developers are restricted to using materials from the public domain for TDM and machine-learningThe recognition of Indigenous sovereignty in the development, training, and application of AI and changes to copyright and intellectual property lawThe existing and future impacts on human rights in AI development and implementationThe implications for education around ethical approaches to pedagogy in the age of GAIIn this document, OCAD University makes a set of recommendations. Key among them is the need for continued consultation and consideration of these sensitive and quickly evolving topics. Further, it is critical that creatives be part of these ongoing discussions, and OCAD U recommends that ISED work closely with Canadian Heritage, and include the voices of creatives and creators as part of this work.The definition of an author or creator may need to be redefined to account for how GAI is involved in the creative process. The revision of these definitions should be led by authors and creators working alongside policy makers, and not by those developing GAI technologies. The government should continue consultation on this topic, alongside the Department of Canadian Heritage and creatives.Develop regulations to ensure transparency around datasets. With these regulations should come oversight and compliance.Put safeguards in place that track, record, and disclose how an artist's work is being used in text and data mining (TDM) activities.Put the onus of developing those mechanisms and obtaining permissions or licensing for the use of content in TDM activities on AI tool and model developers, not content creators.The definition of an author or creator may need to be redefined to account for how GAI is involved in the creative process.The revision of these definitions should be led by authors and creators working alongside policy makers, and not by those developing GAI technologies.Continue consultation on this topic, alongside the Department of Canadian Heritage and creatives.The government needs to be proactive in putting regulations in place rather than encouraging innovation and then leaving it up to the courts to make legal determinations of liability in instances of infringement (or suspected infringement)."
"Copyright Office, University of Alberta",University,"Post-secondary institutions are involved in all sides of the development and use of assistive and generative AI tools.A generative AI tool is largely developed by humans, with the selection, accessing, and ingestion of content for training datasets directed by humans, the prompts to direct the generative AI tool to create outputs normally provided by humans, and the decision regarding whether and how to distribute those outputs generally made by humans.Where there is an alleged copyright infringement in relation a generative AI tool, it could be either that the generative AI tool’s accessing and reproducing copyright-protected works as part of the training datasets is alleged to be infringing, or it could be that the generated output that is made public is alleged to be infringing.Developers of generative AI tools should be aware of copyright considerations in relation to the text and data those tools ingest for their training datasets. The type of outputs that the tool is designed to generate – which may be the ultimate purpose of the tool – might have a bearing on whether and the extent to which the use by the tool of any copyright-protected text and data might be found to be infringing. This determination will generally involve a fair dealing assessment, in cases where there has been no other authorization to access and use the copyright protected text and data.Users of these tools are often not the developers of these tools. Therefore, for users who are publishing outputs from generative AI tools, transparency regarding what tools have been used and how they are used in relation to AI-generated outputs, along with good record keeping regarding these, may be useful voluntary measures that can be undertaken to assist in the defense of cases where those outputs are alleged to be infringing and thereby to mitigate legal risks.","TDM is an important research tool, incorporating the latest technology to save time and expense in gathering and analyzing data for research purposes. There are a broad range of texts and datasets accessed via TDM, and not all such sources, nor the ultimate uses of the research outputs, give rise to copyright concerns.Regarding copyright licenses from rights-holders that might govern TDM activities, these may be beneficial in certain cases where the use of TDM would not reasonably be covered under fair dealing or any other exception. However, to the extent that fair dealing is applicable to TDM activities, it is important to note that “the availability of a license is not relevant to deciding whether a dealing has been fair.” (CCH Canadian Ltd. v. Law Society of Upper Canada [2004] 1 S.C.R. 339 at paragraph 70).0As the use of generative AI tools broadens and grows, it will be increasingly significant to understand the impacts of any limitations placed on the material those learning datasets can draw upon. If the datasets are not appropriately current and drawn from appropriately diverse sources, the output could be outdated or biased.In any discussion regarding adding clarity around copyright and TDM in Canada, “clarity” is the operative word. A broad range of cases of TDM could be reasonably considered to be fair dealings, based on the purpose of the ultimate use of the outputs derived from the TDM activity, in conjunction with the other factors of a fair dealing analysis.There are always (or should always be) concerns about imposing strict limitations in relation to activities that have such a broad range of potential approaches and uses. To establish such strict parameters in the statute might not appropriately allow for new or unforeseen approaches or uses. It would be unfortunate if any such bright lines led to a result other than what a proper fair dealing analysis might determine.Acknowledging that not all uses of outputs derived from TDM would be fair dealing, it would be useful to make clear to the TDM community that fair dealing is available to them, should an objection be raised under the Copyright Act to the TDM activity itself or to how the outputs arising from that activity are made publicly available.Any such added “clarity” should do nothing to reduce or limit the application of fair dealing in cases of TDM. This added clarity might take the form of a “TDM exception” that would explicitly allow for the use of TDM in certain defined ways that are deemed to be in the public interest. If such a TDM exception were to become part of the Copyright Act, the application of that exception should not be limited by the terms of contracts governing access to content where those terms purport to override terms of the Act.Regarding imposing obligations for record-keeping and disclosure regarding content accessed, such an approach would be undesirable and impractical. While voluntary record-keeping regarding content accessed might be a good practice, obligatory practices would be difficult to monitor and enforce, and such obligations would only serve to create a potential violation under the Act that is not copyright infringement. As was mentioned earlier, maintaining such records may be useful to the developer in the event of a claim of copyright infringement against any output generated through its generative AI tool, but that is not a compelling reason to make the burden of such record-keeping obligatory.Regarding other jurisdictions, the US Copyright Office has issued a notice of inquiry regarding artificial intelligence and copyright. This notice of inquiry was issued on 30 August 2023, and the due date for reply comments has been extended to 06 December 2023. The outcome of that inquiry may be a useful supplement to the results of this consultation. Additionally, the European Union has recently agreed upon a new law known as the A.I. Act.","There are clearly economic interests that would arise from a determination of authorship or copyright ownership for certain outputs from generative AI tools. In such cases, the determination of who would be the rightsholder in those outputs and what level of copyright protection would apply for what length of term might be important to the parties involved. However, the fact that these interests in AI-generated content are important to certain parties is not sufficient to determine whether it would be in the broader public interest to provide any level of statutory protection to this content under copyright law.One of the foundational purposes of copyright protection is to protect the interests of (human) authors, ensuring that they can receive a just reward for their creative works. This is intended to provide such (human) authors with an incentive to spend the time and effort and skill and judgment to produce those new creative works. Providing this copyright protection to such (human) authors is in the public interest, as it encourages the ongoing creation of new works that benefit the public.The extent to which the works created by a generative AI tool require such copyright protection to incentivize their creation is much less clear. While it may be in the public interest to ensure that the developers of generative AI tools can benefit from the value of the outputs of those tools, this benefit can readily be derived from user fees, perhaps including royalties, and other terms of use associated with their tools. Copyright protection is not necessary to further incentivize the developers of these tools, and there is no compelling reason to “reward” the users of these tools with copyright protection in their outputs.In cases where there is significant human contribution to a “work” that also had a significant contribution from a generative-AI tool, there would be the need to establish reasonable thresholds of human skill and judgment relative to the contribution of the tool to reach the level of “human authorship” and thus copyright protection, as well as effective means of determining whether such thresholds have been reached.","Assuming no new changes in what counts as an infringing work under the Copyright Act, then the existing legal tests that are currently applied to decide whether a work authored (entirely) by a human is infringing should be sufficient to determine whether a work generated (in whole or in part) by an AI tool is infringing.In relation to the outputs from generative AI tools, while it may be good practice for the developers/administrators of generative AI tools to track what copyright-protected content has been accessed and/or copied in the development of the learning dataset, this may be most useful as a defense to copyright infringement. Otherwise, the existing tests for similarities between works in determining whether one infringes upon the other in copyright disputes should be sufficient. The courts are well-equipped to decide these issues.Regarding providing greater clarity on where liability lies if an AI-generated work is found to be infringing, again, the operative word is “clarity”. The owner/controller of the generative AI tool might reasonably be liable, at least in part, if the outputs of that tool too closely resemble existing copyright-protected works. Similarly, the individuals who made the decision of what prompts to provide the generative AI tool, and whether and how to distribute the outputs from that tool, might also reasonably be liable, at least in part, in cases where those outputs are found to be infringing. However, given the very broad range of possible specific circumstances for such cases, it would be important that any such additional “clarity” would not limit the range of liability that might apply to any of these parties. There are a number of human decisions at play at all stages of the process, by each of the parties to the process, and it is the extent of the connection between those decisions and the specific nature of the alleged infringement that will determine whether and the extent to which each of the parties involved in the matter will be liable, or not be liable, for the ultimate distribution of an infringing output. Again, existing approaches to determining and apportioning liability should be sufficient in such cases, and the courts are well-equipped to decide these matters.","At the end of the day, generative AI is a tool to serve human purposes, some of which involve the generation of outputs that on their faces might give rise to copyright protection. The statutory copyright regime is in place to provide protection to works where that protection benefits the broader public interest. Before the choice is made to expand or modify copyright protection of works to accommodate the use of generative AI tools to create outputs that are published, it should be properly determined whether existing rights, protections and exceptions under the Copyright Act, and the underlying goals of providing those rights, protections and exceptions, might be sufficient as they are to address any issues that arise.Some “additional clarity” might be required around how the rights, protections and exceptions apply in these cases, but a minimally intrusive approach has generally been the initial approach of the copyright regime in dealing with the impacts of new technologies. In the case of generative AI, it may be too early to try to do too much. If sufficient guidance can be provided so as not to unduly stifle the development and use of such generative AI tools in ways that serve the broader public interest, that may be the best outcome at this stage."
Simon Fraser University,University,"Numerous researchers at Simon Fraser University (SFU), across a variety of disciplines, are engaged in multidisciplinary research in artificial intelligence to help create innovative, equitable and novel solutions to the challenges facing contemporary Canadian society across diverse sectors (see https://www.sfu.ca/big-data/using-data/artificial-intelligence-at-sfu.html). Researchers at SFU develop AI systems for a variety of applications, from improved medical diagnostics and decision making to enhanced language training. These researchers use licensed datasets for training AI models, and also create their own training datasets when necessary. When creating their own datasets SFU researchers follow relevant copyright policies as well as research and ethics protocols to ensure data and privacy protection.SFU’s Copyright Office assists researchers in understanding the copyright implications of their AI research projects. Researchers want to responsibly develop AI tools, which includes ensuring that copyright is considered and respected. Many generative AI applications being developed by SFU researchers do not involve copyright protected works – for example those involved with medical imaging and data pattern correlations. SFU researchers and copyright specialists review dataset licenses to ensure that use of the dataset respects license terms. When potential training dataset content is not licensable the SFU Copyright Office or external experts provide guidance to researchers regarding the application of fair dealing to their curation and use of the contents well as their use of generative AI systems to generate outputs.SFU is interested in not only mitigating the risk of copyright infringement, but also ensuring transparency and non-bias in training data. Many researchers are concerned about the potential for generated outputs to be infringing or cause other harms and therefore some SFU researchers are working on solutions to attribute, or link, training data to the generated works to provide greater transparency to the user. To do so requires using datasets that come with sufficient metadata describing the ownership of each piece of copyrighted content such that each content element is identifiable. SFU researchers, particularly graduate students, who use generative AI to create new works as part of their research are often very aware of terms of use of different AI systems and tend to use only those systems where they can use the model locally, without contributing their copyrighted works to the larger training set. Transparency requirements for high-risk AI applications (e.g., biometrics, medical devices) and codes of conduct for lower risk AI applications (e.g., image generation systems) in the proposed EU AI Act (European Commission, 2021; see: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206) offer a model for possible applicability in the Canadian context. As well, ethical transparency should also ensure that items of knowledge or cultural significance to Indigenous communities are not included in training datasets without consent and participation of those same communities.While SFU researchers are very involved in the design and training of generative AI models, this does not mean that these same researchers can necessarily claim copyright in the output of their models. SFU advises its researchers that the outputs of their models are likely not protected by copyright. This is because outputs from generative AI systems are not directly attributable to the model’s developers, but instead the outputs are based on deterministic statistical probabilities (Lee et al., 2023; see https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551). Consequently, the developers responsible for the AI model are unable to claim any exercise of skill and judgement in each output of a generative AI system. Since an exercise of skill and judgement is a requirement for the adherence of copyright to a work,  the developer cannot claim copyright in the AI model’s outputs (see: CCH Canadian Ltd. v. Law Society of Upper Canada, 2004. Para 16.).In addition to developing AI systems for a variety of purposes, SFU researchers, educators and students also use AI systems and AI generated content. Students use AI systems such as ChatGPT or Stable Diffusion to assist in the creation of assignments. Staff and faculty use generative AI tools to assist them in developing ideas and content. Note that they are not using AI systems to create their work, but rather using them as a starting point or an aid in creating new works. Educators use AI systems to help them develop student assessment tools such as quizzes – for example, an instructor can feed a chapter from a book into an AI question generator in order to obtain a short multiple-choice quiz based on the content of the chapter. Digital resources that universities subscribe to likely cannot be used in such ways due to license restrictions, but short extracts from print books could conceivably be used.Universities also utilize regular and generative AI tools to carry out laborious and time-consuming tasks. For example, university instructors will use AI tools to assess student writing for plagiarism and ensure academic integrity. Libraries and archives are employing generative AI tools to create and enrich metadata for their unique collections. These tools are becoming key to supporting a variety of ways in which the University carries out its mission.RECOMMENDATIONSProvide clarity around training dataset content by requiring transparency in training dataset metadata for high-risk AI applications and developing transparency codes of conduct for training dataset metadata for lower-risk AI applications with the aim of having sufficient metadata such that each content element is identifiable.Facilitate the development of protocols created through collaboration between Indigenous communities and researchers to ensure that Indigenous Knowledge and Traditional Cultural Expressions are not captured in training datasets without consent and participation of the relevant Indigenous communities.Provide clarity regarding copyright implications of using unlicensed data for training generative AI models (see recommendations in Text and Data Mining section).","TDM as an analytical tool involves a non-consumptive use of a work to reveal trends and relationships in the facts and ideas underlying the work’s expressed form. Generative AI is one example of the application of TDM technology that allows users to engage with the facts and ideas presented in works. By non-consumptive we mean the use of a work in a way that does not involve consumption of a work by a human being. When a digital work is mined for data and facts by a computer, there is no human consumption, or enjoyment, of the work in the way that the creator of the work envisioned the work being used. No one writes a novel so that a computer can analyze it – they write it so that a human can read it and engage with it emotionally and intellectually.Current legislative ambiguity around the copyright implications of engaging in TDM with copyright protected works hinders SFU from confidently providing access to the information and knowledge to develop TDM tools for application in society. Not only do researchers and students need clarity for TDM uses of works, we also require clear language in the Copyright Act clarifying that a contract cannot override exceptions in the Act in order to halt the erosion of the public domain, and to safeguard against restrictive licensing agreements that override fundamental user rights codified in the Copyright Act and clearly expressed in Supreme Court jurisprudence. See, for example, Alberta (Education) v. Canadian Copyright Licensing Agency (Access Copyright), 2012 SCC 37, [2012] 2 SCR 345. Para 22 & CCH Canadian Ltd. v Law Society of Upper Canada, 2004 SCC 13, [2004] 1 SCR 339. Para 12 as examples of the Supreme Court endorsing the view that exceptions are “user rights.”Twenty-first century Canadian copyright legislation and jurisprudence have given Canadians a balanced copyright regime. This regime recognizes that a copyright owner cannot have exclusive control over all uses of their work (i.e., the doctrine of exhaustion) but instead confers upon users of copyrighted works certain user rights (see: CCH Canadian Ltd. v. Law Society of Upper Canada, 2004. Paras 12-13 & 54.). This balance must be maintained when considering the copyright implications of TDM. Users must not face additional barriers to engaging with the facts and ideas in copyrighted works just because they are using these works for TDM purposes. It is imperative that universities like SFU be able to foster and encourage, through research, the increasingly complex ways that users interact with the ideas and facts contained in corpora of copyrighted works. However, it is important for SFU to make clear that we specifically support applications of non-consumptive use which do not encroach on the original expression of the work by generating copies of existing works. That is, TDM applications that extract and understand the patterns, information and correlations – essentially the facts and ideas behind these works – to generate, or assist in the generation of, new and different works.Many jurisdictions have enacted provisions in their copyright legislation to support TDM, or have existing systems that provide the flexibility to implement TDM. For example, the USA’s flexible and illustrative fair use provision provides a solid legal basis for the non-consumptive use of copyrighted works. Canada’s fair dealing exception lacks the flexibility of US fair use. Although SFU favours expanding Canada’s fair dealing exception to be illustrative and flexible, SFU and all research institutions would benefit from an explicit exception for non-consumptive uses of copyrighted works along the lines of Japan and Singapore. Japan’s exception has been described as one that “comprehensively allows an exploitation of a work by any means to the extent deemed necessary, if the exploitation is aimed at neither enjoying nor causing another person to enjoy the work, unless such exploitation unreasonably prejudices the interests of the copyright holder” (Ueno, 2021. See https://doi.org/10.1093/grurint/ikaa184).  A similar exception in Canada would meet the desire for a technologically neutral Copyright Act and would ensure that future non-consumptive TDM-like processes would also be covered. Acknowledging the separation of the economic interests vested in the original expression and the user rights to the information behind the work further supports an exception for both commercial and non-commercial applications.RECOMMENDATIONSCreate a specific exception to infringement that would allow for the copying and use of a work or other subject-matter for the purposes of informational analysis and related purposes. This aligns with recommendation 23 from the 2019 Statutory Review of the Copyright Act (INDU, 2019). A number of Canada’s key trading partners already have a specific exception for TDM, including Japan, Singapore, the United Kingdom and the EU. SFU supports an exception that applies to both commercial and non-commercial research, and which includes both the reproduction right and the communication right.Introduce an provision in the Copyright Act that prevents contracts from overriding copyright exceptions for non-infringing purposes. This provision should apply to all future and pre-existing contracts. Moreover, this exception would equally apply not only to Canadian law-governed contracts, but also contracts governed by foreign law to avoid situations where the choice of a foreign contract is made to evade the contract override exception. For example, see Singapore Copyright Act 2021, s 188 (https://sso.agc.gov.sg/Acts-Supp/22-2021/Published/).Allow circumvention of Technological Protection Measures (TPMs) for any non-infringing purpose. This would make the users’ rights in the Copyright Act technologically neutral and contribute to restoring the balance between copyright owners’ rights and users’ rights.Follow the recommendation of the Standing Committee on Industry, Science and Technology in the 2019 Copyright Act Review and make fair dealing illustrative by adopting an illustrative, rather than exhaustive, list of purposes by including the words “such as” before the list of purposes in s 29. An illustrative list would provide the flexibility to carry out AI related research in a legally secure manner.","At SFU, the ongoing research and development of generative AI systems is not impacted by uncertainties around the copyright ownership in outputs of AI systems. This is either because the outputs are not copyrightable – such as medical image enhancement or large scale data analysis – or because in many cases the developers are also the ones generating the output as in the case of musical generative AI research projects. The development work is going on irrespective of concerns about copyright ownership of outputs. However, this is for now. According to a Bloomberg report 2023 Generative AI Growth, generative AI is poised to become a $1.3 trillion dollar (USD) market by 2032. Technology with such a large financial impact requires certainty around its various copyright elements. It is clear that the development of an AI algorithm and model is a work of skill and judgement and is therefore protected by copyright as it incorporates an incentive to create – one of the main functions of granting copyright protection. However, as research projects move out of the lab and into the public market the question of who owns the output from generative AI systems must be addressed.Copyright in Canada protects the expression of human creativity that involves the exercise of skill and judgement. Generative AI makes us consider the characteristics of originality, creativity, data and computation. The outputs of generative AI systems are the result of statistical and routine processes and therefore may not reach the originality bar set out in CCH (see: CCH Canadian Ltd. v. Law Society of Upper Canada). While outputs are created based on human prompts – either textual or visual – it is the complexity of these prompts that will determine if there is any copyright protection to the outputs. In situations where the complexity of the human prompts is considered an exercise of skill and judgement, then the human user of the AI system would own some copyright in the output. However, substantial amounts of the output would still be purely the product of the AI system and should not be protected by copyright.Copyright legislation also strives to “maintain a balance between the rights of authors and the larger public interest, particularly education, research and access to information” (WIPO Copyright Treaty, 1996). AI processes create works in a faster and more systematic way than human authors. The mass output that AI makes possible can cause an economic reordering – disadvantaging human authors and privileging machine outputs over human creations (Abbott, 2022; see: https://doi.org/10.4337/9781800881907). If protected by the full range of copyright protections, this kind of volume-based output will crowd out human authors and enclose the space of the public domain. SFU agrees with the stance taken by the US Copyright Office regarding copyright protection for AI generated works and when and how copyright protection may adhere to works partially generated by generative AI. “If a work’s traditional elements of authorship were produced by a machine, the work lacks human authorship” and is therefore not protected by copyright (see: US Copyright Office, Copyright Registration Guidance for Works Containing AI-Generated Materials. Federal Register, 88 Fed. Reg. 16,190). However, “a human may select or arrange AI-generated material in a sufficiently creative way that ‘the resulting work as a whole constitutes an original work of authorship.’ Or an artist may modify material originally generated by AI technology to such a degree that the modifications meet the standard for copyright protection” (US Copyright Office). That is, if a work is solely the output of a generative AI system, SFU supports the position that the work should remain in the public domain. Providing full copyright protection for generative AI outputs with no human creativity involved in their creation threatens copyright’s balance and the value Canada places on human expression as Carys Craig and others have warned (Craig, 2014. See https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3733958). However, if a human selects and arranges AI-generated material in a sufficiently creative way, then those specific creative elements are deserving of copyright protection.RECOMMENDATIONSAI authored works that are produced solely by an AI system should not be protected by copyright. But, where human creativity is involved in the creation or adaptation of an AI generated work, then copyright should adhere to those elements that are the product of human skill and judgement.The Canadian Intellectual Property Office should not accept copyright registrations for works solely created by AI systems. Accepting such works for registration results in confusion in the research community, and in the general public, as it goes against the generally accepted requirements for copyright protection in Canada.","In Canada it is the courts who determine if copyright infringement has occurred, and this function is best left for the courts when it comes to generative AI outputs. The courts, on a case by case basis, are well placed to determine if generative AI outputs are reproductions of a substantial part of a work or adaptations of a work, and to determine who would be considered liable (the company providing the service, the programmer or the user). However, there is a problem with identifying the content of datasets. This leads to difficulties in applying the existing tests for copyright infringement since without transparency around the dataset’s content how can a court know if the work is protected by copyright, or even if the work was copied, or if there is a causal connection between a generated output and an original work within the training dataset? Currently it is difficult for a claimant to prove that they are the copyright owner of a work, particularly when attempting to prove infringement in an AI generated work. For example, in the ongoing US litigation Andersen v Stability AI the parties have been told to sort out during discovery which images were part of the training set as it was not immediately obvious if the claimant’s works were in the training dataset (see: https://www.findlaw.com/legalblogs/federal-courts/judge-trims-copyright-lawsuit-against-ai-model-stable-diffusion/). A lack of transparency when it comes to training data is an obstacle for the discovery of whether or not a non-consumptive copy of a specific copyright protected work was used in the AI-training process and subsequently substantially reproduced in an output.This transparency problem demonstrates the need for developers of AI systems to ensure that their training datasets contain sufficient metadata to identify every work in the content set to promote transparency and to guarantee that rights holders can properly exercise their rights. Along with the need for rich metadata is the need for transparency in how the AI model is trained, and in the intentions and designs behind the algorithm. When AI is operating, only the humans involved in the design of the algorithms for that specific application can be responsible for the AI model. Bias and dominant modes of thought can easily find their way into selection for training datasets used to train AI systems. Therefore, underlying all AI systems must be ethical considerations that promote transparency and trustworthiness (Mehan, 2022) amongst regulators and the general public so that they understand how and why an AI model renders a certain output.  As a public institution committed to the public good, SFU strongly supports ethically centred AI that is developed with the intention of ensuring marginalized communities are not disrespected and again shunted to the side when it comes to the development of AI systems.Some private generative AI companies that used creative copyright-protected works to train their machines, such as Stability AI, Microsoft and Google, have already taken steps to create tools that allow for creators to opt-out of the inclusion of their work in the companies’ models going forward. (See the following for further information: Stability AI - https://arstechnica.com/information-technology/2022/12/stability-ai-plans-to-let-artists-opt-out-of-stable-diffusion-3-image-training/; Microsoft - https://blogs.bing.com/webmaster/september-2023/Announcing-new-options-for-webmasters-to-control-usage-of-their-content-in-Bing-Chat; Google - https://blog.google/technology/ai/an-update-on-web-publisher-controls/).It is also possible for creators themselves to implement technological protection measures to prevent their works from being scraped and included in AI training datasets. For example, the Overlai AI photo protection app due for release in December 2023 uses distributed ledger technology (DLT), decentralized storage and advanced watermarks to enable creators to protect their photographs from being added to AI training datasets (https://www.overlai.app).The ability to opt out of contributing to training data however should remain a private ordering matter and not be legislated. Legislating TDM in a way that allows opt-outs could have a number of significant unintended consequences. While attempting to protect creative industries, legislating opt-outs could lead to serious long-term effects on the future reliability of AI machines in high-risk applications such as biometrics, health care or autonomous vehicles where the broadest and most inclusive training datasets are required. For example, see Philipp Hacker’s “A legal framework for AI training data—from first principles to the Artificial Intelligence Act” (2021) for an explanation of the discrimination risks in biased (non-inclusive) training datasets (see: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3556598).AI authored works that infringe copyright should be removed from distribution and any circulation of the outputs ceased. When addressing where copyright liability lies when a generative AI output is found to be infringing, SFU believes this is best left to the courts on a case by case basis. This is because the liability may well lie with the AI developer, the AI company, the user or along a continuum of all three. For example, an AI developer or AI company may be guilty of infringement if a defect was present upon the AI’s release that allowed for substantial reproduction of existing works in generated outputs. Thus determining liability is best left with the courts.RECOMMENDATIONSRetain existing distinctions between commercial and non-commercial statutory damages in section 38.1(1) of the Copyright Act. As noted above, liability is context dependent. Society and the judicial system must always consider the underlying purpose that led to the infringement; infringement that happens as part of a research project at a university is vastly different than infringement that happens as part of a profit-oriented motive.","As noted earlier, AI possesses the capacity to revolutionize many occupations and alter the work of creators. Similar disruptive innovations, or technologies, such as printing presses, industrial automation, automobiles and the internet, are seen throughout human history. Addressing the resultant innovative disruption by supporting training for new opportunities in jobs related to AI development or by supporting worker retraining through organizations like community colleges, universities and public libraries, should be approached at an economic and society wide level (see: https://www.librarycopyrightalliance.org/wp-content/uploads/2023/06/AI-principles.pdf). Since these disruptions need to be addressed at a societal level, the Copyright Act is not the tool to use to attempt to remediate the effects of these disruptions – for example by implementing a mandatory licensing scheme for AI training datasets. Nor should AI innovation be constrained in Canada by implementing constraining copyright laws with fewer exceptions than other competing jurisdictions, such as the US and Japan, who have more AI innovation friendly copyright exceptions."
UNB Libraries and the UNB Legal Innovation Laboratory (UNB Law),University,"The University of New Brunswick Libraries (UNB Libraries) respond to the learning and research needs of the UNB community through developing collections and providing access services, including online databases for discovery and document delivery. We currently maintain access to collections of over 2.5 million items in multiple formats and are committed to providing the broadest possible access to the resources that this community needs. UNB is a comprehensive university, and the premier research institute in New Brunswick – responsible for 75% of publicly funded research. As a public institution, UNB Libraries’ mandate includes serving as a resource to the wider community in New Brunswick, the Atlantic Canadian region and beyond, through such services as an institutional repository for published works, the digitisation of historic New Brunswick newspapers and other documents, and the collection of New Brunswickana.  Recognizing the importance of access to knowledge for all people across Canada, UNB Libraries are positioned as a pivotal resource for the intellectual, scholarly, and creative communities of our province. We also invest specifically in the collection and preservation of New Brunswick’s creative and scholarly output which we preserve for the benefit of all Canadians. We take pride in being a leader in the support of Canadian publishing specifically from the New Brunswick and the Atlantic region. Our Centre for Digital Scholarship hosts 22 journals, all of which contribute to the international publishing market. Furthermore, University Archives and Special Collections, a unit of UNB Libraries, purchases the works and papers of provincial and regional authors with a commitment to acquiring and preserving copies of New Brunswick’s literary heritage, which include works produced in English, French, and in Indigenous languages of our region.UNB Libraries have longstanding licensing relationships with aggregators and vendors of vast databases of copyrighted materials. We regularly negotiate licensing agreements on behalf of researchers and learners to provide legitimate access for teaching, innovation, and discovery. While these digital collections have expanded the quantity of our holdings, the move to electronic access has evolved in ways that undermined many fundamental user rights encoded in the Copyright Act. Although UNB Libraries do not advocate for legislation that would eliminate incentives for a viable market for electronic books and other digital information resources, we are concerned about an ever-increasing number of constraints in licensing agreements proposed by aggregators and vendors. These constrains expand to cover non-consumptive use of works by our researchers, thus creating challenges and uncertainty about our ability to encode in training datasets copyright-protected content that we lawfully own or have access to.Over the past two years UNB Libraries have investigated and subsequently approached multiple vendors exploring the licensing options that market datasets for text and data mining (TDM) and other computational uses. The trend around such products is typified by inconsistency and is alarming considering the lack of clarity around copyright. We acknowledge that computational methods of research and discovery are in their infancy for many areas of study. Meanwhile, our experience points to fundamental contradictions, such as the requirement that all TDM analysis be conducted on a publisher's platform for an extra fee, in relying on market models and licensing regimes for access to textual data across multiple platforms, especially platforms that are not interoperable. Moreover, a lack of interoperability result in barriers to access diverse datasets, and ultimately producing non-representative training data for Generative AI systems. Libraries must keep up with technological advances to manage collections, across various formats, that are outstretching human resource capacities. UNB Libraries have been utilizing AI to enable access to the more than 2.5 million items catalogued in our collection. UNB Libraries’ computational experts are exploring the potential of Generative AI tools in the management and usage of these collections, specifically in the development of applications that will support user inquiries particular to our collections. Access to quality pre-trained large language model (LLM) tools is essential to the effectiveness of ‘fine-tuning’ the task-specific layers for our application. Library collections are curated sources of invaluable insights and can be the foundation for further development of Generative AI. It is equally important for UNB Libraries to enable legitimate access to resources unique to the Atlantic Canada region and provide opportunities to inform and enrich analytical research methodologies with their data. UNB is home to leading experts in Data Science and AI, who conduct research across our campuses, including at the Research Institute in Data Science and Artificial Intelligence, the Canadian Institute for Cybersecurity, the New Brunswick Institute for Research, Data and Training, the Institute for Biomedical Engineering and the SPECTRAL laboratory for spatial computing. Human researchers, which include faculty members, graduate and undergraduate students, and other members of the UNB community, are involved in the development of AI systems. Members of our university community are leading research projects in all the above institutes which involve multidisciplinary teams working in areas such as natural language processing, computational linguistics health, cybersecurity, mapping and positioning, manufacturing, finance, and transportation. Some of these experts lead partnerships with industry and other private actors in the region and beyond. In their respective projects, these teams use training datasets to develop AI systems. For instance, experts in the Faculty of Computer Science and CIC are working to build language technologies to improve the identification of spam and phishing emails across multiple languages. UNB Libraries are committed to support our community and their partners in curating datasets for the development of AI systems that adhere to stewardship principles, developing findable, accessible, interoperable, and reusable data and metadata in both official languages of the province and in Indigenous languages. Specifically for Generative AI applications, the quantity and quality of data are equally important, rendering stewardship and other policies designed specifically to ensure data quality very important. (See Wong, Janis. ""Data Practices and Data Stewardship."" Interactions 30.3 (2023): 60-63, https://doi.org/10.1145/3589133; Kahana, Eran. AI Data Stewardship Framework (March 9, 2023), https://law.stanford.edu/2023/03/09/a-data-stewardship-framework-for-generative-ai/) Furthermore, we are committed to support the UNB community of researchers, instructors, and students in their uses of Generative AI for both research and learning purposes. We support our users in navigating the complexities of copyright and licensed access to resources. This includes providing guidance and support in accessing copyrighted works through the UNB Libraries catalogues and services, as well as providing guidance and support in the making and curating datasets for research purposes. To mitigate liability risks regarding AI-generated content, UNB Libraries organize workshops and provide information online. Our staff members are also trained to support with questions around data protection and ethical uses of data. Furthermore, UNB’s Research Ethics Boards (REBs) ensure compliance with Tri-Council and UNB policies for all research projects at UNB that involve collecting data from humans.Overall, as stewards of information and a resource for the responsible use of protected works through our institution, UNB library professionals require more clarity to confidently provide guidance in evolving methods of research and inquiry. Without this clarity and absent clear exceptions and limitations that have traditionally allowed libraries to perform their public service role, our work will be jeopardized.","UNB Libraries have long advocated for clarity on Canada’s copyright framework, especially concerning text and data mining (TDM) activities. Recent developments in Generative AI technology further highlight the need for clarity. TDM, as a form of analysis involving the automated identification of patterns within extensive datasets, is an example of a non-consumptive use of material. It extracts patterns from expressed facts and ideas. Generative AI exemplifies an application of TDM; it enables users to generate non-human content. The social and scientific impact of tools like Generative AI depends, among other factors, on fair access to the collective knowledge within published works including via TDM. UNB libraries recognize that obstacles to TDM analysis jeopardize hard-earned user rights. Libraries need more clarity as to whether and under which circumstances copying of works for TDM uses can constitute infringement and as to how statutory damages for infringing activities are calculated. The lack of clarity around TDM is illustrative of larger issues that fundamentally question access and use of information in digital format. We are concerned about the negative impact on university research if TDM licensing packages become additional costs required to support access to information.  These packages are derived from materials that our researchers and learners already have legitimate access to, and in certain cases we require further legislative support to use these resources without additional cost. University libraries cannot be expected to pay additional costs for access to datasets of information for which legitimate access already exists. UNB Libraries are confident that the Copyright Act maintains the balance necessary to ensure the economic interests of the copyright owner are protected. What is needed is to ensure user rights by way of an explicit exception for TDM and limiting contractual override of user rights.With decades of experience managing diverse formats and licensing models from numerous vendors, UNB Libraries allocate over $5 million annually, constituting half of their operating budget, to ensure access to essential research and learning materials for a campus population of fewer than 9,000 full time equivalent students. Maintaining this access is a continuing challenge, buffeted by market influences, including threats posed by the consolidation of the publishing industry and volatile rates of exchange for the Canadian dollar.In some cases, UNB Libraries partner with other libraries and negotiate consortia packaging arrangements. These practices tend to increase our negotiating power to reflect the bargaining leverage of bigger institutions. Such consortia arrangements have helped us reclaim user rights to a certain extent. An example is the academic library industry standard Canadian Research Knowledge Network Model License in which Section 3.9 identifies a users' rights for TDM research across publishers' works. Consortia packaging arrangements are not always possible, nor a reliable or sustainable way to support the needs of our community. We regularly find ourselves independently negotiating many licenses that often come with burdensome and confusing terms of use along with non-disclosure clauses. Smaller and regional institutions like us lack the negotiating influence to mitigate market forces placing our researchers and learners at a disadvantage. For example, recently we invested more than $50,000 piloting specific TDM licensing packages with two publisher vendors. Our experience thus far demonstrates that such licensing packages do not satisfy our colleagues research needs. It is – again – unsustainable to cover current and future TDM needs maintaining similar licenses on a case-by-case, or especially on an on-going basis.We posit that as it currently stands language from the Copyright Act can enable licensing terms that override user rights and clear jurisprudence. From our perspective, enabling or creating additional access barriers to works in a digital format is contrary to Canada’s commitment to technological neutrality and to modernizing the balance of rights for creators and users. Many jurisdictions have implemented and recognized TDM provisions and exceptions into their legal frameworks, as for instance, the European Union with article 3 of the EU Directive 2019/790 on Copyright in the Digital Single Market. The United States has established a strong foundation for non-consumptive use of copyrighted materials within its fair use framework. Moreover, scholars have convincingly argued that copyright reform clearly allowing TDM practices will benefit research. See Fiil-Flynn, S. M., Butler, B., Carroll, M., Cohen-Sasson, O., Craig, C., Guibault, L., ... & Contreras, J. L. (2022). Legal reform to enhance global text and data mining research. Science, 378(6623), 951-953, available at https://www.science.org/doi/10.1126/science.add6124While expanding Canada’s fair dealing framework is essential for a flexible and balanced approach to developing tools of textual analysis, UNB Libraries would benefit from a more direct approach such as the explicit exceptions implemented in Japan and Singapore and recommended by the Australian law reform. SeeJapan Copyright Act https://www.japaneselawtranslation.go.jp/en/laws/view/1980/enSingapore Copyright Act 2021 S244(2)(d). https://sso.agc.gov.sg/Acts-Supp/22-2021/Published/Australian Government Law Reform Commission (2013) https://www.alrc.gov.au/publication/copyright-and-the-digital-economy-dp-79/8-non-consumptive-use/non-consumptive-uses-and-fair-use/  It is important to acknowledge that the library community’s support for applications of this technology is not concerned with or attempting to encroach on the original expression of the work, but to extract and understand the patterns, information, correlations, essentially the facts and ideas behind these works. The non-expressive nature of these uses of works is an important concept to build into any technologically durable copyright policy. Acknowledging the separation of the economic interests vested in the original expression, on the one hand, and the user rights to the information behind the work, on the other, further supports a TDM exception for both commercial and non-commercial applications. While the application of TDM in certain areas, like Generative AI, has not been tested in court, TDM itself does not impede the original publication's incentives or rewards. Simultaneously, advancements in computing capacity have allowed for the storage and collection of copies of published material, leading to the development of various commercial opportunities, including platforms like Google Books, Hathi Trust, CCC, Elsevier, etc. Finally, enabling TDM from legitimately accessed published works safeguards against unfair monopolies and unnecessary enclosure of information. As a university library we advocate for the widest possible access to data and knowledge for our community of researchers, instructors, and students, to enable them to study and build unbiased and ethical AI applications. The changes we advocate for in Canada's legislation, outlined below aim to modernize the copyright framework and re-establish checks and balances. This would align with legislative approaches of our most influential trading and research partners globally and satisfy current research demands. Future proofing copyright legislation that will enable libraries to maintain their public service role in the age of AI is key.  Recommendations for changes to the Copyright Act:    1. Make fair dealing purposes illustrative. UNB Library supports the adoption of an illustrative rather than an exhaustive list of purposes, through the addition of the words ‘such as’ in the fair dealing framework. 2. Create a specific exception for Text and Data Mining. To meet the needs of UNB’s research and innovation goals this exception should be for both commercial and non-commercial applications. 3. Strengthen Canada’s commitment to Technological Neutrality by implementing measures to safeguard libraries and their users from licenses and terms of use that supersede essential copyright exceptions. Many of these exceptions are enforced through technological protection measures (TPMs).","UNB Libraries submit that any uncertainty around this matter should not impact the development and adoption of responsible AI technologies. This is appropriate given the current state of the technology and the national and international debates around authorship or ownership of AI-assisted and AI-generated works. Generative AI, in particular, is already widely used in various stages of the creative production. While AI-assisted and AI-generated works are proliferating, AI systems and models and the ways in which creators experiment with them are still evolving.  Therefore, we believe that there is no imminent need for the Government to propose any clarification or modification of the copyright ownership and authorship regimes in light of AI-assisted or AI-generated works. Most jurisdictions have taken this approach, requiring human authorship for copyright protection. The Copyright Act supports and rewards human authorship and creativity. It is unclear whether there are any benefits in treating AI-assisted or generated output as potentially copyrightable content. In fact, at this stage UNB Libraries support that AI-generated works should not be protected by copyright to avoid further erosion of the public domain. Our position aligns with IP Scholars' 2021 Joint Submission to the Canadian Government Consultation “A Modern Copyright Framework for Artificial Intelligence” See Carys Craig et al, Submission on Artificial Intelligence from IP Scholars to the Minister of Innovation, Science, & Industry & the Minister of Canadian Heritage (26 September 2021) for the Consultation on a Modern Copyright Framework for Artificial Intelligence and the Internet of Things, [unpublished, archived at Schulich Law Scholars, Dalhousie University], available at https://digitalcommons.schulichlaw.dal.ca/reports/70/","In the case of AI-assisted or AI-generated content, it is unclear to us whether existing legal tests for demonstrating copyright infringement apply at the input or output phase. Instead, we understand that Generative AI models use statistical analysis to learn patterns from large amounts of data. Looking at input, is accessing and analyzing data an act of copyright infringement? We understand that it is not. At this phase it is unclear to us whether potential liability could be tied to any specific act of reproduction, and specifically to temporary copies. It is also unclear to us whether liability could be established in the absence of output substantially similar to an existing work. Furthermore, in the case of substantially similar output, it is unclear whether that is a result of the system memorizing and reproducing training data, or of the end-user's prompts, or both. It is also unclear how opt-in/opt out regimes or voluntary collective licensing schemes might affect liability questions. An additional point of concern relates to the exercise of moral rights of rightsholders and how to determine or enforce infringement of moral rights in the context of AI-generated content. We understand that questions around copyright infringement and liability questions are unclear in more jurisdictions and follow global developments, which include legislative efforts and litigation. See Andres Guadamuz, A Scanner Darkly: Copyright Liability and Exceptions in Artificial Intelligence Inputs and Outputs, GRUR International, 2024;, ikad140, https://doi.org/10.1093/grurint/ikad140  Explicit copyright exceptions, including for TDM, would remedy the current lack of clarity around liability. Canada’s unique orphan works framework (Copyright Act s77) might also be a solution to some of the uncertainty surrounding copyright liability issues with AI generated outputs, especially in cases of commercial output. Training data for transformer-based Generative AI almost certainly contains both copyrighted material and orphan works. A user who wants to publish or fix a form of generative output could follow the orphan works framework by making reasonable efforts to find a rights holder, then applying for an orphan works license through the copyright board. If this was successful, the user would pay a royalty to a collective society and be granted a non-exclusive license to use the output. Assuming the process was efficient and simple to meet market and general demands, this could reduce uncertainty and provide some recompense to a potential copyright holder if the work turned out to be substantially similar to an existing work and the copyright holder came forward. In this case, however, particularly for non-commercial uses, the administrative costs and inefficiencies are worrisome. This discussion focused on infringing output, not on computational analysis of data (input) which, we posit, should always be covered by a clear TDM exception. Finally, besides robust exceptions or regulatory schemes such as the orphans works framework, technical solutions such as watermarking data sources might also prove helpful in detecting and deterring copyright infringement, so long as copyright liability is clearer and exceptions, including fair dealing, are sustained.Currently we have little knowledge of the training datasets that feed Generative AI models. Lack of transparency around the training datasets is another barrier to determining copyright infringement, without knowledge of the input data we cannot determine whether specific copyright-protected content has in fact been used. Trade secret protections and other intellectual property protections, such as copyright or patent protection of algorithms, could act as additional barriers. Thus, being able to audit both the training dataset and the algorithm, especially in cases of infringing output, might prove important. Last but not least, recent revelations regarding illegal and unethical content included in popular training datasets confirm the urgent need for more transparency around training data. (Catherine Thorbecke, Hundreds of images of child sexual abuse found in dataset used to train AI image-generating tools, CNN, December 21, 2023, at https://edition.cnn.com/2023/12/21/tech/child-sexual-abuse-material-ai-training-data/index.html citing studies such: Thiel, D. (2023). Identifying and Eliminating CSAM in Generative ML Training Data and Models. Stanford Digital Repository. Available at https://purl.stanford.edu/kh752sm9123).UNB Libraries believe that libraries are best positioned to engage and assist their users in testing computational uses of data extracted by non-infringing copies of lawfully acquired or licensed content. This includes the use of Generative AI tools and the development of Generative AI applications. This is because the quality of the output of such tools and applications is dependent upon the quality of their data input.  Furthermore, dataset creation and curation involve careful decision-making about the data that should be included in a training dataset. These decisions can shape a model’s outputs. See Lee, Katherine and Cooper, A. Feder and Grimmelmann, James, Talkin’ ‘Bout AI Generation: Copyright and the Generative-AI Supply Chain (July 27, 2023). Forthcoming, Journal of the Copyright Society 2024, Available at SSRN: https://ssrn.com/abstract=4523551 or http://dx.doi.org/10.2139/ssrn.4523551. The data scientists employed by UNB Libraries have the expertise and training to create and curate training datasets and develop standards for appropriate computational uses of those datasets by their users. We have the expertise to create datasets, but not additional funds to essentially buy our resources again in a new format. We believe that copyright law was not intended to restrict new ways of learning or analysing content that is lawfully accessed by or within a library, nor to chill innovation within research libraries and universities. In view of the above, and to better serve the needs of the UNB community, UNB Libraries would welcome more clarity around attribution and liability, which would be achieved by robust exceptions. In addition, and as discussed in our answer to the previous question, an explicit exception for TDM and the making of the fair dealing purposes illustrative would help UNB Libraries better serve the needs of the UNB community without risking primary or secondary infringement even in the rare case of substantially similar output. We also endorse legislative approaches such as the one taken by the EU’s AI Act whose latest drafts include disclosure data requirements, such as requirements to describe the training data sets used, how the data was obtained and selected for training purposes, labelling procedures, data cleaning methodologies, and the training methodologies and techniques.","Further suggestions- FAIR Principles for data management and data stewardship frameworks to ensure high quality data: UNB Libraries would welcome support to formalize and promote FAIR Principles for data management in the space of Generative AI. Recognizing the transformative potential of AI tools, UNB Libraries points to the key role of government to support standards in data, including metadata, management and stewardship such as the FAIR (Findable-Accessible-Interoperable-Reusable) principles. See FAIR Guiding Principles for scientific data management and stewardship, https://www.go-fair.org/fair-principles/This emphasis on findable, accessible, interoperable, and reusable data is essential to lay a sturdy foundation for future data management and can be critical in current efforts to develop explainable AI models. For our purposes, the successful implementation of these standards is crucial as it directly influences the effectiveness of AI tools in facilitating entry and enabling growth of the library collections. This position resonates with the position of the broader Library, Archive, and Museum community, emphasizing the need for cohesive efforts in ensuring robust metadata practices. Information specialists continuously advocate and adhere to standards that strive to create best practices and guidelines for the responsible management of information. See, for example, the important work of National Information Standards Organization (NISO) https://www.niso.org/Overall, we believe that libraries are best positioned to engage and assist their users in testing computational uses of data extracted by non-infringing copies of lawfully acquired or licensed content. This includes the use of Generative AI tools and the development of Generative AI applications. The data scientists employed by UNB Libraries have the expertise and training to develop standards for appropriate computational uses of those datasets by their users and are in the position to collaborate with university experts towards establishing fair and ethical uses of AI tools and other computational methods."
Universities Canada,University,"Copyright Implications of Generative Artificial IntelligenceIntroductionThis submission constitutes Universities Canada’s perspective on the issues identified in the Government of Canada’s discussion paper entitled Consultation on Copyright in the Age of Generative Artificial Intelligence. On behalf of our member institutions, Universities Canada thanks the Government of Canada for its engagement on these important topics.About Universities CanadaUniversities Canada is the voice of Canada’s universities at home and abroad. As a membership organization, we represent 97 public and private not-for-profit Canadian universities.Our members are home to copyright owners, creators, buyers, sellers and users. University teachers and researchers are the creators of most content used in the classroom. Maintaining a balanced approach to copyright is critical to nurturing a higher education ecosystem that delivers the highest quality education for students, making use of the most innovative and up-to-date materials and approaches, while also ensuring that copyright owners and creators are remunerated for their work.","RecommendationsUniversities Canada has consulted with our members and offer the following recommendations for the Government of Canada as it considers changes to the Copyright Act in light of generative artificial intelligence.1. Do not amend the Copyright Act without substantial further consultation with stakeholders, including the post-secondary sector.Canada’s universities urge the government to move slowly and deliberately with any changes to the Copyright Act. The current consultations are a productive first step at gathering evidence of the ways that the digital transformation of teaching and learning are impacting long-standing copyright principles. However, noting that the Copyright Act has an upcoming deadline for a legislated review, the government should not proceed with amendments until a more substantive review of the Act has occurred.2. Do not make changes to the Copyright Act that would adversely impact the ability of students and teachers to access the best course materials.Canada’s universities have championed a balanced approach to copyright that includes the essential role of fair dealing. Fair dealing is essential because it recognizes that users have rights to access content for purposes in the public interest, including education and research. It is important to emphasize that fair dealing is increasingly rare due to the changing nature of digital access to course materials and the associated licensing practices that university libraries employ. However, it remains a fundamental principle. Encroaching on the fair dealing rights of students and teachers would be harmful and would upend decades of jurisprudence on the spirit of copyright law.3. Do not make changes to the Copyright Act that would harm Canada’s competitiveness in AI research and development.Canada’s universities also urge the government to prioritize Canada’s international competitiveness when considering any changes to the Copyright Act targeting generative artificial intelligence.  Universities Canada has heard concerns among AI researchers, librarians, and instructors that Canada’s current fair dealing and anti-circumvention exceptions may be insufficient to enable the development and deployment of generative AI for either commercial or non-commercial purposes. While some argue that text and data mining activities are covered by the fair dealing exception for research, others suggest that this is not self-evident to researchers who are not copyright experts. We note that Canadian courts have not yet had the opportunity to adjudicate this, and may well do so, following jurisprudential developments in the United States and elsewhere. There is also significant concern that license owners may utilize contract terms to override user rights that the Supreme Court of Canada has said are “essential parts” of the Copyright Act. We encourage the government to clarify that contracts cannot override user rights like fair dealing.In other jurisdictions, like in Canada, members of the AI research community have advocated measures to limit legal uncertainty and avoid the risk of stifling AI research, particularly early-stage exploratory research where various datasets may be tested. In light of this, some jurisdictions, including the United Kingdom and Japan, have enumerated specific fair dealing and anti-circumvention exceptions for text and data mining to ensure the technology can flourish.Though there is a strong foundation that underlies AI research in Canada, we risk falling behind as other countries work to reduce barriers to entry for innovation and attract talent. We therefore urge the government to find positive ways to support institutions in these efforts, and to avoid changes to the Copyright Act that would add to existing legal uncertainty or create a chilling effect on AI research.","Canada’s universities and generative AIDespite current challenges facing the research ecosystem, Canada has been a leader in AI research for decades. Years of sustained investment in fundamental science in Canada enabled the creation of artificial intelligence technologies that has led to the proliferation we are witnessing today. The Government of Canada should be proud of its accomplishments in funding AI research at a time when other funders scaled back investments in the face of significant obstacles, and it should continue to fund fundamental research as a core pillar of federal economic policy.As the institutions on the front lines of the development of generative AI, Canada’s universities are leading in the deployment of these technologies as a tool for research, instruction, and scholarly communications. Universities are taking a range of approaches, developing best practices, creating forums for faculty to share experiences and insights, and empowering instructors to responsibly utilize generative AI in the classroom.Some universities are deploying library services to assist faculty and students. Some, such as OCAD U through its Cultural Policy Hub, are creating networks across the country to lead on issues of bias, inclusion, decolonization, and other important considerations that can be significantly impacted by artificial intelligence. Still others have created new positions to explore the implications of AI, such as the first Chief AI Officer in Canada at the University of Western Ontario. All of these are examples of universities responding to the unique needs of their communities while working collaboratively to address shared challenges.Use of AI as a tool for research and educationAs autonomous institutions, universities are best positioned to lead according to their unique community needs. Those universities that choose to deploy AI as a tool for instruction are following the best practices that are currently established, but are rapidly changing. These range from establishing guidelines for the use of AI tools; proscribing some tools and encouraging others based on evaluations of the processes involved in their development, their dependability and usability, and other factors; and creating iterative feedback processes for faculty and staff to report and gain advice on the use of tools. Most of the tools in use today utilize large language models, like those that power OpenAI’s ChatGPT.Universities must stay abreast of the latest developments in AI technologies to ensure their responsible use. Members of university communities have various concerns about the full adoption of AI in the classroom. Some fear that issues around racial and gender bias in large language models have not been adequately addressed, while others have expressed concern about academic integrity. However, there is wide consensus that universities must embrace AI within certain parameters, and that it would be premature for the federal government to pre-empt these decisions. As the technology develops, it is important that the government not take steps that unduly restrict innovation in education.Generative AI as a research and economic enterpriseCanada competes for research talent on the global stage, and there is significant concern among universities that efforts to restrict the development of large language models relying on fair dealing rights for research, or to impose new technological protection measures that prevent text and data mining processes, would hamper Canada’s competitiveness for top research talent in an area of science that is transforming global society. Canada cannot afford to lose out on this knowledge or on access to this talent.These concerns are part of why the United States, the European Union, the United Kingdom, and Japan have all embraced varying degrees of fair dealing and anti-circumvention exceptions for text and data mining activities. Canada’s universities recommend that the government carefully study the approaches in these jurisdictions to better understand how such changes could impact Canada’s competitiveness.","Authorship, ownership, and infringementA long-standing principle underlying copyright is that authorship requires creative human origin. Extending the idea of authorship to works generated entirely by artificial intelligence would be a departure from that principle. At the same time, the principle of technological neutrality is also fundamental, and treating works that are generated with AI assistance but with ultimate human origin differently than works generated using other technological tools may also be problematic under that principle. In any case, we believe it is too early in the development of this technology for the government to make definitive judgements about authorship and ownership.In cases of genuine copyright infringement, the Copyright Act is sufficient as it stands to ensure that creators are properly compensated and liability for infringement is properly assigned. However, it is important to remember that the likelihood of genuine infringement occurring as a result of text and data mining is low, and efforts to restrict TDM to avoid infringement would have negative unintended consequence for Canada’s competitiveness.",ConclusionCanada’s universities thank the government for their attention to this important issue. We also urge the government to avoid taking steps that would harm Canada’s international competitiveness and unfairly restrict the research enterprise in Canada. We ask that the government commit to a deeper level of engagement with affected parties before pursuing any amendments to the Copyright Act. We also ask that the government ensure any measures it does adopt do not adversely impact the user rights of students and teachers by preserving the Copyright Act’s fair dealing exceptions.
University of Toronto Libraries (UTL),University,N/A,"The University of Toronto Libraries (UTL) thanks ISED for the opportunity to share our experiences and comments for this consultation on copyright and generative AI. The University of Toronto (U of T) is consistently ranked among the top 10 public universities worldwide.  U of T is one of the world’s most highly regarded centres for advanced research at the master’s and doctoral level and is home to some of the world’s most talented thinkers, inventors, innovators, and educators, who are advancing knowledge and making critical discoveries for a healthier, more sustainable, prosperous, and secure future. UTL is at the heart of this research enterprise; we build and sustain Canada’s most comprehensive research collection, which serves as the raw material for research, a safe and trusted repository for scholarly outputs, and contributes to the preservation of Canada’s cultural and historical record. UTL spends over $28 Million CAD on licensed electronic materials and provides text and data mining (TDM) services, which includes consultation, instruction, the provision of data, and technical support.UTL is in the early days of understanding how AI systems will be used for teaching and research. However, instructors and researchers have experienced long-standing uncertainty regarding the extent to which exceptions in the Copyright Act can be applied to TDM activities. Because TDM is a critical building block for machine and deep learning, how the Copyright Act addresses TDM impacts AI-related research as well. Uncertainty about how the Copyright Act applies to TDM creates confusion, chills research activities, and potentially risks discouraging use and exploration and therefore potentially limit researchers’ ability to better understand AI through machine and deep learning. This uncertainty means that rightsholders hold the power to determine how researchers can access and use content. Unless clear terms allow for TDM, researchers may require permission from the rightsholder. Obtaining permissions to conduct TDM from a rightsholder can be an incredibly lengthy process, if it can be obtained at all, leaving research at a standstill and the status of projects uncertain. Permission to conduct TDM with library-licensed content alone is insufficient to practically enable many research projects. Many terms of use introduce technical limitations that stymie access to usable content such as setting very low thresholds for the number of downloads per minute or prohibiting systematic or automated downloading. In some cases, a publisher or rightsholder will provide API access to the content to facilitate downloading, but some charge extra costs for API access, even if it has already been licensed. Additionally, license terms may also limit access timeframes or require destruction of content at the end of an agreement period as well as determining if and how researchers can report their findings by limiting how much data can be published and whether it must be published in a derivative form. These technical and retention limitations can complicate or impede research projects and dissemination. Even if TDM is permitted, it could nonetheless be impossible to use the content in an AI system, since there is a growing number of publishers including license terms that restrict the use of content in AI systems, limiting the types of research that can be conducted with paid-for content.There is evidence of growing frustration and confusion among researchers working in international research groups about copyright provisions around TDM and possible jurisdictional collisions. In “Legal Literacies for Text and Data Mining – Cross-Border (“LLTDM-X""): White Paper” (2023), Rachael Samberg et al describe widespread confusion among researchers in the United States when working in international teams. Their research finds that many practitioners felt copyright concerns blocked their projects, despite fair use provisions, and overlooked the impact of contractual law on their research projects and ability to share content with international collaborators (page 12). Some researchers are confused by different affordances. Recently, a researcher contacted UTL about performing TDM on a licensed eResource, hoping to build on research conducted by European colleagues who performed non-consumptive textual analysis of public web content. Since the website’s terms of use indicated they could not scrape the content, they turned to the library to find a way to legally move ahead with this research. Despite UTL having paid for access to this content, contractual terms restricted TDM, requiring additional written permission from the publisher to perform this activity. This publisher has so far been unresponsive. At this point in time, this researcher is unable to move ahead with their work.Recommendations:This example highlights issues and constraints in Canada’s current copyright framework that the library community has been vocal about for many years. UTL strongly believes that authors should be appropriately compensated for the use of their work, however, these updates are necessary to help maintain the balance between creators and the larger public interest, affording Canadian researchers the same advantages their peers hold. Licensing is not an appropriate solution for TDM; it is simply not practical to seek permission for the sheer quantity of content that is often needed for TDM methodologies. UTL endorses the recommendations outlined in the Canadian Association of Research Libraries (CARL) submission to the Consultation on Copyright in the Age of Generative AI (2023). These include:Revising the fair dealing exception (Section 29) to make purposes illustrative, rather than exhaustive. This will provide the clarity needed for the educational community and industry to move ahead more confidently with their work. This is a model used in the US, where they have a much more solid legal basis for non-consumptive research using the fair use exception. The addition of a new provision that clarifies no exception afforded to a user in the Act can be overridden by a contract. This would ensure that users are able to fully utilize the rights granted to them in the Act, helping to create a more balanced environment. The addition of a provision that permits the circumvention of technological protection measures for non-infringing purposes.","Given the ramifications that copyright protection on autonomously created work with little human intervention would have on creative industries, it is recommended that the IP Scholars’ Joint Submission to the Canadian Government Consultation (September 26, 2021) is further consulted. This submission recommends that copyright protection only subsist in the work of a human.Developing best practices, as the US Copyright Office has done in their recently published Copyright Registration Guidance for Works Containing AI-Generated Materials, is recommended. While still undergoing public consultation, this evolving guidance sets parameters for disclosure of the use of AI-generated content and thresholds for when works will not be offered copyright protection.","As the Copyright Act already addresses infringement and liability, allowing time to consider issues that will eventually emerge and other policies that may be more appropriately suited for AI systems is prudent.",N/A
University of Waterloo,University,"The University of Waterloo ContextWe appreciate this opportunity to share our experiences and views on the current challenges and opportunities presented by copyright and generative artificial intelligence. As a premier comprehensive research institution in Canada, the University of Waterloo is committed to supporting inquiry through research and learning. The University enrolls more than 35,000 students across its six faculties and is home to the world’s largest co-operative education system of its kind.The University of Waterloo has consistently been the top comprehensive research university and has also been recognized as Canada’s most innovative university for over a quarter of a century. The University’s uniquely entrepreneurial culture encourages experimentation and innovation. This culture is supported by the University mission to advance learning and knowledge through teaching, research, and scholarship, nationally and internationally, in an environment of free expression and inquiry.In order to achieve our mission, balanced copyright law is a necessary component for success. The University of Waterloo has demonstrated a balanced approach through its IP policy where in many cases the author is the owner of copyright in works created through research and teaching.We urge you to use this opportunity to reinforce the foundation of the Copyright Act to facilitate the increase of access to information, the advancement of knowledge, and the continued technological growth of Canadian society.Development of AI systemsThe way AI systems are used and designed are heavily context dependent. At the University of Waterloo, researchers approach development of AI systems from a wide variety of lenses using approaches based on their discipline, research question, and the availability of data. Research on AI takes place across our campus, from Computer Science to Economics, from Engineering to English Language and Literature.Comfort with copyright risk and/or ability to purchase permission for use heavily influences the kinds of systems that can be developed and by whom. Researchers might choose a method of sourcing content based on the kind and/or focus of the system being designed, the amount of funding dedicated to the project, and/or the kind of hardware or software they have available to them. Given copyright limitations and variance between national copyright laws, some researchers will even limit use of works based on the countries in which their collaborators reside.When accessing information for training datasets, some researchers rely on web scraping to gather publicly available information. Others rely solely on information that is openly licensed (for example, through Creative Commons) and in the public domain. Others yet are able to rely on information licensed by the institution for text and data mining purposes. Those who rely on open, public domain, or institutionally licensed content have necessarily smaller training data sets which limit the capabilities/outputs of the final system. For example, a system built on only public domain data would not be able to surface information about COVID-19. Those who rely on institutionally licenced data are limited by the licence conditions, which may allow training of a system, but not allow generative output of more than a few hundred words.How this data is used will differ depending on the kind of system that is being offered. For example, a researcher designing a generative system, will use the underlying data to train the system such that it can find patterns and create output, like new images, text or code. A researcher designing a recommender or classifier systems would use the underlying data to train the system such that it could make a recommendation or provide a classification for a user. The generative system faces copyright challenges in the input and output stages, where the recommender/classifier system faces copyright issues mainly with input.Approaches to changing the Copyright Act should be done with an understanding that there are a wide range of users and creators of AI systems with a diverse range of use cases.Use of AI generated contentIn day-to-day operations, the University is exploring how generative-AI can be used to improve service and processes. For example, staff are testing out AI tools capacities for assisting with basic writing and evaluation tasks and for deploying chat bots to provide frontline user support. The University is only beginning to understand how use of generative AI will impact the way instructors teach and students learn. As with many other institutions, the University is taking a varied approach to the use of AI by students, encouraging instructors to be clear with students about their class policy. There are several instructors who are actively engaging with AI services in the classroom, even incorporating it into assessments. Many support staff have spent a great deal of time working to clarify what AI systems can and cannot do, when they can be used in a pedagogically sound way, and how instructors can maintain the integrity of their courses. The University has also provided clarity around copyright related risk for using of AI-generated content in teaching; guiding instructors to make risk-informed use of content when connected to learning outcomes.Concerns about the nature of the tools available and their capacity for infringement have limited uptake in some areas. Changes to the Copyright Act that address AI systems potential for infringement and user liability would increase confidence in use.","TDM Activities and factorsInformal observation suggests that research involving TDM is being conducted across many Canadian universities, including the University of Waterloo. It appears that researchers take several approaches to do so, including relying on the fair dealing exception, through licensing agreements, or web-scraping information from the publicly-accessible Web. How researchers engage with these projects seems to be influenced by what is understood as the common practice in their field; for example, researchers may look to widely used practices for web-scraping used in the US and EU. Note that in each of these cases, researchers must engage in a careful risk analysis regarding their planned use and any potential conflict with contracts from various providers. In many cases, the researcher could make a good case for TDM under the Copyright Act, but many institutional licenses or website terms of use would prohibit them from further engaging in their research. In addition, given the scale of data collection needed, analyzing terms of use for each website to determine whether each site could be used would not be feasible.To provide clarity for AI developers and users and enable Canada to be competitive in AI research and development, we recommend that the fair dealing exception is expanded to be illustrative (i.e. through the use of “such as” language) and extended to include informational analysis. Fair dealing is currently limited to the eight enumerated purposes in the Act. Although the Supreme Court has encouraged a large and liberal interpretation of these purposes, it would provide greater confidence for researchers developing AI systems for illustrative language and the specific purpose of informational analysis to be added. Explicit inclusion of informational analysis would provide clarity and would reduce complications in using fair dealing for TDM research; rather than guessing that TDM might fit under a research purpose, researchers would be confident their work would fit under informational analysis. Illustrative language would have the effect of legislating the Supreme Court’s guidance on large and liberal interpretation of the purposes. The use of the works for this purpose would have all the safeguards of fair dealing, requiring the use to be fair and tested against the six-factor test outlined by the Supreme Court in CCH Canadian Ltd. v. Law Society of Upper Canada, 2004 SCC 13 (CanLII). While commercial uses would not necessarily be precluded, the six-factor test would act as a safeguard against unchecked commercial usage. A precursor to using fair dealing also requires that the content is accessed legally, another safeguard. This expansion of the fair dealing exception would be most effective if accompanied by the addition of a contract override provision and revision to allow circumvention of technological protection measures (TPMs) for non-infringing purposes.Many uses of content are limited by contracts of various kinds – whether that be the terms of use of a website, or of a streaming platform, or an institutional license (e.g., the contracts libraries may sign to gain access to databases). Contract override ensures that users are not prevented from accessing their user rights under the Act by signing away rights via contract. Note that contract override does not mean that users do not have to pay for access, rather it means that once they have access all users have the same rights to reuse. In this way, contract override works to ensure a more democratic ability to use information and respects the technological neutrality goal of the Act. This would mean that the ability to exercise one’s user rights under the Copyright Act would not be connected to negotiating power. Currently, large companies or user groups with more resources would be more likely to be able to negotiate a licence with favourable terms than a single person, who might be saddled with the standard terms and conditions of a website with no option to negotiate. With contract override, this isn’t an issue. We would encourage the Government to explore the contract override provision in Ireland’s Copyright and Related Rights Act, 2000, section 2 (10).The current TPM language in the Act does not allow users make non-infringing uses of a work (aside from limited carve outs, e.g., accessibility uses) when a TPM is in place. This means that users are denied the ability to exercise their user rights for content that is digitally locked down. This violates principles of technological neutrality; for example, a user may be able to copy a short excerpt from a print book under fair dealing, but not the same title in eBook form. In terms of AI usage, if a user wanted to incorporate video content stored on DVDs in a training dataset, they might be limited by digital rights management on the DVD from copying it off of the original medium. Current language would not allow a user to break the digital lock to use the content for fair dealing purposes. We recommend that the TPMs section in the Act is revised to allow users to exercise user rights (e.g., fair dealing) regardless of TPMs.A multifaceted approach would enable development of AI while providing opportunities for creators to be compensated where appropriate.Licenses availableThe University of Waterloo Library licenses information from a wide variety of publishers. The bulk of our licenses are with foreign information providers, which influence the copyright law referenced in our contracts and our ability to use Copyright Act exceptions to use this content. Only 14% of our licences permit any kind of TDM. Of those that do allow TDM, most come with heavy restrictions on reuse of the data that would make incorporation into AI systems impractical, such as restrictions on the number of words that can be included in any published extract. Some of the publishers that do not allow TDM as part of their standard license will offer it as an added service, but often at prices researchers consider prohibitive. Traditionally, TDM allowances in Library licenses have been directed at enabling research looking for patterns within a corpus to answer a specific research question; these patterns may have been found programmatically, but not through the building of an AI system or service. In recent months, publishers have started to introduce new clauses in our contracts that aim to forestall use of content as training material for AI systems, further clarifying their position that the TDM clauses in these licenses were not designed with AI in mind.Obligations for AI systemsThe University understands AI development from the perspective of researchers and learners as developers of AI systems. To try to strike a balance between the requirement for attribution to respect the moral rights of the creators and the complexity of AI systems, the government could use language similar to the non-commercial user-generated content exception (s. 29.21). As provided in section 29.21(b) the user of a work is required to mention the source where it is reasonable to do so. Using similar language when developing provisions for AI systems would encourage attribution while being flexible. That said, there are two sets of issues with AI systems related to copyright and attribution – input and output. Regarding input, a compromise between traditional respect of moral rights (attribution) and feasibility in an AI development environment would be for developers to maintain records of what content was used to train their systems. This is to say that developers should be able to tell users where content was sourced and to understand that it is extremely difficult, if not impossible in many cases for developers to identify the copyright owner and to provide a list of copyright-protected content used to train a system. While a great deal of content is used and it is a time-consuming task to maintain a list of sources, this requirement could help creators understand where their works are being used. Regarding output, at this early stage in the development of AI systems, it seems likely that generated outputs contain only insubstantial amounts of the training material; such tiny amounts of content that the Copyright Act does not require attribution or permission.","We recommend that the status quo be maintained. The current requirements for copyright protection, namely originality, fixation, and the exercise of skill and judgement work well. We understand these requirements to mean that content generated by AI is not protected unless an original work is created with the sufficient addition of human skill and judgement. We support the approach taken by the United States Copyright Office in their document, Copyright registration guidance: Works containing material generated by artificial intelligence, and recommend the work of Dr. Carys Craig, The AI-Copyright challenge: Tech-neutrality, authorship, and the public domain as two slightly different but interconnected ways to approach this issue.","At present, the way that many AI systems are trained relies on encoding content, changing bits of text into numbers that relate to each other (Stephen Wolfram Writings article What is ChatGPT doing and why does it work may be helpful for understanding this). When a user enters a prompt, the system looks to the training data for patterns in those small bits to generate new content. Currently, those small bits of information are not encoded with attribution information and so the resulting system is not able to provide the end-user with information about the source material. This has implications for testing infringement and for considering liability. Regarding infringement, the end-user does not know what sources are used to generate the content, and so is limited in their ability to understand whether permission is needed. They could compare the result to existing content if they’d started with a reference, but lacking that, they may have no clue if something was infringing, especially given the breadth and depth of the training models. Regarding liability, we again face the issue of dual copyright concerns related to input and output. When it comes to outputs, things are more complicated, and depend on the promises made by developers to users. If a developer promises that their content is copyright-cleared, the user would have a reasonable expectation to be able to use the service without issue. Both infringement and liability would be better addressed by reducing risk of infringement through the expansion of the fair dealing exception and addition of a contract override provision.","Copyright is just one tool in the toolbox for providing appropriate controls on use of content in AI systems. A multifaceted, nuanced approach will be necessary to enable AI to be an opportunity rather than a hindrance to society. Changes to law, policy, and regulations should be done with an eye to equitable access and use of this new technology across our society."